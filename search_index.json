[["index.html", "   ", "  Wang Zhen 2024-03-13  Statistics is the grammar of science. - Karl Pearson   Analysis of Messy Data Volume 1: Designed Experiments, 2nd edn  / Elegant Bookdown Template R  SPSS  R  SPSS     1210683652@qq.com            4 - 5   1  3  7 / *    1 ***  2 *** 1    3 ***  4 **  5 ***  6 *   7 *  8 **  9 - 15   9 **  10 *** I-IV   11 **  12 *-  13 * 14 *  15 * 12 -  16 *  17 ** SAS-GLM   18 - 21   18 *** Hartleys  Henderson   19 *** MIVQUE.  20 ***  21 **--  22 *** BLUE, BLUP   23 **  24 ****  25 **-  26 ***  27 *** 26  \\(p\\)   28 **  29 ***  30 ** 5   Estimation, estimate, estimator   Treatment   Population   Subject   Subject   Subject       experimental unit  subject  Balanced    -       -  \\({\\Large{\\text{}}}\\)/\\({\\Tiny{\\text{}}}\\)//  \\(\\boldsymbol y\\)  \\(\\boldsymbol X,\\boldsymbol X^\\prime\\)  \\(\\boldsymbol\\varepsilon\\)  \\(\\boldsymbol \\Sigma,\\boldsymbol \\Sigma^{-1}\\) n  \\(\\boldsymbol I_n\\) n  1  \\(\\boldsymbol j_n\\) n  1  \\(\\boldsymbol J_n\\)  \\(\\mu\\)  \\(\\sigma^2_\\varepsilon,\\hat \\sigma^2_\\varepsilon\\)  \\(x\\) \\(\\text{index}=i,j,k,\\ldots\\)  \\(1,2,\\ldots,n_\\text{index}\\).  \\(\\cdot\\) \\(\\bar x\\).   \\(n_{ijk}\\) \\(N=\\sum_i^{n_i}\\sum_j^{n_j}\\sum_k^{n_k} n_{ijk}=n_{\\cdot\\cdot\\cdot}\\) \\(\\sum_j^{n_j}n_{ijk}=n_{i\\cdot k}\\)  \\(\\mu_{ij}\\) \\(\\frac{1}{n_i}\\sum_{i}^{n_i}\\left(\\frac{1}{n_j}\\sum_{j}^{n_j}\\mu_{ij}\\right)=\\bar \\mu_{\\cdot\\cdot}=\\mu\\) \\(\\frac{1}{n_i}\\sum_{i}^{n_i}\\mu_{ij}=\\bar \\mu_{\\cdot j}\\)  \\(\\varepsilon_{ijk}\\) \\(\\frac{1}{n_i}\\sum_{i}^{n_i}\\left[\\frac{1}{n_j}\\sum_{j}^{n_j}\\left(\\frac{1}{n_k}\\sum_{k}^{n_k}\\varepsilon_{ijk}\\right)\\right]=\\bar\\varepsilon_{\\cdot\\cdot\\cdot}\\) \\(\\frac{1}{n_k}\\sum_{k}^{n_k}\\varepsilon_{ijk}=\\bar\\varepsilon_{ij\\cdot}\\) "],["chap1.html", " 1   1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9  1.10  1.11  1.12  1.13  1.14 R ", "  1   Randomization is too important to be left to chance. - J. D. Petruccelli 1 1.3 1.5 1.7  1.9  1.11  1.1   \\(N\\) 2 4  5   \\(t\\)  \\(N\\)  \\(t\\)  \\(i\\)  \\(n_i\\)  \\(i=1,2,\\dots,t\\)  \\(N=\\sum_{i=1}^tn_i\\).  \\(t\\) \\(t\\) \\(t\\)  \\(t\\)  \\(n_1\\)  1  \\(n_2\\)  2  \\(n_t\\)  t   \\(y_{ij}\\)  \\(i\\)  \\(j\\)  \\(y_{11},y_{12},\\dots,y_{1n_1}\\)  \\(m_1\\)  \\(s^2_1\\)  \\(n_1\\)  \\(y_{21},y_{22},\\dots,y_{2n_1}\\)  \\(m_2\\)  \\(s^2_2\\)  \\(n_2\\)  \\(i = 3,4,\\dots,t\\)  \\(\\mu_i\\)  \\(\\sigma^2_i\\)  \\(i\\)   \\(\\sigma^2_1= \\sigma^2_2=\\cdots = \\sigma^2_t\\).  \\(i\\)  2    \\(\\mu_i\\)  (means model) \\[y_{ij}=\\mu_{i}+\\varepsilon_{ij}\\quad i=1,2,\\dots,t,\\,j=1,2,\\dots,n_{i}\\]  \\[\\begin{equation} \\varepsilon_{ij}\\sim \\text{i.i.d.}\\,N(0,\\sigma^{2})\\quad i=1,2,\\ldots,t,\\,j=1,2,\\ldots,n_{i} \\tag{1.1} \\end{equation}\\]  \\(\\varepsilon_{ij}\\sim \\text{i.i.d.}\\,N(0,\\sigma^{2})\\)  \\(\\varepsilon_{ij}\\,(i=1,2,\\dots,t;\\,j=1,2,\\dots,n_i)\\)  \\(\\varepsilon_{ij}\\)  \\(0\\) \\(s^2\\)  1.2   \\(\\sigma^2\\) . - \\(s^2\\)   \\(n_i &gt; 1\\)  \\(i(=1,2,\\dots,t)\\)  \\(\\sigma^2\\)  \\(i\\)  \\(\\sigma^2\\)  \\[\\hat{\\sigma}_i^2=\\sum_{j=1}^{n_j}\\frac{\\left(y_{ij}-\\overline{y}_{i\\cdot}\\right)^2}{n_i-1}\\]  \\(\\sigma^2\\)  \\[\\overline{y}_{i\\cdot}=\\frac{\\sum_{j=1}^{n_i}y_{ij}}{n_i}\\]  \\(i\\)  \\(\\sigma^2\\)  \\(\\sigma^2_i\\)  \\(n_i - 1\\)  \\((n_i - 1)\\hat\\sigma_i^2/\\sigma^2\\)  \\(n_i - 1\\)  \\(\\sigma^2\\)  \\(t\\)  \\(\\sigma^2\\) \\(\\sigma^2\\)  \\[\\hat{\\sigma}^2=\\sum_{i=1}^t(n_i-1)\\hat{\\sigma}_i^2\\left/\\sum_{i=1}^t(n_i-1)\\right.\\]  \\[(n_{i}-1)\\hat{\\sigma}_{i}^{2}=\\sum_{i=1}^{t}\\left(y_{ij}-\\overline{y}_{i\\cdot}\\right)^{2}=\\sum_{i=1}^{t}y_{ij}^{2}-n_{i}\\overline{y}_{i\\cdot}^{2}=\\sum_{i=1}^{t}y_{ij}^{2}-(y_{i.})^{2}/n_{i}=SS_{i}\\]  \\(y_{i\\cdot}=\\sum_{j=1}^{n_{i}}y_{ij}\\).  (pooled estimate)  \\[\\hat{\\sigma}^2=\\frac{SS_1+SS_2+\\cdots+SS_t}{(n_1-1)+(n_2-1)+\\cdots+(n_t-1)}=\\frac{\\sum_{i=1}^tSS_i}{N-t}\\]  \\(\\sigma^2\\)  \\(N-t\\)  \\((N-t)\\hat\\sigma^2/\\sigma^2\\)  \\(N-t\\) \\((N-t)\\hat\\sigma^2/\\sigma^2\\sim \\chi^2_{N-t}\\).  \\(\\mu_i\\)  \\(\\hat{\\mu}_{i}=\\bar{y}_{i\\cdot},\\,i=1,2,\\dots,t\\).  (1.1) \\(\\hat\\mu_i\\)  \\(\\mu_i\\)  \\(\\sigma^2/n_i\\).  \\[\\begin{equation} \\hat{\\mu}_i\\sim N{\\left(\\mu_i,\\frac{\\sigma^2}{n_i}\\right)}\\quad i=1,2,\\ldots,t \\tag{1.2} \\end{equation}\\]  \\(\\hat\\mu_i,\\hat\\sigma_i^2\\)  \\[\\begin{equation} t_{i}=\\frac{\\hat{\\mu}_{i}-\\mu_{i}}{\\sqrt{\\hat{\\sigma}^{2}/n_{i}}}\\sim t_{\\Tiny{N-t}}\\quad i=1,2,\\ldots,t \\tag{1.3} \\end{equation}\\] \\(t_i\\)  \\(N-t\\)  \\(t\\) \\(\\mu_1,\\mu_2,\\dots,\\mu_t\\)  \\(\\sigma_i^2\\)  1.3   \\(\\mu_i\\)  \\(\\mu_i\\)  \\(\\mu_i\\)   \\(c_1,c_2,\\dots,c_t\\)  \\(a\\)  \\[H_{01}{:}\\,\\sum_{i=1}^{t}c_{i}\\mu_{i}=a\\,\\mathrm{~vs.~}\\, H_{a1}{:}\\mathrm{~(not~}H_{01}{:})\\\\ H_{02}{:}\\,\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}\\,\\mathrm{~vs.~}\\,H_{a2}{:}\\mathrm{~(not~}H_{02}{:})\\\\ H_{03}{:}\\,\\mu_i=\\mu_{i^\\prime}\\text{ for some }i\\neq i^{\\prime}\\mathrm{~vs.~}H_{a3}{:}\\mathrm{~(not~}H_{03}{:})\\]  \\(H_{01}\\)  \\[\\begin{equation} \\frac{\\sum_{i=1}^tc_i\\hat{\\mu}_i-\\sum_{i=1}^tc_i\\mu_i}{\\sqrt{\\hat{\\sigma}^2\\sum_{i=1}^tc_i^2/n_i}}\\thicksim t_{\\Tiny{N-t}} \\tag{1.4} \\end{equation}\\]  \\(\\sum_{i=1}^tc_i\\mu_i\\)  \\(H_{03}\\)  \\(H_{03}:\\,\\mu_i-\\mu_{i^\\prime}=0\\) \\(H_{01}\\)  \\(c_i=1,c_{i^\\prime}=-1\\) \\(c_k=0\\)  \\(k\\ne i\\)  \\(i^\\prime\\). \\(H_{02}\\)  1.5 \\(\\sum_{i=1}^tc_i\\hat{\\mu}_i\\)  \\[\\begin{equation} \\widehat{s.e.}\\left(\\sum c_i\\hat{\\mu}_i\\right)=\\sqrt{\\hat{\\sigma}^2\\sum\\frac{c_i^2}{n_i}} \\tag{1.5} \\end{equation}\\]  \\(H_{01}{:}\\,\\sum_{i=1}^{t}c_{i}\\mu_{i}=a\\,\\mathrm{~vs.~}\\, H_{a1}{:}\\mathrm{~(not~}H_{01}{:})\\) \\(t\\)  \\[\\begin{equation} t_c=\\frac{\\sum c_i\\hat{{\\mu}}_i-a}{\\widehat{s.e.}\\left(\\sum c_i\\hat{\\mu}_i\\right)} \\tag{1.6} \\end{equation}\\]  \\(|t_{c}| &gt;t_{\\alpha/2,v}\\) \\(v=N-t\\) \\(H_{01}\\)  \\(\\alpha100\\%\\)3 \\(t_{\\alpha/2,v}\\)  \\(v\\)  \\(t\\)  \\(\\alpha/2\\) 4\\(\\sum_{i=1}^{t}c_{i}\\mu_{i}\\)   \\((1-\\alpha)100\\%\\)  \\[\\begin{equation} \\sum c_i\\hat{\\mu}_i\\pm t_{\\alpha/2,v}\\widehat{s.e.}\\left(\\sum c_i\\hat{\\mu}_i\\right) \\tag{1.7} \\end{equation}\\] 1.4   1.1 \\(78\\)  \\(13\\)  \\(1\\)  \\(13\\)  \\(20s\\)  \\(N = 68\\)  \\(y = 2197\\).  1.1:  x \\(\\sigma^2\\)  \\[\\hat{\\sigma}^{2}=\\sum_{i=1}^{6}SS_{i}\\left(N-t\\right)=1,916.0761/62=30.9045\\]  \\(62\\) \\(\\mu_i\\)  \\(\\hat\\mu_1 = 31.923,\\hat\\mu_2 = 31.083,\\hat\\mu_3 = 35.800,\\hat\\mu_4 = 38.000,\\hat\\mu_5 = 29.500\\)  \\(\\hat\\mu_6 = 28.818\\).   \\(H_0:\\,\\mu_3=30\\,\\mathrm{~vs.~}\\,H_a:\\,\\mu_3\\ne30\\).  \\(\\mu_1\\)  \\(95\\%\\)   \\(H_0:\\,\\mu_4=\\mu_5\\,\\mathrm{~vs.~}\\,H_a:\\,\\mu_4\\ne\\mu_5\\).  \\(H_0:\\,\\mu_1=(\\mu_2+\\mu_3+\\mu_4)/3\\,\\mathrm{~vs.~}\\,H_a:\\,\\mu_1\\ne(\\mu_2+\\mu_3+\\mu_4)/3\\).  \\(4\\mu_1-\\mu_3-\\mu_4-\\mu_5-\\mu_6\\)  \\(90\\%\\)   a (1.6)  \\(H_0:\\,\\mu_3=30\\)  \\(t\\)  \\[t_{c}=\\frac{\\hat{\\mu}_{3}-30}{\\widehat{s.e.}(\\hat{\\mu}_{3})}=\\frac{\\hat{\\mu}_{3}-30}{\\sqrt{\\hat{\\sigma}^{2}/n_{3}}}=\\frac{35.8-30.0}{\\sqrt{30.9045/10}}=3.30\\]  \\(t\\)  \\(\\hat \\alpha = \\operatorname{Pr}\\{|t_c| &gt; 3.30\\} = 0.0016\\) \\(\\operatorname{Pr}\\{|t_c| &gt; 3.30\\}\\)  \\(62\\)  \\(t\\)  \\(3.30\\)  \\(-3.30\\)  \\(\\hat\\alpha\\)  \\(t_c = 3.30\\)  \\(t_{\\alpha/2,62}\\)  \\(\\alpha\\). b\\(\\mu_1\\)  \\(95\\%\\)  \\[\\begin{aligned} \\hat{\\mu}_{1}\\pm t_{0.025,62}\\widehat{s.e.}(\\hat{\\mu}_{1})&amp; =31.923\\pm2.00\\sqrt{30.9045/13} \\\\ &amp;=31.923\\pm2.00\\times1.542 \\end{aligned}\\]  \\(\\mu_1\\)  \\(95\\%\\)  \\(28.839&lt;\\mu_1&lt;35.007\\) \\(95\\%\\)  \\(\\mu_1\\). c \\(H_0:\\,\\mu_4=\\mu_5\\) \\(l_1=\\mu_4-\\mu_5\\) \\(\\hat l_1=\\hat \\mu_4-\\hat\\mu_5=38.0-29.5=8.5\\) \\(c_1=c_2=c_3=c_6=0,c_4=1,c_5=-1\\) \\[\\widehat{s.e.}(\\hat{l}_{1})=\\sqrt{\\hat{\\sigma}^{2}\\sum_{i=1}^{6}c_{i}^{2}/n_{i}}=\\sqrt{30.9045{\\left(\\frac{1}{10}+\\frac{1}{12}\\right)}}=2.380\\]  \\(H_0:\\,\\mu_4=\\mu_5\\)  \\(t\\)  \\[t_c=\\frac{8.5}{2.380}=3.57\\]  \\(\\hat\\alpha=0.0007\\). d \\(H_0:\\,\\mu_1=(\\mu_2+\\mu_3+\\mu_4)/3\\)  \\(H_0:\\,\\mu_1-\\frac{1}{3}\\mu_2-\\frac{1}{3}\\mu_3-\\frac{1}{3}\\mu_4=0\\)  \\(H_0:\\,3\\mu_1-\\mu_2-\\mu_3-\\mu_4=0\\).  \\(t_c\\)   \\(l_2=3\\mu_1-\\mu_2-\\mu_3-\\mu_4\\) \\[\\hat{l}_2=3\\hat{\\mu}_1-\\hat{\\mu}_2-\\hat{\\mu}_3-\\hat{\\mu}_4=3(31.923)-31.083-35.8-38.0=-9.114\\] \\(\\hat l_2\\)  \\[\\widehat{s.e.}(\\hat{l}_2)=\\sqrt{30.9045{\\left(\\frac9{13}+\\frac1{12}+\\frac1{10}+\\frac1{10}\\right)}}=5.491\\]  \\(H_0:\\,3\\mu_1-\\mu_2-\\mu_3-\\mu_4=0\\)  \\(t\\)  \\[t_c=\\frac{-9.114}{5.491}=-1.66\\]  \\(\\hat\\alpha=0.1020\\). e \\(l_{3}=4\\mu_{1}-\\mu_{3}-\\mu_{4}-\\mu_{5}-\\mu_{6}\\).  \\(\\hat{l}_{3}=-4.426\\)  \\(\\widehat{s.e.}(\\hat{l}_{3})=7.0429\\). \\(l_3\\)  \\(90\\%\\)  \\[\\hat{l}_{3}\\pm t_{0.05,62}\\widehat{s.e.}\\left(\\hat{l}_{3}\\right)=-4.426\\pm1.671\\times7.043=-4.426\\pm11.769\\]  \\(90\\%\\)  \\(-16.195&lt;4\\mu_1-\\mu_3-\\mu_4-\\mu_5-\\mu_6&lt;7.343\\). 1.5   (simultaneous hypothesis) \\(k\\)  (linearly independent linear combinations)  \\[\\begin{equation} H_0{:}\\quad\\begin{aligned}c_{11}\\mu_1+c_{12}\\mu_2+&amp;\\cdots+c_{1t}\\mu_t=a_1\\\\c_{21}\\mu_1+c_{22}\\mu_2+&amp;\\cdots+c_{2t}\\mu_t=a_2\\\\&amp;\\vdots\\\\c_{k1}\\mu_1+c_{k2}\\mu_2+&amp;\\cdots+c_{kt}\\mu_t=a_k\\end{aligned}\\quad\\mathrm{~vs.~}\\quad H_a{:}(\\operatorname{not}H_0) \\tag{1.8} \\end{equation}\\]   (1.8)  \\[\\begin{equation} H_0{:}\\,\\boldsymbol{C}\\boldsymbol\\mu=\\boldsymbol a\\quad\\mathrm{~vs.~}\\quad H_a{:}\\,\\boldsymbol{C}\\boldsymbol\\mu\\neq\\boldsymbol a \\tag{1.9} \\end{equation}\\]  \\[\\begin{equation} \\boldsymbol{C}=\\begin{bmatrix}c_{11}&amp;c_{12}&amp;\\cdots&amp;c_{1t}\\\\c_{21}&amp;c_{22}&amp;\\cdots&amp;c_{2t}\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\c_{k1}&amp;c_{k2}&amp;\\cdots&amp;c_{kt}\\end{bmatrix},\\quad\\boldsymbol{\\mu}=\\begin{bmatrix}\\mu_{1}\\\\\\mu_{2}\\\\\\vdots\\\\\\mu_{t}\\end{bmatrix},\\quad\\mathrm{and}\\quad\\boldsymbol{a}=\\begin{bmatrix}a_{1}\\\\a_{2}\\\\\\vdots\\\\a_{k}\\end{bmatrix} \\tag{1.10} \\end{equation}\\]  \\(\\boldsymbol C\\)  \\(k\\)  \\(\\boldsymbol C\\)  \\(\\boldsymbol C\\)  \\(k\\)  \\(\\boldsymbol C\\)   \\[H_0{:}\\,\\mu_1-\\mu_2=0,\\,\\mu_1-\\mu_3=0\\quad\\mathrm{and}\\quad\\mu_2-\\mu_3=0\\]  \\(\\boldsymbol C\\)  \\[\\boldsymbol C=\\begin{bmatrix}1&amp;-1&amp;0\\\\1&amp;0&amp;-1\\\\0&amp;1&amp;-1\\end{bmatrix}\\]  \\(\\boldsymbol C\\)  \\(H_{0}\\colon\\,\\mu_{\\mathrm{l}}-\\mu_{2}=0\\mathrm{~and~}\\mu_{\\mathrm{l}}-\\mu_{\\mathrm{3}}=0\\) \\(\\mu_1-\\mu_2=0\\)  \\(\\mu_1-\\mu_3=0\\) \\(\\mu_2-\\mu_3\\)  \\(0\\).  \\(\\boldsymbol C\\)   \\(\\hat{\\boldsymbol \\mu}\\) \\(\\hat{\\boldsymbol \\mu}\\)  \\[\\left.\\hat{\\boldsymbol{\\mu}}\\sim {N_t}(\\boldsymbol{\\mu},{\\sigma}^2\\boldsymbol{D})\\quad\\mathrm{~~}\\quad \\boldsymbol D=\\left[\\begin{array}{ccccc}1/n_1&amp;0&amp;\\cdots&amp;0\\\\0&amp;1/n_2&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;1/n_t\\end{array}\\right.\\right]\\] \\(t×1\\)  \\(\\hat{\\boldsymbol \\mu}\\)  \\(t\\)  \\(\\boldsymbol \\mu\\) \\(\\boldsymbol \\sigma^2\\boldsymbol D\\) \\(\\boldsymbol \\sigma^2\\boldsymbol D\\)  \\(i\\)  \\(\\hat\\mu_i\\)  \\((i,\\,j)\\)  \\(\\hat\\mu_i,\\hat\\mu_j\\)  \\(\\boldsymbol C \\hat{\\boldsymbol \\mu}\\)  \\[\\boldsymbol C\\hat{\\boldsymbol{\\mu}}\\sim N_k(\\boldsymbol C\\boldsymbol{\\mu},\\sigma^2 \\boldsymbol {CDC}^{\\prime})\\]  \\(H_0\\)  \\(H_0{:}\\,\\boldsymbol C \\boldsymbol \\mu =\\boldsymbol a\\)  \\[\\begin{equation} SS_{H0}=(\\boldsymbol C\\boldsymbol{\\hat{\\mu}}-\\boldsymbol{a})^{\\prime}(\\boldsymbol{C}\\boldsymbol D\\boldsymbol{C}^{\\prime})^{-1}(\\boldsymbol{C}\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{a}) \\tag{1.11} \\end{equation}\\]  \\(k\\)  \\(\\boldsymbol C\\) \\(SS_{H0}/\\sigma^2\\)  \\(k\\)  \\(H_0\\)  \\(SS_{H_0}/\\sigma^2\\sim\\chi^2_k\\).  \\(H_0\\)  \\[F_c=\\frac{SS_{H0}/k}{\\hat{\\sigma}^2}\\]  \\(F_c&gt;F_{\\alpha,k,N-t}\\) \\(F_{\\alpha,k,N-t}\\)  \\(k\\)  \\(N-t\\)  \\(F\\)  \\(\\alpha\\)  \\(H_0{:}\\,\\boldsymbol C\\boldsymbol \\mu=\\boldsymbol \\alpha\\).  Graybill (1976)  6.3.1   \\(H_0\\) \\(\\frac{SS_{H0}/k}{\\hat{\\sigma}^2}\\)  \\(\\sigma^2\\)  \\(\\hat\\sigma^2\\)  \\(H_0\\) \\(\\hat\\sigma^2\\)  \\(\\sigma^2\\)  \\(H_0\\)  \\(F\\)  \\(1\\) \\(H_0\\)  \\(SS_{H0}/k\\)  \\[\\sigma^2+\\frac1k(\\boldsymbol C\\boldsymbol\\mu-\\boldsymbol a)^{\\prime}(\\boldsymbol C\\boldsymbol D\\boldsymbol C^{\\prime})^{-1}(\\boldsymbol C\\boldsymbol\\mu-\\boldsymbol a)\\]  \\(H_0\\)  \\(F\\)  \\(1\\)  \\(F\\)  \\(1\\)  \\(H_0\\). 1.6   1.4   \\(i\\) \\(1\\) \\(2\\) \\(3\\) \\(4\\) \\(5\\) \\(6\\) \\(n_i\\) \\(13\\) \\(12\\) \\(10\\) \\(10\\) \\(12\\) \\(11\\) \\(\\bar y_{i\\cdot}\\) \\(31.9231\\) \\(31.0833\\) \\(35.8000\\) \\(38.0000\\) \\(29.5000\\) \\(28.8182\\)  \\(\\hat\\sigma^2 = 30.9045\\) \\(62\\)  \\(\\boldsymbol D\\)  \\[\\boldsymbol D=\\begin{bmatrix}\\frac1{13}&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;\\frac1{12}&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;\\frac1{10}&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;\\frac1{10}&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;\\frac1{12}&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;\\frac1{11}\\end{bmatrix}\\]  (simultaneously testing the following hypothesis) \\[H_0{:}\\,\\mu_4-\\mu_5=4\\,\\mathrm{~and~}\\,3\\mu_1-\\mu_2-\\mu_3-\\mu_4=0\\,\\mathrm{~vs.~}\\,H_a{:}\\,(\\operatorname{not}H_0)\\]  \\(SS_{H0}\\)  \\[\\begin{aligned} \\boldsymbol{C\\hat{\\mu}}-\\boldsymbol{a}&amp; =\\begin{bmatrix}8.5-4\\\\-9.114-0\\end{bmatrix}=\\begin{bmatrix}4.500\\\\-9.114\\end{bmatrix} \\\\ \\boldsymbol C\\boldsymbol D \\boldsymbol C^\\prime&amp; =\\begin{bmatrix}\\dfrac{1}{10}+\\dfrac{1}{12}&amp;-\\dfrac{1}{10}\\\\-\\dfrac{1}{10}&amp;\\dfrac{9}{13}+\\dfrac{1}{12}+\\dfrac{1}{10}+\\dfrac{1}{10}\\end{bmatrix} \\\\ &amp;=\\begin{bmatrix}0.1833&amp;-0.1000\\\\-0.1000&amp;0.9756\\end{bmatrix} \\\\ (\\boldsymbol C \\boldsymbol D \\boldsymbol C^{\\prime})^{-1}&amp; =\\begin{bmatrix}5.7776&amp;0.5922\\\\0.5922&amp;1.0856\\end{bmatrix} \\end{aligned}\\]  \\[SS_{H0}=(\\boldsymbol C\\hat{\\boldsymbol \\mu}-\\boldsymbol a)^{\\prime}(\\boldsymbol C\\boldsymbol D\\boldsymbol C^{\\prime})^{-1}(\\boldsymbol C\\hat{\\boldsymbol \\mu}-\\boldsymbol a)=158.602\\]  \\(2\\).  \\[F_c=\\frac{158.602/2}{30.9045}=2.566\\]  \\(F\\)  \\(\\hat{\\alpha}=\\mathrm{Pr}\\{F&gt;2.566\\}=0.0850\\). 1.7   \\(H_{0}\\colon\\,\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}\\,\\mathrm{~vs.~}H_{a}{:}\\,(\\operatorname{not}H_{0})\\) 1.9   \\(H_{0}\\colon\\,\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}\\) \\(H_{0}\\,\\colon\\mu_{1}-\\mu_{2}=0,\\mu_{1}-\\mu_{3}=0,\\ldots,\\mu_{1}-\\mu_{t}=0\\) \\(\\mu_i\\)  \\(t - 1\\)  \\(t - 1\\)  \\(\\boldsymbol C\\)  \\(\\boldsymbol a\\)  \\[\\boldsymbol C=\\begin{bmatrix}1&amp;-1&amp;0&amp;0&amp;\\cdots&amp;0\\\\1&amp;0&amp;-1&amp;0&amp;\\cdots&amp;0\\\\1&amp;0&amp;0&amp;-1&amp;\\cdots&amp;0\\\\1&amp;0&amp;0&amp;0&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\1&amp;0&amp;0&amp;0&amp;\\cdots&amp;-1\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{a}=\\begin{bmatrix}0\\\\0\\\\0\\\\0\\\\\\vdots\\\\0\\end{bmatrix}\\]  \\(\\mu_i\\)  \\(t - 1\\)  \\(H_{0}{:}\\,\\mu_{1}-\\mu_{2}=0,\\mu_{1}+\\mu_{2}-2\\mu_{3}=0,\\mu_{1}+\\mu_{2}+\\mu_{3}-3\\mu_{4}=0,\\ldots,\\mu_{1}+\\mu_{2}+\\cdots-\\left(t-1\\right)\\mu_{t}=0\\)  \\(\\boldsymbol C\\)  \\(\\boldsymbol a\\)  \\[\\boldsymbol C=\\begin{bmatrix}1&amp;-1&amp;0&amp;0&amp;\\cdots&amp;0\\\\1&amp;1&amp;-2&amp;0&amp;\\cdots&amp;0\\\\1&amp;1&amp;1&amp;-3&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;0\\\\1&amp;1&amp;1&amp;1&amp;\\cdots&amp;t-1\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{a}=\\begin{bmatrix}0\\\\0\\\\0\\\\\\vdots\\\\0\\end{bmatrix}\\]  \\(\\boldsymbol C \\boldsymbol \\mu = \\boldsymbol 0\\)  \\(\\mu_1 = \\mu_2 = \\cdots = \\mu_t\\) \\(H_0\\)  \\(t - 1\\) \\(F\\)  (1.11)  \\[\\begin{equation} SS_{H0:\\,\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}}=\\sum_{i=1}^{t}n_{i}(\\overline{y}_{i.}-\\overline{y}_{..})^{2}=\\sum_{i=1}^{t}\\left(\\frac{y_{i.}^{2}}{n_{i}}\\right)-\\frac{y_{..}^{2}}{N} \\tag{1.12} \\end{equation}\\] 1.8   1.4  (1.11)  (1.12)  \\(SS_{H0:\\,\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}}\\).  (1.12)  \\[\\begin{aligned} SS_{H0}&amp; =\\frac{415^2}{13}+\\frac{373^2}{12}+\\frac{358^2}{10}+\\frac{380^2}{10}+\\frac{354^2}{12}+\\frac{317^2}{11}-\\frac{2197^2}{68} \\\\ &amp;=694.4386 \\end{aligned}\\]  \\(t - 1 = 5\\). \\(F_c\\)  \\[F_c=\\frac{694.4386/5}{30.9045}=4.49\\]  \\(\\hat \\alpha = 0.0015\\).  (1.11) \\(\\boldsymbol C\\) \\(\\boldsymbol a\\)  \\(\\boldsymbol D\\)  \\[\\boldsymbol C=\\begin{bmatrix}1&amp;-1&amp;0&amp;0&amp;0&amp;0\\\\1&amp;0&amp;-1&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;-1&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0&amp;-1&amp;0\\\\1&amp;0&amp;0&amp;0&amp;0&amp;-1\\end{bmatrix},\\quad \\boldsymbol a=\\begin{bmatrix}0\\\\0\\\\0\\\\0\\\\0\\end{bmatrix}\\] \\[\\boldsymbol D=\\begin{bmatrix}\\frac{1}{13}&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;\\frac{1}{12}&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;\\frac{1}{10}&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;\\frac{1}{10}&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;\\frac{1}{12}&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;\\frac{1}{11}\\end{bmatrix}\\]  (1.11)  \\[\\boldsymbol{C\\hat{\\boldsymbol{\\mu}}}-\\boldsymbol{a}=\\begin{bmatrix}0.844\\\\-3.877\\\\-6.077\\\\2.423\\\\3.105\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{C}\\boldsymbol D\\boldsymbol{C}^{\\prime}=\\begin{bmatrix}\\frac{25}{156}&amp;\\frac1{13}&amp;\\frac1{13}&amp;\\frac1{13}&amp;\\frac1{13}\\\\\\frac1{13}&amp;\\frac{23}{130}&amp;\\frac1{13}&amp;\\frac1{13}&amp;\\frac1{13}\\\\\\frac1{13}&amp;\\frac1{13}&amp;\\frac{23}{130}&amp;\\frac1{13}&amp;\\frac1{13}\\\\\\frac1{13}&amp;\\frac1{13}&amp;\\frac1{13}&amp;\\frac{25}{156}&amp;\\frac1{13}\\\\\\frac1{13}&amp;\\frac1{13}&amp;\\frac1{13}&amp;\\frac1{13}&amp;\\frac{24}{143}\\end{bmatrix}\\] \\(\\boldsymbol{CDC&#39;}\\)  \\[(\\boldsymbol{CDC&#39;})^{-1}=\\begin{bmatrix}9.882&amp;-1.765&amp;-1.765&amp;-2.118&amp;-1.941\\\\-1.765&amp;8.529&amp;-1.471&amp;-1.765&amp;-1.618\\\\-1.765&amp;-1.471&amp;8.529&amp;-1.765&amp;-1.618\\\\-2.118&amp;-1.765&amp;-1.765&amp;9.882&amp;-1.941\\\\-1.941&amp;-1.618&amp;-1.618&amp;-1.941&amp;9.221\\end{bmatrix}\\]  \\[SS_{H0}=(\\boldsymbol C\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{a})^{\\prime}(\\boldsymbol C\\boldsymbol D\\boldsymbol{C}^{\\prime})^{-1}(\\boldsymbol{C}\\hat{\\boldsymbol{\\mu}}-\\boldsymbol{a})=694.4386\\]  (1.12)   \\(\\boldsymbol C\\) 1.9   \\(y_{ij} = \\mu_i + \\varepsilon_{ij}\\) (general)  (unreduced model)\\(y_{ij} = \\mu_i + \\varepsilon_{ij}\\) \\(H_0:\\,\\mu_1 = \\mu_2 = \\cdots = \\mu_t = \\mu\\) (full model)  (unrestricted model) (reduced model)  (restricted model).  (principle of conditional error)  \\(ESS_F\\) \\(ESS_R\\)  \\(SS_{H0}=ESS_R-ESS_F\\). \\(ESS_R\\)  \\(ESS_F\\)  [ (essential parameters)  6 ] \\(df_R\\)  \\(df_F\\)  \\(ESS_R\\)  \\(ESS_F\\)  \\(SS_{H0}\\)  \\(df_{H0} = df_R - df_F\\).  \\(H_0\\)  \\(F\\)  \\[F_c=\\frac{SS_{H0}/df_{H0}}{ESS_F/df_F}\\]  \\(F_{c}&gt;F_{\\alpha,df_{{H0}},df_{F}}\\) \\(H_0\\). \\(y_{ij} = \\mu_i + \\varepsilon_{ij}\\)  \\(y_{ij} = \\mu + \\varepsilon_{ij}\\)  \\[ESS_{F}=\\sum_{i=1}^{t}\\sum_{j=1}^{n_{i}}(y_{ij}-\\overline{y}_{i\\cdot})^{2}=(N-t)\\hat{\\sigma}^{2}\\]  \\(df_F=N-t\\).  \\[ESS_{_R}=\\sum_{i=1}^{t}\\sum_{j=1}^{n_{i}}(y_{_{ij}}-\\overline{y}_{\\cdot\\cdot})^{2}\\]  \\(df_R=N-1\\).  \\(H_0\\)  \\[SS_{H0{:}\\,\\mu_1=\\mu_2=\\cdots=\\mu_t}=ESS_{R}-ESS_{F}=\\sum_{i=1}^{t}n_{i}(\\overline{y}_{i\\cdot}-\\overline{y}_{\\cdot\\cdot})^{2}\\]  \\(t-1\\).  (1.12)   (analysis of variance, ANOVA) 1.2  source of variation   1.2:  x : df=degrees of freedom , SS=sum of square , MS=mean square .  1.10   \\(H_{0}\\colon\\,\\mu_{1}=\\mu_{2}=\\mu_{3}\\,\\mathrm{~vs.~}\\,H_{a}\\colon\\,(\\mathrm{not}\\,H_{0})\\) \\(H_0\\)  \\[\\begin{array}{ll}y_{ij}=\\mu_0+\\varepsilon_{ij}&amp;\\mathrm{~for~}i=1,2,3\\\\y_{ij}=\\mu_i+\\varepsilon_{ij}&amp;\\mathrm{~for~}i=4,5,6\\end{array}\\]  \\(1,2,3\\)  \\(0\\) \\(4,5,6\\) . 1.11   1.4 \\(H_{0}\\colon\\,\\mu_{1}=\\mu_{2}=\\mu_{3}=\\mu_{4}=\\mu_{5}=\\mu_{6}\\,\\mathrm{~vs.~}\\,H_{a}\\colon(\\mathrm{not}\\,H_{0})\\).  \\(ESS_F=1916.076\\), \\(df_F=62\\).  \\(ESS_R=73593-(2197)^2/68=2610.545\\), \\(df_R=67\\). \\(SS_{H0}=2610.545-1916.076=694.439\\), \\(df_{H0}=67-62=5\\).  1.3   1.3:  x SAS®BMDP®SYSTAT®JMP®SPSS® MATLABSAS-IML  APL SASJMPBMDPSYSTAT  SPSS  1.4  SAS-GLM  estimate  contrast estimate  \\(t\\) contrast  \\(F\\) SAS-GLM estimate  contrast  \\(\\boldsymbol a\\)   1.4: Proc GLM  estimate  contrast  x  1.5  SAS-IML  1.6  \\(\\boldsymbol C \\boldsymbol \\mu = \\boldsymbol a\\)   1.5: Proc IML 1.6  x 1.12   1.13  1.14 R  # Chap 1 ---- library(gmodels) data &lt;- data.frame( task = factor(rep(1:6, times=c(13,12,10,10,12,11)), levels = 1:6), y = c(27,31,26,32,39,37,38,39,30,28,27,27,34, 29,28,37,24,35,40,40,31,30,25,29,25, 34,36,34,41,30,44,44,32,32,31, 34,34,43,44,40,47,34,31,45,28, 28,28,26,35,31,30,34,34,26,20,41,21, 28,26,29,25,35,34,37,28,21,28,26) ) m &lt;- aov(y ~ -1 + task, data) # &quot;-1&quot; IMPORTANT! n &lt;- aov(y ~ task, data) # R  ## a) test: mu3=30 ---- #  m c1 &lt;- c(0,0,1,0,0,0) names(c1) &lt;- paste0(&quot;task&quot;,1:6) #  c11 &lt;- c(1,0,0,0,0,0) names(c11) &lt;- paste0(&quot;task&quot;,c(3,1,2,4,5,6)) #  estimable(m,c1,beta0 = 30) ## beta0 Estimate Std. Error t value DF Pr(&gt;|t|) ## (0 0 1 0 0 0) 30 35.8 1.757966 3.299267 62 0.001609292 estimable(m,c11,beta0 = 30) ## beta0 Estimate Std. Error t value DF Pr(&gt;|t|) ## (0 0 1 0 0 0) 30 35.8 1.757966 3.299267 62 0.001609292 #  c1 &lt;- rbind(&quot;c1&quot;=c(0,0,1,0,0,0)) estimable(m,c1,beta0 = 30) ## beta0 Estimate Std. Error t value DF Pr(&gt;|t|) ## c1 30 35.8 1.757966 3.299267 62 0.001609292 #  n  d1 &lt;- c(1,0,1,0,0,0) #  1  1  1  estimable(n,d1,beta0 = 30) ## beta0 Estimate Std. Error t value DF Pr(&gt;|t|) ## (1 0 1 0 0 0) 30 35.8 1.757966 3.299267 62 0.001609292 ## b) 95% CI for mu1 ---- c2 &lt;- rbind(&quot;c2&quot;=c(1,0,0,0,0,0)) estimable(m,c2,conf.int = 0.95) ## Estimate Std. Error t value DF Pr(&gt;|t|) Lower.CI Upper.CI ## c2 31.92308 1.541838 20.70455 62 0 28.84099 35.00517 ## c) test: mu3=mu4 ---- c3 &lt;- c(0,0,1,-1,0,0) c31 &lt;- c(0,0,-1,1,0,0) #  c3 &lt;- rbind(&quot;c3&quot;=c3, &quot;c31&quot;=c31) estimable(m,c3,beta0 = 0) ## beta0 Estimate Std. Error t value DF Pr(&gt;|t|) ## c3 0 -2.2 2.48614 -0.884906 62 0.3796264 ## c31 0 2.2 2.48614 0.884906 62 0.3796264 ## d) test: mu1=(mu2+mu3+mu4)/3 ---- c4 &lt;- c(1,-1/3,-1/3,-1/3,0,0) c41 &lt;- -c4 c42 &lt;- c(3,-1,-1,-1,0,0) c4 &lt;- rbind(&quot;c4&quot;=c4, #  &quot;c41&quot;=c41, &quot;c42&quot;=c42) estimable(m,c4,beta0 = 0) ## beta0 Estimate Std. Error t value DF Pr(&gt;|t|) ## c4 0 -3.038034 1.830351 -1.65981 62 0.1020029 ## c41 0 3.038034 1.830351 1.65981 62 0.1020029 ## c42 0 -9.114103 5.491052 -1.65981 62 0.1020029 #  library(emmeans) contrastc4 &lt;- emmeans(m, ~ task) c4 &lt;- list(&quot;c4&quot;=c(3,-1,-1,-1,0,0)) test(contrast(contrastc4,c4)) ## contrast estimate SE df t.ratio p.value ## c4 -9.11 5.49 62 -1.660 0.1020 ## e) 90% CI for 4mu1-mu3-mu4-mu5-mu6 ---- c5 &lt;- rbind(&quot;c5&quot;=c(4,0,-1,-1,-1,-1)) estimable(m,c5,conf.int = .90) ## Estimate Std. Error t value DF Pr(&gt;|t|) Lower.CI Upper.CI ## c5 -4.425874 7.042869 -0.6284192 62 0.5320376 -16.18609 7.334338 #  contrastc5 &lt;- emmeans(m, ~ task) c5 &lt;- list(&quot;c5&quot;=c(4,0,-1,-1,-1,-1)) confint(contrast(contrastc5,c5),level = .90) ## contrast estimate SE df lower.CL upper.CL ## c5 -4.43 7.04 62 -16.2 7.33 ## ## Confidence level used: 0.9 ## sec 1.6, https://bookdown.org/wangzhen/AMD/chap1.html#sec1-6 ---- c &lt;- rbind(&quot;a&quot;=c(0,0,0,1,-1,0), &quot;b&quot;=c(3,-1,-1,-1,0,0)) estimable(m,c,beta0 = c(4,0),joint.test=TRUE) #  ## X2.stat DF Pr(&gt;|X^2|) ## 1 5.132057 2 0.07684013 #  F  Wald  #  car::linearHypothesis library(car) linearHypothesis(m, c(&quot;task4-task5=4&quot;, &quot;3*task1-task2-task3-task4=0&quot;), test = &#39;F&#39;) #  F  ## Linear hypothesis test ## ## Hypothesis: ## task4 - task5 = 4 ## 3 task1 - task2 - task3 - task4 = 0 ## ## Model 1: restricted model ## Model 2: y ~ -1 + task ## ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 64 2074.7 ## 2 62 1916.1 2 158.6 2.566 0.08498 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #  linearHypothesis  ## sec 1.7 - 1.11, https://bookdown.org/wangzhen/AMD/chap1.html#sec1-7 ---- linearHypothesis(m, c(&quot;task2-task1=0&quot;, &quot;task3-task2=0&quot;, &quot;task4-task3=0&quot;, &quot;task5-task4=0&quot;, &quot;task6-task5=0&quot;), test = &#39;F&#39;) ## Linear hypothesis test ## ## Hypothesis: ## - task1 + task2 = 0 ## - task2 + task3 = 0 ## - task3 + task4 = 0 ## - task4 + task5 = 0 ## - task5 + task6 = 0 ## ## Model 1: restricted model ## Model 2: y ~ -1 + task ## ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 67 2610.5 ## 2 62 1916.1 5 694.44 4.4941 0.001471 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1  treatment     population    \\(\\alpha=100\\%\\) critical point "],["chap2.html", " 2   2.1  2.2  2.3  2.4  2.5  2.6  2.7  Satterthwaite  2.8  2.9  2.10  2.11 R ", "  2   Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write. - H.G.Wells  \\(y_{ij} = \\mu_i + \\varepsilon_{ij}\\)  \\(i = 1,2,\\cdots,t;\\,j =1,2,\\cdots,n_i\\).  1  1     \\(\\sum_{i=1}^tc_i\\mu_i=a\\)  \\(\\sum_{i=1}^tc_i\\mu_i\\)       (tests of homogeneity of variances)  BehrensFisher 5 \\(F\\)  \\(t\\)   2.1   \\[\\begin{equation} y_{ij}=\\mu_{i}+\\varepsilon_{ij}\\quad\\mathrm{for}\\quad i=1,2,\\ldots,t,\\,j=1,2,\\ldots,n_{i}\\quad\\mathrm{and}\\quad\\varepsilon_{ij}\\sim\\text{independent}\\,N(0,\\sigma_{i}^{2}) \\tag{2.1} \\end{equation}\\]  \\(\\varepsilon_{ij}\\sim\\text{independent}\\,N(0,\\sigma_{i}^{2})\\)  \\(\\varepsilon_{ij}\\)  \\(i\\) 2.2   \\[\\hat{\\mu}_i=\\sum_{j=1}^{n_i}y_{ij}/n_i=\\bar{y}_{i\\cdot},\\quad i=1,2,\\ldots,t\\]  \\[\\hat\\sigma_i^2=\\frac{\\sum_{j=1}^{n_i}(y_{ij}-\\overline{y}_i)^2}{n_i-1},\\quad i=1,2,\\ldots,t\\]  \\[\\hat{\\mu}_i\\thicksim\\text{independent}\\,N(\\mu_i,\\sigma_i^2/n_i),\\quad i=1,2,\\ldots,t\\]  \\[\\frac{\\left(n_i-1\\right)\\hat\\sigma_i^2}{\\sigma_i^2}\\thicksim\\text{independent }\\,\\chi_{n_i-1}^2,\\quad i=1,2,\\ldots,t\\]  2.3   \\[H_{0}\\colon\\,\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\cdots=\\sigma_{t}^{2}\\,\\mathrm{~vs.~}\\,H_{a}\\colon(\\mathrm{not~}H_{0}:)\\]  1  2.5  \\(\\alpha\\le0.01\\)  2.3.1 Hartleys F-Max Test  Hartleys F-max (Hartley, 1950).  \\(n_1 = n_2 = \\cdots= n_t\\).  \\[F_{\\max}=\\frac{\\max_i\\{\\hat\\sigma_i^2\\}}{\\min_i\\{\\hat\\sigma_i^2\\}}\\]  A.1  \\(\\alpha = 0.05\\)  \\(0.01\\)  \\(F_{\\max}\\)  \\(F_{\\max} &gt; F_{\\max,\\alpha,v,k}\\) \\(v = n - 1\\)  \\(k\\)  \\(H_0\\).  \\(n_i\\)  \\(n=\\max_i\\{n_i\\}-1\\)  \\(H_0\\,\\mathrm{~vs.~} H_a\\)  (liberal) \\(\\alpha\\) 67{#sec2-4}  2.3.2 Bartletts Test  (Bartlett, 1937)  \\(n_i\\) Bartlett  \\[\\begin{equation} U=\\frac1C{\\left[v\\log_\\mathrm{e}(\\hat\\sigma^2)-\\sum_{i=1}^tv_i\\log_\\mathrm{e}(\\hat\\sigma_i^2)\\right]} \\tag{2.2} \\end{equation}\\]  \\[v=n_i-1,\\quad v=\\sum_{i=1}^tv_i,\\quad\\hat\\sigma^2=\\sum_{i=1}^tv_i\\hat\\sigma_i^2/v \\]  \\[C=1+\\frac1{3(t-1)}{\\left[\\sum_{i=1}^t\\frac1{v_i}-\\frac1v\\right]}\\]  \\(U&gt;\\chi_{\\alpha,t-1}^2\\) 2.3.3 Levenes Test Levene (1960)  \\(z_{ij}=|y_{ij}-\\overline{y}_{i\\cdot}|,i=1,2,\\ldots,t;j=1,2,\\ldots,n_{i}\\)  \\(F\\)  3 Levenes Test  2.3.4 Brown and Forsythes Test Brown and Forsythe (1974)  Levene  \\(u_{ij}=|y_{ij}-y_{i\\mathrm{med}}|,i=1,2,\\ldots,t;j=1,2,\\ldots,n_{i}\\)  \\(F\\)  Levenes method  2.3.5 OBriens Test OBrien (1979)  \\[\\begin{equation} r_{ij}=[(w+n_i-2)n_i(y_{ij}-\\overline{y}_{i\\cdot})^2-w\\hat\\sigma_i^2(n_i-1)]/[(n_i-1)(n_i-2)] \\tag{2.3} \\end{equation}\\]  \\(w\\)  \\(w=0.5\\)  \\(\\hat \\sigma^2_i\\)  [ Conover et al. (1981)  Olejnik &amp; Algina (1987)]McGaughey (2003)  (data depth)  2.3.6  Conover (1981)  Olejnik &amp; Algina (1987)  Olejnik  AlginaLevenes Test  Conover OBriens Test  (size test) (heavy tails) BrownForsythes Test   BrownForsythes test.  OBriens test.  Bartletts  Hartleys tests. Levenes  OBriens tests  (Milliken and Johnson, 2002). Levenes, OBriens  BrownForsythes tests  Bartletts  Hartleys tests Conover et al.  Olejnik  Algina  2.4   2.1 8 (paired-association learning task) 121324 2.1  2.1:  x F-max  \\(F_\\max=16.286/1.867=8.723\\).  \\(k=t=4,v=7\\)  \\(5\\%\\)  A.1  \\(8.44\\) \\(8.723&gt;8.44\\) \\(0.05\\)  \\(H_{0}\\colon\\,\\sigma_{1}^{2}=\\sigma_{2}^{2}=\\cdots=\\sigma_{t}^{2}\\,\\mathrm{~vs.~}\\,H_{a}\\colon(\\mathrm{not~}H_{0}:)\\) \\(0.01\\)  Bartletts test  \\[C=1+\\frac1{3\\times3}{\\left(\\frac16+\\frac15+\\frac17+\\frac17-\\frac1{25}\\right)}\\]  \\[\\hat\\sigma^2=\\frac{6(16.2857)+5(1.8667)+7(9.6964)+7(2.7860)}{25}=7.7769\\]  \\[\\begin{aligned} U&amp; =\\frac1C{\\left(v\\log_e\\hat\\sigma^2-\\sum_{i=1}^4v_i\\log_e\\hat\\sigma_i^2\\right)} \\\\ &amp;=\\frac1{1.068}[25\\log_{\\mathrm{e}}(7.7769)-6\\log_{\\mathrm{e}}(16.2857)-5\\log_{\\mathrm{e}}(1.8667) \\\\ &amp;-7\\log_{\\mathrm{e}}(9.6964)-7\\log_{\\mathrm{e}}(2.7860)] \\\\ &amp;=7.8111 \\end{aligned}\\]  \\(U\\)  \\(3\\)  \\(0.0501\\) \\(5\\%\\)  Levenes test  2.2  \\(F\\)  \\(6.97\\) \\(3,25\\) Levenes test  \\(0.0015\\).  2.2  Levenes test \\(F\\)  \\(7.36\\) \\(0.0011\\) \\(3,25\\)  2.2:  Levenes test  \\(z_{ij} = |y_{ij}-y_{i\\cdot}|\\)  \\(y_{ij}\\)  2.1 x BrownForsythes test  2.1 2.3  \\(F\\)  \\(5.49\\) \\(0.0049\\) \\(3,25\\)  2.3:  x  2.4  (2.3)  \\(r_{ij}\\)  \\(w = 0.5\\).  OBriens test \\(F\\)  \\(6.30\\) \\(0.0025\\).  \\(w = 0.7\\) \\(F\\)  \\(5.90\\) \\(0.0035\\).  OBriens test  \\(3,25\\).  2.4:  \\(w=0.5\\)  OBriens Test  x  2.5 2.621  2.5:  x  2.6:  x 2.5   \\(\\sigma_i^2\\)  1  \\(\\sum_{i=1}^tc_i\\mu_i\\)  \\(0.01\\)  \\(1\\%\\)  1  \\(\\sum_{i=1}^tc_i\\mu_i\\)  \\(\\sum_{i=1}^tc_i\\hat \\mu_i\\) \\[\\sum_{i=1}^tc_i\\hat{\\mu}_i\\sim N{\\left(\\sum_{i=1}^tc_i\\mu_i,\\sum_{i=1}^tc_i^2\\sigma_i^2/n_i\\right)}\\]  \\[z=\\frac{\\sum_{i=1}^{t}c_{i}\\hat{{\\mu}}_{i}-\\sum_{i=1}^{t}c_{i}\\mu_{i}}{\\sqrt{\\sum_{i=1}^{t}c_{i}^{2}\\sigma_{i}^{2}/n_{i}}}\\sim N(0,1)\\]  \\(\\sum_{i=1}^tc_i\\mu_i\\)  \\[z=\\frac{\\sum_{i=1}^tc_i\\hat{\\mu}_i-\\sum_{i=1}^tc_i{\\mu}_i}{\\sqrt{\\sum_{i=1}^tc_i^2\\hat\\sigma_i^2/n_i}}\\]  \\(c_i\\)  \\(n_i\\)  \\(Z\\)  \\(N(0,1)\\)  \\(Z\\)  \\(\\sum_{i=1}^tc_i\\mu_i\\).  \\(\\sum_{i=1}^tc_i\\mu_i\\)  \\((1 - \\alpha)100\\%\\)  \\[\\sum_{i=1}^tc_i\\hat{\\mu}_i\\pm z_{\\alpha/2}\\sqrt{\\sum_{i=1}^tc_i^2\\hat\\sigma_i^2/n_i}\\] \\(|z| &gt; z_{\\alpha/2}\\) \\(\\alpha\\)  \\(H_0\\).  \\(z\\)  \\[z=\\frac{\\left(\\sum_{i=1}^tc_i\\hat{{\\mu}}_i-\\sum_{i=1}^tc_i\\mu_i\\right)\\Big/\\sqrt{\\sum_{i=1}^tc_i^2\\sigma_i^2/n_i}}{\\sqrt{\\sum_{i=1}^tc_i^2\\hat{\\sigma}_i^2/n_i}\\Big/\\sqrt{\\sum_{i=1}^tc_i^2\\sigma_i^2/n_i}}\\] \\(z\\) \\(z\\) \\(z\\)  \\(t(v)\\)  \\(v\\)  \\[V=v\\times\\frac{\\sum_{i=1}^tc_i^2\\hat\\sigma_i^2\\big/n_i}{\\sum_{i=1}^tc_i^2\\sigma_i^2\\big/n_i}\\]  \\(\\chi^2(v)\\).  \\(V\\)  \\(V\\)  \\(v\\) \\(v\\)  \\(V\\)  \\(\\chi^2(v)\\)  Satterthwaites method  \\[{v}=\\frac{\\left(\\sum_{i=1}^tc_i^2\\sigma_i^2/n_i\\right)^2}{\\sum_{i=1}^t\\left[c_i^4\\sigma_i^4/n_i^2(n_i-1)\\right]}\\]  \\(v\\)  \\(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_t^2\\) \\(v\\) \\[\\begin{equation} \\hat{{v}}=\\frac{\\left(\\sum_{i=1}^tc_i^2\\hat{\\boldsymbol\\sigma}_i^2/n_i\\right)^2}{\\sum_{i=1}^t\\left[c_i^4\\hat{\\sigma}_i^4/n_i^2(n_i-1)\\right]} \\tag{2.4} \\end{equation}\\]  \\(H_0\\colon\\sum_{i=1}^tc_i\\mu_i=a\\,\\mathrm{~vs.~}H_a{:}\\sum_{i=1}^tc_i\\mu_i\\neq a\\) \\[\\left|t_c\\right|=\\frac{\\left|\\sum_{i=1}^tc_i\\hat{\\mu}_i-a\\right|}{\\sqrt{\\sum_{i=1}^tc_i^2\\hat\\sigma_i^2/n_i}}&gt;t_{\\alpha/2,\\hat{v}}\\]  \\(\\hat v\\)  (2.4) \\(\\sum_{i=1}^tc_i\\mu_i\\)  \\((1 - \\alpha)100\\%\\)  \\[\\sum_{i=1}^tc_i\\hat{\\mu}_i\\pm t_{\\alpha/2,\\hat{v}}\\sqrt{\\sum_{i=1}^tc_i^2\\hat\\sigma_i^2/n_i}\\]  \\(\\hat v\\)  \\(n_*-1\\leq\\hat{v}\\leq t(n^*-1)\\)  \\(n_*=\\min\\{n_1,n_2,\\ldots,n_t\\}\\)  \\(n^*=\\max\\{n_1,n_2,\\ldots,n_t\\}\\).  \\(|t_c|&gt;t_{\\alpha/2,n_*-1}\\) \\(|t_c|&gt;t_{\\alpha/2,\\hat{v}}\\) \\(|t_c|&lt;t_{\\alpha/2,t(n^*-1)}\\) \\(|t_c|&lt;t_{\\alpha/2,\\hat{v}}\\).  \\(\\hat v\\).  \\(t_{\\alpha/2,t(n^*-1)}&lt;|\\left.t_c\\right|&lt;t_{\\alpha/2,n^*-1}\\) \\(\\hat v\\)  \\(\\hat v\\).  2.6   2.1      \\[H_{01}{:}\\,l_1=\\mu_1-\\frac{(\\mu_2+\\mu_3+\\mu_4)}3=0\\mathrm{~vs~}H_{a1}{:}\\,l_1\\neq0\\]  \\[\\hat{l}_1=\\hat{\\mu}_1-\\frac{\\hat{\\mu}_2+\\hat{\\mu}_3+\\hat{\\mu}_4}3=4.571-\\frac13(34.042)=-6.776\\] \\(\\hat l_1\\)  \\[\\begin{aligned} s.e.(\\hat{l}_1)&amp; =\\sqrt{\\sum_{i=1}^4\\left(\\frac{c_i^2\\hat\\sigma_i^2}{n_i}\\right)} \\\\ &amp;=\\sqrt{\\frac{\\hat\\sigma_1^2}7+\\frac19{\\left(\\frac{\\hat\\sigma_2^2}6\\right)}+\\frac19{\\left(\\frac{\\hat\\sigma_3^2}8\\right)}+\\frac19{\\left(\\frac{\\hat\\sigma_4^2}8\\right)}}\\\\ &amp;=\\sqrt{2.535}\\\\ &amp;=1.592 \\end{aligned}\\]  \\[\\sum_{i=1}^4\\frac{c_i^4\\hat\\sigma_i^4}{n_i^2(n_i-1)}=0.9052\\]  \\[\\hat{v}=\\frac{(2.535)^2}{0.9052}=7.10\\]  \\(t_c=-6.776/1.992=-4.256\\) \\(\\hat \\alpha= 0.0038\\). \\(l_1\\)  \\(95\\%\\)  \\[\\hat{l}_1\\pm t_{\\alpha/2,\\hat{v}}\\times\\widehat{s.e.}(\\hat{l}_1)=-6.776\\pm(2.365)(1.592)\\]  \\[-10.54&lt;\\mu_1-\\frac{\\mu_2+\\mu_3+\\mu_4}3&lt;-3.01\\]  \\[H_{02}\\colon l_2=\\mu_4-\\frac{\\mu_2+\\mu_3}2=0\\,\\mathrm{~vs.~}H_{a2}{:}\\,l_2\\neq0\\]  \\[\\hat l_2=\\hat{\\mu}_4-\\frac{\\hat{\\mu}_2+\\hat{\\mu}_3}2=3.6042\\]  \\[\\begin{aligned} \\widehat{s.e.}(\\hat{l}_{2})&amp; =\\sqrt{\\sum_{i=1}^4\\left(\\frac{c_i^2\\hat\\sigma_i^2}{n_i}\\right)} \\\\ &amp;=\\sqrt{\\frac14\\!\\left(\\frac{\\hat\\sigma_2^2}6\\right)+\\frac14\\!\\left(\\frac{\\hat\\sigma_3^2}8\\right)+\\left(\\frac{\\hat\\sigma_4^2}8\\right)}\\\\ &amp;=\\sqrt{0.7290}\\\\ &amp;=0.8538 \\end{aligned}\\]  \\(t_c = 3.6042/0.8538 = 4.221\\) \\(|t_c|&gt;t_{0.005,5}\\)  \\(\\alpha=0.01\\)  \\(\\hat v\\)  \\(n_ *-1\\)  \\(\\hat v\\)  \\(16.8\\)  \\(l_2\\)   \\(H_0{:}\\,l_3 = \\mu_2 - \\mu_3 = 0 \\,\\mathrm{~vs.~} H_a{:}\\,l_3 = \\mu_2 - \\mu_3 \\ne 0\\).  \\(\\hat l_3 = \\hat\\mu_2 - \\hat\\mu_3=3.042\\) \\[\\widehat{s.e.}(\\hat{l}_3)=\\sqrt{\\sum_{i=1}^4\\left(\\frac{c_i^2\\hat\\sigma_i^2}{n_i}\\right)}=\\sqrt{\\left(\\frac{\\hat\\sigma_2^2}{6}\\right)+\\left(\\frac{\\hat\\sigma_3^2}8\\right)}=\\sqrt{1.523}=1.234\\]  \\[\\sum_{i=1}^4\\frac{c_i^4\\hat\\sigma_i^4}{n_i^2(n_i-1)}=0.229\\]  \\[\\hat{v}=\\frac{(1.523)^2}{0.229}=10.1\\] \\(t_c = 3.042/1.234 = 2.465\\) \\(\\hat\\alpha = 0.0334\\). 2.7  Satterthwaite   Satterthwaite  \\[v=\\frac{2*(E\\{[\\widehat{s.e.}(\\hat{l})]^2\\})^2}{\\mathrm{Var}\\{[\\widehat{s.e.}(\\hat{l})]^2\\}}\\]  \\([\\widehat{s.e.}(\\widehat{l})]^2\\)  \\(E[s.e.(\\hat{l})]^2\\) \\(\\mathrm{Var}[\\widehat{s.e.}(\\hat{l})]^2\\)  \\(\\sum_{i=1}^t\\left[c_i^4\\sigma_i^4/n_i^2(n_i-1)\\right]\\) \\(\\mathrm{Var}[\\widehat{s.e.}(\\widehat{l})]^2\\)  (Kendall and Stuart, 1952)  \\(\\boldsymbol q&#39;\\boldsymbol M \\boldsymbol q\\) \\(\\boldsymbol M\\)  \\(\\boldsymbol q\\)  \\(E[s.e.(\\hat{l})]^2\\) 9 \\[q_{i}=\\frac{\\partial E[(s.e.(\\hat{l})]^{2}}{\\partial\\sigma_{i}^{2}},\\quad i=1,2,\\ldots,t\\]  \\(q_i\\) (Montgomery and Runger, 1993, 1994).  \\[\\frac{(n_i-1)\\hat\\sigma_i^2}{\\sigma_i^2}\\]  \\(E(\\hat\\sigma_i^2)=\\sigma_i^2\\)  \\(\\operatorname{Var}(\\hat\\sigma_i^2)=2\\sigma_i^4/(n_i-1)\\).  \\(l=\\sum_{i=1}^{t}c_{i}\\mu_{i}\\) \\(\\sigma_{l}^{2}=\\sum_{i=1}^{t}c_{i}^{2}\\sigma_{i}^{2}/n_{i}\\) \\(\\sigma_{l}^{2}\\)  \\(\\hat \\sigma_{i}^{2}\\)  \\[\\frac{\\partial\\sigma_l^2}{\\partial\\sigma_i^2}=\\frac{c_i^2}{n_i}\\]  \\(\\sigma_{l}^{2}\\)  \\[\\mathrm{Var}(\\sigma_l^2)=\\sum_{i=1}^t\\left[\\left[\\frac{c_i^2}{n_i}\\right]^2\\left[\\frac{2\\sigma_i^4}{n_i-1}\\right]\\right]^2\\]  \\[\\hat{v}=\\frac{2*\\left(E\\{[\\widehat{s.e.}(\\hat{l})]^2\\}\\right)^2}{\\mathrm{Var}\\{[\\widehat{s.e.}(\\hat{l})]^2\\}}=\\frac{\\left(\\sum_{i=1}^tc_i^2\\hat\\sigma_i^2\\right)^2}{\\sum_{i=1}^tc_i^4\\hat\\sigma_i^4/[n_i^2(n_i-1)]}\\]  Satterthwaite  2.8   \\(F\\)  \\(H_{0}\\colon\\,\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}\\,\\mathrm{~vs.~}H_{a}\\colon\\,(\\operatorname{not}H_{0}{:})\\)  Welch (1951)  Welchs test \\(W_{i}=n_{i}/\\hat\\sigma_{i}^{2}\\) \\(\\bar{y}^{*}=\\sum_{i=1}^{t}W_{i}\\bar{y}_{i\\cdot}\\big/\\sum_{i=1}^{t}W_{i}\\)  \\[\\Lambda=\\sum_{i=1}^{t}\\frac{(1-W_{i}/W_{\\cdot})^{2}}{n_{i}-1}\\]  \\(W_\\cdot=\\sum_{i=1}^tW_{i\\cdot}\\).  Welchs test  \\[\\begin{equation} F_c=\\frac{\\sum_{i=1}^tW_i\\frac{(\\bar{y}_i.-\\bar{y}^*)}{(t-1)}}{1+2(t-1)\\Lambda/(t^2-1)} \\tag{2.5} \\end{equation}\\]  \\(F\\)  \\(v_{1}=t-1,\\,v_{2}=(t^{2}-1)/3\\Lambda\\).  \\(F_{c}&gt;F_{\\alpha,v_{1},v_{2}}\\) \\(H_{0}\\colon\\,\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}\\).  (2.5) \\([\\sum_{i=1}^{t}W_{i}\\bar{y}_{i\\cdot}^{2}-\\overline{W}\\bar{y}^{*2}]/(t-1)\\).  2.7  2.7.  2.7:  Welchs test  x  \\(W_\\cdot=7.341,\\bar{y}^{*}=11.724\\) \\[\\Lambda=\\frac{(1-0.430/7.341)^2}6+\\frac{(1-3.214/7.341)^2}5+\\frac{(1-0.825/7.341)^2}7+\\frac{(1-2.872/7.341)^2}7=0.376\\]  \\(\\sum_{i=1}^{t}W_{i}\\left.\\bar{y}_{i\\cdot}^{2}-\\overline{W}\\right.\\bar{y}^{*2}=1050.8069-1009.0954=43.7114\\). Welchs test  \\[F_c=\\frac{41.7114/3}{1+2\\times2\\times0.376/15}=\\frac{13.9038}{1.1003}=12.6355\\]  \\(v_1=3,v_2=15/(3×0.376) = 13.283\\).  \\(F_c\\)  \\(\\hat \\alpha=0.00035\\).  \\(F\\)  \\(F_c=14.91\\) \\(3,25\\). Welchs test  SAS®GLM  MEANS  Welch  2.8  GLM  BF  Welch  2.8  O'BrienLevene  Bartlett   2.8: SAS-GLM  Brown-Forsythe  Welch  x  \\(\\mu_i\\)   \\(r\\)  \\(\\mu_i\\)  \\(H_{0}\\colon\\,\\sum_{i=1}^{t}c_{1i}\\mu_{i}=0,\\sum_{i=1}^{t}c_{2i}\\mu_{i}=0,\\ldots,\\sum_{i=1}^{t}c_{ri}\\mu_{i}=0\\,\\mathrm{~vs.~}H_{a}:(\\mathrm{not}\\,H_{0})\\).  \\(\\boldsymbol C\\)  \\(k\\)  \\(k\\)  \\(\\hat{\\boldsymbol{\\mu}}\\sim N[\\boldsymbol{\\mu},\\boldsymbol V]\\) \\(\\boldsymbol V\\)  \\(i\\)  \\(\\sigma^2_i /n_i\\).  \\(\\boldsymbol C \\boldsymbol \\mu\\)  \\(\\boldsymbol{C\\hat{\\boldsymbol{\\mu}}}\\sim N[\\boldsymbol{C\\mu},\\boldsymbol{CV}\\boldsymbol{C}^{\\prime}]\\).  \\(SSH_{0} = [\\boldsymbol C\\hat{\\boldsymbol{\\mu}}]^{\\prime}[\\boldsymbol C\\hat{\\boldsymbol V}\\boldsymbol C^{\\prime}]^{-1}[\\boldsymbol C\\hat{\\boldsymbol{\\boldsymbol \\mu}}]\\) \\(r\\)  \\(F_c = SSH_ 0/r\\) \\(F\\) \\(r,v\\) \\(v\\)  (Fai and Cornelius, 1996; SAS Institute, Inc., 1999, p. 2118).  \\(\\boldsymbol C \\hat {\\boldsymbol V} \\boldsymbol C&#39; = \\boldsymbol Q \\boldsymbol D \\boldsymbol Q&#39;\\)  \\(\\boldsymbol D\\)  \\(\\boldsymbol C \\hat {\\boldsymbol V} \\boldsymbol C&#39;\\)  \\(r×r\\)  \\(\\boldsymbol Q\\)  \\(\\boldsymbol C \\hat {\\boldsymbol V} \\boldsymbol C&#39;\\)  \\(r×r\\)  \\(\\boldsymbol z_k&#39;\\)  \\(\\boldsymbol Q \\boldsymbol C\\)  \\(k\\)  \\[v_k=\\frac{2(d_k)^2}{\\boldsymbol b_k&#39;\\boldsymbol M\\boldsymbol b_k}\\]  \\(d_k\\)  \\(\\boldsymbol D\\)  \\(k\\) \\(\\boldsymbol b_k\\)  \\(\\boldsymbol z_k&#39;\\boldsymbol V \\boldsymbol z_k\\)  \\(\\boldsymbol V\\) \\(\\boldsymbol M\\)  \\[S=\\sum_{k=1}^r\\frac{v_k}{v_k-2}I[v_k&gt;2]\\]  \\(I[v_k&gt;2]\\)  \\(v_k &gt; 2\\)  \\(1\\) \\(0\\). \\(F_c\\)  \\[v=\\begin{cases}\\frac{2S}{S-r}&amp;\\mathrm{if~}S&gt;r\\\\0&amp;\\mathrm{if~}S\\leq r&amp;\\end{cases}\\]  \\(t - 1\\)  \\(\\mu_i\\)  SAS-Mixed  \\(F\\) SAS-Mixed  REPEATED  GROUP =  2.9  Mixed  2.1 REPEATED  Estimate  2.6   2.9:  2.1  SAS-Mixed  x Mixed  2.10 AIC  Akaike Information Criteria (Akaike, 1974) III  2.6  \\(t\\)  \\(95\\%\\)  2.11  2.11  1  2 T 1  1 0.  T  class  Repeated/Group=T; \\(2.4028\\)  \\(12.7376\\)\\(AIC\\)  \\(126.4\\) \\(AIC\\)   2.10:  2.1  x  2.11:  x 2.9    \\(1\\%\\)   \\(1\\%\\)  Welchs test   \\(1\\%\\)  \\(AIC\\)    2.10  2.11 R  # Chap2---- ## sec 2.4, https://bookdown.org/wangzhen/AMD/chap2.html#sec2-4 ---- data &lt;- data.frame( g = factor(rep(c(&quot;NoDrug&quot;,&quot;Drug1&quot;,&quot;Drug2&quot;,&quot;Drug12&quot;), times=c(7,6,8,8)), levels = c(&quot;NoDrug&quot;,&quot;Drug1&quot;,&quot;Drug2&quot;,&quot;Drug12&quot;)), y = c(1,8,9,9,4,0,1, 12,10,13,13,12,10, 12,4,11,7,8,10,12,5, 13,14,14,17,11,14,13,14) ) library(PMCMRplus) library(DescTools) library(lawstat) PMCMRplus::hartleyTest(y ~ g,data=data) #  Maximum F-ratio test  ## ## Hartley&#39;s maximum F-ratio test of homogeneity of variances ## ## data: y by g ## F Max = 8.7245, df = 5, k = 4, p-value = 0.1277 bartlett.test(y ~ g,data=data) # Bartletts test ## ## Bartlett test of homogeneity of variances ## ## data: y by g ## Bartlett&#39;s K-squared = 7.8111, df = 3, p-value = 0.05008 DescTools::LeveneTest(y ~ g,data=data,center=mean) # center = mean  Levene&#39;s ## Levene&#39;s Test for Homogeneity of Variance (center = mean) ## Df F value Pr(&gt;F) ## group 3 6.9664 0.001454 ** ## 25 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 DescTools::LeveneTest(y ~ g,data=data,center=median) # center = mean  BrownForsythe&#39;s ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 5.4943 0.004861 ** ## 25 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 lawstat::levene.test(data$y ,data$g, correction.method = &quot;correction.factor&quot;) # O&#39;Brien&#39;s test BrownForsythe, Levene, O&#39;Brien&#39;s test  ## ## Modified robust Brown-Forsythe Levene-type test based on the ## absolute deviations from the median with correction factor ## ## data: data$y ## Test Statistic = 5.4975, p-value = 0.004848 ## sec 2.6, https://bookdown.org/wangzhen/AMD/chap2.html#sec2-6 ---- library(SimComp) #  1 c &lt;- rbind(&quot;c&quot;=c(1,-1/3,-1/3,-1/3)) SimTestDiff(y ~ g,data=data, ContrastMat=c, #  covar.equal=FALSE) #  F  Satterthwaite  ## ## Test for differences of means of multiple endpoints ## Assumption: Heterogeneous covariance matrices for the groups ## Alternative hypotheses: True differences not equal to the margins ## ## comparison endpoint margin estimate statistic degr.fr p.value.raw ## c c y 0 -6.776 -4.256 7.096 0.0038 ## p.value.adj ## c 0.0038 ## #  2 c &lt;- rbind(&quot;c&quot;=c(0,-1/2,-1/2,1)) SimTestDiff(y ~ g,data=data, ContrastMat=c, covar.equal=FALSE) ## ## Test for differences of means of multiple endpoints ## Assumption: Heterogeneous covariance matrices for the groups ## Alternative hypotheses: True differences not equal to the margins ## ## comparison endpoint margin estimate statistic degr.fr p.value.raw ## c c y 0 3.604 4.221 16.79 6e-04 ## p.value.adj ## c 6e-04 ## #  3 c &lt;- rbind(&quot;c&quot;=c(0,1,-1,0)) SimTestDiff(y ~ g,data=data, ContrastMat=c, covar.equal=FALSE) ## ## Test for differences of means of multiple endpoints ## Assumption: Heterogeneous covariance matrices for the groups ## Alternative hypotheses: True differences not equal to the margins ## ## comparison endpoint margin estimate statistic degr.fr p.value.raw ## c c y 0 3.042 2.465 10.12 0.0334 ## p.value.adj ## c 0.0334 ## ## sec 2.8, https://bookdown.org/wangzhen/AMD/chap2.html#sec2-8 ---- library(onewaytests) welch.test(y ~ g,data=data) ## ## Welch&#39;s Heteroscedastic F Test (alpha = 0.05) ## ------------------------------------------------------------- ## data : y and g ## ## statistic : 12.63548 ## num df : 3 ## denom df : 13.28303 ## p.value : 0.0003469085 ## ## Result : Difference is statistically significant. ## -------------------------------------------------------------  the actual and physical conduct of an experiment must govern the statistical procedure of its interpretation. - R. A. Fisher : heterogeneous error variances pose a much more serious problem when ignored than non-normality of the error variances : so you are going to reject the null hypothesis more often than specified by the choice of \\(\\alpha\\). : not too unequal.  subject   \\(\\partial\\) "],["chap3.html", " 3   3.1  3.2  3.3  3.4 Fishers LSD Procedure 3.5 Bonferronis Method 3.6 Scheffés Procedure 3.7 TukeyKramer Method 3.8  3.9 idák Procedure 3.10  3.11 Dunnetts Procedure 3.12  3.13  \\(t\\) 3.14  3.15  3.16  3.17  3.18 WallerDuncan Procedure 3.19  3.20  3.21  3.22 ", "  3    \\(\\mu_i\\) / 2.4   \\(25\\)  \\(0.05\\)  \\((0.05)(25)= 1.25\\) Fisher (1949)  (least significant difference, LSD  (simultaneous confidence intervals) \\(\\mu_i\\)  \\(95\\%\\)  (simultaneously)  \\(\\mu_i\\)  3.1   (error rates)  3.1   (comparisonwise error rate)   3.2   (experimentwise error rate, EER) EER  (experimentwise error rate under the complete null hypothesis, EERC).  3.3   (familywise error rate, FWER) (Westfall et al, 1999)  \\(k\\)  \\(k\\)   3.4   (false discovery rate, FDR)(Benjamini and Hochberg, 1995)  EER  \\(k\\)  \\(H_{01},H_{02},\\cdots,H_{0k}\\)  \\(t\\)  \\(k\\)  (partial null hypothesis) FWER 2.3buttons, blue choc, red choc, small choc, chocChip  WchocChip small choc  (null hypothesis)  small choc  blue choc  red choc  FWER  EER FDR   FWER  \\(0.05\\).  FWER  3.2  1) 2)  \\(t\\) 3)  (simultaneous confidence intervals or simultaneous tests of hypotheses)4)  5)  (data snooping) (comparisons) 2 Westfall et al. (1999), SAS Institute, Inc. (1999), and Westfall (2002)   \\(t\\)  \\(LSD\\)   Dunnetts procedure Dunnetts procedure   Tukeys method.  (unbalanced) (Westfall et al., 1999)   \\(t\\)  \\(t\\)  \\(t\\)  Bonferroni method 20 Scheffé procedure  idák (1967), Holm (1979),  idákHolm  FWER SAS®-MULTTEST  bootstrap   Scheffé procedure EER  FWER.  FDR  Benjamini and Hochberg (1995)  III  \\(p\\)   1  \\(v\\)  \\(\\sigma^2\\)  1  \\(v = N-t\\). 3.3  LSD (least significant difference)  \\(\\mu_i\\)  \\(\\mu_j\\)  \\(\\alpha100\\%\\)10 LSD  \\[\\begin{equation} \\mathrm{LSD}_\\alpha=t_{\\alpha/2,v}\\hat{\\sigma}\\sqrt{\\frac1{n_i}+\\frac1{n_j}} \\tag{3.1} \\end{equation}\\]  \\(|\\hat{\\mu}_i-\\hat{\\mu}_j|&gt;\\text{LSD}_\\alpha\\)  \\(\\mu_i\\ne \\mu_j\\).  \\(\\alpha\\). \\(\\mu_i\\mu_j\\)  \\(100(1-\\alpha)\\%\\)  \\[\\begin{equation} \\hat{\\mu}_i-\\hat{\\mu}_j\\pm t_{\\alpha/2,v}{\\hat\\sigma}\\sqrt{\\frac1{n_i}+\\frac1{n_j}} \\tag{3.2} \\end{equation}\\]  \\(n\\)  LSD  \\(\\mathrm{LSD}_{\\alpha}\\)  \\[\\begin{equation} \\mathrm{LSD}_\\alpha=t_{\\alpha/2,v}{\\hat\\sigma}\\sqrt{\\frac2n} \\tag{3.3} \\end{equation}\\]  \\(t\\)  \\(5\\%\\)  3.1  \\(t\\)  3.1  6 35.8%  LSD Westfall et al. (1999) /  3.1: LSD Procedure  x 3.4 Fishers LSD Procedure Fisher  LSD  Fishers procedure LSD  (3.1)  \\(\\alpha100\\%\\)  \\(H_0{:}\\,\\mu_1=\\mu_2=\\cdots=\\mu_t\\)  1  \\(F\\)   LSD procedure  \\(\\alpha\\).  \\(H_0{:}\\,\\mu_1=\\mu_2=\\cdots=\\mu_t\\)  \\(H_0{:}\\,\\mu_i=\\mu_j\\) \\(i\\ne j\\).  \\(F\\)  \\(F\\) LSD FWER  Fishers LSD.  LSDs procedure  \\(\\mu_i\\)   LSDs procedure  \\(\\sum_{i=1}^{t}c_{i}\\mu_{i}\\neq0\\)  \\[\\begin{equation} \\left|\\sum_{i=1}^tc_i\\hat{\\mu}_i\\right|&gt;t_{\\alpha/2,v}{\\hat\\sigma}\\sqrt{\\sum_{i=1}^tc_i^2/n_i} \\tag{3.4} \\end{equation}\\]  3.10, 3.12, 3.14  3.16  3.5 Bonferronis Method  FWER  \\(p\\)  \\(\\sum_{i=1}^tc_{iq}\\mu_i\\neq0,q=1,2,\\ldots,p\\) \\[\\begin{equation} \\left|\\sum_{i=1}^tc_{iq}\\hat{\\mu}_i\\right|&gt;t_{\\alpha/2p,v}{\\hat\\sigma}\\sqrt{\\sum_{i=1}^t\\frac{c_{iq}^2}{n_i}} \\tag{3.5} \\end{equation}\\]  \\(p\\)  FWER \\(\\le \\alpha\\)  \\(=\\alpha/p\\).  FWER  \\(\\alpha\\)  A.2  \\(\\alpha,p,n\\)  \\(t_{\\alpha/2p,v}\\)  \\(\\alpha = 0.05,p = 5,n = 24\\) A.2  \\(t_{\\alpha/2p,v}=2.80\\). 3.10, 3.12, 3.14  3.16  Bonferronis method  \\(m\\)  \\(p\\)   Bonferronis method  \\[\\begin{equation} \\sum_{i=1}^tc_{iq}\\hat{\\boldsymbol{\\mu}}_i\\pm t_{\\alpha/2p,v}\\hat{\\boldsymbol\\sigma}\\sqrt{\\sum_{i=1}^t\\frac{c_{iq}^2}{n_i}},\\quad q=1,2,\\ldots,p \\tag{3.6} \\end{equation}\\] Bonferronis method  3.6 Scheffés Procedure  \\(\\boldsymbol c\\) \\(H_0{:}\\,\\sum_{i=1}^tc_i\\mu_i=0\\) \\[\\Pr\\left\\{\\frac{\\left(\\sum_{i=1}^tc_i\\hat{{\\mu}}_i-\\sum_{i=1}^tc_i{\\mu}_i\\right)^2}{\\sum_{i=1}^tc_i^2/n_i}\\leq(t-1)F_{{\\alpha,t-1,v}}\\hat{\\sigma}^2\\quad\\text{ for all contrast vectors }c\\right\\}=1-\\alpha \\]  \\(\\mu_i\\)  \\(0\\)  FWER \\(=\\alpha\\)  \\(H_0{:}\\,\\sum_{i=1}^tc_i\\mu_i=0\\)  \\[\\begin{equation} \\left|\\sum_{i=1}^tc_i\\hat{\\mu}_i\\right|&gt;\\sqrt{(t-1)F_{\\alpha,t-1,v}}{\\hat\\sigma}\\sqrt{\\sum_{i=1}^tc_i^2/n_i} \\tag{3.7} \\end{equation}\\] Scheffés procedure  FWER  \\(\\alpha\\). Bonferronis method  \\(t\\)  Scheffés procedure. Bonferronis method  \\(t\\) Scheffés procedure \\(\\sum_{i=1}^tc_i\\hat \\mu_i\\)  \\(\\sum_{i=1}^tc_i\\mu_i\\) 11 Scheffés procedure Scheffés procedure  1  \\(F\\)  \\(H_0\\colon\\,\\mu_1=\\mu_2=\\cdots=\\mu_t\\). Scheffés procedure  \\(\\mu_i\\)  \\(c_1,c_2,\\dots,\\) \\((1-\\alpha)100\\%\\)  \\(\\sum_{i=1}^tc_{iq}\\mu_i\\)  \\[\\begin{equation} \\sum_{i=1}^tc_{iq}\\hat{\\mu}_i\\pm\\sqrt{(t-1)F_{\\alpha,t-1,v}}{\\hat\\sigma}\\sqrt{\\sum_{i=1}^tc_{iq}^2/n_i}\\quad\\text{ for all }q=1,2,\\ldots \\tag{3.8} \\end{equation}\\]  \\(\\mu_i\\)  (3.7)  (3.8)  \\([(t-1)F_{\\alpha,t-1,v}]\\)  \\([tF_{\\alpha,t,v}]\\).  3.10, 3.12  3.14  3.7 TukeyKramer Method  \\(n_i\\) Tukeys honest significant difference (HSD) procedure (Tukey, 1952, 1953; Kramer, 1956)  \\(n_i\\). Tukey (1953)  Kramer (1956) Hayter (1984)  TukeyKramer method  FWER  \\(n_i\\) 12 \\(i\\ne i&#39;\\)TukeyKramer method  \\(H_0{:\\mu_i}=\\mu_{i&#39;}\\) \\[\\begin{equation} \\left|\\hat{\\mu}_i-\\hat{\\mu}_{i^{\\prime}}\\right|&gt;q_{\\alpha,t,v}\\sqrt{\\frac{{\\hat\\sigma}^2}2{\\left(\\frac1{n_i}+\\frac1{n_{i^{\\prime}}}\\right)}} \\tag{3.9} \\end{equation}\\]  \\(q_{\\alpha,t,v}\\)  \\(\\alpha,t,v\\)  \\(q_{\\alpha,t,v}\\)  A.4   \\(n\\) \\(H_0\\colon\\sum_{i=1}^tc_i\\mu_i=0\\) \\[\\left|\\sum_{i=1}^tc_i\\hat{\\mu}_i\\right|&gt;q_{\\alpha,t,v}\\frac{\\hat\\sigma}{\\sqrt{n}}{\\left(\\frac12\\sum_{i=1}^t|c_i|\\right)}\\] 3.8   FWER   \\(\\mu_i\\)  \\(p\\)  \\(\\sum_{i=1}^{t}c_{iq}\\mu_{i},q=1,2,\\dots,p\\).  \\(H_{0}\\colon\\,\\sum_{i=1}^{t}c_{iq}\\mu_{i}=0,q=1,2,\\ldots,p\\)  FWER \\(\\sum_{i=1}^tc_{iq}\\mu_i\\) FWER.  59367  \\(p\\)  \\(t\\)  \\[t_q=\\frac{\\sum_{i=1}^tc_{iq}\\hat{{\\mu}}_i}{\\sqrt{\\hat{\\sigma}^2\\sum_{i=1}^tc_{iq}^2/n_i}}\\quad q=1,2,\\ldots,p\\]  \\(t_q\\)  \\(T_{s}=\\max(|t_{1}|,|t_{2}|,\\ldots,|t_{p}|)\\).  1, 2  3 \\(T_s\\)  \\(T_s\\)  \\(\\alpha100\\)  \\(T_\\alpha\\)   \\(t_q,q=1,2,\\dots,p\\) \\(|t_q| &gt;T,q=1,2,\\dots,p\\)  \\(q\\)  \\[\\sum_{i=1}^tc_{iq}\\hat{{\\mu}}_i\\pm T_\\alpha\\sqrt{{\\hat\\sigma}^2\\sum_{i=1}^tc_{iq}^2/n_i},\\quad q=1,2,\\ldots,p\\]  Edwards and Berry (1987) SAS-MULTTEST  bootstrap  (Westfall et al., 1999). Bootstrap  3.9 idák Procedure idák (1967)  Bonferronis method  \\(t\\)  \\[t_q=\\frac{\\sum_{i=1}^tc_{iq}\\hat{{\\mu}}_i}{\\sqrt{\\hat{\\sigma}^2\\sum_{i=1}^tc_{iq}^2/n_i}},\\quad q=1,2,\\ldots,p\\]  \\(p_1,p_2,\\dots p_p\\).  FWER \\(=\\alpha\\) \\(p_q\\le 1-(1-\\alpha)^{1/p}\\)  \\(\\alpha\\ge 1-(1-p_q)^p\\) 3.10  1.6  3.2  SAS-Mixed LSMeans  3.3 TukeyKramerBonferroniidákScheffé  \\(t\\) \\(t\\) \\(0.05\\)  I  FWER TukeyKramer  idák  Bonferroni  Scheffé  3.4  1  42  43  43  53  64  5 4  6 \\(t\\)  LSD  4  5 4  6  \\(t\\)  LSD  Tukey-Kramer idák  Bonferroni  idák Scheffé  FWER 15  \\(95\\%\\)  \\(\\mu_1-\\mu_2\\)  \\(95\\%\\)  \\(0.840 \\pm 6.526\\).  3.5  \\(p\\) \\(p\\)  3.4  \\(5\\%\\) .  3.2:  Proc Mixed  x  3.3:  x  3.4:  \\(t\\)  x  3.5:  TASK  _TASK  \\(t\\)  \\(t\\) x 3.11 Dunnetts Procedure Dunnetts test  \\(\\mu_i\\)  \\(\\mu_0\\)  \\[|\\hat{\\mu}_i-\\hat{\\mu}_0|&gt;d_{\\alpha,t,v}\\sqrt{{\\hat\\sigma}^2{\\left(\\frac1{n_i}+\\frac1{n_0}\\right)}}\\]  \\(d_{\\alpha,t,v}\\)  \\(t\\)  (many-to-one t-statistic)(Miller, 1967)  \\(\\alpha100\\) Dunnetts method  FWER 3.12  1.6 2 3.6  SAS-Mixed  \\(t\\)BonferroniDunnettSchefféidák  2LSMean  DIFF=CONTROL('2') 2 3.7  \\(95\\%\\) Dunnett  \\(t\\) Bonferroni  idák Scheffé  3.4 4(2) 3.8 \\(\\mu_1-\\mu_2\\)  \\(95\\%\\)  \\(0.840 \\pm 5.765\\).  3.9  \\(p\\)   3.6:  Proc Mixed  x  3.7: 2 x  3.8:  \\(t\\)  x  3.9:  \\(H_0:\\,\\mu_i = \\mu_2\\)2\\(t\\)  \\(t\\) x 3.13  \\(t\\)  \\(\\mu_i\\)  \\(t\\)  \\(p\\)  \\(q\\)  \\(\\sum_{i=1}^tc_{iq}\\mu_i\\neq0\\)  \\[\\begin{equation} \\left|\\sum_{i=1}^tc_{iq}\\hat{\\mu}_i\\right|&gt;t_{\\alpha/2,p,v}{\\hat\\sigma}\\sqrt{\\sum_{i=1}^t\\frac{c_{iq}^2}{n_i}} \\tag{3.10} \\end{equation}\\]  \\(t_{\\alpha/2,p,v}\\)  \\(v\\)  \\(\\boldsymbol I_{p}\\)  \\(p\\)  \\(t\\)  \\(\\alpha/2\\)  \\(\\alpha,p,v\\)  \\(t_{\\alpha/2,p,v}\\)  A.3  \\(t\\)  A.3  \\(m=p\\)   \\(t\\)  FWER \\(\\le\\alpha\\) \\(\\sum_{i=1}^tc_{iq}\\hat\\mu_i\\)  FWER  \\(=\\alpha\\) \\(t\\)  \\(t\\)  Bonferroni method   \\(t\\)  \\(l_1,l_2,\\dots,l_p\\)  \\(\\mu_i\\)  \\(|lq|\\le cq\\) \\[\\left|\\sum_{i=1}^p\\lambda_ql_q\\right|\\leq\\sum_{i=1}^p\\left|\\lambda_q\\right|c_q\\]   \\(l_1,l_2,\\dots,l_p\\)  \\(\\mu_i\\)  \\(l_q=\\sum_{i=1}^tc_{iq}\\mu_i\\)  \\[\\begin{equation} \\left|\\hat{l}_q\\right|&gt;t_{\\alpha/2,p,v}{\\hat\\sigma}\\sqrt{\\sum_{i=1}^tc_{iq}^2/n_i} \\tag{3.11} \\end{equation}\\]  \\(l^*\\)  \\(l_q,q=1,2,\\dots,p\\)  \\(\\lambda_q\\) \\(l^*=\\sum_{q=1}^p\\lambda_ql_q\\) \\(l^*\\)  \\[\\begin{equation} \\left|\\hat{l}^*\\right|&gt;t_{\\alpha/2,p,v}\\hat{\\boldsymbol\\sigma}\\sum_{q=1}^p\\left(\\left|\\lambda_q\\right|\\sqrt{\\sum_{i=1}^tc_{iq}^2/n_i}\\right) \\tag{3.12} \\end{equation}\\]  FWER  \\(l^*\\)  \\(t\\)  3.16  3.14   3.10  SAS-Mixed  \\[\\begin{aligned} &amp;\\mu_1-\\frac12(\\mu_2+\\mu_3),\\,\\frac13(\\mu_1+\\mu_2+\\mu_3)-\\frac13(\\mu_4+\\mu_5+\\mu_6) \\\\ &amp;\\mu_6-\\frac12(\\mu_4+\\mu_5),\\,\\frac12(\\mu_1+\\mu_6)-\\frac12(\\mu_4+\\mu_5) \\\\ &amp;\\frac12(\\mu_1+\\mu_6)-\\frac14(\\mu_2+\\mu_3+\\mu_4+\\mu_5) \\end{aligned}\\]  3.10:  Proc Mixed  x  3.11:  \\(t\\)  x  3.11  \\(t\\)Bonferroni \\(t\\)  Scheffé  \\(t\\) 2×Q×(stderr)  Q  \\(t\\)\\(Q=t_{0.025,62}=1.999\\) \\(t\\)\\(Q=t_{0.025,5,60=2.649}\\)6062 Bonferroni \\(t\\)\\(Qt_{0.025,15,62}=2.657\\) Scheffé\\(Q(5F_{0.05,5,62}=3.437\\) \\(t\\)  Bonferroni  Scheffé Bonferroni \\(t\\)  \\(t\\)Bonferronit  \\(\\le47\\)  Bonferroni  Scheffé  \\(&gt;47\\) Scheffé  Bonferroni  3.15   (sequantial)  (Westfall et al., 1999).  \\(p\\) \\(H_{0q}\\colon\\sum_{i=1}^{t}c_{iq}\\mu_{i}=0\\,\\mathrm{~vs.~}\\,H_{0q}\\colon\\sum_{i=1}^{t}c_{aq}\\mu_{i}\\neq0,q=1,2,\\ldots,p\\).  \\(p\\)  \\(t\\)  \\[t_{q}=\\frac{\\sum_{i=1}^{t}c_{iq}\\hat{\\mu}_{i}}{\\sqrt{{\\hat\\sigma}^{2}\\sum_{i=1}^{t}c_{iq}^{2}/n_{i}}},\\quad q=1,2,\\ldots,p\\]  \\(p_1,p_2,\\dots,p_p\\)  \\(p_q\\)  \\(p_{(1)}\\le p_{(2)}\\le\\cdots p_{(p)}\\). 3.15.1 BonferroniHolm Method Bonferroni-Holm  Bonferroni  (Holm, 1979).  \\(p_{(1)}&gt;\\alpha/p\\) \\(p_{(1)}&lt;\\alpha/p\\) \\(p_{(1)}\\)  \\(p_{(2)}\\)  \\(\\alpha/(p-1)\\)  \\(p_{(2)}&gt;\\alpha/(p-1)\\) \\(p_{(2)}&lt;\\alpha/(p-1)\\) \\(p_{(2)}\\)  \\(p_{(3)}\\)  \\(\\alpha/(p-2)\\)  \\(q\\)\\(p_{(q)}&gt;\\alpha/(p-q+1)\\) \\(p_{(q)}\\)  FWER Bonferroni method  \\(p\\)  3.15.2 idákHolm Method BonferroniHolm method  Holm  idák  \\(p\\)  \\[\\begin{aligned} \\tilde{p}_{(1)}&amp; =1-(1-p_{(1)})^k \\\\ \\tilde{p}_{(2)}&amp; =\\min[\\tilde{p}_{(1)},1-(1-p_{(2)})^{k-1}] \\\\ \\tilde{p}_{(j)}&amp; =\\min[\\tilde{p}_{(j-1)},1-(1-p_{(j)})^{k-j+1}] \\\\ \\tilde{p}_{(k)}&amp; =\\min(\\tilde{p}_{(k-1)},p_{(k)}) \\end{aligned}\\]  FWER  (Holland and Copenhaver, 1987). 3.15.3  FDR  Benjamini  Hochberg Method  \\(p\\)  \\(\\sum_{i=1}^{t}c_{iq}\\mu_{i},q=1,2,\\ldots,p\\).  \\(p\\)  \\(t\\)  \\[t_q=\\frac{\\sum_{i=1}^tc_{iq}\\hat{\\mu}_i}{\\sqrt{\\hat{\\sigma}^2\\sum_{i=1}^tc_{iq}^2/n_i}},\\quad q=1,2,\\ldots,p\\]  \\(p_1,p_2,\\dots,p_p\\)  \\(p_q\\)  \\(p_{(1)}\\le p_{(2)}\\le\\cdots p_{(p)}\\).  FDR FWER \\(p\\)  \\[\\begin{aligned} \\tilde{p}_{(k)}&amp; =p_{(k)} \\\\ \\tilde{p}_{(k-1)}&amp; =\\min\\{\\tilde{p}_{(k)},[k/(k-1)]p_{(k-1)}\\} \\\\ \\tilde{p}_{(k-j)}&amp; =\\min\\{\\tilde{p}_{(k-j+1)},[k/(k-j)]p_{(k-j)}\\} \\\\ \\tilde{p}_{(1)}&amp; =\\min(\\tilde{p}_{(2)},kp_{(1)}) \\end{aligned}\\] 3.16   \\(t\\)Bonferroni \\(t\\)BonferroniHolmidákdákHolm  BenjaminiHochberg  \\[\\begin{aligned} &amp;\\mu_1-\\mu_2,\\mu_1-\\frac12(\\mu_2+\\mu_3),\\mu_1-\\mu_3 \\\\ &amp;\\frac13(\\mu_1+\\mu_2+\\mu_3)-\\frac13(\\mu_4+\\mu_5+\\mu_6),\\mu_4-\\mu_5 \\\\ &amp;\\mu_6-\\frac12(\\mu_4+\\mu_5),\\frac12(\\mu_1+\\mu_6)-\\frac12(\\mu_4+\\mu_5) \\\\ &amp;\\frac12(\\mu_1+\\mu_6)-\\frac14\\left(\\mu_2+\\mu_3+\\mu_4+\\mu_5\\right) \\end{aligned}\\]  3.12  SAS-MULTTEST  \\(p\\)  \\(p\\)  3.13  Raw  \\(p\\) Bonferroni  Bonferronis  \\(p\\) Stepdown Bonferroni  Bonferroni-Holm  \\(p\\) idák  idàk  \\(p\\) Stepdownidák idèkHolm  \\(p\\) False Discovery Rate  BenjaminiHochberg  \\(p\\) idák  \\(p\\)  Bonferroni \\(t\\)  \\(p\\) Stepdown idèk  \\(p\\)  stepdown Bonferronis \\(p\\)  idàk  \\(p\\) Bonferronistepdown Bonferroniidák  stepdown Shidák  FWER   3.12:  Proc MULTTEST  x  3.13:  \\(p\\)  x  \\(t\\)  \\(\\mu_1 -1/2(\\mu_2 + \\mu_3)\\)  \\(\\mu_1 - \\mu_2\\)  \\(\\mu_1 - \\mu_3\\).  \\(\\mu_1 -1/2(\\mu_2 + \\mu_3)=1/2(\\mu_1-\\mu_2)+1/2(\\mu_1-\\mu_3)\\) 3.13 \\(l^*=\\mu_1-1/2(\\mu_2+\\mu_3)=1/2(\\mu_1-\\mu_2)+1/2(\\mu_1-\\mu_3)\\) \\(\\lambda_1=\\lambda_2=1/2\\).  \\(l^*\\)  (3.12) \\[\\begin{aligned} t_{\\alpha/2,p,v}\\hat{\\sigma}\\sum_{q=1}^{p}\\left(\\left|\\lambda_{q}\\right|\\sqrt{\\sum_{i=1}^{t}c_{iq}^{2}/n_{i}}\\right)&amp; =(2.649)(5.559){\\left(\\left|\\frac12\\right|\\sqrt{\\frac1{13}+\\frac1{12}}+\\left|\\frac12\\right|\\sqrt{\\frac1{13}+\\frac1{10}}\\right)} \\\\ &amp;=\\frac12(5.895)+\\frac12(6.194) \\\\ &amp;\\text{=6.044} \\end{aligned}\\]  \\(2\\) \\(12.088\\).  \\(t\\)Bonferroni \\(t\\)  Scheffé  \\(10.319,10.352\\) \\(13.390\\) (primary comparisonns) (secondary comparisons).  (3.12)  Scheffé  \\(t\\)  Scheffé  3.17  Duncan  StudentNewmanKeul  (multiple range tests)  FWER Westfall et al. (1999, p. 154)  3.17.1 StudentNewmanKeuls Method  \\(n_i\\) 13 \\(n\\)  \\(n_i\\)  (harmonic mean)  \\[\\tilde{n}=t\\Bigg(\\frac{1}{n_{1}}+\\frac{1}{n_{2}}+\\cdots+\\frac{1}{n_{t}}\\Bigg)^{-1}\\]  EERC EERC.  \\(t\\)  \\(\\bar{y}_{(1)}\\leq\\bar{y}_{(2)}\\leq\\cdots\\leq\\bar{y}_{(t)}\\). \\(t\\)  (Studentized range)  \\[\\frac{\\overline{y}_{(t)}-\\overline{y}_{(1)}}{{\\hat\\sigma}/\\sqrt{n}}\\]  \\(q_{\\alpha,t,v}\\)  \\[\\overline{y}_{(t)}-\\overline{y}_{(1)}\\leq\\frac{\\hat\\sigma}{\\sqrt{n}}q_{\\alpha,t,v}\\] \\(t\\)  \\[\\overline{y}_{(t)}-\\overline{y}_{(1)}&gt;\\frac{\\hat\\sigma}{\\sqrt{n}}q_{\\alpha,t,v}\\] \\(\\mu_{(t)}&gt;\\mu_{(1)}\\)  \\(t\\)  \\(\\{\\bar{y}_{(t)},\\bar{y}_{(t-1)},\\ldots,\\bar{y}_{(2)}\\}\\)  \\(\\{\\bar{y}_{(t-1)},\\bar{y}_{(t-2)},\\ldots,\\bar{y}_{(1)}\\}\\)  \\([{\\hat\\sigma}/(n)]q_{\\alpha,t-1,v}\\)  \\[\\bar{y}_{(t)}-\\bar{y}_{(2)}\\leq\\frac{\\hat\\sigma}{\\sqrt{n}}q_{\\alpha,t-1,v}\\]  \\(\\{\\mu_{(t)},\\mu_{(t-1)},\\ldots,\\mu_{(2)}\\}\\) 14 \\[\\bar{y}_{(t-1)}-\\bar{y}_{(1)}\\leq\\frac{\\hat\\sigma}{\\sqrt{n}}q_{\\alpha,t-1,v}\\]  \\(\\{\\mu_{(t-1)},\\mu_{(t-2)},\\ldots,\\mu_{(1)}\\}\\) 15  \\[\\bar{y}_{(t)}-\\bar{y}_{(2)}&gt;\\frac{\\hat\\sigma}{\\sqrt{n}}q_{\\alpha,t-1,v}\\]  \\(\\mu_{(t)}&gt;\\mu_{(2)}\\).  \\[\\bar{y}_{(t-1)}-\\bar{y}_{(1)}&gt;\\frac{\\hat\\sigma}{\\sqrt{n}}q_{\\alpha,t-1,v}\\]  \\(\\mu_{(t-1)}&gt;\\mu_{(1)}\\).  \\(\\{\\bar{y}_{(t)},\\bar{y}_{(t-1)},\\ldots,\\bar{y}_{(3)}\\},\\{\\bar{y}_{(t-1)},\\bar{y}_{(t-2)},\\ldots,\\bar{y}_{(2)}\\}\\)  \\(\\{\\bar{y}_{(t-2)},\\bar{y}_{(t-2)},\\ldots,\\bar{y}_{(1)}\\}\\).  \\([{\\hat\\sigma}/(n)]q_{\\alpha,t-2,v}\\)    1.6  \\(\\alpha=0.05\\).  \\(11.23\\).  Task 6 5 2 1 3 4 Mean 28.818 29.500 31.083 31.923 35.800 38.000 Rank 1 2 3 4 5 6  \\(38.000-28.818=9.182\\)  \\[q_{0.05,6,62}\\frac{\\hat\\sigma}{\\sqrt{\\tilde{n}}}=(4.16)\\sqrt{\\frac{30.9045}{11.23}}=6.900\\]  \\(9.819&gt;6.90\\) \\(t-1=5\\)  \\(35.800-28.818=6.982\\)  \\(38.000-29.500=8.500\\)  \\[q_{0.05,5,62}\\frac{\\hat\\sigma}{\\sqrt{\\tilde{n}}}=(3.98)\\sqrt{\\frac{30.9045}{11.23}}=6.593\\]  \\(7.619&gt;6.60,8.5&gt;6.60\\) \\(t-2=3\\)  \\(31.923 - 28.818 = 3.105,35.800 - 29.500 = 6.300,38.0 - 31.083 = 6.917\\)  \\[q_{0.05,4,62}\\frac{\\hat\\sigma}{\\sqrt{\\tilde{n}}}=(3.74)\\sqrt{\\frac{30.9045}{11.23}}=6.195\\]  \\(3.105&lt;6.195\\) \\(6.300&gt;6.195,6.917&gt;6.195\\)  {29.500, 31.083, 31.923, 35.800}  \\(29.50031.923\\)  \\(28.81831.083\\).  \\(31.923 - 29.500 = 2.423\\)  \\(31.083 - 28.818 = 2.265\\)  \\(35.800 - 31.083 = 4.717\\)  \\(38.0 - 31.923 = 6.077\\) \\[q_{0.05,3,62}\\mathrm{~}\\frac{\\hat\\sigma}{\\sqrt{\\tilde{n}}}=(3.40)\\sqrt{\\frac{30.9045}{11.23}}=5.635\\]  \\(4.717 &lt; 5.635\\) \\(6.077 &gt; 5.635\\)  2  {35.8, 38.0}  \\(38.0 - 35.8 = 2.2\\)  \\[q_{0.05,2,62}\\frac{{\\hat\\sigma}}{\\sqrt{\\tilde{n}}}=(2.83)\\sqrt{\\frac{30.9045}{11.23}}=4.691\\]  \\(2.2&lt;4.69\\)  Task Mean 1 31.923 bc 2 31.083 bc 3 35.800 ab 4 38.000 a 5 29.500 c 6 28.818 c 3.17.2 Duncans New Multiple Range Method  Duncans method Fishers LSD method Duncans method  FWER \\(n_i\\)  \\(n\\)  \\(\\tilde n\\).  Student-Newman-Keul method  \\(p\\)  \\(q_{\\alpha,p,v}\\)  \\(q_{\\alpha_p,p,v}\\) \\(\\alpha_p=1-(1-\\alpha)^{p-1}\\). \\(q_{\\alpha_p,p,v}\\)  A.5   \\(38.000 - 28.818 = 9.182\\)  \\[q_{\\alpha_{6},6,62}\\frac{\\hat\\sigma}{\\sqrt{\\tilde{n}}}=(3.198)\\sqrt{\\frac{30.9045}{11.23}}=5.303\\]  \\(\\alpha_6=1-(1-0.05)^{6-1}=0.226\\).   \\(35.800 - 28.818 = 6.982\\)  \\(38.000 - 29.500 = 8.500(3.143)(1.659) = 5.213\\)  \\[q_{\\alpha_5,5,62}\\frac{\\hat\\sigma}{\\sqrt{\\tilde{n}}}=(3.143)\\sqrt{\\frac{30.9045}{11.23}}=5.214\\]  \\(\\alpha_5=1-(1-0.05)^{5-1}=0.186\\).   \\(31.923 - 28.818 = 3.105\\)\\(35.800 - 29.500 = 6.300\\)  \\(38.000 - 31.083 = 6.917\\)  \\((3.073)(1.659) = 5.098\\)   \\(35.800 - 31.083 = 4.717\\)\\(38.000 - 31.923 = 6.077\\)  \\((2.976)(1.659) = 4.937\\)   \\(38.000 - 35.800 = 2.200\\)  \\((2.829)(1.659) = 4.693\\)   Student-Newman-Keuls method  Duncans method Duncans method  FWER  3.18 WallerDuncan Procedure  \\(n_i\\)Waller-Duncan procedure  Tukey-Kramer Fishers LSD \\(F\\)  \\(H_{0}\\colon\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}\\).  \\(F\\)  Waller-Duncan procedure  \\(F\\) Waller-Duncan procedure  (error rate ratio)  \\(K\\) I  II \\(K\\)  I  \\(\\alpha\\) \\(K\\) 0.10 50 0.05 100 0.01 500  \\(K,n,t\\)  \\(H_{0}\\colon\\mu_{1}=\\mu_{2}=\\cdots=\\mu_{t}\\)  \\(F\\)  Ott (1988)  WallerDuncan LSD LSD  Fishers LSD procedure  TukeyKramer HSD procedure  SAS-GLM  Means/Waller  WallerDuncan LSD  3.19  DuncanStudentNewmanKeul  WallerDuncan  SAS-GLM  Means  3.14  GLM  Means  3.15  Duncans  \\(5.096\\)  \\(A,B,C\\)   3.14:  DucanStudentNewmanKuels  WallerDuncan  GLM  x  3.15:  Duncans  x :  I   3.16  StudentNewmanKeuls method StudentNewmanKeuls method  Duncans method  StudentNewmanKeuls method  Duncans method  3.17  WallerDuncan method  \\(4.448\\) 3.4  \\(t\\)  \\(F\\)   3.16: SNK  x :  I   3.17: Waller-Duncan  x :  3.20   \\(2\\) \\(50\\)  Treatment 1 2 3 4 \\(\\hat\\mu_i\\) 39.3 40.1 42.0 43.0 \\(n_i\\) 2 25 25 2  \\(F\\)  \\(4.90\\) \\(0.005\\) \\(\\mu_1\\)  \\(\\mu_2\\)\\(\\mu_1\\)  \\(\\mu_3\\)\\(\\mu_2\\)  \\(\\mu_4\\)  \\(\\mu_3\\)  \\(\\mu_4\\)  \\(5\\%\\) LSD \\((2.008)(2)(1/2+1/25)=2.951\\).  \\(\\mu_1\\)  \\(\\mu_4\\)  \\(5\\%\\) LSD \\((2.008)(2)(1/2+1/2)=4.016\\) \\(\\mu_2\\)  \\(\\mu_3\\)  \\(5\\%\\) LSD \\((2.008)(2)(1/25+1/25)=1.136\\).  \\(\\hat\\mu_1-\\hat\\mu_4=3.7\\)  \\(\\hat\\mu_2-\\hat\\mu_3=1.9\\)  \\(\\mu_2\\)  \\(\\mu_3\\)  3.21   \\(F\\)  \\(F\\)  \\(\\alpha\\)  \\(F\\)  \\(\\alpha\\)  Fishers protected LSD 2  SAS-Mixed  LSMeans  REPEATED  3.22   100% significance level.   That is, a smaller value of \\(\\sum_{i=1}^tc_i\\hat \\mu_i\\) can often enable one to declare that \\(\\sum_{i=1}^tc_i\\mu_i\\) is significantly different from zero using Bonferronis method or the multivariate t-method than can be declared significant by Scheffés method.  : not too unequal. : not too unequal.  significant   significant  "],["chap4.html", " 4   4.1  4.2  4.3  4.4  4.5 ", "  4    the null hypothesis is never proved or established, but is possibly disproved, in the course of experimentation. Every experiment may be said to exist only to give the facts a chance of disproving the null hypothesis. - R. A. Fisher  (treatment structure)  (design structure) (replication) (block)  (experimental unit)  (size) (completely randomized, CRD) (randomized complete block, RCBD) (incomplete block, IBD) (Latin square, LSD) \\(n\\)  (observations that are treated alike)  (split-plot) (repeated measures) (strip-plot)  (crossover designs )  5  (nesting)  5  4.1      0102030405060708090  100% 100%100%100% 20%30%40%  50% 105010%50%115020304050%0%   5  5      \\(t\\)  \\(r\\)  \\(y_{ij}\\)  \\(i\\)  \\(j\\)  \\(y_{ij}\\)  \\[\\begin{equation} y_{ij}=\\mu_i+\\varepsilon_{ij}\\quad\\mathrm{for~}i=1,2,\\ldots,t,\\mathrm{~and~}j=1,2,\\ldots,r \\tag{4.1} \\end{equation}\\]  \\(\\mu_i\\)  \\(i\\) \\(\\varepsilon_{ij}\\)  \\(rt\\)  \\(r\\)  (permutation analysis)  (Kempthorne, 1952).   (conceptual population) (inference)  (conjecture)   (homogeneous)  \\(rt\\)  \\(\\varepsilon_{ij}\\)  Milliken and Johnson (2001)  (analysis of covariance) (block) (covariate)   \\(r\\)  \\(t\\)  \\(j\\)  \\(i\\)  \\[\\begin{equation} y_{ij}=\\mu_i+b_j+\\varepsilon_{ij}^*\\quad\\mathrm{~for~}i=1,2,\\ldots,t,\\mathrm{~and~}j=1,2,\\ldots,r \\tag{4.2} \\end{equation}\\]  (4.2) (4.1)  \\(\\varepsilon_{ij}\\)s  \\(\\varepsilon_{ij} = b_j + \\varepsilon_{ij}^*\\) \\(\\varepsilon_{ij}^*\\)  (within-block variation)  (contrasts)   (within-block differences)  \\[\\begin{aligned} y_{ij}-y_{i^{\\prime}j}&amp; =(\\mu_i+b_j+\\varepsilon_{ij}^*)-(\\mu_{i^{\\prime}}+b_j+\\varepsilon_{i^{\\prime}j}^*) \\\\ &amp;=\\mu_i-\\mu_{i^{\\prime}}+\\varepsilon_{ij}^*-\\varepsilon_{i^{\\prime}j}^* \\end{aligned}\\]  \\(b_j\\) (between-block variation)   \\(t\\)  \\(t\\)  \\(\\varepsilon_{ij}\\)  \\(\\varepsilon_{ij}^*\\)  (replications)  \\(10\\)  (duplicate)  (split samples)  (replications) (sub-samples)  (repeated measures).   \\(22,000\\)  \\(100\\)  \\(100\\)  \\(100\\)  \\(100\\)  \\(200\\)  \\(100\\)  \\(100\\)  \\(100\\)  \\(200\\)  \\(100\\)  (variability)  \\(100\\)  \\(100\\)  \\(100\\)  \\(100\\)  \\(100\\)  \\(100\\)   \\(9\\)  \\(10\\)  \\(10\\)  \\(10\\)  \\(10\\)  (within-cake variation)  (experimental-unit-to-experimental-unit variation)  (cake-to-cake variation)  \\(10\\)  \\(10\\)  \\(10\\)  \\(10\\)  \\(10\\)   \\(10\\)   (strip trial) (rows)a group of rows 4.1  (strip plot)16 (randomized complete block design structure)  \\(20\\)  (parts)  \\(100\\)  (strips)  \\(F\\)   4.1:  4.2   (designed experiment)   4.1   (treatment structure) /  (arrangement)   4.2   (design structure)   (completely randomized design structure).  (interact).   12 3 4.2   4.2:   (nuisance factors) (Cobb, 1997).  (Milliken and Johnson, 2001).   4.2.1   (complete block)  (incomplete block) 4.3   (Completely randomized design structure).  (Milliken and Johnson, 2001).  (Randomized complete block design).  \\(t\\)  \\(t\\)  (block size)  \\(t\\) \\(t\\)  \\(t=5\\)  \\(8\\) (balanced) 4.3  \\(8\\)  \\(c\\times t\\)  \\(c\\)  \\(c\\)   4.3:  \\(8\\)   (Latin square design).  \\(t\\) \\(t^2\\)  \\(t\\times t\\)  (square) (row blocks) (column blocks) \\(t\\times t\\)  (blocked) Cochran and Cox (1957) GraecoLatin  (Cochran and Cox, 1957).  (Incomplete block design) (balanced incomplete blocks)  (partially balanced incomplete blocks).  5  4.5   (Various combinations and generalizations).  4.2.2   4.3   (One-way treatment structure).  \\(t\\) 120130150160°C (factorial)  13   (Two-way treatment structure).  (levels)  (possibilities)  \\(s\\)  \\(r\\)  \\(sr\\)  4.4  \\(A\\)  \\(B\\)  \\(12\\)   4.4:  \\(A\\)  \\(B\\)  \\(12\\)   (Factorial arrangement treatment structure).  \\(n\\) \\(n\\)  \\(n\\)  \\(s_1,s_2,\\dots,s_n\\)  \\(s_1\\times s_2\\times\\dots\\times s_n\\)   (Fractional factorial arrangement treatment structure).  (fraction) \\(8\\)  \\(2^8\\)  (one-fourth fraction) 64 \\(2^{8-4}\\)  Milliken and Johnson (1989).  \\(n\\) \\(n\\)  \\(n\\)  (cells)  \\(n^3\\)  \\(n^2\\) \\(n^3\\)  \\(1/n =(n^2/n^3)\\)   (Optimal design treatment structures) (St. John and Draper, 1975)   (Factorial arrangement with one or more controls).  \\(c\\)  4.5  \\(A\\)  \\(B\\)   4.5:   4.5   5  4.3   Cochra and Cox (1957), Davies (1954), Federer (1955), Hicks (1993), John (1971), Kirk (1968), Cornell (1990), Anderson and McLean (1974), Box et al. (1978), Cobb (1997), Kempthorne (1952), Laundsby and Weese (1993), Lentner and Bishop (1986), Meed (1988), Montgomery (1991) and Winer (1971).  4.2  4.3.1  4.1:   \\(20\\)  \\[\\begin{equation} y_{ij}=\\mu_i+\\varepsilon_{ij}\\quad i=1,2,\\ldots,t,j=1,2,\\ldots,n_i \\tag{4.3} \\end{equation}\\]  \\(\\mu_i\\)  \\(i\\) \\(\\varepsilon_{ij}\\)  (4.3)  4.1 \\(\\varepsilon_{ij}\\sim \\text{i.i.d.}\\,N(0,\\sigma^2)\\).  4.1  (4.3)  \\(15\\)  1 \\(15\\)  2   4.1:  x  \\[\\begin{equation} y_{ij}=\\mu_i+b_j+\\varepsilon_{ij}\\quad i=1,2,3,4,5,j=1,2,3,4 \\tag{4.4} \\end{equation}\\]  \\(\\mu_i\\)  \\(i\\) \\(b_j\\)  \\(j\\) \\(\\varepsilon_{ij}\\)  \\(j\\)  \\(i\\)  (4.4)  4.2  \\[\\begin{array}{ll}q_{1j}=y_{1j}-y_{2j}&amp;j=1,2,3,4\\\\q_{2j}=y_{1j}+y_{2j}-2y_{3j}&amp;j=1,2,3,4\\\\q_{3j}=y_{1j}+y_{2j}+y_{3j}-3y_{4j}&amp;j=1,2,3,4\\\\q_{4j}=y_{1j}+y_{2j}+y_{3j}+y_{4j}-4y_{5j}&amp;j=1,2,3,4\\end{array}\\]  4.2:  x  \\(i\\)  \\(q_{ij}\\)  \\(q_{ij}\\)  \\(12\\) \\(q_{ij}\\)  (pooling)  \\(j = 1, 2, 3, 4\\) \\(\\text{Var}(q_{1j}) = 2\\sigma^2,\\text{Var}(q_{2j})= 6\\sigma^2,\\text{Var}(q_{3j})= 12\\sigma^2\\)  \\(\\text{Var}(q_{4j})= 20\\sigma^2\\) \\(q_{ij}\\)  \\(\\sigma^2\\)  (block-by-treatmen interaction)   \\(20\\)  \\(10\\)  \\(10\\)  \\(10\\)  \\[\\begin{equation} y_{ijk}=\\mu_{i}+b_{j}+\\boldsymbol{\\varepsilon}_{ijk}\\quad i=1,2,3,4,5,j=1,2,k=1,2 \\tag{4.5} \\end{equation}\\]  \\(\\mu_i\\)  \\(i\\) \\(b_j\\)  \\(j\\) \\(\\varepsilon_{ijk}\\)  \\(j\\)  \\(i\\)  \\(k\\)  (4.5)  4.3  4.1  \\((2-1)×(5-1)=4\\).  \\(10\\)  \\(14\\)   4.3:  x  (interact) (Milliken and Johnson, 2001).  \\(10\\)  (4.5)  \\[\\begin{equation} y_{ijk}=\\mu_{ij}+\\varepsilon_{ijk}\\quad i=1,2,\\ldots,5,j=1,2,k=1,2 \\tag{4.6} \\end{equation}\\]  \\(\\mu_{ij}\\)  \\(ij\\) \\(\\varepsilon_{ijk}\\)  \\(\\mu_{ij}\\)  \\[\\mu_{ij}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij}\\]  \\(\\mu\\) 17(overall mean)\\(\\tau_i\\)  \\(i\\) \\(\\beta_j\\)  \\(j\\) \\(\\gamma_{ij}\\)  4.4  (4.6)  \\(\\mu_{ij}\\)   4.4:  x  4.6 ×× \\[\\begin{equation} y_{ijk}=\\mu_{ij}+\\varepsilon_{ijk}\\quad i=0,1,2,3,4,j=1,2,k=1,2 \\tag{4.7} \\end{equation}\\]  \\(\\mu_{01}\\)  \\(\\mu_{02}\\)  \\(\\mu_{ij},i = 1, 2, 3, 4, j = 1, 2\\)  4.5  (4.7)  Control vs 22  6   4.5:  x  4.6:  4.3.2  4.2:   Cochran and Cox, 1957 4.6   4.6:  x  \\[\\begin{equation} y_{ijk}=\\mu_i+h_j+d_k+\\boldsymbol{\\varepsilon}_{ijk}\\quad i=1,2,3,4,j=1,2,3,4,k=1,2,3,4 \\tag{4.8} \\end{equation}\\]  \\(\\mu_i\\)  \\(i\\) \\(h_j\\)  \\(j\\) \\(d_k\\)  \\(k\\) \\(\\varepsilon_{ijk}\\)  4.7  (4.8)   4.7:  x  12 +  I3 +  II 4 +  I + II[] I[] II 4.8.  4.8:  x  \\[\\begin{equation} y_{ijkm}=\\mu+\\gamma_i+\\beta_j+(\\gamma\\beta)_{ij}+h_k+d_m+\\varepsilon_{ijkm}\\quad i=1,2,\\quad j=1,2,\\quad k=1,2,3,4,\\quad m=1,2,3,4 \\tag{4.9} \\end{equation}\\]  \\(\\gamma_i\\)  I \\(b_j\\)  II \\((gb)_{ij}\\)  4.9  (4.9)  (4.8)  (4.9)  (4.9)  I II  I  II   4.10 - 4.8  \\[\\begin{align} y_{ijkmn}&amp;=\\mu+\\gamma_i+\\beta_j+(\\gamma\\beta)_{ij}+s_k+h_{n(k)}+d_m+\\varepsilon_{ijkmn}\\\\ i&amp;=1,2,\\,j=1,2,\\,k=1,2,\\,m=1,2,3,4,\\,n=1,2,3,4 \\tag{4.10} \\end{align}\\]  \\(s_k\\)  \\(k\\) \\(h_{n(k)}\\)  \\(k\\)  \\(n\\)  (4.10)  4.11   4.9:  x  4.10:  x : Square 1  Square 2   4.11:  x : Square  4.3.3  4.3:   (block)  I  II  \\(25\\)  \\(25\\)  \\(0.2cm\\) \\(1 m^2\\)  \\(25\\)  \\(25\\)  \\(5^3\\)  I ×  II ×  \\(125\\)  \\(25\\)  (Latin square arrangement)  (Latin square treatment structure).  (partially aliased) Cochran and Cox, 1957, p. 245 4.12  \\[\\begin{align} y_{ijk}&amp;=\\mu+\\mathrm{AI}_i+\\mathrm{AII}_j+T_k+\\varepsilon_{ijk},\\quad(i,j,k)\\in\\mathrm{Index} \\tag{4.11} \\end{align}\\]  \\(\\mathrm{AI}_i\\)  I  \\(i\\) \\(\\mathrm{AII}_j\\)  II  \\(j\\) \\(T_k\\)  \\(k\\) \\(\\mathrm{Index}\\)  \\(25\\)   4.12:  \\(T_i\\)  \\(i\\)  x  4.13  4.14. AI  AII  \\(16\\)  AI  AII  4.15  AI  AII  (aliased).  AI  AII  AII  AI  4.16  (4.11)  (residual)  (error) \\(F\\)   4.13:  I  II  x  4.14:  x  4.15:  x  4.16:  x 4.3.4  4.4:  i) ii)  iii)  (N)  (K)  \\(12\\) \\(3\\)  × \\(4\\)  \\(12\\)  (plots).  (replications) (replications)  4.5  \\[\\begin{equation} y_{ijk}=\\mu_{ij}+b_{k}+\\boldsymbol{\\varepsilon}_{ijk}\\quad i=1,2,3,j=1,2,3,4,k=1,2,3 \\tag{4.12} \\end{equation}\\]  \\(\\mu_{ij}\\)  \\(i\\)  \\(j\\) \\(b_k\\)  \\(k\\) \\(\\varepsilon_{ijk}\\)  \\[\\begin{equation} Y= \\mathrm{treatment structure} + \\mathrm{design structure} + \\mathrm{error structure(s)} \\tag{4.13} \\end{equation}\\]  4.17  (4.13)  4.18  (4.12)  5   4.17:  x  4.18:  x 4.3.5  4.5:   (confusion) (Cochran and Cox, 1957).  4.19  4.19  4.19  4.19  \\[\\begin{equation} y_{ij}=\\mu_i+b_j+\\boldsymbol{\\varepsilon}_{ij},\\quad\\mathrm{for~}(i,j)\\in\\mathrm{Index} \\tag{4.14} \\end{equation}\\]  \\(\\mathrm{Index}=\\{(A, 1), (B, 1), (A, 2), (C, 2), (A, 3), (D, 3), (B, 4), (C, 4), (B, 5), (D, 5), (C, 6), (D, 6)\\}\\) \\((i,j)\\)  ×  4.20  (4.14) 18- (connected block-treatment) 19 4.21 - X  \\((6-1)(4-1)=15\\)  \\(12\\)  \\(15-12=3\\).  4.19:  x  4.20:  4.19  x  4.21:  \\(X\\)  \\(12\\)  x  4.22  \\(A\\)  \\(B,C,D\\) 4.14 \\[\\mathrm{Index}=\\{(A, 1), (B, 1), (A, 2), (C, 2), (A, 3), (D, 3), (A, 4), (B, 4), (A, 5), (C, 5), (A, 6), (D, 6)\\}\\]  4.22:  x  4.20  4.22  \\(\\mu_A = \\mu_B = \\mu_C = \\mu_D\\) 4.19  D-St. John and Draper, 1975 \\(A\\)  \\(\\mu_A = \\mu_B,\\mu_A = \\mu_C,\\mu_A = \\mu_D\\) 4.22   4.23  \\(A\\)  \\(B\\)  \\(C\\)  \\(D\\)  \\(A\\)  \\(C\\)  \\(D\\)  (not connected) (group)  \\(1,3,5\\)  \\(2,4,6\\)  (between-block comparisons).  \\(A\\)  \\(B\\)  \\(C\\)  \\(D\\)  (within-block comparisons).  \\(A\\)  \\(B\\) \\(C\\)  \\(D\\) 4.23  4.24 \\(\\mu_A + \\mu_B = \\mu_C + \\mu_D\\) (confounded)  (aliasing)   4.23:  x  4.24:  4.23  x  4.194.22  4.23  4.3.6  4.6 Cochran and Cox, 1957 \\(A\\)  \\(B\\)  \\(24\\)  \\(4\\)  4.25  \\[\\begin{align} y_{ijkm}&amp;=\\mu+\\alpha_i+\\beta_j+(\\alpha\\beta)_{ij}+r_k+c_m+(rc)_{km}+\\varepsilon_{ijkm}\\\\ i&amp;=1,2,j=1,2,k=1,2,m=1,2,3 \\tag{4.15} \\end{align}\\]  \\(\\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij}\\)  A  B \\(r_k\\) \\(c_m\\) \\((rc)_{km}\\) \\(\\varepsilon_{ijkm}\\)  (4.15)  4.26.  A × A × A ×  × B × B × B ×  × A × B × A × B ×  A × B ×  ×   4.25:  x  4.26: - x  4.4   4.5    4.1   \\(\\mu\\)  Stroup (2012) xxi  P.54  Note.  6.3.2  The degrees of freedom associated with this connected blocktreatment arrangement are computed from the degrees of freedom associated with the block by treatment interaction as if all combinations were observed minus the number of empty cells. "],["chap5.html", " 5   5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8 ", "  5   We must be careful not to confuse data with the abstractions we use to analyze them. - William James  (size)  5.1   (multilevel designs structures) (split-plot)  (strip-plot)  (repeated measures)  (hierarchical)  (nested)  24  25  26 - 28  30   (completely randomized design structure) (randomized complete block design structure) (split-plot design structure)  (strip-plot design structure).  18   (cupcake)  3  18  5.1  18  (oven)  18  18  2  \\(12\\)  \\[y_{ijk}=\\mu+\\tau_{i}+\\beta_{j}+(\\tau\\beta)_{ij}+\\varepsilon_{ijk},\\quad i=1,2,j=1,2,3,\\mathrm{and}\\,k=1,2,3\\]  \\(y_{ijk}\\)  \\(j\\)  \\(i\\)  \\(k\\) \\(\\mu\\) \\(\\tau_i\\)  \\(i\\) \\(\\beta_j\\)  \\(j\\) \\((\\tau\\beta)_{ij}\\)  \\(\\varepsilon_{ijk}\\)  5.1  12  5 12  5.1  \\(EMS\\)  \\(\\phi^2(\\tau),\\phi^2(\\beta),\\phi^2(\\tau\\beta)\\)   5.1:   5.1:  x  5.2  5.2  4  (3 - 1)(6 - 1) = 10  10  \\[y_{ijk}=\\mu+\\tau_i+\\beta_j+(\\tau\\beta)_{ij}+d_k+\\varepsilon_{ijk},\\quad i=1,2,~j=1,2,3,~\\mathrm{and~}~k=1,2,3\\]  \\(d_k\\)  \\(k\\) \\(\\varepsilon_{ijk}\\)  5.2  10  5  12  5.2  \\(\\sigma^2_{day}\\)  \\(d_k\\) \\(k = 1, 2, 3\\).   5.2:   5.2:  x  18  5.3  5.3  5.3   5.3:   (whole-plot)  (subplot)   5.4  \\[y_{ik}^*=\\mu+\\tau_i+e_{ik},\\quad i=1,2,\\mathrm{~and~}k=1,2,3\\]  \\(y_{ik}^*\\)  \\(i\\)  \\(k\\) \\(\\varepsilon_{ik}\\)  5.3   5.4:   5.3:  x  5.5  \\[y_{ijk}=\\mu+\\beta_j+o_{ik}+\\varepsilon_{ijk}^*,\\quad i=1,2,\\quad j=1,2,3,\\mathrm{~and~}\\quad k=1,2,3\\]  \\(o_{ik}\\) \\(\\varepsilon_{ijk}^*\\)  5.4  5.4 ? (reduction).  1  5.6  1 5.5  2  (computing the oven by recipe interaction within a temperature pooled across temperatures).  5.6  \\[y_{ijk}=\\mu+\\tau_i+\\beta_j+(\\tau\\beta)_{ij}+o_{ik}+\\varepsilon_{ijk},\\quad i=1,2,~j=1,2,3,\\mathrm{~and~}~k=1,2,3\\]  \\(o_{ik}\\) \\(\\varepsilon_{ijk}\\)  5.6  5  12  4  8   5.5:   5.4:  x  5.6: 1  5.5: 1 x  5.6:  x  5.7  \\[y_{iik}=\\mu+\\tau_i+\\beta_j+(\\tau\\beta)_{ij}+d_k+o_{ik}+\\varepsilon_{iik},\\quad i=1,2,~j=1,2,3,~\\mathrm{and~}~k=1,2,3\\]  \\(d_k\\) \\(o_{ik}\\) \\(\\varepsilon_{ijk}\\)  5.7 error (oven)  error (cupcake)   5.7:   5.7:  x  5.8  (partially balanced incomplete block)  5.8:    5.9  1  2   5.9:   5.9  5.8  error (oven)  5.9  error (batch)  (contrasts that are free of the row effects and free of the column effects) \\[y_{ijk}=\\mu+\\tau_i+\\beta_j+(\\tau\\beta)_{ij}+d_k+o_{ik}+b_{jk}+\\varepsilon_{ijk},\\quad i=1,2,\\quad j=1,2,3,\\mathrm{~and~}\\quad k=1,2,3\\]  \\(d_k\\) \\(o_{ik}\\) \\(b_{jk}\\) \\(\\varepsilon_{ijk}\\)  5.10 12 error (oven) error (batch)  error (cupcake).   5.8:  x  5.9:  x  5.10:  x  20 *   18  18  18  18   5.11   5.11:  x   4   5.2   18 5.2   \\[y_{ijkm}=\\mu+\\tau_i+c_{ij}+\\beta_k+(\\tau\\beta)_{jk}+\\varepsilon_{ijkm},\\quad i=1,2,j=1,2,3,k=1,2,m=1,2,\\ldots,n_{ijk}\\]  \\(y_{ijkm}\\)  \\(i\\)  \\(j\\)  \\(k\\)  \\(m\\) \\(\\mu\\) \\(\\tau_i\\) \\(c_{ij}\\)  \\(i\\)  \\(j\\)  \\(\\beta_k\\)  \\(k\\) \\((\\tau\\beta)_{jk}\\) \\(\\varepsilon_{ijkm}\\)  5.12  18  \\(k_1\\)  \\(k_2\\)  18   5.12:  x 5.3   5.3.1  5.1  15  (rows)  5.10  (box)  \\[y_{ij}=\\mu_i+r_{ij},\\quad i=1,2,3,4,5,\\quad j=1,2,3\\]  \\(\\mu_i\\)  \\(i\\) \\(r_{ij}\\)  \\(j\\)  \\(i\\)  5.13  error (row)  error (row)  10   5.10:   5.13:  x  5.11  5.11  5.14   5.11:   5.14:  x  [ Milliken &amp; Johnson, 1989; Millikan &amp; Graybill,1970; Johnson &amp; Grayboll, 1972  (two-way non-replicated experiment techniques) ]  (batch) 5.12   5.12: 115  5.15   5.15:  x  5.13  error (row)  1 2 1  1  (3-1)*(3-1)=4  (obtained by pooling the row by cooking method interaction sum of squares within a variety across the five varieties) error (batch)  20  \\[y_{ijk}=\\mu_{ik}+r_{ij}+\\varepsilon_{ijk},\\quad i=1,2,3,4,5,j=1,2,3,k=1,2,3\\] \\(\\mu_{ik}\\)  \\(k\\)  \\(i\\) \\(r_{ij}\\)  \\(i\\)  \\(j\\)  \\(N(0,\\sigma^2_{\\mathrm{row}})\\) \\(\\varepsilon_{ijk}\\)  \\(k\\)  \\(i\\)  \\(j\\)  \\(N(0,\\sigma^2_{\\mathrm{batch}})\\) \\(r_{ij}\\)  \\(\\varepsilon_{ijk}\\)   \\(\\mu_{ik}\\)  \\[\\mu_{ik}=\\mu+\\upsilon_i+\\omega_k+(\\upsilon\\omega)_{ik}\\]  \\(\\mu\\) \\(\\upsilon_i\\)  \\(i\\) \\(\\omega_k\\)  \\(k\\) \\((\\upsilon\\omega)_{ik}\\)  \\[\\begin{aligned}y_{ijk}=&amp;\\mu+\\upsilon_i+r_{ij}\\,&amp;&amp;\\text{\\}row part of model}\\\\&amp;+\\omega_k+(\\upsilon\\omega)_{ik}+\\varepsilon_{ijk}\\,&amp;&amp;\\text{\\}batch part of model}\\end{aligned}\\]  5.16   5.16:  x  5.3.2  5.2  (variety) [ (roll gap)] 15  (runs) (day)  15  15  5.13  \\[y_{ij}=\\mu+R_i+d_j+e_{ij},\\quad i=1,2,3,j=1,2,3,4,\\mathrm{~where~}d_j\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_{\\mathrm{day}}^2)\\mathrm{~and~}e_{ij}\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_{\\mathrm{run}}^2)\\]  \\(R_i\\) \\(d_j\\)  (random day effect)\\(e_{ij}\\)  5.17  1.5mm 5.18  1.5mm  12  12  36  variety × day (roll gap) (variety by day interaction pooled across the levels of roll gap).  5.13:   5.17:  x  5.18: 1.5mm x  \\[y_{ijk}=\\mu+R_i+d_j+e_{ij}+V_k+(RV)_{ik}+\\varepsilon_{ijk},\\quad i=1,2,3,\\quad j=1,2,3,4,\\quad k=1,2,\\ldots,5,\\]  \\[d_j\\thicksim i.i.d.\\mathrm{~}N(0,\\sigma_{\\mathrm{day}}^2)\\text{, }e_{ij}\\thicksim i.i.d.\\mathrm{~}N(0,\\sigma_{\\mathrm{run}}^2)\\text{, and }\\varepsilon_{ijk}\\thicksim i.i.d.\\mathrm{~}N(0,\\sigma_{\\mathrm{batch}}^2)\\] \\(R_i\\)  \\(i\\) \\(V_k\\)  \\(k\\) \\((RV)_{ik}\\) \\(\\varepsilon_{ijk}\\) \\(\\mu+R_i+d_j+e_{ij}\\)  \\(V_k+(RV)_{ik}+\\varepsilon_{ijk}\\).  5.19   5.19:  x 5.3.3  5.3  (bread)  5.14  (day)  (oven)  5.20  5.14  \\[y_{ij}=\\mu+T_i+d_j+o_{ij},\\quad(i,j)\\in\\{(1,1),(2,1),(1,2),(3,2),(2,3),(3,3),(1,4),(3,4),(2,5),(3,5),(1,6),(2,6)\\}\\]  \\[d_j\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{day}}^2)\\quad\\mathrm{and}\\quad o_{ij}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{oven}}^2)\\]  \\((i,j)\\)  5.21. III 10   5.20  (3-1)(6-1)=10  10-6=4  160°C  5.22  5.22  160°C 160°C  5.23  error (bread)  \\[\\begin{aligned} &amp;y_{ijk}=\\mu+T_i+d_j+o_{ij}+R_k+(TR)_{ik}+\\varepsilon_{ijk} \\\\ &amp;(i,j)\\in\\{(1,1),(2,1),(1,2),(3,2),(2,3),(3,3),(1,4),(3,4),(2,5),(3,5),(1,6),(2,6)\\},k=1,2 \\end{aligned}\\]  \\[d_j\\thicksim N(0,\\sigma_\\mathrm{day}^2),\\quad o_{ij}\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_\\mathrm{oven}^2)\\quad\\mathrm{and}\\quad\\varepsilon_{ijk}\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_\\mathrm{loaf}^2)\\]  5.14:   5.20:  x : X   5.21: (EMS)III x  5.22: 160°C  x  5.23:  x  5.24IIIIII \\(\\mu+T_i+d_j+o_{ij}\\) \\(R_k+(TR)_{ik}+\\varepsilon_{ijk}\\).   5.24: (EMS)III 10  x 5.3.4  5.4 temperature, Tpackaging, Plightning, Lintensity, I (cooler) 135°C 5.15   4×4  16  (partitions) 5.16 (column)  5.16   5.15:   5.16:  T  \\[y_{ij}=\\mu+T_i+c_{ij},\\quad i=1,2,3,j=1,2,\\mathrm{~and~}c_{ij}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{cooler}}^2)\\]  5.25  (computed from the variation of the two coolers within a temperature, pooled across the three temperatures). error (cooler)   5.25:  x I  1°C  1°C  5.17 I  \\[y_{1jk}=\\mu+I_k+c_{1j}+d_{1jk},\\quad j=1,2,\\,k=1,2,3,4,\\,c_{1j}\\sim i.i.d. N(0,\\sigma_{\\mathrm{cooler}}^2)\\,\\mathrm{~and~}\\,d_{1jk}\\sim i.i.d.N(0,\\sigma_{\\mathrm{colum}n}^2)\\]  5.17  error (column) error (column)  intensity × cooler (temperature)  (intensity by cooler interaction pooled across the levels of temperature).  5.17:  1  L  24  1°C  I1  5.18  5.18  5.18  \\[\\begin{aligned}y_{1j1m}&amp;=\\mu+L_m+d_{1j1}^*+p_{1j1m},\\quad j=1,2,m=1,2,3,4,d_{1j1}^*\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{column}}^{2^*})\\mathrm{~and}\\\\p_{1j1m}&amp;\\sim i.i.d.N(0,\\sigma_{\\mathrm{partition}}^2)\\end{aligned}\\]  \\(d_{1j1}^*\\)  (the combination of cooler and column of that cooler effect).  5.18  12  error (partition)  12  error (partition)  36 error (partition)  light × intensity × cooler (temperature).  5.18:  1  1   (half-partitions) P 96  1°C I1  L1  5.19  5.19  \\[\\begin{aligned}y_{1j11n}&amp;=\\mu+P_n+p_{1j1n}^*+\\varepsilon_{1j11n},\\quad j=1,2,n=1,2,p_{1j1m}^*\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{partition}}^{2*})\\quad\\mathrm{and}\\\\\\varepsilon_{1j11n}&amp;\\sim i.i.d.N(0,\\sigma_{\\frac12\\text{partition}} ^ 2 ) \\end{aligned}\\]  5.19  48  48  error (half-partition)  48 error (half-partition)  packaging × light × intensity × cooler (temperature).  5.19:  1 1  1   \\[\\begin{aligned} \\mathcal{Y}_{ijkmn}=&amp; \\mu+T_i+\\mathcal{C}_{ij} &amp;&amp;\\{\\text{cooler part of the model}\\\\ &amp;+I_k+(TI)_{ik}+d_{ijk} &amp;&amp;\\{\\text{column part of the model}\\\\ &amp;+L_m+(TL)_{im}+(IL)_{km}+(TIL)_{ikm}+p_{ijkm} &amp;&amp;\\{\\text{partition part of the model}\\\\ &amp;+P_n+(TP)_{in}+(IP)_{kn}+(TIP)_{ikn}+(LP)_{mn}+(TLP)_{imn}+(ILP)_{km}+(TILP)_{ikmn}+\\varepsilon_{ijkmn} &amp;&amp;\\{\\text{half-partition part of the model}\\\\ &amp;i=1,2,3,\\quad j=1,2,\\quad k=1,2,3,4,\\quad m=1,2,3,4,\\quad n=1,2,\\\\ &amp;c_{ij}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{cooler}}^2),\\quad d_{ijk}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{column}}^2),\\quad p_{ijkn}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{partition}}^2),\\quad \\boldsymbol{\\varepsilon}_{ijkmn}\\thicksim i.i.d.N(0,\\sigma_{\\frac12\\text{partition}} ^ 2 ) \\end{aligned}\\]  5.26 -- (split-split-split-plot)   5.26:  x :  5.4   5.4.1  5.5  (batch)  (cheese block).  (chamber)  24  5.20  5.21  \\[\\begin{aligned}y_{ijk}=&amp;\\mu+T_j+H_k+(TH)_{jk}+m_i+c_{ijk},\\quad i=1,2,3,4,j=1,2,k=1,2\\\\&amp;m_i\\sim i.i.d.N(0,\\sigma_{\\mathrm{month}}^2),\\text{ and }c_{ijk}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{chamber}}^2)\\end{aligned}\\]  5.27 error (chamber)  SAS-Mixed   5.20:   5.21:   5.27:  x  5.22  \\[\\begin{aligned}y_{imn}=&amp;\\mu+F_m+C_n+(FC)_{mn}+m_i+b_{imn},\\quad i=1,2,3,4,m=1,2,n=1,2,3,\\\\&amp;m_i\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{month}}^2)\\mathrm{~and~}b_{imn}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{batch}}^2)\\end{aligned}\\]  5.28  15 error (batch)  SAS-Mixed   5.22:   5.28:  x 1  \\[\\begin{aligned}&amp;(TF)_{jm}+(TC)_{jn}+(TFC)_{jmn}+(HF)_{kn}+(HC)_{kn}+(HFC)_{kmn}+(THFC)_{jkmn}+\\varepsilon_{ijkmn}\\\\&amp;\\varepsilon_{ijkmn}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{block}}^2)\\end{aligned}\\]  \\[\\begin{aligned}y_{ijk}&amp;=\\mu+m_i&amp;&amp;\\{\\text{blocking part of the model}\\\\&amp;+T_j+H_k+(TH)_{jk}+c_{ijk}&amp;&amp;\\{\\text{chamber part of the model}\\\\&amp;+F_m+C_n+(FC)_{mn}+b_{imn}&amp;&amp;\\{\\text{batch part of the model}\\\\&amp;+(TF)_{jm}+(TC)_{jn}+(TFC)_{jmn}+(HF)_{km}+(HC)_{kn}+(HFC)_{kmn}+(THFC)_{jkmn}+\\varepsilon_{ijkmn}&amp;&amp;\\{\\text{cheese block part of the model}\\\\ &amp;i=1,2,3,4,\\quad j=1,2,\\quad k=1,2,\\quad m=1,2,\\quad n=1,2,3 \\\\ &amp;m_i\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{month}}^2),\\quad c_{ijk}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{chamber}}^2),\\quad b_{imn}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{batch}}^2), \\\\ &amp;\\mathrm{and~}\\varepsilon_{ijkmn}\\sim i.i.d.N(0,\\sigma_{\\mathrm{block}}^2)\\end{aligned}\\]  5.29  (4 - 1)(6 - 1)(4 - 1) = 45   5.29:  x   5.5   5.5.1  5.6   (horse feet)    FPT 23  (Cochran and Cox, 1957).  5.30   5.30:  x :  \\(F_1\\)  \\(F_2\\) \\(T_1\\)  \\(T_2\\) \\(P_1\\)  \\(P_2\\)  \\(y_{ijkm}\\)  \\(i\\)  \\(j\\)  \\(k\\)  \\(m\\)  \\[y_{ijkm}=\\mu_{ijk}+h_m+\\varepsilon_{ijkm},\\quad i=1,2,\\quad j=1,2,k=1,2,m=1,2,\\ldots,4\\]  \\(\\mu_{ijk}\\)  \\(i\\)  \\(j\\)  \\(k\\) \\(h_m\\)  \\(m\\) \\(\\varepsilon_{ijkm}\\)  \\(\\mu_{ijk}\\)  (intra-horse or within-horse)  (inter-horse or between-horse)  \\[\\begin{aligned} \\text{Mean}&amp; =\\bar{\\mu}_{\\cdot\\cdot\\cdot} \\\\ F&amp; =\\bar{\\mu}_{1\\cdot\\cdot}-\\bar{\\mu}_{2\\cdot\\cdot},P=\\bar{\\mu}_{\\cdot1\\cdot}-\\bar{\\mu}_{\\cdot2\\cdot},T=\\bar{\\mu}_{\\cdot\\cdot1}-\\bar{\\mu}_{\\cdot\\cdot2} \\\\ F\\times P&amp; \\begin{aligned}&amp;=\\bar{\\mu}_{11\\cdot}-\\bar{\\mu}_{12\\cdot}-\\bar{\\mu}_{21\\cdot}+\\bar{\\mu}_{22\\cdot}\\end{aligned} \\\\ F\\times T&amp; =\\bar{\\mu}_{1\\cdot1}-\\bar{\\mu}_{1\\cdot2}-\\bar{\\mu}_{2\\cdot1}+\\bar{\\mu}_{2\\cdot2} \\\\ P\\times T&amp; =\\bar{\\mu}_{\\cdot11}-\\bar{\\mu}_{\\cdot12}-\\bar{\\mu}_{\\cdot21}+\\bar{\\mu}_{\\cdot22} \\\\ F\\times P\\times T&amp; =\\mu_{111}-\\mu_{112}-\\mu_{121}+\\mu_{122}-\\mu_{211}+\\mu_{212}+\\mu_{221}-\\mu_{222} \\end{aligned}\\] \\(\\mu_{ijk}\\)  \\(\\bar y_{ijk\\cdot}\\).  \\(P\\)  \\[\\begin{aligned}\\hat{P}&amp;=\\bar{y}_{\\cdot1\\cdot\\cdot}-\\bar{y}_{\\cdot2\\cdot\\cdot}\\\\&amp;=\\frac{1}{4}[({y}_{1111}-{y}_{1221})+({y}_{1122}-{y}_{1212})+({y}_{2113}-{y}_{2223})+({y}_{2124}-{y}_{2214})]\\end{aligned}\\]  \\(P\\)  \\({y}_{ijkm}\\) \\[\\begin{aligned}\\hat{P}&amp;=\\frac14[(\\mu_{111}+h_1+\\varepsilon_{1111}-\\mu_{122}-h_1-\\varepsilon_{1221})+(\\mu_{112}+h_2+\\varepsilon_{1122}-\\mu_{121}-h_2-\\varepsilon_{1212})\\\\&amp;+(\\mu_{211}+h_3+\\varepsilon_{2113}-\\mu_{22}-h_3-\\varepsilon_{223})+(\\mu_{212}+h_4+\\varepsilon_{2124}-\\mu_{221}-h_4-\\varepsilon_{2214})]\\\\&amp;=\\bar{\\mu}_{\\cdot1}-\\bar{\\mu}_{\\cdot2}+\\frac{1}{4}[(\\varepsilon_{1111}-\\varepsilon_{1221})+(\\varepsilon_{1122}-\\varepsilon_{1212})+(\\varepsilon_{2113}-\\varepsilon_{222})+(\\varepsilon_{2124}-{\\varepsilon}_{2214})]\\end{aligned}\\]  \\(h_m\\) \\(\\hat P\\)  \\(\\varepsilon_{ijkm}\\)  \\(h_m\\)  \\(\\hat P\\)  \\(\\operatorname{Var}(P) = \\sigma^2_{\\varepsilon} /2\\). \\(F\\)  \\[\\begin{aligned}\\hat{F}&amp;=\\bar{y}_{1\\cdot\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot\\cdot}\\\\&amp;=\\frac14[(y_{1111}+y_{1221})+(y_{1122}+y_{1212})-(y_{2113}+y_{2223})-(y_{2124}+y_{2214})]\\end{aligned}\\]  1  2  3  4  \\(F\\)  \\[\\begin{aligned} \\hat{F}&amp; =\\frac14[(\\mu_{111}+h_1+\\varepsilon_{1111}+\\mu_{122}+h_1+\\varepsilon_{1221})+(\\mu_{112}+h_2+\\varepsilon_{1122}+\\mu_{121}+h_2+\\varepsilon_{1212}) \\\\ &amp;=[\\bar{\\mu}_{\\cdot1}-\\bar{\\mu}_{\\cdot2}+\\frac14[(\\varepsilon_{1111}+\\varepsilon_{1221})+(\\varepsilon_{1122}+\\varepsilon_{1212})-(\\varepsilon_{2113}+\\varepsilon_{2223})-(\\varepsilon_{2124}+\\varepsilon_{2214})] \\\\ &amp;+\\frac12[h_1+h_2-h_3-h_4] \\end{aligned}\\]  \\(h_m\\)\\(\\hat F\\)  \\(h_m\\)  \\(\\varepsilon_{ijkm}\\) \\(\\mathrm{Var}(\\hat{F})=\\frac{1}{2}\\left[\\sigma_{\\varepsilon}^{2}+2\\sigma_{\\mathrm{horse}}^{2}\\right]\\)\\(P,T,F\\times T,F\\times P\\)  \\(F,P\\times T,F\\times P\\times T\\)  \\(h_m\\) (confounded) \\(F,P\\times T,F\\times P\\times T\\)   \\(h_m\\)  \\(\\varepsilon_{ijkm}\\)  5.30  5.31   \\(F,P,T,F\\times P\\times T\\) \\(F\\times T,F\\times P,P\\times T\\)  5.31  \\(F,T,P,F \\times P \\times T\\)  error (feet)  \\(F\\times T,F\\times P , P\\times T\\)  error (horse)  5.32   5.31:  x  5.32:  x  5.5.2  5.7  12  3  36  6  1  36  6  5.23  5.23 T1T2T3 12  3 1 1 1  \\[y_{ijk}=\\mu+E_i+d_j+c_{ij}+T_k+(ET)_{ik}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,6,\\quad j=1,2,\\ldots,6,\\quad k=1,2,3\\]  \\(d_j\\)  \\(j\\) \\(c_{ij}\\)  \\(j\\)  \\(i\\) \\(\\varepsilon_{ijk}\\)  5.33   \\(d_j,c_{ij},\\varepsilon_{ijk}\\)  \\(\\sigma^2_\\text{day},\\sigma^2_\\text{chamber},\\sigma^2_\\varepsilon\\).  \\(d_j,c_{ij},\\varepsilon_{ijk}\\)  \\(\\varepsilon_{ijk}\\)  26  27   5.23:   5.33:  x  5.5.3  5.8  A  A  (diminish)  (wash out) B  B  (sequence) A  B  B  A  A  B  B  A AB  BA A  B  5.34  \\[y_{ijk}=\\mu_{ik}+s_{ij}+\\varepsilon_{ijk},\\quad\\mathrm{~where~}(i,j,k)\\in I_\\text{D}{ , s _ { i j }}\\thicksim i.i.d.\\text{ N}(0,\\sigma_{\\mathrm{subject}}^2),\\mathrm{~and~}\\varepsilon_{ijk}\\thicksim i.i.d.\\text{ N}(0,\\sigma_{\\mathrm{time}}^2)\\]  \\(I_D\\)  \\((i,j,k)\\) \\(\\mu_{ik}\\)  \\(i\\)\\(k\\)\\(s_{ij}\\)\\(i\\)\\(j\\)\\(\\varepsilon_{ijk}\\)\\(k\\)\\(i\\) 29   5.34:  x 5.6   (nested effects).  5.35  4.2 X \\(s_k + h_{m(k)}\\)  \\(s_k\\)  \\(k\\) \\(h_{m(k)}\\)  \\(k\\)  \\(m\\)  SSSQUARE  SSHOUSES(SQUARES) SSHOUSES SSHOUSES = SSSQUARES + SSHOUSES(SQUARES)  5.35:  x 5.6.1  5.9  4  12  5.36 X  5.36:  x  5.6.2  5.10  (maturity groups)  45  6  8  2  44  52  6 5.37  \\[\\begin{aligned}&amp;y_{ijk}=\\mu+M_i+V(M)_{j(i)}+b_k+\\varepsilon_{ijk},\\quad i=1,2,3,j=1,\\ldots,n_i,k=1,2,3,4\\\\&amp;b_k\\sim i.i.d.N(0,\\sigma_{\\mathrm{row}}^2),\\varepsilon_{ijk}\\sim i.i.d.N(0,\\sigma_{\\varepsilon}^2),n_1=n_3=2,\\mathrm{~and~}n_2=4.\\end{aligned}\\]  \\(M_i\\)  \\(i\\) \\(V(M)_{j(i)}\\)  \\(i\\)  \\(j\\) \\(b_k\\)  \\(k\\) \\(\\varepsilon_{ijk}\\)  5.38 +  5.37:  x  5.38:  x  4  5  5  6  (plots)  (sets of plots) \\[\\begin{aligned}y_{ijk}&amp;=\\mu+M_i+b_k+w_{ik}+V(M)_{j(i)}+\\varepsilon_{ijk},\\quad i=1,2,3,j=1,\\ldots,n_i,k=1,2,3,4\\\\b_k&amp;\\sim i.i.d.N(0,\\sigma_{\\mathrm{row}}^2),v_{ik}\\sim i.i.d.N(0,\\sigma_{\\mathrm{wplot}}^2),\\mathrm{and}\\,\\,\\varepsilon_{ijk}\\sim i.i.d.N(0,\\sigma_{\\varepsilon}^2)\\end{aligned}\\]  \\(w_{ik}\\) \\(\\varepsilon_{ijk}\\)  5.39   5.39:  x 5.6.3  5.11  5.40 -X  5.40: - x  5.40   21 - \\(y_{ijk}\\)  \\(i\\)  \\(j\\)  \\(k\\)  \\[\\begin{aligned}y_{ijk}&amp;=\\mu_{ij}+p_{ijk},\\quad\\text{for }(i,j)\\in\\Theta\\text{ and }p_{ijk}\\thicksim i.i.d.N(0,\\sigma_{\\text{plane}}^2)\\end{aligned}\\]  \\[y_{ijk}=\\mu+A_i+E_{j(i)}+p_{ijk},\\quad\\mathrm{for~}(i,j)\\in\\Theta,\\]  \\[\\Theta=\\{(1,A),(1,B),(1,C),(2,D),(2,E),(3,F),(3,G)\\}\\]  5.41  (The plane error term is computed from the variation of the performance scores of the three planes made with the same engine type and aircraft type configuration pooled across the seven configurations).  \\[\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\bar{\\mu}_{3\\cdot}\\]  \\[\\frac{{\\mu}_{1A}+{\\mu}_{1B}+{\\mu}_{1C}}3=\\frac{{\\mu}_{2D}+{\\mu}_{2E}}2=\\frac{{\\mu}_{3F}+{\\mu}_{3G}}2\\]  \\[{\\mu}_{1A}={\\mu}_{1B}={\\mu}_{1C},\\quad{\\mu}_{2D}={\\mu}_{2E},\\quad\\mathrm{and}\\quad{\\mu}_{3F}={\\mu}_{3G}\\]   5.41:  x 5.6.4  5.12  18°C21°C  24°C M  F (environmental chambers)  (chambers)  18  18  5.24   3  \\[y_{ijkm}=\\mu_{ik}+c_{j(i)}+p_{m(ijk)}\\quad i=1,2,3,~j=1,2,3,~k=1,2,~m=1,2\\]  \\[c_{j(i)}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{chamber}}^2)\\mathrm{~and~}p_{m(ijk)}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{person}}^2)\\]  \\[y_{ijkm}=\\mu+T_i+c_{j(i)}+S_k+(TS)_{ik}+p_{m(ijk)}\\]  \\(\\mu_{ik}\\)  \\(i\\)  \\(k\\) \\(c_{j(i)}\\)  \\(i\\)  \\(j\\) \\(p_{m(ijk)}\\)  \\(j\\)  \\(k\\)  \\(k\\)  \\(m\\) \\(T_i,S_k,(TS)_{ik}\\)   5.24:   5.42  (between-person comparisons)  5.42:  x 5.6.5  5.13  (locations)  5.25  (plots)  5.26  (cut)  (harvest)  5.26  (entity) (layer)   5.25:   5.26:   5.43:  x  (pooled across locations).  \\[y_{ijkm}=\\mu+l_i+b_{j(i)}+V_k+(lV)_{ik}+(bV)_{jk(i)}+C_m+(lC)_{im}+(VC)_{km}+(lVC)_{ikm}+\\varepsilon_{ijkm}\\]  \\[\\begin{aligned}&amp;l_i\\thicksim N(0,\\sigma_{\\mathrm{Loc}}^2),\\quad b_{j(i)}\\thicksim N(0,\\sigma_{blk(\\mathrm{Loc})}^2),\\quad(lV)_{ik}\\thicksim N(0,\\sigma_{V*\\mathrm{Loc}}^2),\\quad(bV)_{jk(i)}\\thicksim N(0,\\sigma_{V*Blk(\\mathrm{Loc})}^2),\\\\&amp;(lC)_{im}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{C^*Loc}}^2),\\quad(lVC)_{ikn}\\thicksim i.i.d.N(0,\\sigma_{V*C *\\text{Loc}}^2),\\quad\\varepsilon_{ijkn}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{cell}}^2)\\end{aligned}\\]  18  26  27  5.43  18  5.7   24  30  Milliken (2003a, b)  Milliken et al. (1998). 5.8  "],["chap6.html", " 6   6.1  6.2  6.3  6.4  6.5  6.6  6.7 ", "  6   The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of certain verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work - John Von Neumann  (unbalanced)  6.3  (estimability)  6.1   \\[\\begin{equation} \\underset{n\\times1}{\\boldsymbol y}=\\underset{n × p}{\\vphantom{\\boldsymbol y}\\boldsymbol X} \\,\\,\\underset{p × 1}{\\vphantom{\\boldsymbol y}\\boldsymbol \\beta}+\\underset{n × 1}{\\vphantom{\\boldsymbol y}\\boldsymbol\\varepsilon} \\tag{6.1} \\end{equation}\\]  \\(\\boldsymbol y\\)  \\(n \\times 1\\) \\(\\boldsymbol X\\)  \\(n \\times p\\)  (designed matrix)\\(\\boldsymbol \\beta\\)  \\(p \\times 1\\) \\(\\boldsymbol \\varepsilon\\)  \\(n \\times 1\\)  \\(i\\) \\(\\boldsymbol y\\)  \\(i\\)  \\[\\begin{equation} y_i=\\beta_0+\\beta_1x_{i1}+\\beta_2x_{i2}+\\cdots+\\beta_{p-1}x_{ip-1}+\\varepsilon_i,\\quad i=1,2,\\ldots,n \\tag{6.2} \\end{equation}\\]  (6.2)  (6.1)  \\[\\begin{equation} \\boldsymbol{y}=\\begin{bmatrix}y_1\\\\y_2\\\\\\vdots\\\\y_n\\end{bmatrix},\\quad\\boldsymbol{X}=\\begin{bmatrix}1&amp;x_{11}&amp;x_{12}&amp;\\cdots&amp;x_{1p-1}\\\\1&amp;x_{21}&amp;x_{22}&amp;\\cdots&amp;x_{2p-1}\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\1&amp;x_{n1}&amp;x_{n2}&amp;\\cdots&amp;x_{np-1}\\end{bmatrix},\\quad\\boldsymbol{\\beta}=\\begin{bmatrix}\\beta_0\\\\\\beta_1\\\\\\beta_2\\\\\\vdots\\\\\\beta_{p-1}\\end{bmatrix},\\quad\\mathrm{and}\\quad\\boldsymbol{\\varepsilon}=\\begin{bmatrix}\\varepsilon_1\\\\\\varepsilon_2\\\\\\vdots\\\\\\varepsilon_n\\end{bmatrix} \\tag{6.3} \\end{equation}\\]  (6.3)  \\(\\boldsymbol X\\)  \\(\\boldsymbol \\beta\\)  \\(\\boldsymbol \\varepsilon\\)  6.1.1   \\(y_i=\\beta_0+\\beta_1x_i+\\varepsilon_i,i=1,2,\\ldots,n\\)  \\[\\begin{bmatrix}y_1\\\\y_2\\\\\\vdots\\\\y_n\\end{bmatrix}=\\begin{bmatrix}1&amp;x_1\\\\1&amp;x_2\\\\\\vdots&amp;\\vdots\\\\1&amp;x_n\\end{bmatrix}\\begin{bmatrix}{\\beta}_0\\\\{\\beta}_1\\end{bmatrix}+\\begin{bmatrix}{\\varepsilon}_1\\\\{\\varepsilon}_2\\\\\\vdots\\\\{\\varepsilon}_n\\end{bmatrix}\\] \\(\\boldsymbol X\\)  1  \\(\\boldsymbol \\beta_0\\)\\(x_i\\)  6.1.2   \\(t\\)  \\(i\\)  \\(n_i\\)  \\(x_{ij}\\)  \\[x_{kij}=\\begin{cases}0&amp;\\text{ if the }ij\\text{th observation is not from the }k\\text{th treatment}\\\\1&amp;\\text{ if the }ij\\text{th observation is from the }k\\text{th treatment}&amp;\\end{cases}\\]  \\(i=1,2,\\cdots,t\\)\\(j=1,2,\\cdots,n_i\\).  \\(x_{kij}\\)  (indicator variable) 1  k.  0  k.  (means model)  \\(y_{ij}={\\mu}_1x_{1ij}+{\\mu}_2x_{2ij}+\\cdots+{\\mu}_tx_{tij}+{\\varepsilon}_{ij}\\) \\(i=1,2,\\cdots,t\\)\\(j=1,2,\\cdots,n_i\\).  \\[\\begin{bmatrix}{y}_{11}\\\\{y}_{12}\\\\\\vdots\\\\{y}_{1n_1}\\\\{y}_{22}\\\\\\vdots\\\\{y}_{2{n}_2}\\\\\\vdots\\\\{y}_{t1}\\\\\\vdots\\\\{y}_{t{n}_t}\\end{bmatrix}=\\begin{bmatrix}1&amp;0&amp;\\cdots&amp;0\\\\1&amp;0&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\1&amp;0&amp;\\cdots&amp;0\\\\0&amp;1&amp;\\cdots&amp;0\\\\0&amp;1&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\0&amp;1&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;1\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;1\\end{bmatrix}\\begin{bmatrix}\\mu_1\\\\\\mu_2\\\\\\vdots\\\\\\mu_t\\end{bmatrix}+\\boldsymbol \\varepsilon\\]  \\(y_{ij}=\\mu_i+\\varepsilon_{ij}\\) \\(i=1,2,\\cdots,t\\)\\(j=1,2,\\cdots,n_i\\).  (effect model)  \\(y_{ij}=\\mu+\\tau_1x_{1ij}+\\tau_2x_{2ij}+\\cdots+\\tau_tx_{tij}+\\varepsilon_{ij}\\) \\(i=1,2,\\cdots,t\\)\\(j=1,2,\\cdots,n_i\\).  \\[\\begin{bmatrix}{y}_{11}\\\\{y}_{12}\\\\\\vdots\\\\{y}_{1{n}_1}\\\\{y}_{21}\\\\{y}_{22}\\\\\\vdots\\\\{y}_{2{n}_2}\\\\\\vdots\\\\{y}_{t1}\\\\\\vdots\\\\{y}_{t{n}_t}\\end{bmatrix}=\\begin{bmatrix}1&amp;1&amp;0&amp;\\cdots&amp;0\\\\1&amp;1&amp;0&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\1&amp;1&amp;0&amp;\\cdots&amp;0\\\\1&amp;0&amp;1&amp;\\cdots&amp;0\\\\1&amp;0&amp;1&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\1&amp;0&amp;1&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\1&amp;0&amp;0&amp;\\cdots&amp;1\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\1&amp;0&amp;0&amp;\\cdots&amp;1\\end{bmatrix}\\begin{bmatrix}\\mu\\\\\\tau_1\\\\\\tau_2\\\\\\vdots\\\\\\tau_t\\end{bmatrix}+\\boldsymbol \\varepsilon \\]  \\(y_{ij}=\\mu+\\tau_i+\\varepsilon_{ij}\\) \\(i=1,2,\\cdots,t\\)\\(j=1,2,\\cdots,n_i\\).  \\(\\mu\\)  1  1  6.1.3   \\(t\\)  \\(b\\)  \\[\\begin{equation} y_{ijk}=\\mu_{ij}+\\varepsilon_{ijk}\\quad i=1,2,\\ldots,t,j=1,2,\\ldots,b,\\mathrm{~and~}k=1,2,\\ldots,n_{ij} \\tag{6.4} \\end{equation}\\]  (6.4)  \\[\\begin{bmatrix}y_{111}\\\\y_{112}\\\\\\vdots\\\\y_{11n_1}\\\\y_{121}\\\\\\vdots\\\\y_{12n_2}\\\\\\vdots\\\\y_{1b1}\\\\\\vdots\\\\y_{1bn_{1b}} \\\\y_{211}\\\\\\vdots\\\\y_{21n_{21}}\\\\\\vdots\\\\y_{tb1}\\\\\\vdots\\\\y_{tbn_{tb}} \\end{bmatrix}=\\begin{bmatrix} 1&amp;0&amp;\\cdots&amp;0&amp;0&amp;\\cdots&amp;0\\\\ 1&amp;0&amp;\\cdots&amp;0&amp;0&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 1&amp;0&amp;\\cdots&amp;0&amp;0&amp;\\cdots&amp;0\\\\ 0&amp;1&amp;\\cdots&amp;0&amp;0&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;1&amp;\\cdots&amp;0&amp;0&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;0&amp;\\cdots&amp;1&amp;0&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;0&amp;\\cdots&amp;1&amp;0&amp;\\cdots&amp;0\\\\ 0&amp;0&amp;\\cdots&amp;0&amp;1&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;0&amp;\\cdots&amp;0&amp;1&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;0&amp;\\cdots&amp;0&amp;0&amp;\\cdots&amp;1\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;0&amp;\\cdots&amp;0&amp;0&amp;\\cdots&amp;1\\end{bmatrix} \\begin{bmatrix}\\mu_{11}\\\\\\mu_{12}\\\\\\vdots\\\\\\mu_{1b}\\\\\\mu_{21}\\\\\\vdots\\\\\\mu_{tb}\\end{bmatrix} + \\boldsymbol \\varepsilon \\]  \\[\\begin{equation} y_{ijk}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij}+\\varepsilon_{ijk}\\quad i=1,2,\\ldots,t,j=1,2,\\ldots,b,k=1,2,\\ldots,n_{ij} \\tag{6.5} \\end{equation}\\]  \\[ \\begin{bmatrix}y_{111}\\\\y_{112}\\\\\\vdots\\\\y_{11n_1}\\\\y_{121}\\\\\\vdots\\\\y_{12n_2}\\\\\\vdots\\\\y_{1b1}\\\\\\vdots\\\\y_{1bn_{1b}} \\\\y_{211}\\\\\\vdots\\\\y_{21n_{21}}\\\\\\vdots\\\\y_{tb1}\\\\\\vdots\\\\y_{tbn_{tb}} \\end{bmatrix}=\\begin{bmatrix} 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; 1 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ 0 &amp; 1 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 1 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 1 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 1 \\\\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; \\cdots &amp; 1 \\\\ \\end{bmatrix} \\begin{bmatrix}\\mu_{11}\\\\\\mu_{12}\\\\\\vdots\\\\\\mu_{1b}\\\\\\mu_{21}\\\\\\vdots\\\\\\mu_{tb}\\end{bmatrix}+ \\boldsymbol \\varepsilon \\]  6.1.4  6.1  6.1  6.1  \\[\\begin{bmatrix}3\\\\6\\\\9\\\\10\\\\2\\\\5\\\\3\\\\8\\\\4\\\\2\\\\6\\end{bmatrix}=\\begin{bmatrix} 1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0\\\\ 0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\end{bmatrix}\\begin{bmatrix}\\mu_{11}\\\\\\mu_{12}\\\\\\mu_{13}\\\\\\mu_{21}\\\\\\mu_{22}\\\\\\mu_{23}\\\\\\mu_{31}\\\\\\mu_{32}\\\\\\mu_{33}\\end{bmatrix}+\\boldsymbol \\varepsilon\\]  6.1  \\[ \\begin{bmatrix}3\\\\6\\\\9\\\\10\\\\2\\\\5\\\\3\\\\8\\\\4\\\\2\\\\6\\end{bmatrix}=\\begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\begin{bmatrix} \\mu_1 \\\\ \\tau_1 \\\\ \\tau_2 \\\\ \\tau_3 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ \\gamma_{11} \\\\ \\gamma_{12} \\\\ \\gamma_{13} \\\\ \\gamma_{21} \\\\ \\gamma_{22} \\\\ \\gamma_{23} \\\\ \\gamma_{31} \\\\ \\gamma_{32} \\\\ \\gamma_{33} \\end{bmatrix} +\\boldsymbol \\varepsilon \\]  \\[\\boldsymbol y=\\boldsymbol j\\boldsymbol\\mu+\\boldsymbol X_1\\boldsymbol \\tau+\\boldsymbol X_2\\boldsymbol\\beta+\\boldsymbol X_3\\boldsymbol \\gamma+\\boldsymbol\\varepsilon \\] \\(\\boldsymbol j\\)  11×1 \\(\\boldsymbol X_1\\)  2-4  11×3 \\(\\boldsymbol X_2\\)  5-7  11×3 \\(\\boldsymbol X_3\\)  11×9   6.1: CRD  x  (categorical effects)  6.2   \\(\\boldsymbol \\beta\\)  (least squares estimator) \\[\\begin{equation} y_i=f(x_i;\\boldsymbol{\\beta})+\\varepsilon_i\\quad\\mathrm{~for~}i=1,2,\\ldots,n \\tag{6.6} \\end{equation}\\]  \\(y_i=f(x_i;\\boldsymbol{\\beta})\\)  \\(x_i\\)  \\(\\boldsymbol \\beta\\). \\(\\boldsymbol \\beta\\)  \\(\\hat {\\boldsymbol \\beta}\\)  \\[\\begin{equation} SS(\\boldsymbol{\\beta})=\\sum_{i=1}^n[y_i-f(x_i;\\boldsymbol{\\beta})]^2 \\tag{6.7} \\end{equation}\\]  (6.6)  \\(\\varepsilon_i \\sim i.i.d\\,N(0,\\sigma^2),i1,2,\\cdots,n\\) \\(\\boldsymbol \\beta\\)  (maximum likelihood estimator).  \\[f(x_{ij};\\boldsymbol{\\beta})=\\mu_i,\\quad i=1,2,\\ldots,t;\\quad j=1,2,\\ldots,n_i\\] \\(\\mu_i\\)  \\(\\hat \\mu_1,\\cdots,\\hat \\mu_t\\) \\[\\begin{aligned}SS({\\mu})=\\sum_{i=1}^t\\sum_{j=1}^{n_j}(y_{ij}-\\mu_i)^2\\end{aligned}\\]  \\[f(x_{ijk};\\boldsymbol{\\beta})=\\mu_{ij}\\quad i=1,2,\\ldots,t;j=1,2,\\ldots,b;k=1,2,\\ldots,n_{ij}\\] \\(\\mu_{ij}\\)  \\(\\hat \\mu_{11},\\cdots,\\hat \\mu_{tb}\\) \\[\\begin{aligned}SS({\\mu})=\\sum_{i=1}^{t}\\sum_{j=1}^{b}\\sum_{k=1}^{n_{ij}}(y_{ijk}-\\mu_{ij})^2\\end{aligned}\\]  \\[f(x_{ijk};\\boldsymbol{\\beta})=\\mu+\\tau_i+{\\beta}_j+\\gamma_{ij},\\quad i=1,2,\\ldots,t;j=1,2,\\ldots,b;k=1,2,\\ldots,n_{ij}\\] \\(\\mu,\\tau_i,\\beta_j,\\gamma_{ij}\\)  \\[SS(\\mu,\\tau_i,\\beta_j,\\gamma_{ij})=\\sum_{i=1}^t\\sum_{j=1}^b\\sum_{k=1}^{n_{ij}}(y_{ijk}-\\mu-\\tau_i-\\beta_j-\\gamma_{ij})^2\\]  (6.1)  \\(\\boldsymbol \\beta\\)  \\(\\hat {\\boldsymbol \\beta}\\)  \\[\\begin{equation} SS(\\boldsymbol\\beta)=(\\boldsymbol y-\\boldsymbol X \\boldsymbol\\beta)^{\\prime}(\\boldsymbol y-\\boldsymbol X \\boldsymbol\\beta) \\tag{6.8} \\end{equation}\\] 6.2.1   \\(\\boldsymbol\\beta\\)  \\(\\hat {\\boldsymbol \\beta}\\)  (least squares equations)  (normal equations).  (6.1) \\[\\begin{equation} \\boldsymbol X^{\\prime} \\boldsymbol X\\hat{\\boldsymbol{\\beta}}=\\boldsymbol X^{\\prime}\\boldsymbol{y} \\tag{6.9} \\end{equation}\\]  \\(\\hat {\\boldsymbol \\beta}\\)  \\(\\boldsymbol\\beta\\)  6.1   \\[\\begin{bmatrix}n_1&amp;0&amp;\\cdots&amp;0\\\\0&amp;n_2&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;n_t\\end{bmatrix}\\begin{bmatrix}\\hat{\\mu}_1\\\\\\hat{\\mu}_2\\\\\\vdots\\\\\\hat{\\mu}_t\\end{bmatrix}=\\begin{bmatrix}y_{1\\cdot}\\\\y_{2\\cdot}\\\\\\vdots\\\\y_{t\\cdot}\\end{bmatrix}\\mathrm{~where~}y_{i\\cdot}=\\sum_{i=1}^{n_i}y_{ij}\\]  \\[\\begin{bmatrix}n_{\\cdot}&amp;n_1&amp;n_2&amp;\\cdots&amp;n_t\\\\n_1&amp;n_1&amp;0&amp;\\cdots&amp;0\\\\n_2&amp;0&amp;n_2&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\n_t&amp;0&amp;0&amp;\\cdots&amp;n_t\\end{bmatrix}\\begin{bmatrix}\\hat{\\mu}\\\\\\hat{\\tau}_1\\\\\\hat \\tau_2\\\\\\vdots\\\\\\hat{\\tau}_t\\end{bmatrix}=\\begin{bmatrix}y_{\\cdot\\cdot}\\\\y_{1\\cdot}\\\\y_{2\\cdot}\\\\\\vdots\\\\y_{t\\cdot}\\end{bmatrix}\\quad\\mathrm{where~}y_{\\cdot\\cdot}=\\sum_{i=1}^t\\sum_{j=1}^{n_i}y_{ij}\\quad\\mathrm{and}\\quad n_{\\cdot}=\\sum_{i=1}^tn_t\\]  6.1  \\[\\begin{bmatrix}2&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;2&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\end{bmatrix}\\begin{bmatrix}\\hat{\\mu}_{11}\\\\\\hat{\\mu}_{12}\\\\\\hat{\\mu}_{13}\\\\\\hat{\\mu}_{21}\\\\\\hat{\\mu}_{22}\\\\\\hat{\\mu}_{23}\\\\\\hat{\\mu}_{31}\\\\\\hat{\\mu}_{32}\\\\\\hat{\\mu}_{33}\\end{bmatrix}=\\begin{bmatrix}y_{11\\cdot}\\\\y_{12\\cdot}\\\\y_{13\\cdot}\\\\y_{21\\cdot}\\\\y_{22\\cdot}\\\\y_{23\\cdot}\\\\y_{31\\cdot}\\\\y_{32\\cdot}\\\\y_{33\\cdot}\\end{bmatrix}\\]  \\[y_{ij\\cdot}=\\sum_{k=1}^{n_{ij}}y_{ijk}\\]  6.1  $$$$ \\[\\begin{bmatrix} 11&amp;4&amp;4&amp;3&amp;4&amp;4&amp;3&amp;2&amp;1&amp;1&amp;1&amp;2&amp;1&amp;1&amp;1&amp;1\\\\ 4&amp;4&amp;0&amp;0&amp;2&amp;1&amp;1&amp;2&amp;1&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 4&amp;0&amp;4&amp;0&amp;1&amp;2&amp;1&amp;0&amp;0&amp;0&amp;1&amp;2&amp;1&amp;0&amp;0&amp;0\\\\ 3&amp;0&amp;0&amp;3&amp;1&amp;1&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;1&amp;1\\\\ 4&amp;2&amp;1&amp;1&amp;4&amp;0&amp;0&amp;2&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;0\\\\ 4&amp;1&amp;2&amp;1&amp;0&amp;4&amp;0&amp;0&amp;1&amp;0&amp;0&amp;2&amp;0&amp;0&amp;1&amp;0\\\\ 3&amp;1&amp;1&amp;1&amp;0&amp;0&amp;3&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1\\\\ 2&amp;2&amp;0&amp;0&amp;2&amp;0&amp;0&amp;2&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 1&amp;1&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 1&amp;1&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0\\\\ 2&amp;0&amp;2&amp;0&amp;0&amp;2&amp;0&amp;0&amp;0&amp;0&amp;0&amp;2&amp;0&amp;0&amp;0&amp;0\\\\ 1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0\\\\ 1&amp;0&amp;0&amp;1&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0\\\\ 1&amp;0&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0\\\\ 1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\end{bmatrix} \\begin{bmatrix}\\hat\\mu\\\\\\hat\\tau_{1}\\\\\\hat{\\tau}_2\\\\\\hat\\tau_{3}\\\\\\hat\\beta_{1}\\\\\\hat\\beta_{2}\\\\\\hat\\beta_{3}\\\\\\hat\\gamma_{11}\\\\\\hat\\gamma_{12}\\\\\\hat\\gamma_{13}\\\\\\hat\\gamma_{21}\\\\\\hat\\gamma_{22}\\\\\\hat\\gamma_{23}\\\\\\hat\\gamma_{31}\\\\\\hat\\gamma_{32}\\\\\\hat\\gamma_{33}\\end{bmatrix}=\\begin{bmatrix}y_{\\cdot\\cdot\\cdot}\\\\y_{1\\cdot\\cdot}\\\\y_{2\\cdot\\cdot}\\\\y_{3\\cdot\\cdot}\\\\y_{\\cdot1\\cdot}\\\\y_{\\cdot2\\cdot}\\\\y_{\\cdot3\\cdot}\\\\y_{11\\cdot}\\\\y_{12\\cdot}\\\\y_{13\\cdot}\\\\y_{21\\cdot}\\\\y_{22\\cdot}\\\\y_{23\\cdot}\\\\y_{31\\cdot}\\\\y_{32\\cdot}\\\\y_{33\\cdot}\\end{bmatrix}\\]  \\[y_{\\cdot\\cdot\\cdot}=\\sum_{i=1}^t\\sum_{j=1}^b\\sum_{k=1}^{n_{ij}}y_{ijk},\\quad y_{i\\cdot\\cdot}=\\sum_{j=1}^b\\sum_{k=1}^{n_{ij}}y_{ijk},\\quad y_{\\cdot j\\cdot}=\\sum_{i=1}^t\\sum_{k=1}^{n_{ij}}y_{ijk},\\quad\\mathrm{and}\\quad y_{ij\\cdot}=\\sum_{k=1}^{n_{ij}}y_{ijk}\\]  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  (Graybill, 1976) \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\({\\boldsymbol \\beta}\\)  (6.9)  \\(\\hat {\\boldsymbol \\beta}\\)  \\[\\begin{equation} \\hat {\\boldsymbol \\beta}=(\\boldsymbol X^\\prime \\boldsymbol X)^{-1}\\boldsymbol{X^{\\prime}y} \\tag{6.10} \\end{equation}\\]  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\(\\boldsymbol X^\\prime \\boldsymbol X\\) \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\(\\mu_i\\)  \\[\\begin{bmatrix}\\hat{{\\mu}}_1\\\\\\hat{{\\mu}}_2\\\\\\vdots\\\\\\hat{{\\mu}}_t\\end{bmatrix}=\\begin{bmatrix}\\frac1{n_1}&amp;0&amp;\\cdots&amp;0\\\\0&amp;\\frac1{n_2}&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;\\frac1{n_t}\\end{bmatrix}\\begin{bmatrix}y_{1\\cdot}\\\\y_{2\\cdot}\\\\\\vdots\\\\y_{t\\cdot}\\end{bmatrix}\\]  \\[\\hat{\\mu}_i=\\frac{y_{i\\cdot}}{n_i}=\\bar{y}_{i\\cdot}\\quad i=1,2,\\ldots,t\\]  \\(\\mu_{ij}\\)  \\[\\hat{\\mu}_{ij}=\\frac{y_{ij\\cdot}}{n_{ij}}=\\bar{y}_{ij\\cdot}\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b\\]  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  (overspecified models)  (sigular models)  \\({\\boldsymbol \\beta}\\)  (Graybill, 1976) g-inverse  6.2.2   6.1  (Sum-to-Zero Restrictions)  \\[\\begin{aligned} &amp;\\begin{aligned}\\sum_{i=1}^3\\tau_i=0,\\sum_{j=1}^3\\beta_j=0,\\sum_{i=1}^3\\gamma_{i1}=0,\\sum_{i=1}^3\\gamma_{i2}=0,\\sum_{i=1}^3\\gamma_{i3}=0\\end{aligned} \\\\ &amp;\\sum_{j=1}^3\\gamma_{1j}=0,\\sum_{j=1}^3\\gamma_{2j}=0,\\,\\text{and }\\sum_{j=1}^3\\gamma_{3j}=0 \\end{aligned}\\]  \\[\\begin{aligned}\\tau_3&amp;=-\\tau_1-\\tau_2,\\quad\\beta_3=-\\beta_1-\\beta_2,\\quad\\gamma_{13}=-\\gamma_{11}-\\gamma_{12}\\\\\\gamma_{23}&amp;=-\\gamma_{21}-\\gamma_{22},\\quad\\gamma_{31}=-\\gamma_{11}-\\gamma_{21},\\quad\\gamma_{32}=-\\gamma_{12}-\\gamma_{22}\\\\\\gamma_{33}&amp;=-\\gamma_{13}-\\gamma_{23}=-\\gamma_{31}-\\gamma_{32}=\\gamma_{11}+\\gamma_{12}+\\gamma_{21}+\\gamma_{22}\\end{aligned}\\]  \\(\\tau_3,~\\beta_3,~\\gamma_{13},~\\gamma_{23},~\\gamma_{33},~\\gamma_{31}\\)  \\(\\gamma_{32}\\) \\[ \\begin{bmatrix}y_{111}\\\\y_{112}\\\\y_{121}\\\\y_{131}\\\\y_{211}\\\\y_{221}\\\\y_{222}\\\\y_{231}\\\\y_{311}\\\\y_{321}\\\\y_{331}\\end{bmatrix}= \\begin{bmatrix}1&amp;1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0\\\\1&amp;1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0\\\\1&amp;1&amp;0&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0\\\\1&amp;1&amp;0&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0\\\\1&amp;1&amp;0&amp;-1&amp;-1&amp;-1&amp;-1&amp;0&amp;0\\\\1&amp;0&amp;1&amp;1&amp;0&amp;0&amp;0&amp;1&amp;0\\\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;1\\\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;1\\\\1&amp;0&amp;1&amp;-1&amp;-1&amp;0&amp;0&amp;-1&amp;-1\\\\1&amp;-1&amp;-1&amp;0&amp;0&amp;-1&amp;0&amp;-1&amp;0\\\\1&amp;-1&amp;-1&amp;0&amp;1&amp;0&amp;-1&amp;0&amp;-1\\\\1&amp;-1&amp;-1&amp;-1&amp;-1&amp;1&amp;1&amp;1&amp;1\\end{bmatrix}\\begin{bmatrix}\\mu^*\\\\\\tau_1^*\\\\\\tau_2^*\\\\\\beta_1^*\\\\\\beta_2^*\\\\\\gamma_{11}^*\\\\\\gamma_{12}^*\\\\\\gamma_{21}^*\\\\\\gamma_{22}^*\\end{bmatrix}+\\boldsymbol{\\varepsilon} \\]  \\[\\begin{aligned}\\boldsymbol{y}=\\boldsymbol{X}^*\\boldsymbol{\\beta}^*+\\boldsymbol{\\varepsilon}\\end{aligned}\\]  6.1  \\(\\hat{\\boldsymbol{\\beta^*}}=(\\boldsymbol X^{*\\prime} \\boldsymbol X^*)^{-1}\\boldsymbol X^{*\\prime}\\boldsymbol{y}\\).  \\[\\begin{aligned} \\hat{\\boldsymbol \\beta}^{*\\prime}&amp;=[\\hat{\\mu}^*,\\hat{\\tau}_1^*,\\hat{\\tau}_2^*,\\hat{\\beta}_1^*,\\hat{\\beta}_2^*,\\hat{\\gamma}_{11}^*,\\hat{\\gamma}_{12}^*,\\hat{\\gamma}_{21}^*,\\hat{\\gamma}_{22}^*] \\\\ &amp;=[5.500,2.333,-0.833,-2.000,-0.5000,-1.333,1.667,-0.667,-0.167] \\end{aligned}\\] \\(\\boldsymbol \\beta\\)  \\[\\begin{aligned} \\hat{{\\tau}}_3^*&amp;=-\\hat{{\\tau}}_1^*-\\hat{{\\tau}}_2^*=-1.500,\\quad\\hat{{\\beta}}_3^*=-\\hat{{\\beta}}_1^*-\\hat{{\\beta}}_2^*=2.500 \\\\ \\hat{\\gamma}_{13}^*&amp;=-\\hat{\\gamma}_{11}^*-\\hat{\\gamma}_{12}^*=-0.333,\\quad\\hat{\\gamma}_{23}^*=-\\hat{\\gamma}_{21}^*-\\hat{\\gamma}_{22}^*=0.833 \\\\ \\hat{\\gamma}_{31}^*&amp;=-\\hat{\\gamma}_{11}^*-\\hat{\\gamma}_{21}^*=2.000,\\quad\\hat{\\gamma}_{32}^*=-\\hat{\\gamma}_{12}^*-\\hat{\\gamma}_{22}^*=-1.500 \\\\ \\hat{\\gamma}_{33}^*&amp;=\\hat{\\gamma}_{11}^*+\\hat{\\gamma}_{12}^*+\\hat{\\gamma}_{21}^*+\\hat{\\gamma}_{22}^*=-0.500 \\end{aligned}\\]  \\(\\mu_{ij}\\) \\(\\mu^*,t_i^*,\\beta_{j}^*,\\gamma^*_{ij}\\)  \\[\\mu^*=\\bar{\\mu}_{\\cdot\\cdot},\\quad\\tau_i^*=\\bar{\\mu}_{i\\cdot}-\\bar{\\mu}_{\\cdot\\cdot\\cdot},\\quad\\beta_j^*=\\bar{\\mu}_{\\cdot j}-\\bar{\\mu}_{\\cdot\\cdot\\cdot},\\quad\\mathrm{and}\\quad\\gamma_{ij}^*=\\mu_{ij}-\\bar{\\mu}_{i\\cdot}-\\bar{\\mu}_{\\cdot j}+\\bar{\\mu}_{\\cdot\\cdot}\\] 6.2.3   (Set-to-Zero) 6.1  \\[\\tau_3=0,\\beta_3=0,\\gamma_{13}=0,\\gamma_{23}=0,\\gamma_{33}=0,\\gamma_{31}=0,\\mathrm{~and~}\\gamma_{23}=0\\]  \\[\\begin{bmatrix}y_{111}\\\\y_{112}\\\\y_{121}\\\\y_{131}\\\\y_{211}\\\\y_{221}\\\\y_{222}\\\\y_{231}\\\\y_{311}\\\\y_{321}\\\\y_{331}\\end{bmatrix}=\\begin{bmatrix}1&amp;1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0\\\\1&amp;1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0\\\\1&amp;1&amp;0&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0\\\\1&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\1&amp;0&amp;1&amp;1&amp;0&amp;0&amp;0&amp;1&amp;0\\\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;1\\\\1&amp;0&amp;1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;1\\\\1&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0&amp;1&amp;0&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\\begin{bmatrix}\\mu^+\\\\\\tau_1^+\\\\\\tau_2^+\\\\\\beta_1^+\\\\\\beta_2^+\\\\\\gamma_{11}^+\\\\\\gamma_{12}^+\\\\\\gamma_{21}^+\\\\\\gamma_{22}^+\\end{bmatrix}+\\boldsymbol\\varepsilon \\]  \\(\\boldsymbol{y}=\\boldsymbol{X}^+\\boldsymbol{\\beta}^++\\boldsymbol{\\varepsilon}\\) \\(\\boldsymbol{X}^+\\)  \\(\\boldsymbol X\\)  \\(\\tau_3,\\beta_3,\\gamma_{31},\\gamma_{32},\\gamma_{33},\\gamma_{13},\\gamma_{23}\\)  \\[\\hat{\\boldsymbol{\\beta}}^+=(\\boldsymbol X^{+\\prime}\\boldsymbol X^{+})^{-1}\\boldsymbol X^{+\\prime}\\boldsymbol y\\]  \\[\\begin{aligned} \\hat{\\boldsymbol{\\beta}}^{+\\prime}&amp; =[\\hat{{\\mu}}^+,\\hat{{\\tau}}_1^+,\\hat{{\\tau}}_2^+,\\hat{{\\beta}}_1^+,\\hat{{\\beta}}_2^+,\\hat{{\\gamma}}_{11}^+,\\hat{{\\gamma}}_{12}^+,\\hat{{\\gamma}}_{21}^+,\\hat{{\\gamma}}_{22}^+] \\\\ &amp;=[6.0,4.0,2.0,-2.0,-4.0,-3.5,3.0,-4.0,0.0] \\end{aligned}\\]  \\[\\hat{\\tau}_3^+=\\hat{\\beta}_3^+=\\hat{\\gamma}_{31}^+=\\hat{\\gamma}_{32}^+=\\hat{\\gamma}_{33}^+=\\hat{\\gamma}_{13}^+=\\hat{\\gamma}_{23}^+=0\\]  \\(\\mu_{ij}\\)  \\(\\mu^+,t_i^+,\\beta_j^+,\\gamma_{ij}^+\\) \\[\\begin{aligned}\\mu^+=\\mu_{tb},&amp;\\,\\,\\tau_i^+=\\mu_{ib}-\\mu_{tb},\\,\\,\\beta_j^+=\\mu_{tj}-\\mu_{tb}\\,\\mathrm{~and~}\\,\\gamma_{ij}^+=\\mu_{ij}-\\mu_{tj}-\\mu_{ib}+\\mu_{tb}\\end{aligned}\\]  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  \\(\\boldsymbol X^\\prime \\boldsymbol X\\)  16  9  9  (essential)  6.3  6.2.4  6.2  6.2:  6.2.4  x  6.2  \\(\\boldsymbol X^*\\)  \\(\\tau_1^*+\\tau_2^*+\\tau_3^*+\\tau_4^*=0\\).  \\[\\boldsymbol X^*=\\begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; -1 &amp; -1 \\\\ \\end{bmatrix}\\]  \\[\\begin{bmatrix}26&amp;-1&amp;-3&amp;-2\\\\-1&amp;15&amp;8&amp;8\\\\-3&amp;8&amp;13&amp;8\\\\-2&amp;8&amp;8&amp;14\\end{bmatrix}\\begin{bmatrix}\\hat{\\mu}^*\\\\\\hat{\\tau}_1^*\\\\\\hat{\\tau}_2^*\\\\\\hat{\\tau}_3^*\\end{bmatrix}=\\begin{bmatrix}55.1\\\\-0.9\\\\-2.5\\\\-5.9\\end{bmatrix}\\]  \\[\\hat{\\boldsymbol{\\beta}}^*=\\begin{bmatrix}\\hat{{\\mu}}^*\\\\\\hat{{\\tau}}_1^*\\\\\\hat{{\\tau}}_2^*\\\\\\hat{{\\tau}}_3^*\\end{bmatrix}=\\begin{bmatrix}2.1510\\\\0.0204\\\\0.5690\\\\-0.4510\\end{bmatrix}\\]  \\(\\hat{\\tau}_4^*=-\\hat{\\tau}_1^*-\\hat{\\tau}_2^*-\\hat{\\tau}_3^*=-0.1384\\).  \\[\\mu^*=\\bar{\\mu}_{\\cdot},\\quad\\tau_1^*=\\mu_1-\\bar{\\mu}_{\\cdot},\\quad\\tau_2^*=\\mu_2-\\bar{\\mu}_{\\cdot},\\quad\\tau_3^*=\\mu_3-\\bar{\\mu}_{\\cdot},\\quad\\tau_4^*=\\mu_4-\\bar{\\mu}_{\\cdot}\\]  \\(\\tau_ 4 ^+ = 0\\)  \\(\\boldsymbol X^+\\)  \\(\\boldsymbol X^*\\) 0-1 \\[\\begin{bmatrix}26&amp;7&amp;5&amp;6\\\\7&amp;7&amp;0&amp;0\\\\5&amp;0&amp;5&amp;0\\\\6&amp;0&amp;0&amp;6\\end{bmatrix}\\begin{bmatrix}\\hat{{\\mu}}^+\\\\\\hat{{\\tau}}_1^+\\\\\\hat{{\\tau}}_2^+\\\\\\hat{{\\tau}}_3^+\\end{bmatrix}=\\begin{bmatrix}55.1\\\\15.2\\\\13.6\\\\10.2\\end{bmatrix}\\]  \\[\\boldsymbol{\\hat{\\beta}}^+=\\begin{bmatrix}{\\hat{\\mu}}^+\\\\{\\hat{\\tau}}_1^+\\\\{\\hat{\\tau}}_2^+\\\\{\\hat{\\tau}}_3^+\\end{bmatrix}=\\begin{bmatrix}2.0125\\\\0.1589\\\\0.7075\\\\-0.3125\\end{bmatrix}\\]  \\(\\tau_ 4 ^+ = 0\\).  \\[\\mu^+=\\mu_4,\\quad\\tau_1^+=\\mu_1-\\mu_4,\\quad\\tau_2^+=\\mu_2-\\mu_4,\\quad\\tau_3^+=\\mu_3-\\mu_4,\\quad\\tau_4^+=\\mu_4-\\mu_4=0\\]  \\(\\sigma^2\\).  \\(\\boldsymbol \\beta\\)  \\(\\sigma^2\\)  \\[\\begin{align} \\hat{\\sigma}^2&amp; =\\frac{1}{n-r}(\\boldsymbol y-X\\hat{\\boldsymbol \\beta})&#39;(\\boldsymbol y-\\boldsymbol X\\hat{\\boldsymbol \\beta}) \\\\ &amp;=\\frac1{n-r}\\sum_{i=1}^n{(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1x_{i1}-\\hat{\\beta}_2x_{i2}-\\cdots-\\hat{\\beta}_{p-1}x_{ip-1})^2} \\tag{6.11} \\end{align}\\]  \\(r=\\operatorname{rank}(\\boldsymbol X)\\).  \\(\\hat \\sigma^2\\)  \\(\\sigma^2\\)  (best quadratic unbiased estimate).  \\(\\hat \\sigma^2\\)  \\(\\sigma^2\\)  (best unbiased estimate) \\((n - r)\\hat \\sigma^2 /\\sigma^2\\)  \\(n - r\\)  6.3  \\(\\tau_2^* = -0.833, \\tau_2^+ = 2.000\\) \\(\\tau_2\\)  \\(\\tau_2\\)  6.3.1   (estimable functions of the parameters).  6.1   \\(f(\\boldsymbol \\beta)\\)  \\(\\boldsymbol \\beta\\)  \\(\\boldsymbol a^\\prime \\boldsymbol \\beta\\) \\(\\boldsymbol a^\\prime\\)  p × 1  \\(\\boldsymbol a^\\prime \\boldsymbol \\beta\\)  \\(r\\) \\(\\boldsymbol a =\\boldsymbol X ^\\prime \\boldsymbol X r\\).  \\(\\boldsymbol x^\\prime_i \\boldsymbol \\beta\\)  \\(\\boldsymbol x^\\prime_i\\)  \\(\\boldsymbol X\\)  \\(i\\) \\(\\boldsymbol x^\\prime_i \\boldsymbol \\beta\\)  6.2  \\(\\mu,\\tau_1,\\tau_2,\\tau_3,\\tau_4\\)  (nonestimable).  \\(\\mu + \\tau_i\\)  \\[\\hat{\\mu}^*+\\hat{\\tau}_i^*=\\hat{\\mu}^++\\hat{\\tau}_i^+,\\quad i=1,2,3,4\\]  \\(\\mu + \\tau_i\\)  \\(\\tau_i\\)  \\({\\tau}_1{-\\tau}_2{,\\tau}_1{-\\tau}_3{,\\tau}_2{-\\tau}_3\\)  \\(\\sum_{i=1}^tc_i\\tau_i\\)  \\(\\sum_{i=1}^tc_i=0\\)  \\(\\mu+\\tau_i+\\beta_j+\\gamma_{ij},\\quad\\gamma_{ij}-\\gamma_{ij^\\prime}-\\gamma_{i^\\prime j}+\\gamma_{i^\\prime j^\\prime},\\quad\\beta_j-\\beta_j+\\bar{\\gamma}_{\\cdot j}-\\bar{\\gamma}_{\\cdot j^\\prime},\\quad\\tau_i-\\tau_i+\\bar{\\gamma}_{i\\cdot}-\\bar{\\gamma}_{i^\\prime\\cdot}\\)  10 SAS®-GLM  SAS®-Mixed  6.3.2   (connectedness).  \\[\\begin{equation} \\mu_{ij}=\\mu+\\tau_i+\\beta_j,\\quad i=1,2,\\ldots,b,j=1,2,\\ldots,t \\tag{6.12} \\end{equation}\\]  (6.12)  \\(j\\ne j^\\prime\\)  \\(i\\ne i^\\prime\\)\\(\\beta_j-\\beta_{j^\\prime}\\)  \\(\\tau_i-\\tau_{i^\\prime}\\)  (connected) 6.1  I  II  I \\[\\beta_1-\\beta_2=(\\mu+\\tau_1+\\beta_1)-(\\mu+\\tau_1+\\beta_5)+(\\mu+\\tau_2+\\beta_5)-(\\mu+\\tau_2+\\beta_2)\\]  \\(\\beta_1-\\beta_2\\)  II \\(\\beta_1-\\beta_2\\) \\(\\beta_1-\\beta_2\\)   6.1:  6.4   1  \\[\\begin{equation} H_0{:\\boldsymbol{H\\beta}}=\\boldsymbol{h}\\mathrm{~vs~}H_a{:\\boldsymbol{H\\beta}}\\neq\\boldsymbol{h} \\tag{6.13} \\end{equation}\\]  \\(\\boldsymbol{H\\beta}\\)  \\(\\boldsymbol \\beta\\) \\(\\boldsymbol H\\)  \\(q\\)  q × p\\(\\boldsymbol H\\)  \\[\\begin{equation} F_c=\\frac{SSH_0/q}{\\hat{\\sigma}^2} \\tag{6.14} \\end{equation}\\]  \\(\\hat \\sigma^2\\)  (6.11)  \\[\\begin{equation} SSH_0=(\\boldsymbol H\\hat{\\boldsymbol{\\beta}}-\\boldsymbol h)^{\\prime}\\left[\\boldsymbol H(\\boldsymbol X^{\\prime}\\boldsymbol X)^{-}\\boldsymbol H^{\\prime}\\right]^{-1}(\\boldsymbol H\\hat{\\boldsymbol{\\beta}}-\\boldsymbol h) \\tag{6.15} \\end{equation}\\]  (sum of squares due to deviations from the null hypothesis) \\((\\boldsymbol X^{\\prime}\\boldsymbol X)^{-}\\)  \\(\\boldsymbol X^{\\prime}\\boldsymbol X\\) Graybill, 1976 \\(i.i.d.\\,N(0,\\sigma^2)\\) \\(F_c\\)  \\(q,n-r\\)  \\(F\\)   (6.13)  \\(\\boldsymbol{y}=\\boldsymbol{X}^*\\boldsymbol{\\beta}^*+\\boldsymbol \\varepsilon\\)  \\(\\boldsymbol X^{*\\prime}\\boldsymbol X^*\\)  \\[H_0{:}H^*\\boldsymbol{\\beta}^*=\\boldsymbol{h}^*\\mathrm{~vs~}H_a{:}H^*\\boldsymbol{\\beta}^*\\neq\\boldsymbol{h}^*\\]  (6.15)  \\(SSH_0\\)  \\[SSH_0=(\\boldsymbol H^*\\hat{\\boldsymbol{\\beta}}^*-\\boldsymbol{h}^*)^{\\prime}[\\boldsymbol H^*(\\boldsymbol X^{*\\prime}\\boldsymbol X^*)^{-1}(\\boldsymbol{H}^*{}^{\\prime}\\hat{\\boldsymbol{\\beta}}^*-\\boldsymbol{h}^*)]\\]  \\[\\begin{aligned}H_0\\colon\\tau_1=\\tau_2=\\cdots=\\tau_t\\text{ vs }H_a\\colon\\tau_i\\neq\\tau_{i&#39;}\\quad\\text{for some }i\\neq i&#39;\\end{aligned}\\]  \\[\\begin{aligned}H_0\\colon\\tau_1^*=\\tau_2^*=&amp;\\cdots=\\tau_{t-1}^*=0\\text{ vs }H_a{:}\\tau_i^*\\neq0\\quad\\text{for some }i\\leq t\\text{ -1}\\end{aligned}\\]  6.2  \\(\\boldsymbol \\beta^*\\)  \\[H_0{:}\\begin{bmatrix}0&amp;1&amp;0&amp;0\\\\0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;1\\end{bmatrix}\\begin{bmatrix}\\mu^*\\\\\\tau_1^*\\\\\\tau_2^*\\\\\\tau_3^*\\end{bmatrix}=0\\quad\\mathrm{or}\\quad \\boldsymbol H^*\\boldsymbol \\beta^*=0\\]  \\(H_0\\)  \\[SSH_0=(\\hat{\\tau}_1^*\\quad\\hat{\\tau}_1^*\\quad\\hat{\\tau}_1^*)\\,\\boldsymbol{Z}^{-1}\\begin{bmatrix}\\hat{\\tau}_1^*\\\\\\hat{\\tau}_2^*\\\\\\hat{\\tau}_3^*\\end{bmatrix}\\]  \\(\\boldsymbol{Z}=\\boldsymbol{H}^*(\\boldsymbol{X}^*\\boldsymbol{&#39;}\\boldsymbol{X}^*)^{-1}\\boldsymbol{H}^*\\boldsymbol{&#39;}\\).  \\((\\boldsymbol{X}^*\\boldsymbol{&#39;}\\boldsymbol{X}^*)^{-1}\\)  \\(\\tau_1,\\tau_2,\\tau_3)\\)   \\(\\boldsymbol a^\\prime \\boldsymbol \\beta\\)  \\((1-\\alpha)100\\%\\)  \\[\\boldsymbol a^{\\prime}\\hat{\\boldsymbol \\beta}-[t_{\\alpha/2,n-p}]S_{\\boldsymbol a^{\\prime}\\hat{\\boldsymbol \\beta}}\\leq a^{\\prime}\\boldsymbol{\\beta}\\leq a^{\\prime}\\hat{\\beta}+[t_{\\alpha/2,n-p}]S_{\\boldsymbol a^{\\prime}\\hat{\\boldsymbol \\beta}}\\]  \\(S_{\\boldsymbol a&#39;\\boldsymbol{\\beta}}^2=\\hat{\\sigma}^2\\boldsymbol{a&#39;}(\\boldsymbol{X&#39;}\\boldsymbol{X})^{-1}\\boldsymbol{a}\\).  3  (simultaneous confidence intervals). 6.5   (population marginal means)  (Searle et al., 1980).  10   \\(i\\)  \\(\\mu+\\tau_i=\\mu_i\\) \\[\\widehat{\\mu+\\tau_i}=\\hat{\\mu}+\\hat{\\tau_i}\\]  \\(\\hat \\mu,\\hat \\tau_i\\)  (estimated population marginal means).  \\((i,j)\\)  \\(\\begin{aligned}\\mu_{ij}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij}\\end{aligned}\\).  \\(i\\)  \\(\\mu_{ij}\\)  \\[\\bar{\\mu}_{i\\cdot}=\\sum_{j=1}^b\\frac{\\mu_{ij}}b=\\mu+\\tau_i+\\bar{\\beta}_{\\cdot}+\\bar{\\gamma}_{i\\cdot}\\]  \\(j\\)  \\(\\mu_{ij}\\)  \\[\\bar{{\\mu}}_{\\cdot j}=\\sum_{i=1}^t\\frac{{\\mu}_{ij}}t={\\mu}+\\bar{{\\tau}}_{\\cdot}+{\\beta}_j+\\bar{{\\gamma}}_{\\cdot j}\\]  \\[\\begin{aligned} \\hat{{\\mu}}_{ij} &amp;=\\hat{\\mu}+\\hat{\\tau}_i+\\hat{\\beta}_j+\\hat{\\gamma}_{ij}, \\\\ \\hat{\\bar{{\\mu}}}_{i\\cdot} &amp;=\\hat{\\mu}+\\hat{\\tau}_i+\\sum_{j=1}^b\\frac{\\hat{\\beta}_j}b+\\sum_{j=1}^b\\frac{\\hat{\\gamma}_{ij}}b,\\\\ \\hat{\\bar{{\\mu}}}_{\\cdot j}&amp;=\\hat{{\\mu}}+\\sum_{i=1}^t\\frac{\\hat{{\\tau}}_i}t+\\hat{{\\beta}}_j+\\sum_{i=1}^t\\frac{\\hat{{\\gamma}}_{ij}}t \\end{aligned}\\]  \\[\\hat{\\mu},\\hat{\\tau}_1,\\hat{\\tau}_2,\\ldots,\\hat{\\tau}_t,\\hat{\\beta}_1,\\hat{\\beta}_2,\\ldots,\\hat{\\beta}_b,\\hat{\\gamma}_{11},\\hat{\\gamma}_{12},\\ldots,\\hat{\\gamma}_{tb}\\]  6.1  \\(\\hat{\\bar\\mu}_{1\\cdot}\\)  \\[\\begin{aligned} \\hat{\\bar{\\mu}}_{1\\cdot}&amp; =\\hat{\\mu}^*+\\hat{\\tau}_1^*+\\frac{\\hat{\\beta}_1^*+\\hat{\\beta}_2^*+\\hat{\\beta}_3^*}3+\\frac{\\hat{\\gamma}_{11}^*+\\hat{\\gamma}_{12}^*+\\hat{\\gamma}_{13}^*}3 \\\\ &amp;=5.500+2.333+\\frac{-2.000-0.500+2.500}3+\\frac{-1.333+1.667-0.333}3 \\\\ &amp;=7.833 \\end{aligned}\\]  \\(\\hat{\\bar\\mu}_{1\\cdot}\\)  \\({\\bar\\mu}_{1\\cdot}\\)   \\((2,2)\\)  2×2  \\(\\mu_{22}\\)  \\(\\mu_{22}\\)  2  \\[\\bar{\\mu}_{\\cdot 2}=\\frac{\\mu_{12}+\\mu_{22}}2\\]  \\(\\bar{\\mu}_{\\cdot 2}\\)  \\(\\mu_{22}\\) \\(\\bar{\\mu}_{\\cdot 2}\\) \\(\\bar{\\mu}_{2\\cdot }\\)   \\(\\boldsymbol a\\)  \\(\\boldsymbol a^\\prime\\boldsymbol \\beta^*\\).  \\[\\mathrm{Var}(\\boldsymbol a^{\\prime}\\hat{\\boldsymbol{\\beta}^*})=\\sigma^2 \\boldsymbol a^{\\prime}(\\boldsymbol X^{*\\prime}\\boldsymbol X^*)^{-1}\\boldsymbol a\\]  \\(\\boldsymbol a^\\prime\\boldsymbol \\beta^*\\)  \\[\\widehat{s.e.}(\\boldsymbol a^{\\prime}\\hat{\\boldsymbol \\beta}^*)=\\hat{\\sigma}\\sqrt{\\boldsymbol a^{\\prime}(\\boldsymbol X^{*\\prime} \\boldsymbol X^*)^{-1}\\boldsymbol a}\\]  \\[\\widehat{\\mu+\\tau_i}=\\hat{\\mu}^*+\\hat{\\tau}_i^*,\\quad i=1,2,\\ldots,t-1\\]  \\[\\widehat{{\\mu}+{\\tau}_t}=\\hat{{\\mu}}^*\\]  \\[\\mathrm{Var}(\\widehat{\\mu+\\tau_i})=\\mathrm{Var}(\\hat{\\mu}^*)+2\\mathrm{Cov}(\\hat{\\mu}^*,\\hat{\\tau}_i^*)+\\mathrm{Var}(\\hat{\\tau}_i^*)\\quad i=1,2,\\ldots,t-1\\]  \\[\\mathrm{Var}(\\widehat{\\mu+\\tau_t})=\\mathrm{Var}(\\hat{\\mu}^*)\\]  6.3:  x  6.3  (GPA) \\[y_{ijk}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij}+\\varepsilon_{ijk}\\quad i=1,2,3,4,\\quad j=1,2,\\quad k=1,2,\\ldots,n_{ij}\\]  \\(y_{ijk}\\)  GPA \\(\\tau_i\\)  \\(i\\) \\(\\beta_j\\)  \\(j\\) \\(\\gamma_{ij}\\)  6.4  \\(1\\)  \\[\\hat{\\mu}_{1f}=\\hat{\\mu}+\\hat{\\tau}_1+\\hat{\\beta}_f+\\hat{\\gamma}_{1f}=3.333-0.133-0.033+0.205=3.372\\]  6.6  6.6  6.7   6.4:  GPA  x  6.5:  x  6.6:  x  6.7:  x  (raw measn)  1  (unadjusted mean)  \\[\\hat{\\bar{\\mu}}_{1\\cdot}=\\frac{7^*3.371+5^*3.200}{7+5}=3.300\\]  (least square means)  1  \\[\\hat{\\bar{\\mu}}_{1\\cdot}=\\frac{3.371+3.200}2=3.286\\]  6.8:  x  (proportional membership structure).  6.8  1  \\[\\hat{\\tilde{\\mu}}_{1\\cdot}=\\frac{11^*3.371+22^*3.200}{33}=3.257\\]  \\[\\hat{\\tilde{\\mu}}_{\\cdot f}=\\frac{11^*3.371+12^*3.180+10^*3.475+8^*3.300}{41}=3.327\\]  \\[\\hat{\\tilde{\\mu}}_{\\cdot m}=\\frac{22^*3.200+14^*3.300+13^*3.267+10^*3.333}{59}=3.261\\]  estimate  6.9  SAS-GLM  6.8   6.9:  estimate SAS®-GLM 6.8  x 6.6   6.7  "],["chap7.html", " 7   7.1  7.2  7.3  7.4  7.5  7.6  7.7 ", "  7   A judicious man looks on statistics not to get knowledge, but to save himself from having ignorance foisted on him. - Thomas Carlyle  4  5  \\(T_1,T_2,\\cdots,T_t\\)  \\(B_1,B_2,\\cdots,B_b\\).  \\(T\\)  \\(B\\)  \\(T_1,T_2,\\cdots,T_t\\)  \\(B_1,B_2,\\cdots,B_b\\)  \\(bt\\)   \\(bt\\)  \\(bt-1\\) \\(\\mu_{11}=\\mu_{12}=\\cdots=\\mu_{tb}\\).  7.1  7.1.1   (means model)  \\[\\begin{equation} Y_{ijk}=\\mu_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b,\\quad k=1,2,\\ldots,n \\tag{7.1} \\end{equation}\\]  \\(\\varepsilon_{ijk}\\sim i.i.d.N(0,\\sigma^2),i=1,2,\\ldots,t,j=1,2,\\ldots,b,k=1,2,\\ldots,n\\) \\((T_i,B_j)\\) \\(\\mu_{ij}\\)  7.1.2   (effects model) (7.1)  \\(\\mu_{ij}\\)  \\[\\begin{equation} \\mu_{ij}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij},\\quad i=1,2,\\ldots,t,j=1,2,\\ldots,b \\tag{7.2} \\end{equation}\\] \\(\\mu\\) \\(\\tau_i\\)  \\(T_i\\) \\(\\beta_j\\)  \\(B_j\\)  \\(\\gamma_{ij}\\)  \\(T_i\\)  \\(B_j\\)  6  7.2  \\(\\sigma^2\\)  \\(\\mu_{ij}\\)  \\(\\sigma^2\\)  \\(\\mu_{11}=\\mu_{12}\\) \\(\\mu_{11}\\)  \\(\\mu_{12}\\)  \\(\\sigma^2\\)  \\(n(\\bar{y}_{11\\cdot}-\\bar{y}_{12\\cdot})^2/2\\)   \\(\\mu_{11}=\\mu_{12}\\) (beliefs).  (additive).  (interact).  \\(\\sigma^2\\).  \\(bt\\)  \\(bt\\)  1  3  \\([\\mu_{11},\\mu_{12},\\ldots,\\mu_{1b},\\ldots,\\mu_{t1},\\mu_{t2},\\ldots,\\mu_{tb}]=[\\mu_1,\\mu_{2},\\ldots,\\mu_{tb}]\\).  \\[\\hat{\\mu}_{ij}=\\frac1n\\sum_{k=1}^ny_{ijk}=\\bar{y}_{ij\\cdot},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b\\]  \\[\\hat{\\sigma}^2=\\frac1{N-bt}\\sum_{ijk}(y_{ijk}-\\bar{y}_{ij\\cdot})^2\\]  \\(N=nbt\\). \\(\\hat \\mu_{ij}\\)  \\(N(\\mu_{ij},\\sigma^2/n)\\) \\(i=1,2\\cdots,t,\\,j=1,2,\\cdots,b\\).  \\((N-bt)\\hat{\\sigma}^2/\\sigma^2\\)  \\(\\chi^2(N^-bt)\\). \\(\\hat{\\mu}_{11},\\hat{\\mu}_{12},\\ldots,\\hat{\\mu}_{tb}\\)  \\(\\sigma^2\\)   \\(T\\)  \\(B\\)  7.3   (interaction hypothesis)  \\(H_0\\colon{{\\mu}}_{ij}-\\mu_{ij}=\\mu_{i&#39;j}-\\mu_{i&#39;j&#39;}\\)  \\(i\\ne i&#39;\\)  \\(j\\ne j&#39;\\) \\(H_0\\colon\\mu_{ij}-\\mu_{i&#39;j}=\\mu_{ij&#39;}-\\mu_{i&#39;j&#39;}\\)  \\(i\\ne i&#39;\\)  \\(j\\ne j&#39;\\) \\(H_0\\colon{\\mu_{ij}-\\mu_{i&#39;j}-\\mu_{ij&#39;}+\\mu_{i&#39;j&#39;}=0}\\)  \\(i\\ne i&#39;\\)  \\(j\\ne j&#39;\\) \\(H_0\\colon\\mu_{ij}=\\mu+\\tau_i+\\beta_j\\)  \\(i\\)  \\(j\\)  \\({\\mu},{\\tau}_1,{\\tau}_2,...,{\\tau}_t,{\\beta}_1,{\\beta}_2,\\cdots,{\\beta}_b\\) 1-4  1  B  T  2  T  B 1  2  33  (the set of all possible two by two table differences).  4  1-4  T  B   7.4   (main effects)  \\[\\begin{aligned}H_{01}\\colon\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\cdots=\\bar{\\mu}_{t\\cdot}\\quad\\text{and}\\quad H_{02}\\colon\\bar{\\mu}_{\\cdot1}=\\bar{\\mu}_{\\cdot2}=\\cdots=\\bar{\\mu}_{\\cdot b}\\end{aligned}\\]  7.5   \\[y=T\\mathrm{~}B\\mathrm{~}T\\times B\\]  3  \\(bt\\)  \\(T\\times B\\)  \\(bt\\)  \\(bt\\)  3  7.6   7.7  "],["chap8.html", " 8   8.1  8.2  8.3  8.4  8.5  8.6  8.7 ", "  8   All life is an experiment. The more experiments you make, the better. - Ralph Waldo Emerson  T  B  B  T   T  B  T  B  T  8.1   T  B   8.1   \\(\\sum_{i=1}^tc_i=0\\) \\(\\bar \\mu_{i\\cdot}\\)  \\(\\sum_{i=1}^tc_i\\bar{\\mu}_{i\\cdot}\\)  T  (contrast). \\(\\sum_{i=j}^td_j=0\\) \\(\\bar \\mu_{\\cdot j}\\)  \\(\\sum_{j=1}^bd_j\\bar{\\mu}_{\\cdot j}\\)  B   8.2   \\(\\sum_{i=1}^tc_ic_i^{\\prime}=0\\) \\(\\sum_{i=1}^tc_i\\bar{\\mu}_{i\\cdot}\\)  \\(\\sum_{i=1}^tc_i^\\prime \\bar{\\mu}_{i\\cdot}\\)  T  (orthogonal contrasts).  \\(\\sum_{j=1}^tc_jc_j^{\\prime}=0\\) \\(\\sum_{j=1}^tc_j\\bar{\\mu}_{\\cdot j}\\)  \\(\\sum_{j=1}^tc_j^\\prime \\bar{\\mu}_{\\cdot j}\\)  B   \\[\\begin{aligned}S_T&amp;=\\left\\{\\sum_{i=1}^tc_{i1}\\bar{\\mu}_{i\\cdot},\\sum_{i=1}^tc_{i2}\\bar{\\mu}_{i\\cdot},\\ldots,\\sum_{i=1}^tc_{it-1}\\bar{\\mu}_{i\\cdot}\\right\\}\\end{aligned}\\]  T  t-1  \\[\\begin{aligned}S_B&amp;=\\left\\{\\sum_{j=1}^bc_{j1}\\bar{\\mu}_{\\cdot j},\\sum_{j=1}^bc_{j2}\\bar{\\mu}_{\\cdot j},\\ldots,\\sum_{j=1}^bc_{\\cdot j}\\bar{\\mu}_{j\\cdot}\\right\\}\\end{aligned}\\]  B  b-1 \\(S_T\\)  \\(S_B\\)  (partitioning)T  \\[\\begin{equation} S_T^*=\\left\\{Q_p^2=\\frac{nb(\\sum_ic_{ip}\\bar{y}_{i\\cdot\\cdot})^2}{\\sum_ic_{ip}^2},\\quad p=1,2,\\ldots,t-1\\right\\} \\tag{8.1} \\end{equation}\\] B  \\[\\begin{equation} S_B^*=\\left\\{Q_q^2=\\frac{nt(\\sum_jd_{jq}\\bar{y}_{\\cdot j\\cdot})^2}{\\sum_jd_{jq}^2},\\quad q=1,2,\\ldots,b-1\\right\\} \\tag{8.2} \\end{equation}\\] \\(S^*_T\\)  \\(Q_p^2\\)  T  0. \\(S^*_T\\)  t-1  \\(H_{01}\\colon\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\cdots=\\bar{\\mu}_{t\\cdot}\\) \\(S^*_B\\)  / 8.2    \\(j=1,2,\\cdots,b\\)  \\(\\sum_i\\omega_{ij}=0\\)  \\(i=1,2,\\cdots,t\\)  \\(\\sum_j\\omega_{ij}=0\\) \\(\\mu_{ij}\\)  \\(\\sum_i\\sum_j\\omega_{ij}\\mu_{ij}\\)  (interaction contrasts).  \\(\\sum_{i=1}^tc_i\\bar{\\mu}_{i\\cdot}\\)  T  \\(\\sum_{j=1}^bd_j\\bar{\\mu}_{\\cdot j}\\)  B  \\(\\sum_i\\sum_jc_id_j{\\mu}_{i{j}}\\)  \\(i,j\\) \\(\\omega_{ij}=c_id_j\\)  \\(\\sum_i\\sum_j\\omega_{ij}\\omega_{ij}^{\\prime}=0\\) \\(\\sum_i\\sum_j\\omega_{ij}\\mu_{ij}\\)  \\(\\sum_i\\sum_j\\omega_{ij}^{\\prime}\\mu_{ij}\\)  (orthogonal interaction contrasts).  \\(\\sum_{i=1}^tc_i\\bar{\\mu}_{i\\cdot}\\)  \\(\\sum_{i=1}^tc_i^{\\prime}\\bar{\\mu}_{i\\cdot}\\)  T  \\(\\sum_{j=1}^bd_j\\bar{\\mu}_{\\cdot j}\\)  \\(\\sum_{j=1}^bd_j^{\\prime}\\bar{\\mu}_{\\cdot j}\\)  B  \\(\\sum_{i=1}^tc_ic_i^{\\prime}=0\\)  \\(\\sum_{j=1}^bd_jd_j^{\\prime}=0\\) \\(\\sum_i\\sum_jc_id_j\\mu_{ij}\\)  \\(\\sum_i\\sum_jc_i^{\\prime}d^{\\prime}_j\\mu_{ij}\\)  \\(S^*_T\\)  \\(S^*_B\\)  8.1  \\(S^*_{T\\times B}\\)  \\[\\begin{equation} S_{T\\times B}^*=\\left\\{Q_{pq}^2=\\frac{n(\\sum_i\\sum_jc_{ip}d_{jq}\\bar{y}_{ij\\cdot})^2}{\\sum_ic_i^2\\sum_jd_j^2},\\quad p=1,2,\\ldots,t-1;q=1,2,\\ldots,b-1\\right\\} \\tag{8.3} \\end{equation}\\]  \\(S_{T\\times B}^*\\) \\(\\sum_p\\sum_qQ_{pq}^2=T{\\times}B\\)  (8.3)  (t-1)(b-1)  8.3   8.1  paint × paving  (paints)  (paving surfaces)  455.04 24  \\(\\hat \\sigma^2=18.96\\).  8.2   8.1:  x :  I  II Asphalt I, Asphalt II, Concrete   8.2:  x  (paving)  8.3  8.4   8.3:  x  8.4:  x : Type  asphalt vs concrete 8.5  8.3  8.4  8.5   8.5:  x  (8.1) \\[Q_1^2=\\frac{3\\cdot3[(1)29.0+(-1)35.0]^2}{(1)^2+(-1)^2}=162.0\\]  (8.2) (asphalt)  (concrete)  \\[Q_2^2=\\frac{3\\cdot4[(1)(26.5)+(1)(27.5)+(-2)(29.5)]^2}{1^2+1^2+(-2)^2}=40.5\\]  (8.3) type × type  \\[Q_3^2=\\frac{3\\left[(1)(30)+(1)(28)+(-2)(29)+(-1)(34)+(-1)(35)+(2)(36)\\right]^2}{\\left(1\\right)^2+\\left(1\\right)^2+\\left(-2\\right)^2+\\left(-1\\right)^2+\\left(-1\\right)^2+\\left(2\\right)^2}=2.25\\]  8.5     \\(F\\)  \\(F=0.32\\) I  II   \\(F\\)  \\(F=8.54\\) II  I  8.1  II   I  II \\(F=4.45\\) \\(F=2.14\\)   I  II \\(\\mu_{11}+\\mu_{12}-\\mu_{21}-\\mu_{22}=0\\).  I  II.  I  II   8.6   8.6:  3  x  8.6  8.1 1 II  I 2 I  II3  II 4  II 5  SAS®  SPSS 12  8.4   (quantitative).  Lin T × Lin BT  B Lin T × Quad B T  B  3×4  T  5, 10, 15 B  2, 4, 6, 8Lin T  \\(-\\bar{\\mu}_{1\\cdot}+0\\bar \\mu_{2\\cdot}+\\bar{\\mu}_{3\\cdot}=0\\) Lin B  \\(-3\\bar{{\\mu}}_{\\cdot1}-\\bar{{\\mu}}_{\\cdot2}+\\bar{{\\mu}}_{\\cdot3}+3\\bar{{\\mu}}_{\\cdot4}=0\\).  Lin T  \\(\\sum_{i=1}^3c_i\\bar{\\mu}_{i\\cdot}=0\\)  \\(c_1=-1,c_2=0,c_3=1\\).  Lin B  \\(\\sum_{j=1}^4d_j\\bar{\\mu}_{\\cdot j}=0\\)  \\(d_1=-3,d_2=-1,d_3=1,d_4=3\\).  Lin T × Lin B  \\(3\\mu_{11}+\\mu_{12}-\\mu_{13}-3\\mu_{14}-3\\mu_{31}-\\mu_{32}+\\mu_{33}+3\\mu_{34}=0\\).  \\(c_i\\)  \\(d_j\\)  Beyer (1968).  8.7  3×4   8.7: 3×4  x  \\(x_1,x_2,\\cdots,x_t\\)  T \\(z_1,z_2,\\cdots,z_b\\)  B  \\(\\alpha_{kh},k=0,1,2,\\cdots,t-1,h=0,1,2,\\cdots,b-1\\)  \\(x_i\\)  \\(z_j\\)  \\(\\alpha_{kh}\\)  \\[\\begin{equation} \\mu_{ij}=\\sum_{k=0}^{t-1}\\sum_{h=0}^{b-1}\\alpha_{kh}x_i^kz_j^h \\tag{8.4} \\end{equation}\\]  (8.4) \\[\\begin{aligned}\\mu_{ij}=&amp;\\alpha_{00}+\\alpha_{10}x_i+\\alpha_{20}x_i^2+\\cdots+\\alpha_{t-10}x_i^{t-1}+\\alpha_{01}z_j+\\alpha_{02}z_j^2+\\cdots+\\alpha_{0b-1}z_j^{b-1}\\\\&amp;+\\alpha_{11}x_iz_j+\\alpha_{12}x_iz_j^2+\\cdots+\\alpha_{t-1b-1}x_i^{t-1}z_j^{b-1}\\end{aligned}\\]  (8.4)  \\(\\alpha_{kh}\\)  8.8  3×4  \\(x\\)  -10  1\\(z\\)  -3, -1, 1  3.  8.8 Lin T  Lin B  \\(40\\alpha_{11}+328\\alpha_{13}=0\\) .  \\(\\alpha_{11}  0\\)  \\(\\alpha_{13}  0\\) \\(\\alpha_{11}  0\\)  8.8: 3×4  x  \\(x^2z^2\\)  \\(xz^2,z^2,x^2z,x^2,xz,x,z\\).  \\(\\alpha_{22}\\)  \\[\\left(\\frac{x-h_1}{c_1}\\right)^2\\left(\\frac{z-h_2}{c_2}\\right)^2\\]  \\(\\left(\\frac{x-h_1}{c_1}\\right)\\)  \\(\\left(\\frac{z-h_2}{c_2}\\right)\\)  \\(x\\)  \\(z\\)  \\(\\left(\\frac{x-h_1}{c_1}\\right)^2\\left(\\frac{z-h_2}{c_2}\\right)^2\\)  \\(xz^2,z^2,x^2z,x^2,xz,x,z\\)  8.5   3  \\(n\\)  \\(n_i\\) B  \\(nt\\)T  \\(nb\\).  3.2  3  LSD procedureBonferronis method \\(t\\)  Scheffés procedure. Scheffés procedure   \\(F\\)   \\(F\\)  LSD procedure Johnson (1976)   \\(F\\)  \\(t\\)  Bonferronis method.  \\(t\\)  Bonferronis method. 8.6   8.7  "],["chap9.html", " 9   9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8 ", "  9   Numerical quantities focus on expected values, graphical summaries on unexpected values. - John Tukey  7  8  13-15  10-12  9.1   7.1.1  \\(\\mu_{ij}\\)  T  \\(i\\)  B  \\(j\\)  \\(Y_{ijk}\\)  \\[\\begin{equation} Y_{ijk}=\\mu_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b,k=1,2,\\ldots,n_{ij} \\tag{9.1} \\end{equation}\\]  \\[\\varepsilon_{ijk}\\sim i.i.d.N(0,\\sigma^2),\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b,\\quad k=1,2,\\ldots,n_{ij}\\]  \\(i\\)  \\(j\\)\\(n_{ij}&gt;0\\). 9.2   \\(bt\\)  \\(bt\\)  1-3  \\[\\begin{equation} \\hat{\\mu}_{ij}=\\frac1{n_{ij}}\\sum_{k=1}^{n_{ij}}y_{ijk}=\\bar{y}_{ij\\cdot},i=1,2,\\ldots,t,j=1,2,\\ldots,b \\tag{9.2} \\end{equation}\\]  \\[\\begin{equation} \\hat{\\sigma}^2=\\frac1{N-bt}\\sum_{ijk}(y_{ijk}-\\overline{y}_{ij\\cdot})^2 \\tag{9.3} \\end{equation}\\]  \\(N=n_{\\cdot}\\). \\(\\hat \\mu_{ij},\\hat \\sigma^2\\)  \\[\\hat{\\mu}_{ij}\\thicksim N(\\mu_{ij},\\sigma^2/n_{ij})\\quad\\mathrm{for~}i=1,2,\\ldots,t,j=1,2,\\ldots,b\\]  \\[(N-bt)\\hat{\\sigma}^2/\\sigma^2\\thicksim\\chi^2(N-bt)\\]  \\(\\hat \\mu_{ij},\\hat \\sigma^2\\)    T  B   \\[\\begin{array}{l}H_{T\\times B}\\colon\\mu_{ij}-\\mu_{i&#39;j}-\\mu_{ij&#39;}+\\mu_{i&#39;j&#39;}=0&amp;\\text{ for all }i\\neq i&#39;\\text{ and }j\\neq j&#39;\\\\H_T\\colon\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\cdots=\\bar{\\mu}_{t\\cdot}\\\\H_B\\colon\\bar{\\mu}_{\\cdot1}=\\bar{\\mu}_{\\cdot2}=\\cdots=\\bar{\\mu}_{\\cdot b}\\end{array}\\]  \\(H_{T\\times B},H_T,H_B\\)   7.2  \\(\\mu,\\tau_i,\\beta_j,\\gamma_{ij},i=1,2,\\cdots,t,j=1,2,\\cdots,b\\)  \\(\\mu_{ij}\\)  \\[\\mu_{ij}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b\\]  10  1.5  1.6  (well-balanced)  10  9.3   9.1  9.1  9.2  (row marginal mean)  (column marginal mean)   9.1:  x  9.2:  9.2  x  T  B  9.1  9.2  T × B  9.1  \\(T_1\\)  22.75 9.2  \\(T_1\\)  23.  9.5   9.1  \\[\\hat{\\sigma}^2=\\frac1{N-bt}\\sum_{ijk}(y_{ijk}-\\overline{y}_{ij.})^2=20/10=2\\]  \\(N-bt=16-6=10\\).  \\[\\begin{aligned}H_0\\colon\\mu_{11}=\\mu_{12}=\\mu_{13}=\\mu_{21}=\\mu_{22}=\\mu_{23}\\end{aligned}\\]  (8.1)  \\[SSH_0=\\frac{60^2}3+\\frac{50^2}2+\\frac{72^2}3+\\frac{52^2}2+\\frac{69^2}3+\\frac{96^2}3-\\frac{399^2}{16}=238.9375\\]  5  \\(H_0\\)  \\(F\\)  \\[F_c=\\frac{238.9375/5}2=23.89\\]  \\(\\hat\\alpha = 0.00003\\) \\(H_0\\)  9.4   9.1  T × B  \\[\\begin{aligned}H_{T\\times B}\\colon\\mu_{ij}-\\mu_{i&#39;j}-\\mu_{ij&#39;}+\\mu_{i&#39;j&#39;}=0&amp;&amp;\\text{ for all }i\\neq i&#39;&amp;\\mathrm{~and~}j\\neq j&#39;\\end{aligned}\\]  1.4  \\(H_{T\\times B}\\)  \\[\\mu_{11}-\\mu_{12}-\\mu_{21}+\\mu_{22}=0\\]  \\[\\mu_{11}-\\mu_{13}-\\mu_{21}+\\mu_{23}=0\\]  \\(\\boldsymbol C\\boldsymbol \\mu=0\\) \\[\\boldsymbol C=\\begin{bmatrix}1&amp;-1&amp;0&amp;-1&amp;1&amp;0\\\\1&amp;0&amp;-1&amp;-1&amp;0&amp;1\\end{bmatrix}\\quad\\mathrm{and}\\quad \\boldsymbol \\mu^{\\prime}=[\\mu_{11}~\\mu_{12}~\\mu_{13}~\\mu_{21}~\\mu_{22}~\\mu_{23}]\\]  (1.11) \\(\\boldsymbol D=\\mathrm{Diag}[1/3,1/2,1/3,1/2,1/3,1/3]\\) \\[SSH_{T \\times B}=[\\boldsymbol C\\hat{\\boldsymbol{\\mu}}]^{\\prime}[\\boldsymbol C\\boldsymbol D\\boldsymbol C^{\\prime}]^{-1}[\\boldsymbol C\\hat{\\boldsymbol{\\mu}}]=[-8\\quad2]\\begin{bmatrix}\\frac{10}6&amp;\\frac56\\\\\\frac56&amp;\\frac96\\end{bmatrix}^{-1}\\begin{bmatrix}-8\\\\2\\end{bmatrix}\\]  \\(SSH_{T\\times B}=776(6/65)=71.631\\)  2  \\(F\\)  \\(F_c=(71.631/2)/2=17.91\\)  2  10 \\(\\hat \\alpha=0.0005\\)  \\(\\boldsymbol C\\)   T × B  \\(H_T{:{\\bar{\\mu}}_{1\\cdot}}=\\bar{{\\mu}}_{2\\cdot}\\).  \\(H_T\\)  \\(\\boldsymbol C\\boldsymbol \\mu=\\boldsymbol 0\\) \\(\\boldsymbol C=[1\\,\\,1\\,\\,1\\,\\,-1\\,\\,-1\\,\\,-1]\\).  (1.11)  \\[SSH_T=[\\boldsymbol C\\hat{\\boldsymbol{\\mu}}]^{\\prime}[\\boldsymbol C\\boldsymbol D\\boldsymbol C^{\\prime}]^{-1}[\\boldsymbol C\\hat{\\boldsymbol{\\mu}}]=[-12][14/6]^{-1}[-12]=61.714\\]  1  \\(F\\)  \\(F_{c}=(61.714/1)/2=30.857\\) \\(\\hat \\alpha=0.00024\\)  \\(\\boldsymbol C=[\\frac{1}{3}\\,\\,\\frac{1}{3}\\,\\,\\frac{1}{3}\\,\\,-\\frac{1}{3}\\,\\,-\\frac{1}{3}\\,\\,-\\frac{1}{3}]\\) \\(\\boldsymbol C\\)  \\(\\boldsymbol C\\)  \\(F\\)   \\(H_B\\colon\\bar{\\mu}_{\\cdot1}=\\bar{\\mu}_{\\cdot2}=\\bar{\\mu}_{\\cdot3}\\) \\(H_B\\)  \\(\\boldsymbol C\\boldsymbol \\mu=\\boldsymbol 0\\)  \\[\\boldsymbol C=\\begin{bmatrix}1&amp;-1&amp;0&amp;1&amp;-1&amp;0\\\\1&amp;0&amp;-1&amp;1&amp;0&amp;-1\\end{bmatrix}\\]  (1.11)  \\[\\begin{aligned}SSH_B&amp;=[C\\hat{\\boldsymbol{\\mu}}]^{\\prime}[\\boldsymbol C\\boldsymbol D\\boldsymbol C^{\\prime}]^{-1}[\\boldsymbol C\\hat{\\boldsymbol{\\mu}}]=[-2\\,\\,-10]\\begin{bmatrix}\\frac{10}6&amp;\\frac56\\\\\\frac56&amp;\\frac96\\end{bmatrix}^{-1}\\begin{bmatrix}-2\\\\-10\\end{bmatrix}\\\\\\\\&amp;=[-2\\,\\,-10]\\frac6{65}\\begin{bmatrix}9&amp;-5\\\\-5&amp;10\\end{bmatrix}\\begin{bmatrix}-2\\\\-10\\end{bmatrix}=77.169\\end{aligned}\\]  2  \\(F\\)  \\(F_c=19.29\\) \\(\\hat \\alpha=0.0037\\)   9.3  7   9.3:  9.1  x  \\[SS_T+SS_B+SS_{T\\times B}=SS_{\\mu_{11}=\\mu_{12}=\\cdot\\cdot\\cdot=\\mu_{23}}\\]  \\(SS_T,SS_B,SS_{T\\times B}\\)   T, B  T × B  T, B  T × B   10  9.5   \\(\\bar{\\mu}_{1\\cdot},\\bar{\\mu}_{2\\cdot},\\ldots,\\bar{\\mu}_{t\\cdot}\\) \\(\\bar{\\mu}_{i\\cdot}\\)  \\[\\begin{equation} \\hat{\\bar{\\mu}}_{i\\cdot}=\\frac1b\\sum_{j=1}^b\\hat{\\mu}_{ij}=\\bar{\\hat{\\mu}}_{i\\cdot}\\quad i=1,2,\\ldots,t \\tag{9.4} \\end{equation}\\] \\(\\hat{\\bar{\\mu}}_{i\\cdot}\\)  \\[\\begin{equation} \\widehat{s.e.}(\\hat{\\bar{\\mu}}_{i\\cdot})=\\frac{\\hat{\\sigma}}b\\sqrt{\\sum_{j=1}^b\\frac1{n_{ij}}},\\quad i=1,2,\\ldots,t \\tag{9.5} \\end{equation}\\] \\(\\bar{\\mu}_{\\cdot j}\\)  \\[\\begin{equation} \\hat{\\bar{\\mu}}_{\\cdot j}=\\frac1t\\sum_{i=1}^t\\hat{\\mu}_{ij}=\\bar{\\hat{\\mu}}_{\\cdot j},\\quad j=1,2,\\ldots,b \\tag{9.6} \\end{equation}\\] \\[\\begin{equation} \\widehat{s.e.}(\\hat{\\bar{\\mu}}_{\\cdot j})=\\frac{\\hat{\\sigma}}t\\sqrt{\\sum_{i=1}^t\\frac1{n_{ij}}},\\quad j=1,2,\\ldots,b \\tag{9.7} \\end{equation}\\]  \\(\\hat{\\bar{\\mu}}_{i\\cdot}\\)  \\(\\bar y_{i\\cdot}\\)  \\(\\hat{\\bar{\\mu}}_{\\cdot j}\\)  \\(\\bar y_{\\cdot j}\\). \\(\\bar{y}_{1\\cdot\\cdot}=22.75,\\hat {\\bar \\mu}_{1\\cdot}=23\\). \\(\\hat{\\bar{\\mu}}_{i\\cdot},\\hat{\\bar{\\mu}}_{\\cdot j}\\)  \\(\\bar{\\mu}_{i\\cdot},\\bar{\\mu}_{\\cdot j}\\)  \\(\\bar{y}_{i\\cdot\\cdot},\\bar{y}_{\\cdot j\\cdot}\\)  \\[\\tilde{\\mu}_{i\\cdot}=\\left(\\sum_{j=1}^bn_{ij}\\mu_{ij}\\right)\\Bigg/n_{i\\cdot},\\quad\\tilde{\\mu}_{\\cdot j}=\\left(\\sum_{i=1}^tn_{ij}\\mu_{ij}\\right)\\Bigg/n_{\\cdot j}\\] \\(\\bar{y}_{i\\cdot\\cdot}\\)  \\(i\\) \\(\\bar{y}_{\\cdot j \\cdot}\\)  \\(j\\) \\(\\hat{\\bar{\\mu}}_{i\\cdot},\\hat{\\bar{\\mu}}_{\\cdot j}\\)  \\(\\bar{y}_{i\\cdot\\cdot},\\bar{y}_{\\cdot j \\cdot}\\)  9.1  9.2  \\(\\hat{\\bar{\\mu}}_{1\\cdot}=23,\\hat{\\bar{\\mu}}_{2\\cdot}=27,\\hat{\\bar{\\mu}}_{\\cdot1}=23,\\hat{\\bar{\\mu}}_{\\cdot2}=27,\\hat{\\bar{\\mu}}_{\\cdot3}=28\\).  \\[\\begin{aligned} &amp;\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{1\\cdot}) =\\frac{\\sqrt{2}}3\\sqrt{\\frac13+\\frac12+\\frac13}=0.51 \\\\ &amp;\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{2\\cdot}) =\\frac{\\sqrt2}3\\sqrt{\\frac12+\\frac13+\\frac13}=0.51 \\\\ &amp;\\widehat{s.e.}(\\hat{\\bar{{\\mu}}}_{\\cdot1}) =\\frac{\\sqrt{2}}2\\sqrt{\\frac13+\\frac12}=0.65 \\\\ &amp;\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{\\cdot2}) =\\frac{\\sqrt2}2\\sqrt{\\frac12+\\frac13}=0.65 \\\\ &amp;\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{\\cdot3}) =\\frac{\\sqrt2}2\\sqrt{\\frac13+\\frac13}=0.58 \\end{aligned}\\]  \\(\\sum_ic_i\\bar{\\mu}_{i\\cdot}\\)  \\(\\sum_jd_j\\bar{\\mu}_{\\cdot j}\\) \\[\\begin{equation} \\frac{\\sum_ic_i\\hat{\\bar{\\mu}}_{i\\cdot}-\\sum_ic_i\\bar{\\mu}_{i\\cdot}}{\\frac{\\hat{\\sigma}}b\\sqrt{\\sum_ic_i^2\\left(\\sum_j\\frac1{n_{ij}}\\right)}}\\thicksim t(v) \\tag{9.8} \\end{equation}\\]  \\[\\begin{equation} \\frac{\\sum_jc_j\\hat{\\bar{\\mu}}_{\\cdot j}-\\sum_jc_j\\bar{\\mu}_{\\cdot j}}{\\frac{\\hat{\\sigma}}t\\sqrt{\\sum_jc_j^2\\left(\\sum_i\\frac1{n_{ij}}\\right)}}\\thicksim t(v) \\tag{9.9} \\end{equation}\\]  (9.8)  (9.9)  (1.4)  \\(H_T{:{\\bar{\\mu}}_{1\\cdot}}=\\bar{{\\mu}}_{2\\cdot}\\)  \\(t\\)  \\[t_c=\\frac{\\hat{\\bar{\\mu}}_{1\\cdot}-\\hat{\\bar{\\mu}}_{2\\cdot}}{\\frac\\partial b\\sqrt{\\sum_j\\frac1{n_{1j}}+\\sum_j\\frac1{n_{2j}}}}=\\frac{23-27}{\\frac{\\sqrt{2}}3\\sqrt{\\left(\\frac13+\\frac12+\\frac13\\right)+\\left(\\frac12+\\frac13+\\frac13\\right)}}=\\frac{-4}{\\frac{1.414}3\\sqrt{\\frac73}}=\\frac{-4}{0.72}=-5.55\\]  \\(\\hat \\alpha=0.00024\\) \\(\\hat{\\bar{\\mu}}_{1\\cdot}-\\hat{\\bar{\\mu}}_{2\\cdot}\\)  95%  \\[\\begin{aligned} \\hat{\\bar{\\mu}}_{\\cdot1}-\\hat{\\bar{\\mu}}_{\\cdot2}\\mp t_{\\frac\\alpha2,v}\\frac{\\hat{\\sigma}}t\\sqrt{\\sum_i\\frac1{n_{i1}}+\\sum_j\\frac1{n_{i2}}}&amp; =23-24\\mp t_{.025,v}\\cdot\\frac{1.414}2\\sqrt{\\left(\\frac13+\\frac12\\right)+\\left(\\frac12+\\frac13\\right)} \\\\ &amp;=-1\\mp(2.228)(0.91)=-1\\mp2.03 \\end{aligned}\\] 9.6   3  3.2  (9.8)  (9.9)  \\(t\\)  \\(F\\)  \\(F\\)  \\(t\\)  Bonferronis method \\(\\alpha/p\\)  \\(\\alpha\\) \\(p\\)  \\(bt(t + 1)/2 + bt(b + 1)/2\\)   \\(F\\)  Fishers LSD  \\(F\\)  Bonferronis method.  Scheffés procedure. 9.4  10.7  9.7   10  9.8  "],["chap10.html", " 10   10.1  10.2  I  10.3  SAS  10.4 IIV  10.5  SAS-GLM  IIV  10.6  10.7  10.8 ", "  10   It is a capital mistake to theorize before one has data. - Sir Arthur Conan Doyle  9  10.1   (9.1)  \\[\\begin{equation} y_{ijk}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t;~j=1,2,\\ldots,b;~k=1,2,\\ldots,n_{ij} \\tag{10.1} \\end{equation}\\]  \\({\\varepsilon}_{ijk}\\thicksim i.i.d.N(0,{\\sigma}^2)\\). 10.2  I   9  3.2  (sequential)  .  \\(y_{ijk}=\\mu+\\varepsilon_{ijk}\\) \\(RSS_1\\). .  \\(y_{ijk}=\\mu+\\tau_i+\\varepsilon_{ijk}\\) \\(RSS_2\\). .  \\(y_{ijk}=\\mu+\\tau_i+\\beta_j+\\varepsilon_{ijk}\\) \\(RSS_3\\). .  \\(y_{ijk}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij}+\\varepsilon_{ijk}\\) \\(RSS_4\\). \\(RSS_i\\)  \\(i(i=1,2,3,4)\\) \\(RSS_1\\)  \\(RSS_2\\)  \\(R(\\tau|\\mu)\\) \\(\\mu\\)  \\(\\tau\\)  \\(R(\\tau|\\mu)=RSS_1-RSS_2\\).  \\(\\tau_i\\) \\(R(\\tau|\\mu)\\)  \\(\\tau_i\\) \\(R(\\tau|\\mu)\\)  T \\(R(\\beta|\\mu,\\tau)=RSS_2-RSS_3\\)  \\(\\mu\\)  \\(\\tau\\)  \\(\\beta\\)  \\(\\beta_j\\)\\(R(\\beta|\\mu,\\tau)\\)  B  T \\(R(\\gamma|\\mu,\\tau,\\beta)=RSS_3-RSS_4\\)  \\(\\mu,\\tau,\\beta\\)  \\(\\gamma\\)  \\(\\gamma_{ij}\\)\\(R(\\gamma|\\mu,\\tau,\\beta)\\)   10.1  (sequential analysis)  I  10.1  T, B  T × B  \\(F\\)  10.1  \\(F\\)  10.4   10.1: I  x  I  9.1  6  \\(y_{ijk}={\\mu}+{\\varepsilon}_{ijk}\\).  \\(\\mu\\)  \\(\\hat{{\\mu}}=\\bar{y}_{\\cdot\\cdot\\cdot}=24.9375\\) \\[RSS_1=\\sum_{i,j,k}(y_{ijk}-\\hat{\\mu})^2=\\sum_{i,j,k}y_{ijk}^2-n_{\\cdot\\cdot}\\bar{y}^2_{\\cdot\\cdot\\cdot}=10209-16(24.9375)^2=258.9375\\]  \\(n_{\\cdot\\cdot} = 16 - 1 = 15\\)   \\[\\begin{bmatrix}16&amp;8&amp;8\\\\8&amp;8&amp;0\\\\8&amp;0&amp;8\\end{bmatrix}\\begin{bmatrix}\\hat{{\\mu}}\\\\\\hat{{\\tau}}_1\\\\\\hat{{\\tau}}_2\\end{bmatrix}=\\begin{bmatrix}399\\\\182\\\\217\\end{bmatrix}\\]  6.2  \\(\\hat{{\\tau}}_2=0,\\hat{{\\tau}}_1=-4.375,\\hat \\mu=27.125\\)  6  \\[ \\begin{aligned}RSS_2=\\sum_{i,j,k}(y_{ijk}-\\hat{\\mu}-\\hat{\\tau}_i)^2&amp;=\\sum_{i,j,k}y_{ijk}^2-\\hat{\\mu}\\cdot y_{\\cdot\\cdot\\cdot}-\\hat{\\tau}_1\\cdot y_{1\\cdot\\cdot}-\\hat{\\tau}_{2} \\cdot y_{2\\cdot\\cdot} \\\\ &amp;=10209-27.125\\cdot399-(-4.375)\\cdot 182-0\\cdot 217 \\\\ &amp;=182.375 \\end{aligned} \\]  16-2=14 \\(R(\\tau|\\mu)=258.9375-182.375=76.5625\\)  15-14=1   \\[\\begin{bmatrix}16&amp;8&amp;8&amp;5&amp;5&amp;6\\\\8&amp;8&amp;0&amp;3&amp;2&amp;3\\\\8&amp;0&amp;8&amp;2&amp;3&amp;3\\\\5&amp;3&amp;2&amp;5&amp;0&amp;0\\\\5&amp;2&amp;3&amp;0&amp;5&amp;0\\\\6&amp;3&amp;3&amp;0&amp;0&amp;6\\end{bmatrix}\\begin{bmatrix}\\hat{\\mu}\\\\\\hat{\\tau}_1\\\\\\hat{\\tau}_2\\\\\\hat{\\beta}_1\\\\\\hat{\\beta}_2\\\\\\hat{\\beta}_3\\end{bmatrix}=\\begin{bmatrix}399\\\\182\\\\217\\\\112\\\\119\\\\168\\end{bmatrix}\\]  \\(\\tau_2 = 0\\)  \\(\\beta_3 = 0\\) 6  \\(\\tau = 0\\)  \\(\\beta = 0\\)  \\[\\begin{bmatrix}16&amp;8&amp;5&amp;5\\\\8&amp;8&amp;3&amp;2\\\\5&amp;3&amp;5&amp;0\\\\5&amp;2&amp;0&amp;5\\end{bmatrix}\\begin{bmatrix}\\hat{\\mu}\\\\\\hat{\\tau}_1\\\\\\hat{\\beta}_1\\\\\\hat{\\beta}_2\\end{bmatrix}=\\begin{bmatrix}399\\\\182\\\\112\\\\119\\end{bmatrix}\\]  \\(\\hat{\\mu}=30.154,\\hat{\\tau}_1=-4.308,\\hat{\\beta}_1=-5.169,\\hat{\\beta}_2=-4.631\\) \\[\\begin{aligned} RSS_3&amp; =\\sum_{i,j,k}y_{ijk}^2-\\hat{\\mu}\\cdot y_{\\cdot\\cdot\\cdot}-\\hat{\\tau}_1\\cdot y_{1\\cdot\\cdot}-\\hat{\\beta}_1\\cdot y_{\\cdot1\\cdot}-\\hat{\\beta}_2\\cdot y_{\\cdot2\\cdot} \\\\ &amp;=10209-30.154\\cdot399-(-4.308)\\cdot182-(-5.169)\\cdot112-(-4.631)\\cdotp119 \\\\ &amp;=91.631 \\end{aligned}\\]  16-4=12  \\(R(\\beta|\\mu,\\tau)=RSS_2-RSS_3=182.375-91.631=90.744\\)  14-12=2   \\[\\begin{bmatrix}16&amp;8&amp;8&amp;5&amp;5&amp;6&amp;3&amp;2&amp;3&amp;2&amp;3&amp;3\\\\8&amp;8&amp;0&amp;3&amp;2&amp;3&amp;3&amp;2&amp;3&amp;0&amp;0&amp;0\\\\8&amp;0&amp;8&amp;2&amp;3&amp;3&amp;0&amp;0&amp;0&amp;2&amp;3&amp;3\\\\5&amp;3&amp;2&amp;5&amp;0&amp;0&amp;3&amp;0&amp;0&amp;2&amp;0&amp;0\\\\5&amp;2&amp;3&amp;0&amp;5&amp;0&amp;0&amp;2&amp;0&amp;0&amp;3&amp;0\\\\6&amp;3&amp;3&amp;0&amp;0&amp;6&amp;0&amp;0&amp;3&amp;0&amp;0&amp;3\\\\3&amp;3&amp;0&amp;3&amp;0&amp;0&amp;3&amp;0&amp;0&amp;0&amp;0&amp;0\\\\2&amp;2&amp;0&amp;0&amp;2&amp;0&amp;0&amp;2&amp;0&amp;0&amp;0&amp;0\\\\3&amp;3&amp;0&amp;0&amp;0&amp;3&amp;0&amp;0&amp;3&amp;0&amp;0&amp;0\\\\2&amp;0&amp;2&amp;2&amp;0&amp;0&amp;0&amp;0&amp;0&amp;2&amp;0&amp;0\\\\3&amp;0&amp;3&amp;0&amp;3&amp;0&amp;0&amp;0&amp;0&amp;0&amp;3&amp;0\\\\3&amp;0&amp;3&amp;0&amp;0&amp;3&amp;0&amp;0&amp;0&amp;0&amp;0&amp;3\\end{bmatrix}\\left.\\left[\\begin{array}{c}\\hat{\\mu}\\\\\\hat{\\tau}_1\\\\\\hat{\\tau}_2\\\\\\hat{\\beta}_1\\\\\\hat{\\beta}_2\\\\\\hat{\\beta}_3\\\\\\hat{\\gamma}_{11}\\\\\\hat{\\gamma}_{12}\\\\\\hat{\\gamma}_{13}\\\\\\hat{\\gamma}_{21}\\\\\\hat{\\gamma}_{22}\\\\\\hat{\\gamma}_{23}\\end{array}\\right.\\right]=\\begin{bmatrix}399\\\\182\\\\217\\\\112\\\\119\\\\168\\\\60\\\\50\\\\72\\\\52\\\\69\\\\96\\end{bmatrix}\\]  \\(\\hat{\\tau}_2=0,\\hat{\\beta}_3=0,\\hat{\\gamma}_{13}=0,\\hat{\\gamma}_{21}=0,\\hat{\\gamma}_{22}=0,\\hat{\\gamma}_{23}=0\\)  6  \\[\\begin{bmatrix}16&amp;8&amp;5&amp;5&amp;3&amp;2\\\\8&amp;8&amp;3&amp;2&amp;3&amp;2\\\\5&amp;3&amp;5&amp;0&amp;3&amp;0\\\\5&amp;2&amp;0&amp;5&amp;0&amp;2\\\\3&amp;3&amp;3&amp;0&amp;3&amp;0\\\\2&amp;2&amp;0&amp;2&amp;0&amp;2\\end{bmatrix}\\begin{bmatrix}\\hat{\\mu}\\\\\\hat{\\tau}_1\\\\\\hat{\\beta}_1\\\\\\hat{\\beta}_2\\\\\\hat{\\gamma}_{11}\\\\\\hat{\\gamma}_{12}\\end{bmatrix}=\\begin{bmatrix}399\\\\182\\\\112\\\\119\\\\60\\\\50\\end{bmatrix}\\]  \\(\\hat{\\mu}=32,\\hat{\\tau}_1=-8,\\hat{\\beta}_1=-6,\\hat{\\beta}_2=-9,\\hat{\\gamma}_{11}=2,\\hat{\\gamma}_{12}=10\\).  \\(\\hat\\sigma^2=2\\) (full model)  \\(RSS_4=10,209-10,189=20\\) 10  \\(R(\\gamma|\\mu,\\tau,\\beta)=RSS_3-RSS_4=91.631-20=71.631\\)  12-10=2  10.2   10.2: I  x I  9  T  B  \\(\\mu\\)  \\(\\beta\\)  \\(\\tau\\) \\(\\gamma\\)  10.2  \\(R(\\beta|\\mu)\\)  \\(R(\\tau|\\mu,\\beta)\\). T  B  \\(F\\)  10.1 / 10.2   6  \\(\\hat{{\\mu}}=32,\\hat{{\\tau}}_1=-8,\\hat{{\\beta}}_1=-6,\\hat{\\beta}_2=-9,\\hat{\\gamma}_{11}=2,\\hat{\\gamma}_{12}=10\\)  \\(\\mu,\\tau_1,\\beta_1,\\beta_2,\\gamma_{11},\\gamma_{12}\\)  \\[\\begin{align} &amp;\\hat{\\mu} \\,\\,\\text{is an unbiased estimate of}\\,\\, \\mu+\\tau_2+\\beta_3+\\gamma_{23} \\\\ &amp;\\hat{\\tau}_1 \\,\\,\\text{is an unbiased estimate of}\\,\\, \\tau_1-\\tau_2+\\gamma_{13}-\\gamma_{23} -\\gamma_{23} \\\\ &amp;\\hat{\\beta}_1 \\,\\,\\text{is an unbiased estimate of}\\,\\, \\beta_1-\\beta_3+\\gamma_{21}-\\gamma_{23} -\\gamma_{23} \\\\ &amp;\\hat{\\beta}_2 \\,\\,\\text{is an unbiased estimate of}\\,\\, \\beta_2-\\beta_3+\\gamma_{22}-\\gamma_{23} \\gamma_{23}\\\\ &amp;\\hat{\\gamma}_{11} \\,\\,\\text{is an unbiased estimate of}\\,\\, \\gamma_{11}-\\gamma_{13}-\\gamma_{21}+\\gamma_{23}\\\\ &amp;\\hat{\\gamma}_{12} \\,\\,\\text{is an unbiased estimate of}\\,\\, \\gamma_{12}-\\gamma_{13}-\\gamma_{22}+\\gamma_{23} \\tag{10.2} \\end{align}\\]  10.3  SAS  SAS®-GLM  SAS  9.1  SAS-GLM  PROC GLM; CLASSES T B; MODEL y = T B T*B/&lt;selected options&gt;;  MODEL  E  SAS-GLM  6  E SAS-GLM  SAS-GLM  10.3  \\(\\boldsymbol\\ell^\\prime\\boldsymbol \\beta\\)  \\(\\boldsymbol\\ell^{\\prime}=[\\ell_1,\\ell_2,\\ldots,\\ell_{12}]\\)  \\(\\boldsymbol\\beta^{\\prime}=[\\mu,\\tau_1,\\tau_2,\\beta_1,\\beta_2,\\beta_3,\\gamma_{11},\\gamma_{12},\\gamma_{13},\\gamma_{21},\\gamma_{22},\\gamma_{23}]\\) \\(L1,L2,L4,L5,L7,L8\\)  \\[\\begin{aligned} \\boldsymbol{\\ell&#39;\\beta} = &amp;({L1})\\mu+({L2})\\tau_1+({L1}-{L2})\\tau_2+({L4})\\beta_1+({L5})\\beta_2+({L1}-{L4}-{L5})\\beta_3+({L7})\\gamma_{11}\\\\&amp;+(\\mathrm{L}8)\\gamma_{12}+(\\mathrm{L}2-\\mathrm{L}7-\\mathrm{L}8)\\gamma_{13}+(\\mathrm{L}4-\\mathrm{L}7)\\gamma_{21}+(\\mathrm{L}5-\\mathrm{L}8)\\gamma_{22} \\\\ &amp;+(L1-L2-L4-L5+L7+L8)\\gamma_{23} \\end{aligned}\\]  10.3:  x  \\(\\mu\\)  \\(\\mu\\)  \\(L1 = 1,L2 = 0\\)  \\(L1 - L2 = 0\\)  \\(\\tau_1\\)  \\(\\tau_1\\)  \\(L1 = 0L2 = 0\\)  \\(L1 - L2 = 0\\)  \\(\\tau_1 - \\tau_2\\)  \\(\\tau_1 - \\tau_2\\)  \\(L1 = 0,L2 = 1,L1 - L2 =-1,L4 = 0,L5 = 0,L1 - L4 - L5 = 0,L7 = 0,L 8 = 0\\)  \\(L2 - L7 -L 8 = 0\\).  \\(L2=1,L7=0,L8=0,L2-L7-L8\\)   6  (a basis set of estimable functions)  \\(L\\)  \\(L1,L2,L4,L5,L7,L8\\).  \\(L\\)   1 \\(L\\)  0.  \\(L1 = 1\\)  \\(L2 = L4 = L5 = L7 = L8 = 0\\) \\(\\mu + \\tau_2 + \\beta_3 + \\gamma_{23}\\) \\(L2 = 1\\)  \\(L\\)  0 \\(\\tau_1-\\tau_2+\\gamma_{13}-\\gamma_{23}\\) 10.4   10.4:  x  6  \\(\\boldsymbol X^\\prime\\boldsymbol X\\)  2×3  10.4  (10.2)  SAS-GLM  L  1 L  0  10.5  \\(L1,L2,L4,L5,L7, L8\\)   10.5:  x  SAS-GLM model  SOLUTION SOLUTION  10.6  SOLUTION  10.2  \\[\\hat{\\mu}=32,\\hat{\\tau}_1=8,\\hat{\\beta}_1=-6,\\hat{\\beta}_2=-9,\\hat{\\gamma}_{11}=2,\\hat{\\gamma}_{12}=10\\]  10.6: SAS-GLM  SOLUTION  x :  \\(\\boldsymbol X^\\prime \\boldsymbol X\\) B SAS-GLM  10.6  B  10.4 20\\(\\hat{\\mu}=32\\)  \\(\\mu+\\tau_2+\\beta_3+\\gamma_{23}\\) \\(\\hat{{\\tau}}_1={-}8\\)  \\(\\tau_1-\\tau_2+\\gamma_{13}-\\gamma_{23}\\) \\(\\hat{{\\tau}}_2=0\\)  0\\(\\hat{{\\beta}}_1=-6\\)  \\(\\beta_1-\\beta_3+\\gamma_{21}-\\gamma_{23}\\)  10.6 \\(\\widehat {s.e.}( \\hat{\\mu})=0.8165,\\widehat{s.e.}(\\hat{\\tau}_1)=1.1547\\) 10.6  \\(t\\)  \\(\\hat \\mu\\)  \\(t=39.19\\) \\(H_0\\colon\\mu+\\tau_2+\\beta_3+\\gamma_{23}=0\\).  SAS-GLM  CONTRAST  ESTIMATE SAS-GLM  ESTIMATE  \\(t\\)  \\(p\\) CONTRAST  \\(F\\)  \\(p\\)  1  ESTIMATE  ESTIMATE &#39;label&#39; INTERCEPT C1 T C2 C3 B C4 C5 C6 T*B C7 C8 C9 C10 C11 C12;  ESTIMATE  CONTRAST  ESTIMATE  CONTRAST 10.5  ESTIMATE 'OVERALL MEAN' INTERCEPT 1 T -5 -5 B .33333 .33333 .33333 T*B .16667 .16667 .16667 .16667 .16667 .16667; ESTIMATE 'TI -T2' T 1 1 T*B .33333 .33333 .33333 .33333 .33333 -.33333; ESTIMATE 'Bl -B3' B 1 0 -1 T*B .5 0 -.5 .5 0 -.5; ESTIMATE 'B2 B3' B 0 1 -1 T*B 0 .5 -.5 0 .5 -.5; ESTIMATE 'INT1' T*B 1 0 -1 -1 0 1; ESTIMATE 'INT2' T*B O 1 -1 0 -1 1; 10.4 IIV  SAS-GLM  9.1  10.2 I II  T  II  \\(R(\\tau|\\mu,\\beta)\\) B  II  \\(R(\\beta|\\mu,\\tau)\\).  16.3  I  II  I  II  10.7  I  II  10.8  9.1  II   10.7: I  II  x  10.8: II  x  I  II / ESTIMATE  CONTRAST  I  II  I  I  10.9  I  (10.1) 9.1 21  SAS-GLM  10.9  T  B  (9.1)  T×B  \\[\\mu_{11}-\\mu_{13}-\\mu_{21}+\\mu_{23}\\quad\\mathrm{and}\\quad\\mu_{12}-\\mu_{13}-\\mu_{22}+\\mu_{23}\\]  (span the iteraction space).  10.10  I T  I  9.1 T  I  \\[H_0{:}\\frac{3\\mu_{11}+2\\mu_{12}+3\\mu_{13}}8=\\frac{2\\mu_{21}+3\\mu_{212}+3\\mu_{213}}8\\]  10.9:  9.1  I  x  10.10:  I  x  9.1  10.11  II   10.11:  9.1  II  x T  II  \\[\\begin{equation} \\sum_{j=1}^b\\left(n_{ij}-\\frac{n_{ij}^2}{n_{\\cdot j}}\\right)\\mu_{ij}=\\sum_{i^{\\prime}=1}^t\\sum_{j=1}^b\\frac{n_{ij}n_{i^{\\prime}j}}{n_{\\cdot j}}\\mu_{i^{\\prime}j},\\quad i=1,2,\\ldots,t \\tag{10.3} \\end{equation}\\]  10.12  10.13  (10.1)  9.1  I  II   10.12:  9.1  I  x  10.13:  9.1  II  x  10.10-10.13 I  II    T  t  t - 1  (dummy variables) B  b  b - 1  \\(\\tau\\)  \\(\\beta\\)  \\(\\tau_t=-(\\tau_1+\\tau_2+\\cdots+\\tau_{t-1})\\)  \\(\\beta_t=-(\\beta_1+\\beta_2+\\cdots+\\beta_{t-1})\\). T  B  \\(j=1,2,\\cdots,b\\)  \\(\\gamma_{tj}=-(\\gamma_{1j}+\\gamma_{2j}+\\cdots+\\gamma_{t-1j})\\)  \\(i=1,2,\\cdots,t\\)  \\(\\gamma_{ib}=-(\\gamma_{i1}+\\gamma_{i2}+\\cdots+\\gamma_{ib-1})\\).  (full-effects model)   3   III  Yatess weighted squares of means technique. III  10.14  III  10.15  10.16  9.1  III   10.14:  III  x  10.15:  III  x  10.16: III  x  9.3  Yatess method  \\[\\begin{bmatrix}19\\\\20\\\\21\\\\24\\\\22\\\\25\\\\25\\\\25\\\\27\\\\21\\\\24\\\\21\\\\32\\\\33\\end{bmatrix}=\\begin{bmatrix}1&amp;-1&amp;1&amp;0&amp;-1&amp;0\\\\1&amp;-1&amp;1&amp;0&amp;-1&amp;0\\\\1&amp;-1&amp;0&amp;1&amp;0&amp;-1\\\\1&amp;-1&amp;0&amp;1&amp;0&amp;-1\\\\1&amp;-1&amp;0&amp;1&amp;0&amp;-1\\\\1&amp;-1&amp;-1&amp;-1&amp;1&amp;1\\\\1&amp;-1&amp;-1&amp;-1&amp;1&amp;1\\\\1&amp;-1&amp;-1&amp;-1&amp;1&amp;1\\\\1&amp;1&amp;1&amp;0&amp;1&amp;0\\\\1&amp;1&amp;1&amp;0&amp;1&amp;0\\\\1&amp;1&amp;1&amp;0&amp;1&amp;0\\\\1&amp;1&amp;0&amp;1&amp;0&amp;1\\\\1&amp;1&amp;0&amp;1&amp;0&amp;1\\\\1&amp;1&amp;-1&amp;-1&amp;-1&amp;-1\\\\1&amp;1&amp;-1&amp;-1&amp;-1&amp;-1\\\\1&amp;1&amp;-1&amp;-1&amp;-1&amp;-1\\end{bmatrix}\\begin{bmatrix}\\mu\\\\\\tau_1\\\\\\beta_1\\\\\\beta_2\\\\\\gamma_{11}\\\\\\gamma_{12}\\end{bmatrix}+\\begin{bmatrix}{\\varepsilon}_{111}\\\\{\\varepsilon}_{112}\\\\{\\varepsilon}_{113}\\\\{\\varepsilon}_{121}\\\\{\\varepsilon}_{122}\\\\{\\varepsilon}_{131}\\\\{\\varepsilon}_{132}\\\\{\\varepsilon}_{133}\\\\{\\varepsilon}_{211}\\\\{\\varepsilon}_{212}\\\\{\\varepsilon}_{213}\\\\{\\varepsilon}_{221}\\\\{\\varepsilon}_{222}\\\\{\\varepsilon}_{231}\\\\{\\varepsilon}_{232}\\\\{\\varepsilon}_{233}\\end{bmatrix}\\]  \\(\\gamma_{11}\\) \\(\\tau_{1}\\)  \\(\\beta_1\\) \\(\\gamma_{12}\\) \\(\\tau_1\\)  \\(\\beta_2\\) SAS-GLM IV  III III  IV  14  IV    III   I / II   \\(R(\\tau|\\mu,\\beta)\\)  \\(R(\\beta|\\mu,\\tau)\\)  SAS-GLM I  T B. 10.5  SAS-GLM  IIV   SAS-GLM  SAS-GLM  10.3  MODEL  E  E1 SAS-GLM  I  9.1  10.17   10.17:  9.1  SAS-GLM  I  x  10.17 \\(\\boldsymbol \\beta=[\\mu,\\tau_1,\\tau_2,\\beta_1,\\beta_2,\\beta_3,\\gamma_{11},\\gamma_{12},\\gamma_{13},\\gamma_{21},\\gamma_{22},\\gamma_{23}]\\)  \\(\\boldsymbol \\ell^\\prime \\boldsymbol \\beta\\)  I  \\(L2\\)  \\[\\begin{aligned} \\boldsymbol \\ell^\\prime \\boldsymbol \\beta =&amp;(L2)\\tau_1-(L2)\\tau_2+(0.125\\cdot L2)\\beta_1-(0.125\\cdot L2)\\beta_2 \\\\ &amp;+(0.375\\cdot L2)\\gamma_{11}+(0.25\\cdot L2)\\gamma_{12}+(0.375\\cdot L2)\\gamma_{13} \\\\ &amp;-(0.25\\cdot L2)\\gamma_{21}-(0.375\\cdot L2)\\gamma_{22}-(0.375\\cdot L2)\\gamma_{23} \\end{aligned}\\] T  I  \\(L2\\)  \\(L2 = 1\\)  \\(L2 = 8\\).  \\(L\\)  T  I  1  \\(L\\)  \\(L2\\) \\(L1 = 0,L4 = 0.125 · L,L5 = -0.125 · L2,L7 = 0.375 · L2\\)  \\(L8 = 0.25 · L2\\).  \\(L2=1\\)I  \\[\\{\\tau_1-\\tau_2+(1/8)(\\beta_1-\\beta_2)+(1/8)(3\\gamma_{11}+2\\gamma_{12}+3\\gamma_{13}-2\\gamma_{21}-3\\gamma_{22}-3\\gamma_{23})\\}\\]  I  10.11.  \\(L2 = 8\\)  \\[\\{8\\tau_1-8\\tau_2+\\beta_1-\\beta_2+3\\gamma_{11}+2\\gamma_{12}+3\\gamma_{13}-2\\gamma_{21}-3\\gamma_{22}-3\\gamma_{23}\\}\\]  \\(\\mu_{ij} = \\mu + \\tau_i + \\beta_j + \\gamma_{ij}\\) \\(\\gamma_{ij}\\)  \\(\\mu_{ij}\\)  T  I  \\[\\begin{array}{l}(3\\mu_{11}+2\\mu_{12}+3\\mu_{13}-2\\mu_{21}-3\\mu_{22}-3\\mu_{23})/8=0\\text{ or equivalently that}\\\\3\\mu_{11}+2\\mu_{12}+3\\mu_{13}-2\\mu_{21}-3\\mu_{22}-3\\mu_{23}=0\\end{array}\\]  10.9  T   MODEL  E2 SAS-GLM  II  9.1  10.18   10.18:  9.1  SAS-GLM  II  x  10.18 \\(\\boldsymbol \\ell^\\prime \\boldsymbol \\beta\\)  II  \\(L4,L5\\)  \\[ \\begin{aligned}\\boldsymbol{\\ell}^{\\prime}\\boldsymbol{\\beta} =&amp;(L4)\\beta_1+(L5)\\beta_2+(-L4-L5)\\cdot\\beta_3+(0.5692\\cdot L4+0.0308\\cdot L5)\\gamma_{11}\\\\ &amp;+(-0.0308\\cdot L4+0.4308\\cdot L5)\\gamma_{12}+(-0.5385\\cdot L4-0.4615\\cdot L5)\\gamma_{13} \\\\ &amp;+(0.4308\\cdot\\text{L4- }0.0308\\cdot L5)\\gamma_{21}+(0.0308\\cdot L4+0.5692\\cdot L5)\\gamma_{22} \\\\ &amp;+(-0.4615\\cdot L4-0.5385\\cdot L5)\\gamma_{23} \\end{aligned} \\]  L  \\(L4\\)  \\(L5\\). B  II  2  10.9  65.  \\(L4 = 1\\)  \\(L5 = 0\\) \\(L4 = 0\\)  \\(L5 = 1\\)  B  II  \\[\\begin{array}{l}\\{\\beta_1-\\beta_3+(1/65)(37\\gamma_{11}-2\\gamma_{12}-35\\gamma_{13}+28\\gamma_{21}+2\\gamma_{22}-30\\gamma_{23})\\mathrm{~and}\\\\\\beta_2-\\beta_3+(1/65)(2\\gamma_{11}+28\\gamma_{12}-30\\gamma_{13}-2\\gamma_{21}+37\\gamma_{22}-35\\gamma_{23})\\}\\end{array}\\]  \\(L4 = 65\\)  \\(L5 = 0\\) \\(L4 = 0\\)  \\(L5 = 65\\) \\[\\begin{gathered} \\{37{\\mu}_{11}-2{\\mu}_{12}-35{\\mu}_{13}+28{\\mu}_{21}+2{\\mu}_{22}-30{\\mu}_{23}\\mathrm{~and} \\\\ 2\\mu_{11}+28\\mu_{12}-30\\mu_{13}-2\\mu_{21}+37\\mu_{22}-35\\mu_{23}\\} \\end{gathered}\\]  10.17 / 10.18  T × B  I / II  L   \\(L7 = 1\\)  \\(L8 = 0\\) \\(L7 = 0\\)  \\(L8 = 1\\) T × B  I  \\[\\{\\gamma_{11}-\\gamma_{13}-\\gamma_{21}+\\gamma_{23}\\mathrm{~and~}\\gamma_{12}-\\gamma_{13}-\\gamma_{22}+\\gamma_{23}\\}\\]  \\[\\{\\mu_{11}-\\mu_{13}-\\mu_{21}+\\mu_{23}\\mathrm{~and~}\\mu_{12}-\\mu_{13}-\\gamma_{22}+\\mu_{23}\\}\\]  \\(i\\ne i^\\prime\\)  \\(j\\ne j^\\prime\\) 2 × 2  \\(\\mu_{ij}-\\mu_{ij&#39;}-\\mu_{i&#39;j}+\\mu_{i&#39;j&#39;}=0\\)   10.18T  II  \\[\\begin{array}{c}(L2)\\tau_1-(L2)\\tau_2+(0.3077\\cdot L2)\\gamma_{11}+(0.3077\\cdot L2)\\gamma_{12}+(0.3846\\cdot L2)\\gamma_{13}\\\\+(-0.3077\\cdot L2)\\gamma_{21}+(-0.3077\\cdot L2)\\gamma_{22}+(-0.3846\\cdot L2)\\gamma_{23}\\end{array}\\]  13 \\(L2 = 1\\)T  II  \\[\\{\\tau_1-\\tau_2+(1/13)(4\\gamma_{11}+4\\gamma_{12}+5\\gamma_{13}-4\\gamma_{21}-4\\gamma_{22}-5\\gamma_{23})\\}\\]  \\(L2=13\\) \\[\\{4\\mu_{11}+4\\mu_{12}+5\\mu_{13}-4\\mu_{21}-4\\mu_{22}-5\\mu_{23}\\}\\]  III  IV  9.1  10.19 T  III  \\[\\{\\tau_1-\\tau_2+\\bar{\\gamma}_{1\\cdot}-\\bar{\\gamma}_{2\\cdot}\\}\\]  \\(L2=1\\) \\[\\{\\bar{\\mu}_{\\cdot 1}-\\bar{\\mu}_{\\cdot 2}\\}\\]  10.19:  9.1  SAS-GLM  III  x  B  III  \\[\\{\\beta_1-\\beta_3+\\bar{\\gamma}_{\\cdot1}-\\bar{\\gamma}_{\\cdot 3}\\mathrm{~and~}\\beta_2-\\beta_3+\\bar{\\gamma}_{\\cdot 2}-\\bar{\\gamma}_{\\cdot 3}\\}\\]  \\[\\{\\bar{\\mu}_{\\cdot1}-\\bar{\\mu}_{\\cdot3}\\mathrm{~and~}\\bar{\\mu}_{\\cdot2}-\\bar{\\mu}_{\\cdot3}\\}\\] \\(H_0\\colon\\bar{{\\mu}}_{\\cdot1}-\\bar{{\\mu}}_{\\cdot3}=0\\mathrm{~and~}\\bar{{\\mu}}_{\\cdot2}-\\bar{{\\mu}}_{\\cdot3}=0\\)  \\(H_0\\colon\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\bar{\\mu}_{3\\cdot}\\)  9.1  IV  III  10.6   T \\[\\bar{\\mu}_{i\\cdot}=\\mu+\\tau_i+\\bar{\\beta}_{\\cdot}+\\bar{\\gamma}_{i\\cdot},\\quad i=1,2,\\ldots,t\\]  B \\[\\bar{\\mu}_{\\cdot j}=\\mu+\\bar{\\tau}_{\\cdot}+\\bar{\\beta}_j+\\overline{\\gamma}_{\\cdot j},\\quad j=1,2,\\ldots,b\\]  \\[\\hat{\\bar{\\mu}}_{i\\cdot}=\\hat{\\mu}+\\hat{\\tau}_i+\\hat{\\bar{\\beta}}_{\\cdot}+\\hat{\\bar{\\gamma}}_i.,i=1,2,\\ldots,t\\quad\\mathrm{and}\\quad\\hat{\\bar{\\mu}}_{\\cdot j}=\\hat{\\mu}+\\hat{\\bar{\\tau}}_{\\cdot}+\\hat{\\bar{\\beta}}_j+\\hat{\\bar{\\gamma}}_{\\cdot j},~j=1,2,\\ldots,b\\]  (9.5)  (9.7)  (9.5)  (9.6) SAS-GLM  LSMEANS T B T*B/PDIFF;  10.20 T  B  9.2  T  B  9.2  10.20  \\(p\\) \\(\\hat{{\\mu}}_{1\\cdot}\\)  0.51 9.5  10.20  \\(\\hat{{\\mu}}_{1\\cdot}\\)  \\(\\hat{{\\mu}}_{2\\cdot}\\)  \\(p=0.0002\\) 9.5  \\(t\\)  \\(p\\)   10.20:  x 10.7   I, II, III  IV  SAS SPSS  I, II  III SPSS  III SAS-GLM  I  III  9.1  9 SAS-GLM  MEANS T B T*B/&lt;options&gt;; Means  Means  \\[\\tilde{\\mu}_{i.}=\\frac1{n_{i\\cdot}}\\sum_{j=1}^{b}n_{ij}\\mu_{ij},\\mathrm{~}i=1,2,\\ldots,t\\quad\\mathrm{and~}\\quad\\tilde{\\mu}_{\\cdot j}=\\frac1{n_{\\cdot j}}\\sum_{i=1}^{t}n_{ij}\\mu_{ij},\\mathrm{~}j=1,2,\\ldots,b\\]  10.4   9.1 T  \\(\\bar y_{1\\cdot\\cdot}=22.75\\)  \\(\\bar y_{2\\cdot\\cdot}=27.125\\)B  \\(\\bar y_{\\cdot1\\cdot}=22.2,\\bar y_{\\cdot2\\cdot}=23.8\\)  \\(\\bar y_{\\cdot3\\cdot}=28.0\\). 10.8   IIII III III   9.1  \\[y_{ijk}=\\mu+\\tau_i+\\beta_j+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t;\\quad j=1,2,\\ldots,b;\\quad k=1,2,\\ldots,n_{ij}\\] T  B  II  III  T  B  II  The functions of the parameters that these estimators are really unbiased estimates of are those given in Table 10.4. Table 10.9 gives the hypotheses tested by a type I analysis of the data in Table 9.1 for model (10.1) in terms of the parameters in a means model. "],["chap11.html", " 11   11.1  11.2  11.3  11.4  11.5  11.6 ", "  11   The science of statistics is the chief instrumentality through which the progress of civilization is now measured, and by which its development hereafter will be largely controlled. - S. N. D. North  11.1   10.7   624×624   (methods of unweighted means)Bancroft 1968 11.2  11.2   III  III   9  10  T  t  B  b  \\(\\mu_{ij}\\)  \\(T_i\\)  \\(B_j\\)  \\[\\hat{\\mu}_{ij}=\\bar{y}_{ij\\cdot}\\quad i=1,2,\\ldots,t,j=1,2,\\ldots,b\\]  \\[\\hat{\\bar{\\mu}_{i\\cdot}}=\\frac1b\\sum_{j=1}^b\\hat{\\mu}_{ij}\\quad\\mathrm{~and~}\\quad\\hat{\\bar{\\mu}}_{\\cdot j}=\\frac1t\\sum_{i=1}^t\\hat{\\mu}_{ij}\\]  \\(H_{0T}\\colon\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\cdots=\\bar{\\mu}_{t\\cdot}\\) \\[\\begin{aligned}SST=b\\sum_{i=1}^t(\\hat{\\bar{\\mu}}_{i\\cdot}-\\hat{\\bar{\\mu}}_{\\cdot\\cdot})^2=\\sum_{i=1}^tb\\hat{\\bar{\\mu}}_{i\\cdot}^2-bt\\hat{\\bar{\\mu}}_{\\cdot\\cdot}^2\\end{aligned}\\]  t-1  \\(H_{0B}{\\colon}\\bar{{\\mu}}_{\\cdot1}=\\bar{{\\mu}}_{\\cdot2}=\\cdots=\\bar{{\\mu}}_{\\cdot b}\\) \\[SSB=t\\sum_{j=1}^b(\\hat{\\bar{\\mu}}_{\\cdot j}-\\hat{\\bar{\\mu}}_{\\cdot\\cdot})^2=t\\sum_{j=1}^b\\hat{\\bar{\\mu}}_{\\cdot j}^2-bt\\hat{\\bar{\\mu}}_{\\cdot\\cdot}^2\\]  b-1  \\(i\\ne i^\\prime\\)  \\(j\\ne j^\\prime\\)  \\(H_{0T\\times B}{:{\\mu}_{ij}-{\\mu}_{i&#39;j}-{\\mu}_{ij&#39;}+{\\mu}_{i&#39;j&#39;}=0}\\) \\[SST\\times B=\\sum_{i=1}^t\\sum_{j=1}^b(\\hat{\\mu}_{ij}-\\hat{\\bar{\\mu}}_{i\\cdot}-\\hat{\\bar{\\mu}}_{\\cdot j}+\\hat{\\bar{\\mu}}_{\\cdot\\cdot})^2=\\sum_{i=1}^t\\sum_{j=1}^b\\hat{\\mu}_{ij}^2-b\\sum_{i=1}^t\\hat{\\bar{\\mu}}_{i\\cdot}^2-t\\sum_{j=1}^b\\hat{\\bar{\\mu}}_{\\cdot j}^2+bt\\hat{\\bar{\\mu}}_{\\cdot\\cdot}^2\\]  (t-1)(b-1)  \\[SSError=\\sum_{i=1}^t\\sum_{j=1}^{b}\\sum_{k=1}^{n_{ij}}(y_{ijk}-\\bar{y}_{ij\\cdot})^2\\]  \\(\\hat\\mu_{ij}\\)  \\(\\sigma^2/n_{ij}\\)  \\(y_{ijk}\\)  \\(\\sigma^2\\)  \\[\\tilde{n}=\\left[\\frac1{bt}{\\left(\\sum_{i=1}^{t}\\sum_{j=1}^{b}\\frac1{n_{ij}}\\right)}\\right]^{-1}\\]  \\(\\tilde{n}\\)  \\(n_{ij}\\)  N - bt.  11.1  \\(F\\)  2   11.1:  x 11.3  T  B  9  10 T  \\(\\bar{{\\mu}}_{i\\cdot},i=1,2,\\ldots,t\\) B \\(\\bar{{\\mu}}_{\\cdot j},j=1,2,\\ldots,b\\)  \\[\\hat{\\bar{{\\mu}}}_{i\\cdot}=\\frac1b\\sum_{j=1}^b\\hat{{\\mu}}_{ij},\\quad i=1,2,\\ldots,t\\]  \\[\\hat{\\bar{{\\mu}}}_{\\cdot j}=\\frac1b\\sum_{i=1}^t\\hat{{\\mu}}_{ij},\\quad i=1,2,\\ldots,t\\] \\(\\hat{\\bar{\\mu}}_{i\\cdot}\\)  (exact estimated standard error)  \\[\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{i\\cdot})=\\frac{\\hat{\\sigma}}b\\sqrt{\\sum_{j=1}^b\\frac1{n_{ij}}}\\] \\(\\hat{\\bar{\\mu}}_{\\cdot j}\\)  (exact estimated standard error)  \\[\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{\\cdot j})=\\frac{\\hat{\\sigma}}t\\sqrt{\\sum_{i=1}^t\\frac1{n_{ij}}}\\]  \\[\\hat{\\sigma}=\\sqrt{\\frac{\\sum_{i=1}^{t}\\sum_{j=1}^{b}\\sum_{k=1}^{n_{ij}}(y_{ijk}-\\bar y_{ij\\cdot})^2}{N-tb}}=\\sqrt{ErrorMS}\\]  \\(\\hat \\sigma/\\sqrt{}(b\\tilde n)\\)  \\(\\hat \\sigma/\\sqrt{}(t\\tilde n)\\) \\(\\hat{\\bar{\\mu}}_{i\\cdot}-\\hat{\\bar{\\mu}}_{i&#39;\\cdot}\\)  \\[\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{i\\cdot}-\\hat{\\bar{\\mu}}_{i&#39;\\cdot})=\\frac{\\hat{\\sigma}}{b}\\sqrt{\\sum_{j=1}^b\\frac1{n_{ij}}+\\sum_{j=1}^b\\frac1{n_{i&#39;j}}}\\]  \\(\\hat \\sigma\\sqrt{}2/\\sqrt{}(b\\tilde n)\\)  \\[\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{\\cdot j}-\\hat{\\bar{\\mu}}_{\\cdot j&#39;})=\\frac{\\hat{\\sigma}}{t}\\sqrt{\\sum_{i=1}^t\\frac1{n_{ij}}+\\sum_{i=1}^t\\frac1{n_{ij&#39;}}}\\]  \\(\\hat \\sigma\\sqrt{}2/\\sqrt{}(t\\tilde n)\\)   \\(i\\ne i^\\prime\\)  \\(j\\ne j^\\prime\\)  2×2  \\(\\mu_{ij}-\\mu_{i&#39;j}-\\mu_{ij&#39;}+\\mu_{i&#39;j&#39;}\\).  \\(\\hat\\mu_{ij}-\\hat\\mu_{i&#39;j}-\\hat\\mu_{ij&#39;}+\\hat\\mu_{i&#39;j&#39;}\\) \\[\\widehat{s.e.}(\\hat{\\mu}_{ij}-\\hat{\\mu}_{i^{\\prime}j}-\\hat{\\mu}_{ij^{\\prime}}+\\hat{\\mu}_{i^{\\prime}j^{\\prime}})=\\hat{\\sigma}\\sqrt{\\frac1{n_{ij}}+\\frac1{n_{i^{\\prime}j}}+\\frac1{n_{ij^{\\prime}}}+\\frac1{n_{i^{\\prime}j}}}\\]  \\(\\hat \\sigma/\\sqrt{}(4/\\tilde n)\\)   \\[t_c=\\frac{\\mathrm{estimate}}{\\text{estimated standard error}}\\]  \\(|t_c|&gt;t_{\\alpha/2,N-tb}\\) \\((1-\\alpha)100\\%\\)  \\[\\mathrm{estimate}\\pm t_{\\alpha/2,N-tb}(\\text{estimated standard error})\\]  3 / \\(\\tilde n\\)  \\(n\\) 8  11.4   11.2:  9.1  x  9.1  20 10 11.2 \\(\\tilde n\\)  \\[\\tilde{n}=\\left[\\frac1{bt}\\left(\\sum_{i=1}^t\\sum_{j=1}^b\\frac1{n_{ij}}\\right)\\right]^{-1}=\\left[\\frac1{(3)(2)}\\left(\\frac13+\\frac12+\\frac13+\\frac12+\\frac13+\\frac13+\\frac13\\right)\\right]^{-1}=\\left(\\frac7{18}\\right)^{-1}=2.5714\\]  \\[\\begin{aligned} &amp;\\sum_{i,j}{\\hat{\\mu}}_{ij}^2 =20^2+25^2+\\cdots+28^2=3830 \\\\ &amp;\\sum_{i,j}\\hat{\\bar{\\mu}}_{i\\cdot}^2 =23^2+27^2=1258 \\\\ &amp;\\sum_j\\hat{\\bar{\\mu}}_{\\cdot j}^2 =23^2+24^2+28^2=1889 \\\\ &amp; \\hat{\\bar{\\mu}}_{\\cdot \\cdot}^2=(25)^2=625 \\end{aligned}\\]  \\[\\begin{aligned}SST&amp;=3(1258)-6(625)=24\\\\SSB&amp;=2(1889)-6(625)=28\\\\SST \\times B &amp;= 3830 - 3(1258) - 2(1889) + 6(625) = 28\\end{aligned}\\]  11.3 11.3  \\(F\\)  9.3  \\(F\\)   11.3:  9.1  x 11.5   Excel®  T, B  T × B    T B  T  B  \\(S_{TB}^2,S_{B}^2,S_{T}^2\\).  \\[\\begin{align} \\text{error } SS&amp; =\\sum_{i,j,k}y_{ijk}^2-(bt-1)S_{TB}^2+bt\\hat{\\bar{\\mu}}_{\\cdot\\cdot}^2 \\\\ SST&amp; =b(t-1)S_T^2 \\\\ SSB&amp; =t(b-1)S_B^2 \\\\ SST\\times B&amp;=(bt-1)S_{TB}^2-b(t-1)S_T^2-t(b-1)S_B^2 \\tag{11.1} \\end{align}\\]  T, B T×B  11.4  SAS®   11.4:  SAS  x 11.6   "],["chap12.html", " 12   12.1 - 12.2 ", "  12    a hypothesis test tells us whether the observed data are consistent with the null hypothesis, and a confidence interval tells us which hypotheses are consistent with the data. - William C. Blackwelder  13-15  12.1 -  (surfactant)  (flour)  10  12.1.  12.1:  x  12.1  SAS®-GLM   III III  E3  SOLUTION  SAS-GLM  LSMeans   12.2  SAS  12.3  12.2  III  \\(F\\) \\(F=8.52\\) \\(p=0.0011\\)  12.4  12.5   12.2:  12.1  SAS  x  12.3:  x  12.4:  ×  x  12.1  \\(p\\)  12.5   12.1:   12.5:  ×  x  12.1  1.  3  3  2.  3  1  3.  1  12.2   SAS-GLM  22  "],["chap13.html", " 13   13.1  13.2  13.3  13.4  13.5 ", "  13   You cant fix by analysis what you bungled by design. - Light, Singer and Willett, page v   13.1   9  15   13.1:  x  13.1  T  B  \\(\\mu_{ij}\\)  \\(T_i\\)  \\(B_j\\)  \\[\\begin{equation} Y_{ijk}=\\mu_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t;\\quad j=1,2,\\ldots,b;\\quad k=1,2,\\ldots,n_{ij} \\tag{13.1} \\end{equation}\\]  \\({\\varepsilon}_{i{j}k}\\thicksim{i}.{i}.{d}.{N}(0,{\\sigma}^2)\\).  \\(i\\) \\(j\\)  \\(n_{ij}=0\\) \\(T_i\\)  \\(B_j\\)  13.2  13.2  \\((12)\\)  \\((33)\\)  \\(\\mu_{12}\\)  \\(\\mu_{33}\\)  \\((12)\\)  \\((33)\\)   13.2:  13.1  x  \\(\\mu_{12}\\) / \\(\\mu_{33}\\)  (assumptions) \\(\\mu_{12}\\) / \\(\\mu_{33}\\)  (hypothesis).  \\(\\mu_{12}=\\mu_{11}\\) \\(\\mu_{12}\\)  13.1  \\(\\hat \\mu_{11}=(2+4)/2=3\\)  \\(\\mu_{12}\\).  13.1  \\(\\mu_{12}\\)  \\(\\mu_{33}\\) T  B  (assuming) \\[\\mu_{12}=\\mu_{11}-\\mu_{21}+\\mu_{22}\\quad\\mathrm{and}\\quad\\mu_{33}=-\\mu_{22}+\\mu_{23}+\\mu_{32}\\]  \\[\\mu_{11}-\\mu_{13}-\\mu_{21}+\\mu_{23}=0\\quad\\mathrm{and}\\quad\\mu_{21}-\\mu_{22}-\\mu_{31}+\\mu_{32}=0\\]  8   \\(\\bar \\mu_{1\\cdot}=\\bar \\mu_{2\\cdot}=\\bar \\mu_{3\\cdot}\\)  \\(\\bar \\mu_{\\cdot1}=\\bar \\mu_{\\cdot2}=\\bar \\mu_{\\cdot3}\\) \\(\\bar \\mu_{1\\cdot}\\)  \\(\\bar \\mu_{3\\cdot}\\)  \\(\\bar \\mu_{\\cdot2}\\)  \\(\\bar \\mu_{\\cdot3}\\).  \\(\\bar \\mu_{2\\cdot}\\)  \\(\\bar \\mu_{\\cdot1}\\)  (13.1)  \\[\\hat{\\mu}_{ij}=\\bar{y}_{ij\\cdot}\\quad i=1,2,\\ldots,t;j=1,2,\\ldots,b\\mathrm{~if~}n_{ij}&gt;0\\]  \\[\\hat{{\\sigma}}^2=\\frac{\\sum_{ijk}(y_{ijk}-\\bar{y}_{ij\\cdot})^2}{N-C}\\]  \\(N = n_{\\cdot\\cdot}\\)  C =  \\(n_{ij} &gt; 0\\) \\(\\hat\\mu_{ ij}\\)  \\(N(\\mu_{ij}, \\sigma^2 /n_{ij}), i = 1, 2, \\cdots , t; j = 1, 2, \\cdots , b\\)  \\((N - C)\\hat\\sigma^2/\\sigma^2\\)  \\(\\chi^2(N - C)\\). \\(\\hat\\mu_{ ij}, i = 1, 2, \\cdots , t; j = 1, 2, \\cdots , b\\)  \\(\\hat\\sigma^2\\)  13.2   1  1  \\(\\mu_{ij}\\)  13.1  13.2.1  13.1  13.1  \\(\\bar\\mu_{2\\cdot}\\)  95%  \\(\\hat\\mu_{11}=3,\\hat\\mu_{13}=6.5,\\hat\\mu_{21}=3,\\hat\\mu_{22}=14,\\hat\\mu_{23}=9.5,\\hat\\mu_{31}=6,\\hat\\mu_{32}=9\\) \\(\\sigma^2\\)  \\[ \\begin{aligned} \\hat\\sigma^2=&amp;\\frac{1}{11-7}[(2-3)^2+(4-3)^2+(7-6.5)^2+(6-6.5)^2+(3-3)^2+(14-14)^2\\\\ &amp;+(10-9.5)^2+(9-9.5)^2+(6-6)^2+(6-6)^2+(9-9)^2]\\\\ =&amp;\\frac{3}{4}\\\\=&amp;0.75 \\end{aligned} \\]  \\(\\sigma^2\\)  4  \\(\\bar\\mu_{2\\cdot}\\)  \\(\\hat{\\bar\\mu}_{2\\cdot} = (3 + 14 + 9.5)/3 = 5.5\\)  \\[\\widehat{s.e.}(\\hat{\\bar{\\mu}}_{2\\cdot})=\\frac{\\sqrt{\\hat{\\sigma}^2\\left(\\frac1{n_{21}}+\\frac1{n_{22}}+\\frac1{n_{23}}\\right)}}b=\\frac{\\sqrt{0.75\\left(\\frac11+\\frac11+\\frac12\\right)}}3=0.4564\\] \\(\\bar\\mu_{2\\cdot}\\)  95%  \\(5.5 ± (2.776)(0.4564) = 5.5 ± 1.267\\)  \\(4.233 &lt; \\bar\\mu_{2\\cdot}&lt; 6.767\\).  3 × 3  4  \\[\\mu_{11}-\\mu_{13}-\\mu_{21}+\\mu_{23}\\quad\\mathrm{~and~}\\quad\\mu_{21}-\\mu_{22}-\\mu_{31}+\\mu_{32}\\]  \\[H_{0T\\times B}\\colon\\mu_{11}-\\mu_{13}-\\mu_{21}+\\mu_{23}=0\\quad\\mathrm{and}\\quad\\mu_{21}-\\mu_{22}-\\mu_{31}+\\mu_{32}=0\\]  1  \\(\\boldsymbol C\\boldsymbol \\mu = \\boldsymbol 0\\)  \\[\\boldsymbol{C}=\\begin{bmatrix}1&amp;-1&amp;-1&amp;0&amp;1&amp;0&amp;0\\\\0&amp;0&amp;1&amp;-1&amp;0&amp;-1&amp;1\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{\\mu}=\\begin{bmatrix}\\mu_{11}\\\\\\mu_{13}\\\\\\mu_{21}\\\\\\mu_{22}\\\\\\mu_{23}\\\\\\mu_{31}\\\\\\mu_{32}\\end{bmatrix}\\]  \\(H_{0T\\times B}\\)  \\[SS_{T\\times B}=(\\boldsymbol C\\hat{\\boldsymbol\\mu})^{\\prime}(\\boldsymbol C\\boldsymbol D\\boldsymbol C)^{-1}\\left.(\\boldsymbol C\\hat{\\boldsymbol \\mu})^{\\prime}\\quad\\mathrm{where~}D=\\mathrm{Diag}\\left(\\frac12,\\frac12,1,1,\\frac12,\\frac12,1\\right)\\right. \\]  \\[SS_{T\\times B}=\\begin{bmatrix}3&amp;-8\\end{bmatrix}\\begin{bmatrix}\\frac52&amp;-1\\\\-1&amp;\\frac72\\end{bmatrix}^{-1}\\begin{bmatrix}3\\\\-8\\end{bmatrix}=18.5161\\]  2  \\(F\\)  \\(F = 18.5161/0.75 = 12.34\\) 2  4  \\(F\\)  0.0194   13.1  \\(\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\bar{\\mu}_{3\\cdot}\\) \\[H_{0T}{:}(\\mu_{11}+\\mu_{13})/2=(\\mu_{21}+\\mu_{23})/2\\quad\\mathrm{and}\\quad(\\mu_{21}+\\mu_{22})/2=(\\mu_{31}+\\mu_{32})/2\\]  T  \\(B_1\\)  \\(B_3\\)  \\(T_1\\)  \\(T_2\\)  \\(B_1\\)  \\(B_2\\)  \\(T_2\\)  \\(T_3\\)   \\(H_{0T}\\)  \\[\\boldsymbol C=\\begin{bmatrix}1&amp;1&amp;-1&amp;0&amp;-1&amp;0&amp;0\\\\0&amp;0&amp;1&amp;1&amp;0&amp;-1&amp;-1\\end{bmatrix}\\]  \\(D=\\mathrm{Diag}\\left(\\frac12,\\frac12,1,1,\\frac12,\\frac12,1\\right)\\).  \\(H_{0T}\\)  \\[SS_T=(\\boldsymbol C\\hat{\\boldsymbol{\\mu}})^{\\prime}(\\boldsymbol C\\boldsymbol D\\boldsymbol C)^{-1}(\\boldsymbol C\\hat{\\boldsymbol{\\mu}})^{\\prime}=\\begin{bmatrix}-3&amp;2\\end{bmatrix}\\begin{bmatrix}\\frac52&amp;-1\\\\-1&amp;\\frac72\\end{bmatrix}^{-1}\\begin{bmatrix}-3\\\\2\\end{bmatrix}=3.8065\\]  2  \\(F\\)  \\(F = (3.8065/2)/0.75 = 2.5377\\) 2  4 \\(p\\) 0.1943 \\(H_{0T}\\). \\(\\boldsymbol C\\boldsymbol D\\boldsymbol C\\)  1.7  14  13.3   13.1  13.3  SAS®-GLM  T  B  Model  Noint  Model  Contrast  13.2  \\(H_{0T×B}\\)  \\(H_{0T}\\)   13.3: SAS-GLM  x  13.4  13.5  13.5   13.4:  13.1  x  13.5:  x  13.6 F  122.10  I  III  \\(\\mu_{ij}\\)  0 \\(F=122.10\\)  \\[H_{0}\\colon\\mu_{11}=\\mu_{13}=\\mu_{21}=\\mu_{22}=\\mu_{23}=\\mu_{31}=\\mu_{32}=0\\]  13.6:  13.1  x  0.75 13.2  \\(\\sigma^2\\)   Contrasts  13.7 Estimates  13.8  \\(T_2\\)  13.9  Solution  13.10  13.10  LSMeans  13.10  LSMeans  pdiff   13.7:  13.1 Contrast  x  13.8:  13.1 Estimate  x  13.9:  13.1 Model  Solution  x  13.10:  13.1  x :  13.4   14  13.5  "],["chap14.html", " 14   14.1 I  II  14.2 III  14.3 IV  14.4  14.5  14.6  14.7 ", "  14   An approximate answer to the right problem is worth a good deal more than an exact answer to an approximate problem. - John Tukey  13  \\[y_{ijk}=\\mu+\\tau_i+\\beta_j+\\gamma_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t;~j=1,2,\\ldots,b;~k=0,1,2,\\ldots,n_{ij}\\]  \\(\\varepsilon_{ijk}\\sim i.i.d.N(0,\\sigma^2)\\)  \\(n_{ij}=0\\)  (i,j)  14.1 I  II   I  II   13.1  I  14.1  14.2  I  II   14.1: I  x  14.2: II  x  10 I  II  14.3  14.4  I  II  14.5  14.6  SAS®-GLM  13.1  10.9  10.3   14.3:  13.1  I  x  14.4:  13.1  II  x  14.5:  13.1  I  x  14.6:  13.1  II  x  I  II I  II  10  10  10  \\(R(\\tau|\\mu)\\)  \\(R(\\beta|\\mu)\\)  I  model  T model  B. 14.2 III  III  13.1  \\(\\hat \\mu_{1\\cdot}\\)  \\(\\hat \\mu_{3\\cdot}\\) \\(\\mu_{12}\\)  \\(\\mu_{33}\\).  \\(\\hat \\mu_{\\cdot 2}\\)  \\(\\hat \\mu_{\\cdot 3}\\).  \\(\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\bar{\\mu}_{3\\cdot}\\)  \\(\\bar{\\mu}_{\\cdot 1}=\\bar{\\mu}_{\\cdot 2}=\\bar{\\mu}_{\\cdot 3}\\).  I  II  III  III  \\(\\bar{\\mu}_{1\\cdot}=\\bar{\\mu}_{2\\cdot}=\\bar{\\mu}_{3\\cdot}\\)  \\(\\bar{\\mu}_{\\cdot 1}=\\bar{\\mu}_{\\cdot 2}=\\bar{\\mu}_{\\cdot 3}\\)  III  III  14.7  13.1  III  14.8  14.9  III  14.8  14.9  T×B III  14.7 - 14.9  SAS-GLM  13.1   14.7: III  x  14.8:  13.1  III  x  14.9:  13.1  III  x 14.3 IV   I II  III  IV   13.1  IV  14.10  IV   14.10:  13.1  x  \\(B_1\\)  \\(B_3\\)  \\(T_1\\)  \\(T_2\\)  IV \\(H_0{:}(\\mu_{11}+\\mu_{13})/2=(\\mu_{21}+\\mu_{23})/2\\).  \\(T_1\\)  \\(T_2\\)  IV  \\(H_0{:\\mu_{11}}=\\mu_{21}\\).  \\(B_1\\)  \\(T_1\\)  \\(T_2\\).  T  IV  14.11. \\(B\\)  IV  14.12  B  IV   14.11:  13.1  T  IV  x *:  SAS-GLM IV   14.12:  13.1  B  IV  x *:  SAS-GLM IV  SAS-GLM  IV  IV  SAS-GLM  (relabeling)  IV  IV  \\(F\\)  IV  (labeled). SAS-GLM  Other Type IV Testable Hypotheses exist which may yield different SS.  13.1 SAS-GLM  T  IV  \\[\\mu_{11}=\\mu_{31}\\quad\\mathrm{and}\\quad\\frac{\\mu_{21}+\\mu_{22}}2=\\frac{\\mu_{31}+\\mu_{32}}2\\] T  IV  \\(B_1\\)  \\(T_1\\)  \\(T_3\\)  \\(B_1\\)  \\(B_2\\)  \\(T_2\\)  \\(T_3\\)  14.11 \\(B_3\\)  SAS-GLM  IV  14.13   14.13: IV  x *:  IV  \\(SS\\)  14.11  SAS-GLM  IV  IV  Estimate  Contrast  14.11  IV  SAS-GLM  Estimate  ESTIMATE &#39;T1 VS T2 AVE OVER Bl AND B3&#39; T 1 1 0 T*B .5 .5 .5 0 .5 0 0; ESTIMATE &#39;T2 VS T3 AVE OVER Bl AND B2&#39; T 0 1 1 T*B 0 0 .5 .5 0 .5 .5; ESTIMATE &#39;T1 VS T2 AT Bl&#39; T 1 1 0 T*B 1 0 1 0 0 0 0; ESTIMATE &#39;TI VS T3 AT Bl&#39; T 1 0 1 T*B 1 0 0 0 0 1 0; ESTIMATE &#39;T2 VS T3 AT B1&#39; T 0 1 1 T*B 0 0 1 0 0 1 0; ESTIMATE &#39;T2 VS T3 AT B2&#39; T 0 1 1 T*B 0 0 0 1 0 0 1; ESTIMATE &#39;T1 VS T2 AT B3&#39; T 1 1 0 T*B 0 1 0 0 1 0 0;  Estimate  14.14   14.14: Estimate  x  SAS-GLM 13.2  14.11  14.12  14.4   9.5  10.6  \\(\\bar \\mu_{ij}\\)  13.1 \\(\\bar\\mu_{2\\cdot}\\) \\(\\bar\\mu_{1\\cdot}\\)  \\(\\hat{\\bar\\mu}_{2\\cdot}=8.333\\)  \\(\\hat{\\bar\\mu}_{1\\cdot}=4.00\\). \\(\\sum_{i,j}c_{ij}\\mu_{ij}\\)  \\(\\sum_{i,j}c_{ij}\\hat{\\mu}_{ij}\\) \\({\\hat{\\sigma}}\\sqrt{\\Sigma_{i,j}(c_{ij}^2/n_{ij})}\\)\\(\\sum_{i,j}c_{ij}\\mu_{ij}\\)  \\((1-\\alpha)100\\%\\)  \\[\\sum_{i,j}c_{ij}\\hat{\\mu}_{ij}\\pm t_{\\alpha/2,v}\\hat{\\sigma}\\sqrt{\\frac{c_{ij}^2}{n_{ij}}}\\]  \\(\\sum_{i,j}c_{ij}\\mu_{ij}=0\\)  \\(v\\)  \\(t\\)  \\[t=\\frac{\\sum_{i,j}c_{ij}\\hat{{\\mu}}_{ij}}{\\hat{{\\sigma}}\\sqrt{\\sum_{i,j}\\frac{c_{ij}^2}{n_{ij}}}}\\] \\(n\\)  \\(\\hat\\sigma^2\\)   \\(F\\)  \\(t\\)  \\(p\\)  \\(F\\)  Bonferronis method \\(p\\) \\(\\alpha/p\\) \\(p\\)  Scheffés procedure. 14.5   15  17  14.6   13   15  14.7  "],["chap15.html", " 15   15.1  15.2 ", "  15   If all the statisticians in the world were laid head to toe, they wouldnt be able to reach a conclusion Anon., after comment on economists by G. B. Shaw 15.1   13  14  15.1  12  15.1  1 3 2 2 \\(FS_{ij}\\)  \\(i\\)  \\(j\\)   15.1:  5  x  15.1:   MODEL SPVOL = BLK FAT SURF FAT*SURF;  ×  MODEL SPVOL = BLK FAT*SURF / NOINT;  2.0941 11.  \\[\\hat{\\sigma}^2=2.0941/11=0.1904\\]  4  2  \\(FS_{11}-FS_{12}-FS_{31}+FS_{32}\\)  \\(FS_{21}-FS_{23}-FS_{31}+FS_{33}\\). SAS®-GLM IV  \\(F\\)  \\[F=(5.4002/2)/0.1904=14.18\\]  2  11   15.2  IV 4  SAS-GLM IV  Contrast  1-3 Estimate  2  3 15.2   15.2:  IV  x  15.3  IV  SAS-GLM IV  3  5  \\(F\\)  \\(F = 6.34\\) 2  11 Contrast  3  Estimate   15.3:  IV  x  15.4  \\(t\\)  \\(p\\)  6  15.2   15.4: \\(t\\)  \\(p\\)  x :   15.2:  ×  15.2   "],["chap16.html", " 16   16.1  16.2  16.3 I  II  16.4  16.5 ", "  16   Statistics are the triumph of the quantitative method, and the quantitative method is the victory of sterility and death - Hilaire Belloc  7 - 15  9   16.1  16.2  16.1   \\(T_i,B_j,C_k\\)  \\(\\mu_{ijk}\\)  \\((T_i,B_j,C_k)\\) \\(i=1,2,\\cdots,t;j=1,2,\\cdots,b;k=1,2,\\cdots,c\\).  \\[(\\mu_{ijk}-\\mu_{i^{\\prime}jk}-\\mu_{ij^{\\prime}k}+\\mu_{i^{\\prime}j^{\\prime}k})-(\\mu_{ijk^{\\prime}}-\\mu_{i^{\\prime}jk^{\\prime}}-\\mu_{ij^{\\prime}k^{\\prime}}+\\mu_{i^{\\prime}j^{\\prime}k^{\\prime}})=0\\quad\\mathrm{for~all~}i,i^{\\prime},j,j^{\\prime},k,\\mathrm{and~}k^{\\prime}\\]  k  k  C  k  T × B  C  k  T × B T × C  B  B × C  T  \\(\\mu_{ijk}-\\bar{\\mu}_{ij\\cdot}-\\bar{\\mu}_{i\\cdot k}-\\bar{\\mu}_{\\cdot jk}+\\bar{\\mu}_{i\\cdot\\cdot}+\\bar{\\mu}_{\\cdot j\\cdot}+\\bar{\\mu}_{\\cdot\\cdot k}-\\bar{\\mu}_{\\cdot\\cdot\\cdot}=0\\quad\\text{ for all }i,j,\\mathrm{~and~}k\\)  \\(\\mu,\\tau_1,\\tau_2,\\cdots,\\tau_t,\\beta_1,\\beta_2,\\cdots,\\beta_b,\\xi_1,\\xi_2,\\ldots,\\xi_c,\\gamma_{11},\\gamma_{12},\\cdots,\\gamma_{tb},\\eta_{11},\\eta_{12},\\cdots,\\eta_{tc},\\theta_{11},\\theta_{12},\\cdots,\\theta_{bc}\\)  \\[\\mu_{ijk}=\\mu+\\tau_i+\\beta_j+\\xi_k+\\gamma_{ij}+\\eta_{ik}+\\theta_{jk}\\quad\\text{for all }i,j,\\mathrm{~and~}k\\] \\(\\mu_{ijk}\\)   16.1   16.1:  16.2   III   13  IV  1  Contrast   17  16.3 I  II   10  I  II I  (sequentially)  II  \\[\\begin{aligned}y_{ijk\\ell}&amp;=\\mu+T_i+B_j+(TB)_{ij}+C_k+(TC)_{ik}+(BC)_{jk}+(TBC)_{ijk}+\\varepsilon_{ijk\\ell}\\\\&amp;\\mathrm{for~}i=1,2,\\ldots,t,~j=1,2,\\ldots,b;~k=1,2,\\ldots,c;~\\mathrm{and}~\\ell=1,2,\\ldots,n_{ijk}\\end{aligned}\\]  \\(i,j,k\\)  \\(n_{ijk}&gt;0\\).  16.1  10  I  II   16.1:  I  II  x 16.4    8  16.5  "],["chap17.html", " 17   17.1  17.2 SAS-GLM  17.3  17.4  17.5 ", "  17   Statistics are no substitute for judgment. - Henry Clay  17.1   17.1 age, race  (food stamps).  17.1:  x 17.2 SAS-GLM   17.2  SAS  SAS®-GLM  17.1  IV  PROC GLM; CLASSES GROUP AGE RACE; MODEL GAIN=GROUP|AGE|RACE/SOLUTION E4; LSMEANS GROUP|AGE|RACE/PDIFF STDERR; RUN;  17.2: IV  x *:  IV  SS  17.2  17.1  \\(\\sigma^2\\)  \\(\\hat\\sigma^2 = 2627.4724/92 = 28.56\\) 92.  17.2  group, age  race  IV  \\(F\\)  17.1  GAIN  GAIN  15  \\(F\\)  2.67 14  92.  \\(p\\)  0.0026 15 \\(F = 2.65,p = 0.1068\\) GROUP  IV  \\(F\\)   17.3: SAS-GLM  IV  x  17.3  SAS-GLM IV  17.3  IV  (age = 1, white)(age = 2, white)(age = 3, black)(age = 3, Hispanic)(age = 3, white)  (age = 4, black)  IV  \\[\\begin{aligned} \\widehat{s.e.}\\text{ (type IV group contras}t)&amp; =\\hat{\\sigma}\\sqrt{\\sum_i\\sum_j\\sum_k\\left(\\frac{c_{ijk}^2}{n_{ijk}}\\right)} \\\\ &amp;=5.344\\sqrt{\\left(\\frac12+\\frac18+\\frac14+\\frac11+\\frac1{31}+\\frac11\\right)+\\left(\\frac13+\\frac18+\\frac16+\\frac12+\\frac1{20}+\\frac11\\right)} \\\\ &amp;=12.047 \\end{aligned}\\]  group  IV  \\[5.344\\sqrt{\\frac11+\\frac11+\\frac11}=9.256\\]   SAS-GLM  IV  I-III   17.4  17.5  \\(p\\)   17.4:  x  17.5:  x  IV  group  \\(\\mu_{\\mathrm{Y3W}}=\\mu_{\\mathrm{N3W}}\\) 17.5  LSMeans 6  13 \\(p\\)  \\(p = 0.0004\\).  age = 3  race = white  age = 2, whites.  LSMeans 3  10 \\(p\\)  \\(p=0.0424\\) age = 3  black  LSMeans 4  11 \\(p\\)  \\(p0.0017\\).  17.3   race × group  age  17.6   17.6:  17.1  age  race × age  x : X  17.6  age = 11 age  race × group 2  IV  \\(\\mu_{\\mathrm{Y1W}}=\\mu_{\\mathrm{N1W}}\\) 3age = 1  race  IV  \\(\\mu_{\\mathrm{Y1B}}=\\mu_{\\mathrm{Y1W}}\\) 4 \\(\\mu_{\\mathrm{Y1B}}=\\mu_{\\mathrm{N1W}}\\)  age = 1  race  group  17.5 \\(\\mu_{\\mathrm{Y1W}}=\\mu_{\\mathrm{N1W}}\\)  \\(p\\)  0.5628 3  4  \\(p\\)  0.5141  0.1975.  17.7  17.8  \\(p\\)  age age = 2  age = 4  17.7:  17.1  age = 2  x : \\(p\\)  17.5  17.8:  17.1  age = 4  x : \\(p\\)  17.5  age = 3  race × group  race × group  age = 3  race  group  \\[\\begin{aligned} &amp;H_{01}\\colon\\mu_\\text{N3B}{ - \\mu _\\text{N3W }{ - \\mu _\\text{Y3B}} }+\\mu_\\text{Y3W}{ = 0,\\,\\text{and}} \\,\\,\\mu_\\text{N3H}{ - \\frac 1 2 }(\\mu_\\text{N3B}+\\mu_\\text{N3W})-\\mu_\\text{Y3H }+\\frac12(\\mu_\\text{Y3B}+\\mu_\\text{Y3W}){=}0 \\\\ &amp;H_{02}\\colon\\bar{\\mu}_{\\text{Y}\\cdot}=\\bar{\\mu}_{\\text{N}\\cdot} \\\\ &amp;H_{03}\\colon\\bar{\\mu}_{\\cdot\\text{}} = \\bar { \\mu }_{\\cdot\\text{}} = \\bar { \\mu }_{\\cdot\\text{W}} \\end{aligned}\\]  \\(H_{01}\\)  17.2  SAS-GLM  \\(H_{01}\\)  race × group IV  \\(F\\)  17.3  race × group  SAS-GLM  Contrast  SAS-GLM  group × age × race  SAS-GLM Contrast  17.9   17.9:  \\(H_{01}\\) - \\(H_{03}\\)  Contrast  x  17.2  SAS  Contrast  17.9  17.10   17.10: SAS Contrast  x  race × age  group  race  group × age  Contrast  age   17.4   SAS-GLM  SAS-GLM  17.5  "],["chap18.html", " 18   18.1  18.2  18.3  18.4  18.5 ", "  18   Maturity is the capacity to endure uncertainty. - John Finley  (random component) , variance components 19  20  21  18.1    18.1   (random effect factor).  18.2   (fixed effect factor).       (chosen)  (fixed).    (Njuho and Milliken, 2005)  18.3   (fixed)  (fixed effects)   18.4   (random)  (random effects)   18.5   (mixed)  (mixed effects)   22  23  18.1.1  18.1  20,000  (state) (sity)  (store).  \\(r\\) \\(r &lt; 50\\) \\(i\\)  \\(C_i\\)  \\(t_i\\) \\(t_i &lt; C_i\\) 20,000.  \\(i\\)  \\(j\\)  \\(S_{ij}\\)  \\(n_{ij}\\) \\(n_{ij} &lt; S_{ij}\\) \\[y_{ijk}=\\mu+s_i+c_{j(i)}+a_{k(ij)}\\quad i=1,2,\\ldots,r,j=1,2,\\ldots,t_i,\\quad k=1,2,\\ldots,n_{ij}\\]  \\(\\mu\\) \\(s_i\\)  \\(i\\) \\(c_{j(i)}\\)  \\(i\\)  \\(j\\) \\(a_{k(ij)}\\)  \\(i\\)  \\(j\\)  \\(k\\)  \\(s_i\\sim i.i.d.\\,N(0,\\sigma_{\\mathrm{State}}^2)\\) \\(c_{j(i)}\\sim i.i.d.\\,N(0,\\sigma_{\\mathrm{City}}^2)\\) \\(a_{k(ij)}\\sim i.i.d.\\,N(0,\\sigma_{\\mathrm{Store}}^2)\\)  \\(\\mu,\\sigma_{\\mathrm{State}}^2,\\sigma_{\\mathrm{City}}^2,\\sigma_{\\mathrm{Store}}^2\\).  \\(s_i,c_{j(i)},a_{k(ij)}\\)  (estimated best linear unbiased predictors, EBLUP) (Littell et al., 2006; Milliken and Johnson, 2002).  \\[\\mathrm{Var}(y_{ijk})=\\sigma_{\\mathrm{Price}}^2=\\sigma_{\\mathrm{State}}^2+\\sigma_{\\mathrm{City}}^2+\\sigma_{\\mathrm{Store}}^2\\]  \\[\\mathrm{Cov}(y_{ij1},~y_{ij2})=\\sigma_{y_{ij1}y_{ij2}}=\\sigma_{\\mathrm{State}}^2+\\sigma_{\\mathrm{City}}^2\\]  \\[\\rho_{y_{ij1}y_{ij2}}=\\frac{\\sigma_{\\mathrm{State}}^2+\\sigma_{\\mathrm{City}}^2}{\\sigma_{\\mathrm{State}}^2+\\sigma_{\\mathrm{City}}^2+\\sigma_{\\mathrm{Store}}^2}\\]  \\(\\mathrm{Cov}(y_{i11},y_{i22})=\\sigma_{y_{i11}y_{i22}}=\\sigma_{\\mathrm{State}}^2\\).  \\[\\rho_{y_{i11}y_{i22}}=\\frac{\\sigma_{\\mathrm{State}}^2}{\\sigma_{\\mathrm{State}}^2+\\sigma_{\\mathrm{City}}^2+\\sigma_{\\mathrm{Store}}^2}\\]  (correlation structure).  18.2   (general random effects model).  18.2.1  18.2  \\[\\begin{equation} y_{ij}={\\mu}+{u}_i+{\\varepsilon}_{ij},\\quad i=1,2,\\ldots,t,j=1,2,\\ldots,n_i \\tag{18.1} \\end{equation}\\]  \\(\\mu\\) \\(\\mu_i\\)  \\(i\\)  \\(i.i.d.\\,N(0, \\sigma^2_u)\\)\\(\\varepsilon_{ij}\\)  \\(i\\)  \\(j\\)  \\(i.i.d.\\,N(0, \\sigma^2_\\varepsilon)\\).  \\(\\mu_i\\)  \\(\\varepsilon_{ij}\\)  \\[\\begin{aligned} \\operatorname{Var}(y_{ij})&amp; ={\\sigma}_y^2=\\mathrm{Var}({\\mu}+{\\mu}_i+{\\varepsilon}_{ij}){=}\\mathrm{Var}({u}_i)+\\mathrm{Var}({\\varepsilon}_{ij}) \\\\ &amp;=\\sigma_u^2+\\sigma_\\varepsilon^2 \\end{aligned}\\] \\(y_{ij}\\)  \\(u\\)  (variance components or components of variance).  \\(u_i\\)  \\[\\begin{aligned}\\mathrm{Cov}(y_{ij},y_{ij^{\\prime}})&amp;=\\mathrm{Cov}(\\mu+u_i+\\varepsilon_{ij},\\mu+u_i+\\varepsilon_{ij^{\\prime}})\\\\&amp;=\\mathrm{Cov}(u_i,u_i)=\\mathrm{Var}(u_i)=\\sigma_u^2\\end{aligned}\\]  \\(i\\)  \\(i\\)  (intraclass correlation) \\[\\rho=\\frac{\\mathrm{Cov}(y_{ij},y_{ij},)}{\\sqrt{\\mathrm{Var}(y_{ij})\\mathrm{Var}(y_{ij},)}}=\\frac{\\sigma_u^2}{\\sigma_u^2+\\sigma_\\varepsilon^2}\\]  \\(i\\)  (18.1)  \\[\\begin{equation} \\boldsymbol y=\\boldsymbol j \\mu+\\boldsymbol Z_1 \\boldsymbol u+\\boldsymbol \\varepsilon \\tag{18.2} \\end{equation}\\]  \\(\\boldsymbol j\\)  N × 1 \\(N=\\sum_{i=1}^tn_i\\)\\(\\boldsymbol Z_1\\)  N × t \\(\\boldsymbol u\\)  \\(N_t(\\boldsymbol 0,\\sigma^2_u\\boldsymbol I_t)\\)  t × 1  \\(\\boldsymbol \\varepsilon\\)  \\(N_N(\\boldsymbol 0,\\sigma^2_\\varepsilon\\boldsymbol I_t)\\)  N × 1  \\(\\boldsymbol y\\)  \\[\\begin{aligned} \\boldsymbol\\Sigma&amp; =\\mathrm{Var}(\\boldsymbol{y})=\\mathrm{Var}(\\boldsymbol{j} \\mu+\\boldsymbol{Z}_1\\boldsymbol{u}+\\boldsymbol{\\varepsilon}) \\\\ &amp;=\\boldsymbol{Z}_1\\operatorname{Var}(\\boldsymbol{u})\\boldsymbol{Z}_1^{\\prime}+\\operatorname{Var}(\\boldsymbol{\\varepsilon}) \\\\ &amp;=\\sigma_u^2\\boldsymbol{Z}_1\\boldsymbol{Z}_1^{\\prime}+\\boldsymbol{\\sigma}_\\boldsymbol{\\varepsilon}^2\\boldsymbol{I}_N \\end{aligned}\\] \\(y_{ij}\\)  \\(\\boldsymbol\\Sigma\\) \\(y_{ij}\\)  \\(\\boldsymbol\\Sigma\\)   \\[ \\begin{bmatrix}y_{11}\\\\y_{12}\\\\\\vdots\\\\y_{1n_1}\\\\y_{21}\\\\y_{22}\\\\\\vdots\\\\y_{2n_2}\\\\\\vdots\\\\y_{t1}\\\\y_{t2}\\\\\\vdots\\\\y_{tn_t}\\end{bmatrix}= \\begin{bmatrix}1\\\\1\\\\\\vdots\\\\1\\\\1\\\\1\\\\\\vdots\\\\1\\\\\\vdots\\\\1\\\\1\\\\\\vdots\\\\1\\end{bmatrix}\\mu+ \\begin{bmatrix} 1&amp;0&amp;\\cdots&amp;0\\\\ 1&amp;0&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 1&amp;0&amp;\\cdots&amp;0\\\\ 0&amp;1&amp;\\cdots&amp;0\\\\ 0&amp;1&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;1&amp;\\cdots&amp;0\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;0&amp;\\cdots&amp;1\\\\ 0&amp;0&amp;\\cdots&amp;1\\\\ \\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ 0&amp;0&amp;\\cdots&amp;1\\\\\\end{bmatrix}\\begin{bmatrix} \\mu_1\\\\\\mu_2\\\\\\vdots\\\\\\mu_t\\end{bmatrix}+ \\begin{bmatrix}\\varepsilon_{11}\\\\\\varepsilon_{12}\\\\\\vdots\\\\\\varepsilon_{1n_1}\\\\\\varepsilon_{21}\\\\\\varepsilon_{22}\\\\\\vdots\\\\\\varepsilon_{2n_2}\\\\\\vdots\\\\\\varepsilon_{t1}\\\\\\varepsilon_{t2}\\\\\\vdots\\\\\\varepsilon_{tn_t}\\end{bmatrix} \\]  \\(r\\) 22 \\(\\mu\\)  \\(\\boldsymbol \\varepsilon\\)  \\[\\begin{equation} \\boldsymbol y=\\boldsymbol j \\mu+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_r\\boldsymbol u_r+\\boldsymbol\\varepsilon \\tag{18.3} \\end{equation}\\]  \\(\\boldsymbol \\mu_s(s=1,2,\\cdots,r)\\)  \\(\\boldsymbol\\varepsilon\\)  \\[\\boldsymbol u_1\\thicksim N(0,\\sigma_1^2\\boldsymbol I_{t_1}),\\quad \\boldsymbol u_2\\thicksim N(0,\\sigma_2^2\\boldsymbol I_{t_2}),\\ldots,\\quad \\boldsymbol u_r\\thicksim N(0,\\sigma_r^2\\boldsymbol I_{t_r}),\\quad\\mathrm{and}\\quad\\boldsymbol\\varepsilon\\thicksim N(0,\\sigma_\\varepsilon^2\\boldsymbol I_N)\\] \\(N\\)  \\(\\boldsymbol y\\) \\(\\boldsymbol Z_i\\)  \\(i\\)  \\(N × t_i\\)  \\[\\begin{aligned}&amp;\\boldsymbol{y}=\\boldsymbol{j}_{\\Tiny N} \\mu+\\boldsymbol{Z}\\boldsymbol{u}+\\boldsymbol{\\varepsilon}\\quad\\mathrm{where~}\\boldsymbol{Z}=\\boldsymbol{[Z}_1,\\boldsymbol{Z}_2,\\ldots,\\boldsymbol{Z}_r],\\\\\\\\&amp;\\boldsymbol{u}=\\begin{bmatrix}\\boldsymbol{u}_1\\\\\\boldsymbol{u}_2\\\\\\vdots\\\\\\boldsymbol{u}_r\\end{bmatrix}\\mathrm{~and~}\\quad\\mathrm{Var}(\\boldsymbol{u})=\\begin{bmatrix}{\\sigma}_1^2\\boldsymbol{I}_{t_1}&amp;0&amp;0&amp;0\\\\0&amp;{\\sigma}_2^2\\boldsymbol{I}_{t_2}&amp;0&amp;0\\\\0&amp;0&amp;\\ddots&amp;0\\\\0&amp;0&amp;0&amp;{\\sigma}_r^2\\boldsymbol{I}_{t_r}\\end{bmatrix}\\end{aligned}\\]  \\[\\operatorname{Var}(\\boldsymbol y)=\\boldsymbol Z^{\\prime}\\operatorname{Var}(\\boldsymbol u)\\boldsymbol Z+\\sigma_\\varepsilon^2\\boldsymbol I_N\\]  \\(\\boldsymbol y\\)  \\[\\begin{aligned} \\boldsymbol \\Sigma&amp; =\\operatorname{Var}(\\boldsymbol y)=\\operatorname{Var}(\\boldsymbol j \\mu+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_r\\boldsymbol u_r+\\boldsymbol\\varepsilon) \\\\ &amp;=\\boldsymbol{Z}_1\\mathrm{Var}(\\boldsymbol{u}_1)\\boldsymbol{Z}_1^{\\prime}+\\boldsymbol{Z}_2\\mathrm{Var}(\\boldsymbol{u}_2)\\boldsymbol{Z}_2^{\\prime}+\\cdots+\\boldsymbol{Z}_r\\mathrm{Var}(\\boldsymbol{u}_r)\\boldsymbol{Z}_r^{\\prime}+\\mathrm{Var}(\\boldsymbol{\\varepsilon}) \\\\ &amp;=\\sigma_1^2\\boldsymbol{Z}_1\\boldsymbol{Z}_1^{\\prime}+\\sigma_2^2\\boldsymbol{Z}_2\\boldsymbol{Z}_2^{\\prime}+\\cdots+\\sigma_r^2\\boldsymbol{Z}_r\\boldsymbol{Z}_r^{\\prime}+\\sigma_\\varepsilon^2\\boldsymbol{I}_N \\end{aligned}\\]  18.3   18.3.1   (18.1)  \\(Q_1\\)  \\(Q_2\\)  \\[\\begin{aligned}Q_1&amp;=\\sum_{i=1}^t\\sum_{j=1}^{n_i}(y_{ij}-\\bar{y}_{i\\cdot})^2=\\sum_{i=1}^t\\sum_{j=1}^{n_i}y_{ij}^2-\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2\\\\\\\\Q_2&amp;=\\sum_{i=1}^tn_i(\\bar{y}_{i\\cdot}-\\bar{y}_{\\cdot\\cdot})^2=\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2-n_{\\cdot\\cdot}\\bar{y}_{\\cdot\\cdot}^2\\end{aligned}\\]  (18.1) \\(Q_1,Q_2\\)  \\[\\begin{align} y_{ij}&amp;=\\mu+\\mu_i+\\varepsilon_{ij}\\\\ \\bar y_{i\\cdot}&amp;=\\mu+\\mu_i+\\bar\\varepsilon_{i\\cdot}\\\\ \\bar y_{\\cdot\\cdot}&amp;=\\mu+\\tilde \\mu_{\\cdot}+\\bar\\varepsilon_{\\cdot\\cdot}\\quad\\text{where}\\,\\,\\tilde\\mu_{\\cdot}=\\frac1N\\sum_{i=1}^tn_i\\mu_i \\tag{18.4} \\end{align}\\]  (18.4)  \\(Q_1\\) \\[Q_1=\\sum_{i=1}^t\\sum_{j=1}^{n_i}[(\\mu+u_i+\\varepsilon_{ij})-(\\mu+u_i+\\bar{\\varepsilon}_{i\\cdot})]^2=\\sum_{i=1}^t\\sum_{j=1}^{n_i}(\\varepsilon_{ij}-\\bar{\\varepsilon}_{i\\cdot})^2\\]  \\(\\boldsymbol \\varepsilon\\)  \\(Q_1\\)  \\[\\begin{aligned} E(Q_1)&amp; =\\sum_{i=1}^t\\sum_{j=1}^{n_i}E({\\varepsilon}_{ij}-\\bar{{\\varepsilon}}_i.)^2=\\sum_{i=1}^t\\sum_{j=1}^{n_i}[E({\\varepsilon}_{ij}^2)+E(\\bar{{\\varepsilon}}_{i\\cdot}^2)-2E({\\varepsilon}_{ij}\\bar{{\\varepsilon}}_{i\\cdot})]\\quad\\text{(by squaring)} \\\\ &amp;=\\sum_{i=1}^t\\sum_{j=1}^{n_i}\\left(\\sigma_\\varepsilon^2+\\frac{\\sigma_\\varepsilon^2}{n_i}-2\\frac{\\sigma_\\varepsilon^2}{n_i}\\right)\\quad\\mathrm{using~}E(\\varepsilon_{ij}^2)=\\sigma_\\varepsilon^2\\quad\\mathrm{and~}\\quad E(\\bar{\\varepsilon}_{i\\cdot}^2)=\\frac{\\sigma_\\varepsilon^2}{N_i} \\\\ &amp;=\\sum_{i=1}^t\\sum_{j=1}^{n_i}\\frac{(n_i-1)\\sigma_\\varepsilon^2}{n_i}=\\sigma_\\varepsilon^2\\sum_{i=1}^t\\left(n_i-1\\right)=\\left(N-t\\right)\\sigma_\\varepsilon^2 \\end{aligned}\\]  \\[E(\\text{mean square of Q}_1)=E{\\left(\\frac{Q_1}{N-t}\\right)}=\\sigma_\\varepsilon^2\\]  (18.4)  \\(Q_2\\)  \\[\\begin{gathered} Q_2 \\begin{aligned}=\\sum_{i=1}^tn_i(\\mu+\\mu_i+\\varepsilon_{ij}-\\mu-\\tilde{u}_{\\cdot}+\\bar{\\varepsilon}_{i\\cdot})^2\\end{aligned} \\\\ =\\sum_{i=1}^tn_i[(u_i-\\tilde{u}_{\\cdot})+(\\varepsilon_{ij}-\\bar{\\varepsilon}_{i\\cdot})]^2 \\end{gathered}\\] \\(Q_2\\)  \\[\\begin{aligned} E(Q_{2})&amp; \\begin{aligned}=\\sum_{i=1}^tn_i[E(u_i-\\tilde{u}_{\\cdot})^2+E(\\bar{{\\varepsilon}}_{i\\cdot}-\\bar{{\\varepsilon}}_{\\cdot\\cdot})^2]\\end{aligned} \\\\ &amp;\\begin{aligned}=\\sum_{i=1}^tn_i[E(u_i)^2+E(\\tilde{u}_{\\cdot})^2-2E(u_i\\tilde{u}_{\\cdot})+E(\\bar{\\varepsilon}_{i\\cdot})^2+E(\\bar{\\varepsilon}_{\\cdot\\cdot})^2-2E(\\bar{\\varepsilon}_{i\\cdot}\\bar{\\varepsilon}_{\\cdot\\cdot})]\\end{aligned} \\end{aligned}\\] \\(Q_2\\)  \\(\\boldsymbol \\varepsilon\\)  \\(\\bar \\varepsilon_{i\\cdot}\\)  \\(\\bar \\varepsilon_{\\cdot\\cdot}\\)  \\[\\bar{{\\varepsilon}}_{i\\cdot}\\sim N{\\left(0,\\frac{{\\sigma}_\\varepsilon^2}{n_i}\\right)}\\quad\\mathrm{and}\\quad\\bar\\varepsilon_{\\cdot\\cdot}\\sim N{\\left(0,\\frac{{\\sigma}_\\varepsilon^2}N\\right)}\\]  \\(Q_2\\)  \\(\\boldsymbol \\varepsilon\\)  \\[\\begin{aligned} &amp;\\sum_{i=1}^{t}n_{i}\\left[E(\\bar{{\\varepsilon}}_{i\\cdot})^{2}+E(\\bar{{\\varepsilon}}_{\\cdot\\cdot})^{2}-2E(\\bar{{\\varepsilon}}_{i\\cdot}\\bar{{\\varepsilon}}_{\\cdot\\cdot})\\right] \\\\ &amp;=\\sum_{i=1}^tn_i\\left\\{\\sigma_\\varepsilon^2{\\left(\\frac1{n_i}\\right)}+\\frac{\\sigma_\\varepsilon^2}N-2E{\\left[\\bar{{\\varepsilon}}_{i\\cdot}\\frac{\\sum_{i^{\\prime}=1}^tn_{i^{\\prime}}\\bar{{\\varepsilon}}_{i^{\\prime}\\cdot}}N\\right]}\\right\\} \\\\ &amp;=\\sum_{i=1}^tn_i\\left\\{\\sigma_\\varepsilon^2{\\left(\\frac1{n_i}\\right)}+\\frac{\\sigma_\\varepsilon^2}N-2\\frac{n_i}NE(\\bar{\\varepsilon}_i)^2\\right\\} \\\\ &amp;=\\sum_{i=1}^tn_i\\left\\{\\sigma_\\varepsilon^2{\\left(\\frac1{n_i}\\right)}+\\frac{\\sigma_\\varepsilon^2}N-2\\frac{n_i}N{\\left(\\frac{\\sigma_\\varepsilon^2}{n_i}\\right)}\\right\\} \\\\ &amp;=\\sum_{i=1}^tn_i\\left(\\frac1{n_i}-\\frac1N\\right){\\sigma}_\\varepsilon^2 \\\\ &amp;=\\sum_{i=1}^t\\left(1-\\frac{n_i}N\\right)\\sigma_\\varepsilon^2=\\left(t-1\\right)\\sigma_\\varepsilon^2 \\end{aligned}\\]  \\(Q_2\\)  \\(u_i\\)  \\(\\tilde{u}_{\\cdot}=\\sum_{i=1}^t(n_iu_i/N)\\).  \\(u_i\\)  \\[\\mathrm{Var}(\\tilde{u}_\\cdot)=E(\\tilde{u}_\\cdot)^2=\\sum_{i=1}^t\\left(\\frac{n_i^2}{N^2}\\right){\\sigma}_u^2=\\left(\\frac1{N^2}\\right){\\sum}_{i=1}^t(n_i^2){\\sigma}_u^2\\]  \\(i\\ne i^\\prime\\)  \\(E(u_iu_{i^\\prime})\\)\\(u_i\\)  \\(\\tilde{u}_\\cdot\\)  \\[\\mathrm{Cov}(\\tilde{u}_\\cdot,u_i)=E(\\tilde{u}_\\cdot u_i)=\\left(\\frac{n_i}N\\right)E(u_i)^2=\\left(\\frac{n_i}N\\right)\\sigma_u^2\\] \\(Q_2\\)  \\(u_i\\)  \\[\\begin{aligned} \\sum_{i=1}^{t} &amp;n_{i}\\left[E(u_{i})^{2}+E(\\tilde{u}_{\\cdot})^{2}-2E(u_{i}\\tilde{u}_{\\cdot})\\right] \\\\ &amp;=\\sum_{i=1}^tn_i\\sigma_u^2+\\sum_{i=1}^t\\frac{n_i\\sigma_u^2}{N^2}\\left(\\sum_{i=1}^tn_i^2\\right)-2\\sum_{i=1}^t\\left(\\frac{n_i^2}N\\right)\\sigma_u^2 \\\\ &amp;\\left.=\\left(\\sum_{i=1}^tn_i{\\sigma}_u^2\\right.-\\frac{\\sum_{i=1}^tn_i^2}N{\\sigma}_u^2\\right)=\\left(N-\\frac{\\sum_{i=1}^tn_i^2}N\\right){\\sigma}_u^2 \\end{aligned}\\] \\(Q_2\\)  \\[\\begin{aligned}E(Q_2)=(t-1)\\sigma_\\varepsilon^2+\\left(N-\\frac{\\sum_{i=1}^tn_i^2}N\\right)\\sigma_u^2\\end{aligned}\\] \\(Q_2\\)  \\[E{\\left(\\frac{Q_2}{t-1}\\right)}=\\sigma_\\varepsilon^2+{\\left(\\frac1{t-1}\\right)}{\\left(N-\\frac{\\sum_{i=1}^tn_i^2}N\\right)}\\sigma_u^2\\]  18.1   18.1:  x 18.3.2 Hartley  Hartley (1967)  (Hartleys method of synthesis).  (18.3)  (quadratic form) \\[\\begin{equation} Q=\\boldsymbol{y&#39;Ay} \\tag{18.5} \\end{equation}\\]  \\(\\boldsymbol y\\) \\(\\boldsymbol A\\)  (the matrix of the quadratic form) (Graybill, 1976). n  \\[s^2=\\sum_{i=1}^n\\frac{(\\boldsymbol y_i-\\bar{\\boldsymbol y}_{\\cdot})^2}{n-1}=\\boldsymbol y^{\\prime}\\biggl[\\frac1{n-1}{\\biggl(\\boldsymbol I_n-\\frac1n\\boldsymbol J_n\\biggr)}\\biggr]\\boldsymbol{y}\\]  \\(\\boldsymbol I_n\\)  n × n \\(\\boldsymbol J_n\\)  n × n  \\(\\boldsymbol{y&#39;Ay}\\)  \\[\\boldsymbol A=\\frac1{n-1}{\\biggl(\\boldsymbol I_n-\\frac1n\\boldsymbol J_n\\biggr)}\\]  \\(\\boldsymbol A\\)  \\(\\boldsymbol A\\)  \\(\\boldsymbol A\\)  \\(\\boldsymbol A\\)   (18.3)  \\(\\boldsymbol \\Sigma\\) (Graybill, 1976)  \\[\\begin{equation} E(\\boldsymbol{y^{\\prime}Ay})=\\mathrm{Tr}[\\boldsymbol{A\\Sigma}]+\\frac12\\mu^2\\boldsymbol{j}_n^{\\prime}\\boldsymbol A\\boldsymbol{j}_n \\tag{18.6} \\end{equation}\\]  \\(\\operatorname{Tr}[\\boldsymbol{B}]=\\sum_{i=1}^nb_{ii}\\)  \\(b_{ii},i=1,2,\\cdots,n\\)  \\(\\boldsymbol B\\)  \\(\\mu^2\\boldsymbol{j}_n^{\\prime}\\boldsymbol A\\boldsymbol{j}_n\\).  \\(\\mu^2\\boldsymbol{j}_n^{\\prime}\\boldsymbol A\\boldsymbol{j}_n\\) \\[\\begin{equation} E(\\boldsymbol{y^{\\prime}Ay})=\\mathrm{Tr}[\\boldsymbol{A\\Sigma}] \\tag{18.7} \\end{equation}\\]  (18.3)  \\[\\boldsymbol{\\Sigma}={\\sigma}_1^2\\boldsymbol{Z}_1\\boldsymbol{Z}_1^{\\prime}+{\\sigma}_2^2\\boldsymbol{Z}_2\\boldsymbol{Z}_2^{\\prime}+\\cdots+{\\sigma}_r^2\\boldsymbol{Z}_r\\boldsymbol{Z}_r^{\\prime}+{\\sigma}_\\varepsilon^2\\boldsymbol{I}_N\\]  \\(\\boldsymbol{y^{\\prime}Ay}\\)  \\[\\begin{aligned}E(\\boldsymbol{y^{\\prime}Ay})&amp;=\\mathrm{Tr}[\\boldsymbol A\\boldsymbol{\\Sigma}]=\\mathrm{Tr}[\\boldsymbol A(\\sigma_1^2\\boldsymbol Z_1\\boldsymbol Z_1^{\\prime}+\\sigma_2^2\\boldsymbol Z_2\\boldsymbol Z_2^{\\prime}+\\cdots+\\sigma_r^2\\boldsymbol Z_r\\boldsymbol Z_r^{\\prime}+\\sigma_\\varepsilon^2\\boldsymbol I_N)]\\\\&amp;=\\sigma_1^2\\mathrm{~Tr}[\\boldsymbol A\\boldsymbol Z_1\\boldsymbol Z_1^{\\prime}]+\\sigma_2^2\\mathrm{~Tr}[\\boldsymbol A\\boldsymbol Z_2\\boldsymbol Z_2^{\\prime}]+\\cdots+\\sigma_r^2\\mathrm{~Tr}[\\boldsymbol A\\boldsymbol Z_r\\boldsymbol Z_r^{\\prime}]+\\sigma_\\varepsilon^2\\mathrm{~Tr}[\\boldsymbol A]\\end{aligned}\\] \\(\\sigma^2_{\\varepsilon}\\)  \\(\\mathrm{Tr}[\\boldsymbol A]\\) \\(\\boldsymbol{y^{\\prime}Ay}\\)  \\(s=1,2,\\cdots,r\\)\\(\\sigma^2_{\\varepsilon}\\)  \\(\\mathrm{Tr}[\\boldsymbol A\\boldsymbol Z_s\\boldsymbol Z_s^{\\prime}]\\). \\(\\mathrm{Tr}[\\boldsymbol A\\boldsymbol Z_s\\boldsymbol Z_s^{\\prime}]=\\mathrm{Tr}[\\boldsymbol Z_s^{\\prime}\\boldsymbol A \\boldsymbol Z_s]\\)  \\(\\mathrm{Tr}[\\boldsymbol Z_s^{\\prime}\\boldsymbol A \\boldsymbol Z_s]\\)  \\(\\boldsymbol Z_s^{\\prime}\\boldsymbol A \\boldsymbol Z_s\\)  \\(\\mathrm{Tr}[\\boldsymbol Z_s^{\\prime}\\boldsymbol A \\boldsymbol Z_s]=\\sum_{j=1}^{t_s}\\boldsymbol z^\\prime_{sj}\\boldsymbol A \\boldsymbol z_{sj}\\)  \\(\\boldsymbol Z_s\\)  \\(t_s\\) \\(\\boldsymbol z^\\prime_{sj}\\boldsymbol A \\boldsymbol z_{sj}\\)  \\(\\boldsymbol{y^{\\prime}Ay}\\)  \\(\\boldsymbol z^\\prime _{sj}\\)  \\(\\boldsymbol y\\)  \\(\\boldsymbol{y^{\\prime}Ay}\\)  \\(\\boldsymbol z^\\prime_{sj}\\boldsymbol A \\boldsymbol z_{sj}\\).  \\(\\boldsymbol{y^{\\prime}Ay}\\) \\(\\sigma^2_s\\)  \\(\\boldsymbol{z&#39;}_{s1}\\boldsymbol{Az}_{s1}+\\boldsymbol{z&#39;}_{s2}\\boldsymbol{Az}_{s2}+\\cdots+\\boldsymbol{z&#39;}_{st_s}\\boldsymbol{Az}_{st_s}\\).  \\(\\boldsymbol A\\)  \\(\\boldsymbol{y^{\\prime}Ay}\\) \\(\\boldsymbol A\\)  \\(\\boldsymbol z^\\prime_{sj}\\boldsymbol A \\boldsymbol z_{sj}\\)  \\(\\boldsymbol z_{sj}\\)  \\(\\boldsymbol y\\) \\([\\boldsymbol Z_1,\\boldsymbol Z_2,\\cdots,\\boldsymbol Z_r]\\) \\(\\boldsymbol{y^{\\prime}Ay}\\)  \\[E(\\boldsymbol{y^{\\prime}Ay})=v\\sigma_\\varepsilon^2+\\left(\\sum_{q=1}^{t_1}\\boldsymbol z_{1q}^{\\prime}\\boldsymbol A\\boldsymbol z_{1q}\\right)\\sigma_1^2+\\left(\\sum_{q=1}^{t_2}\\boldsymbol z_{2q}^{\\prime}\\boldsymbol A\\boldsymbol z_{2q}\\right)\\sigma_2^2+\\cdots+\\left(\\sum_{q=1}^{t_r}\\boldsymbol z_{rq}^{\\prime}\\boldsymbol A\\boldsymbol z_{rq}\\right)\\sigma_r^2\\]  \\(v\\)  \\(\\boldsymbol{y^{\\prime}Ay}\\)   \\(Q_1\\)  \\(Q_2\\)  \\(t=4\\) \\(i\\)  \\(n_i=4\\)  \\[\\begin{bmatrix}y_{11}\\\\y_{12}\\\\y_{13}\\\\y_{14}\\\\y_{21}\\\\y_{22}\\\\y_{23}\\\\y_{24}\\\\y_{31}\\\\y_{32}\\\\y_{33}\\\\y_{34}\\\\y_{41}\\\\y_{42}\\\\y_{43}\\\\y_{44}\\end{bmatrix}=\\begin{bmatrix}1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\end{bmatrix}\\mu+\\begin{bmatrix}1&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0\\\\0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;1\\\\0&amp;0&amp;0&amp;1\\\\0&amp;0&amp;0&amp;1\\\\0&amp;0&amp;0&amp;1\\end{bmatrix}+\\begin{bmatrix}\\boldsymbol u_1\\\\\\boldsymbol u_2\\\\\\boldsymbol u_3\\\\\\boldsymbol u_4\\end{bmatrix}+\\begin{bmatrix} \\varepsilon_{11}\\\\\\varepsilon_{12}\\\\\\varepsilon_{13}\\\\\\varepsilon_{14}\\\\ \\varepsilon_{21}\\\\\\varepsilon_{22}\\\\\\varepsilon_{23}\\\\\\varepsilon_{24}\\\\ \\varepsilon_{31}\\\\\\varepsilon_{32}\\\\\\varepsilon_{33}\\\\\\varepsilon_{34}\\\\ \\varepsilon_{41}\\\\\\varepsilon_{42}\\\\\\varepsilon_{43}\\\\\\varepsilon_{44}\\end{bmatrix}\\]  \\(\\boldsymbol{y}=\\boldsymbol{j}_{16} \\mu+[\\boldsymbol z_1\\,\\,\\boldsymbol z_2\\,\\,\\boldsymbol z_3\\,\\,\\boldsymbol z_4]\\boldsymbol{u}+\\boldsymbol{\\varepsilon}\\).  (within sum of squares23) \\(Q_1\\)  \\[E(Q_1)=E(\\boldsymbol{y&#39;}\\boldsymbol A_w\\boldsymbol{y})=\\boldsymbol{\\sigma}_u^2\\left[\\boldsymbol{\\sum}_{j=1}^4\\boldsymbol{z}&#39;_j\\boldsymbol{A}_w\\boldsymbol{z}_j\\right]+12{\\sigma}_\\varepsilon^2\\]  12  \\(Q_1\\) \\(\\boldsymbol{A}_w\\)  \\(Q_1\\)  \\(\\sigma^2_u\\)  \\(\\boldsymbol z_1\\)  \\(Q_1\\) \\(\\boldsymbol z_2\\)  \\(Q_1\\) \\(\\boldsymbol z_3\\)  \\(Q_1\\) \\(\\boldsymbol z_4\\)  \\(Q_1\\).  \\(\\boldsymbol z_1\\)  \\[\\begin{aligned}Q_1(\\boldsymbol z_1)=\\sum_{i=1}^4\\sum_{j=1}^4z_{1ij}^2-4\\sum_{i=1}^4\\bar{z}_{1i\\cdot}^2&amp;=4-4(1)=0\\end{aligned}\\] \\(Q_1(\\boldsymbol z_2),Q_1(\\boldsymbol z_3),Q_1(\\boldsymbol z_4)\\)  0.  \\(\\sigma^2_u\\)  \\(E(Q_1)\\)  \\(E(Q_1)=12{\\sigma}_\\varepsilon^2\\).  (between sum of squares24) \\(Q_2\\)  \\[E(Q_2)=E(\\boldsymbol{y&#39;}\\boldsymbol A_B\\boldsymbol{y})={\\sigma}_u^2\\biggl[\\boldsymbol{\\sum}_{j=1}^4\\boldsymbol{z&#39;}_{j}\\boldsymbol A_B\\boldsymbol{z}_j\\biggr]+3{\\sigma}_\\varepsilon^2\\]  \\[Q_2=\\sum_{i=1}^tn_i(\\bar{y}_{i\\cdot}-\\bar{y}_{\\cdot\\cdot})^2=\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2-n_{\\cdot\\cdot}\\bar{y}_{\\cdot\\cdot}\\]  3  \\(Q_2\\) \\(\\boldsymbol{A}_B\\)  \\(Q_2\\)  \\(\\sigma^2_u\\)  \\(\\boldsymbol z_1,\\boldsymbol z_2,\\boldsymbol z_3,\\boldsymbol z_4\\)  \\(Q_2\\)  \\(\\boldsymbol z_1\\)  \\[Q_2(\\boldsymbol z_1){=}4\\sum_{i=1}^4\\bar{z}_{1i\\cdot}^2-16\\bar{z}_{\\cdot\\cdot\\cdot}^2=4(1^2+0^2+0^2+0^2){-}16(0.25)^2{=}3\\] \\(Q_2(\\boldsymbol z_2),Q_2(\\boldsymbol z_3),Q_2(\\boldsymbol z_4)\\)  3\\(\\sigma^2_u\\)  \\(3+3+3+3=12\\). \\(E(Q_2)\\)  \\[E(Q_2)=12\\sigma_u^2+3\\sigma_\\varepsilon^2\\]  Hartley  (18.1)  \\[\\begin{bmatrix}y_{11}\\\\\\vdots\\\\y_{1n_1}\\\\y_{21}\\\\\\vdots\\\\y_{2n_2}\\\\\\vdots\\\\y_{t1}\\\\\\vdots\\\\y_{tn_l}\\end{bmatrix}=\\begin{bmatrix}1\\\\\\vdots\\\\1\\\\1\\\\\\vdots\\\\1\\\\\\vdots\\\\1\\\\\\vdots\\\\1\\end{bmatrix} \\mu+\\begin{bmatrix}1&amp;0&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\1&amp;0&amp;\\cdots&amp;0\\\\0&amp;1&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\0&amp;1&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;1\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;1\\end{bmatrix}\\begin{bmatrix}\\boldsymbol{u}_1\\\\\\boldsymbol{u}_2\\\\\\vdots\\\\\\boldsymbol{u}_t\\end{bmatrix}+\\boldsymbol{\\varepsilon}\\]  \\[\\boldsymbol y=\\boldsymbol j_{n} \\mu+[\\boldsymbol z_1,\\boldsymbol z_2,\\ldots,\\boldsymbol z_t]\\boldsymbol u+\\boldsymbol \\varepsilon \\]  \\[Q_1=\\sum_{i=1}^t\\sum_{j=1}^{n_i}y_{ij}^2-\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2=\\boldsymbol{y&#39;A}_w\\boldsymbol{y}\\]  \\[\\begin{aligned}E(Q_1)=\\sigma_u^2\\sum_{i=1}^t\\boldsymbol z_i&#39;\\boldsymbol A_w\\boldsymbol z_i+(N-t)\\sigma_\\varepsilon^2\\end{aligned}\\]  \\(N=\\sum_{i=1}^tn_i\\)  \\(\\boldsymbol A_w\\)  \\(\\boldsymbol z_1\\) \\(Q_1\\)  \\[Q_1(\\boldsymbol z_1)=\\sum_{i=1}^t\\sum_{j=1}^{n_i} z_{1ij}^2-\\sum_{i=1}^tn_i\\bar{ z}_{1i\\cdot}^2=n_1-\\left[n_1(1)+n_2(0)+\\cdots+n_t(0)\\right]=0\\] \\(Q_1(\\boldsymbol z_2),Q_1(\\boldsymbol z_3),Q_1(\\boldsymbol z_4)\\)  0. \\(\\sigma^2_u\\)  \\(E(Q_1)\\)  \\(E(Q_1)=(N-t)\\sigma^2_{\\varepsilon}\\) \\(Q_1\\)  N-t   \\[Q_2=\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2-n_{\\cdot\\cdot}\\bar{y}_{\\cdot\\cdot}^2=\\boldsymbol y^{\\prime}\\boldsymbol A_B\\boldsymbol y\\]  \\[E(Q_2)=\\sigma_u^2\\sum_{i=1}^t\\boldsymbol z_i \\boldsymbol A_B\\boldsymbol z_i+(t-1)\\sigma_\\varepsilon^2\\]  \\(\\boldsymbol A_B\\)  \\(\\boldsymbol z_1\\) \\(Q_2\\)  \\[Q_2(\\boldsymbol z_1){=}\\sum_{i=1}^tn_i\\bar{z}_{1i\\cdot}^2-N\\bar{z}_{1\\cdot\\cdot}^2\\]  \\(\\boldsymbol z_1\\)  \\(\\bar z_{11\\cdot}=1,\\bar z_{12\\cdot}=\\bar z_{13\\cdot}=\\cdots \\bar z_{1t\\cdot}=0\\)  \\(\\bar z_{1\\cdot\\cdot}=n_1/N\\).  \\[Q_2(\\boldsymbol z_1)=n_1(1)^2+n_2(0)^2+\\cdots+n_t(0)^2-N(n_1/N)^2=\\frac{n_1-n_1^2}N\\]  \\(\\boldsymbol Z\\)  \\(Q_2\\)  \\[Q_2(\\boldsymbol z_2)=\\frac{n_2-n_2^2}N,\\quad Q_2(\\boldsymbol z_3)=\\frac{n_3-n_3^2}N,\\ldots,Q_2(\\boldsymbol z_t)=\\frac{n_t-n_t^2}N\\]  \\[E(Q_2)=(t-1)\\sigma_\\varepsilon^2+\\left[\\sum_{i=1}^tQ_2(\\boldsymbol z_i)\\right]\\sigma_u^2=(t-1)\\sigma_\\varepsilon^2+\\left[\\sum_{i=1}^tn_i^2\\right]\\sigma_u^2\\]  Hartley  \\(Q_1\\)  \\(Q_2\\)   Hartley  \\[y_{ijk}=\\mu+a_i+b_j+c_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,s,j=1,2,\\ldots,t,\\quad k=1,2,\\ldots,n_{ij}\\]  \\(a_i,i=1,2,\\cdots,s\\)  \\(i.i.d.\\,N(0,\\sigma^2_a)\\) \\(b_i,i=1,2,\\cdots,t\\)  \\(i.i.d.\\,N(0,\\sigma^2_b)\\) \\(c_{ij}\\) - \\(i.i.d.\\,N(0,\\sigma^2_c)\\) \\(\\varepsilon_{ijk}\\)  \\(i.i.d.\\,N(0,\\sigma^2_\\varepsilon)\\)  18.1   18.1:   18.1  \\[\\begin{bmatrix}y_{111}\\\\y_{112}\\\\y_{113}\\\\y_{121}\\\\y_{122}\\\\y_{131}\\\\y_{132}\\\\y_{211}\\\\y_{212}\\\\y_{221}\\\\y_{222}\\\\y_{223}\\\\y_{231}\\\\y_{232}\\end{bmatrix}=\\begin{bmatrix}1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\\\1\\end{bmatrix}\\mu +\\begin{bmatrix}1&amp;0\\\\1&amp;0\\\\1&amp;0\\\\1&amp;0\\\\1&amp;0\\\\1&amp;0\\\\1&amp;0\\\\0&amp;1\\\\0&amp;1\\\\0&amp;1\\\\0&amp;1\\\\0&amp;1\\\\0&amp;1\\\\0&amp;1\\end{bmatrix}\\begin{bmatrix}a_1\\\\a_2\\end{bmatrix}+\\begin{bmatrix}1&amp;0&amp;0\\\\1&amp;0&amp;0\\\\1&amp;0&amp;0\\\\0&amp;1&amp;0\\\\0&amp;1&amp;0\\\\0&amp;0&amp;1\\\\0&amp;0&amp;1\\\\1&amp;0&amp;0\\\\1&amp;0&amp;0\\\\0&amp;1&amp;0\\\\0&amp;1&amp;0\\\\0&amp;1&amp;0\\\\0&amp;0&amp;1\\\\0&amp;0&amp;1\\end{bmatrix}\\begin{bmatrix}b_1\\\\b_2\\\\b_3\\end{bmatrix}+\\begin{bmatrix}1&amp;0&amp;0&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0&amp;0&amp;0\\\\1&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0&amp;0&amp;0\\\\0&amp;0&amp;1&amp;0&amp;0&amp;0\\\\0&amp;0&amp;1&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;1&amp;0&amp;0\\\\0&amp;0&amp;0&amp;1&amp;0&amp;0\\\\0&amp;0&amp;0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;0&amp;1&amp;0\\\\0&amp;0&amp;0&amp;0&amp;0&amp;1\\\\0&amp;0&amp;0&amp;0&amp;0&amp;1\\end{bmatrix}\\begin{bmatrix}c_{11}\\\\c_{12}\\\\c_{13}\\\\c_{21}\\\\c_{22}\\\\c_{23}\\end{bmatrix}+\\boldsymbol \\varepsilon\\]  \\(\\boldsymbol{y}=\\boldsymbol{j}_{14} \\mu+\\boldsymbol{Z}_1\\boldsymbol{a}+\\boldsymbol{Z}_2\\boldsymbol{b}+\\boldsymbol{Z}_3\\boldsymbol{c}+\\boldsymbol{\\varepsilon}\\)  \\(\\mu,\\sigma_a^2,\\sigma_b^2,\\sigma_c^2\\)  \\(\\sigma_\\varepsilon^2\\)  9  10  SSROWS, SSCOLUMNS, SSINTERACTION  SSERROR  Henderson  I  \\[\\begin{aligned} &amp;Q_1 =\\sum_{i=1}^s\\frac{y_{i\\cdot\\cdot}^2}{n_{i\\cdot}}-\\frac{y_{i\\cdot\\cdot}^2}{n_{\\cdot\\cdot}}\\mathrm{~(SSROWS)} \\\\ &amp;Q_2 =\\sum_{j=1}^t\\frac{y_{\\cdot j\\cdot}^2}{n_{\\cdot j}}-\\frac{y_{\\cdot\\cdot\\cdot}^2}{n_{\\cdot\\cdot}}\\mathrm{~(SSCOLUMNS)} \\\\ &amp;Q_3 =\\sum_{i=1}^\\text{s}{ \\sum _ { j = 1 }^{t}\\frac{y_{ij\\cdot}^2}{n_{ij}}-Q_1-Q_2+\\frac{y^2_{\\cdot\\cdot\\cdot}}{n_{\\cdot\\cdot}}\\quad\\text{(SSINTERACTION)}} \\\\ &amp;Q_4 =\\sum_{i=1}^s\\sum_{j=1}^t\\sum_{k=1}^{n_{ij}}{(y_{ijk}-\\bar{y}_{ij\\cdot})^2}\\quad\\text{(SSERROR)} \\end{aligned}\\]  18.1  \\[Q_2=\\frac{y_{\\cdot1\\cdot}^2}5+\\frac{y_{\\cdot2\\cdot}^2}5+\\frac{y_{\\cdot3\\cdot}^2}4-\\frac{y_{\\cdot\\cdot\\cdot}^2}{14}\\]  \\(k_1,k_2,k_3\\) \\(E(Q_2)\\)  \\(E(Q_2)k_1\\sigma_a^2+k_2\\sigma_b^2+k_3\\sigma_c^2+2\\sigma_\\varepsilon^2\\) 2  \\(Q_2\\)  Hartley  \\(k_1,k_2,k_3\\).  \\(k_1\\)  \\(\\boldsymbol Z_1\\)  \\(Q_2\\).  \\(\\boldsymbol Z_1\\)  \\(Q_2\\)  \\[\\begin{aligned}Q_2( \\boldsymbol z_{11})=\\frac{3^2}5+\\frac{2^2}5+\\frac{2^2}4-\\frac{7^2}{14}=0.1\\end{aligned}\\]  \\(\\boldsymbol Z_1\\)  \\(Q_2\\)  \\[Q_2(\\boldsymbol z_{12})=\\frac{2^2}5+\\frac{3^2}5+\\frac{2^2}4-\\frac{5^2}{14}=0.1\\] \\(k_1Q_2( z_{11})+Q_2( z_{11})=0.1+0.1=0.2\\).  \\(k_2\\)  \\(\\boldsymbol Z_2\\)  \\(Q_2\\)  \\[ \\begin{aligned} Q_2(z_{21})=\\frac{5^2}5+\\frac{0^2}5+\\frac{0^2}4-\\frac{5^2}{14}=3.214 \\\\ Q_2(z_{22})=\\frac{0^2}5+\\frac{5^2}5+\\frac{0^2}4-\\frac{5^2}{14}=3.214 \\\\ Q_{2}(z_{23})=\\frac{0^{2}}{5}+\\frac{0^{2}}{5}+\\frac{4^{2}}{4}-\\frac{4^{2}}{14}=2.857 \\end{aligned} \\] \\(k_2\\)  \\(k_2=Q_2( z_{21})+Q_2( z_{22})+Q_2( z_{23})=3.214+3.214+2.857=9.285\\). \\(k_3\\)  \\(\\boldsymbol Z_3\\)  \\(Q_2\\) \\(Q_2\\)  \\[\\begin{aligned} Q_2({z}_{311}) =\\frac{3^2}5+\\frac{0^2}5+\\frac{0^2}4-\\frac{3^2}{14}=1.157 \\\\ Q_2(z_{312}) =\\frac{0^2}5+\\frac{2^2}5+\\frac{0^2}4-\\frac{2^2}{14}=0.514 \\\\ Q_2(z_{313}) =\\frac{0^2}5+\\frac{0^2}5+\\frac{2^2}4-\\frac{2^2}{14}=0.714 \\\\ Q_{2}({z}_{321}) =\\frac{2^2}5+\\frac{0^2}5+\\frac{0^2}4-\\frac{2^2}{14}=0.514 \\\\ Q_2(z_{322}) =\\frac{0^2}5+\\frac{3^2}5+\\frac{0^2}4-\\frac{3^2}{14}=1.157 \\\\ Q_2({z}_{323})=\\frac{0^2}5+\\frac{0^2}5+\\frac{2^2}4-\\frac{2^2}{14}=0.714 \\end{aligned}\\] \\(k_3=1.157+0.514+0.714+0.514+1.157+0.714=4.770\\).  \\(k_1,k_2,k_3\\) SSROWS  \\[E(Q_2)=0.200\\sigma_a^2+9.285\\sigma_b^2+4.770\\sigma_c^2+2\\sigma_\\varepsilon^2\\]  Hartley \\(Q_1\\)  \\(Q_3\\)  \\[E(Q_1)=7.000{\\sigma}_a^2+0.143{\\sigma}_b^2+2.429{\\sigma}_c^2+(1){\\sigma}_\\varepsilon^2\\]  \\[E(Q_3)=4.371{\\sigma}_c^2+2{\\sigma}_\\varepsilon^2\\] SSERROR  SSERROR  \\({\\sigma}_\\varepsilon^2\\) \\[E(Q_4)=E(\\text{SSERROR})=8\\sigma_\\varepsilon^2\\]  SAS®-GLM  I-IV SAS-MIXED  I-III  Henderson  SAS  SAS-GLM  I-III  SAS  18.2  SAS  \\(\\boldsymbol Z_1\\) \\(\\boldsymbol a_1\\)  \\(\\boldsymbol a_2\\) \\(\\boldsymbol Z_1\\) \\(\\boldsymbol b_1,\\boldsymbol b_2\\)  \\(\\boldsymbol b_3\\)  \\(\\boldsymbol Z_3\\) \\(\\boldsymbol c_{11},\\boldsymbol c_{12},\\boldsymbol c_{13},\\boldsymbol c_{21},\\boldsymbol c_{22}\\)  \\(\\boldsymbol c_{23}\\)  SAS-GLM  18.3  I  \\[\\begin{aligned} E[\\mathrm{SSROW(I)}]=&amp;(1)\\sigma_\\varepsilon^2+(0.6429+0.2857+0.2857+0.2857+0.6429+0.2857)\\sigma_c^2\\\\ &amp;+(0.0714+0.0714+0.000)\\sigma_b^2+(3.500+3.500)\\sigma_a^2 \\\\ =&amp;\\sigma_\\varepsilon^2+2.4284\\sigma_c^2+0.1428\\sigma_b^2+7\\sigma_a^2 \\end{aligned}\\]  18.2:  18.1  19.2  \\([\\boldsymbol Z_1,\\boldsymbol Z_2,\\boldsymbol Z_3]\\)  \\(\\boldsymbol y\\)  I-III  SAS  x  18.3:  18.1  19.2  \\([\\boldsymbol Z_1,\\boldsymbol Z_2,\\boldsymbol Z_3]\\)  \\(\\boldsymbol y\\)  I-III  x  18.4  18.5  18.4  \\(\\sigma^2_\\varepsilon\\)   18.4:  18.3 \\([\\boldsymbol Z_1,\\boldsymbol Z_2,\\boldsymbol Z_3]\\)  I-III  x  18.5:  Hartley  SAS I-III  x Henderson (1953)  Hendersons methods I, II, III  IV  Searle, 1987; Henderson, 1984).  Hendersons methods I  II.  Hendersons methods I  Hendersons methods I   \\[\\begin{aligned}y_{ijk}&amp;=\\mu+a_i+b_j+c_{ij}+\\varepsilon_{ijk}&amp;&amp;i=1,2,\\ldots,s,&amp;j=1,2,\\ldots,t,&amp;k=1,2,\\ldots,n\\end{aligned}\\]  \\[a_i\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_a^2),\\quad b_j\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_b^2),\\quad c_{ij}\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_c^2),\\quad\\mathrm{and~}\\quad\\varepsilon_{ijk}\\thicksim i.i.d.\\mathrm{~N}(0,\\sigma_\\varepsilon^2)\\]  \\[\\begin{aligned} \\text{SSA}&amp; =nt\\sum_{i=1}^{s}(\\bar{y}_{i\\cdot\\cdot}-\\bar{y}_{\\cdot\\cdot\\cdot})^2=\\sum_{i=1}^{s}\\frac{y_{i\\cdot\\cdot}^2}{nt}-\\frac{y_{\\cdot\\cdot\\cdot}^2}{nst} \\\\ \\text{SSB}&amp; =ns\\sum_{j=1}^t(\\bar{y}_{\\cdot j\\cdot}-\\bar{y}_{\\cdot\\cdot\\cdot})^2=\\sum_{j=1}^t\\frac{y_{\\cdot j\\cdot}^2}{ns}-\\frac{y_{\\cdot\\cdot\\cdot}^2}{nst}, \\\\ \\text{SSAB}&amp; =n\\sum_{i=1}^s\\sum_{j=1}^t(\\bar{y}_{ij\\cdot}-\\bar{y}_{i\\cdot\\cdot}-\\bar{y}_{\\cdot j\\cdot}+\\bar{y}_{\\cdot\\cdot\\cdot})^2 \\\\ &amp;=\\sum_{i=1}^s\\sum_{j=1}^t\\frac{y_{ij\\cdot}^2}n-\\sum_{i=1}^s\\frac{y_{i\\cdot\\cdot}^2}{nt}-\\sum_{j=1}^t\\frac{y_{\\cdot j\\cdot}^2}{ns}+\\frac{y_{\\cdot\\cdot\\cdot}^2}{nst} \\end{aligned}\\]  \\(nst\\)  \\(n_{\\cdot\\cdot}\\) \\(ns\\)  \\(n_{\\cdot j}\\) \\(nt\\)  \\(n_{i\\cdot }\\).  \\[ \\begin{aligned} \\text{SSA} &amp;=\\sum_{i=1}^s\\frac{y_{i\\cdot\\cdot}^2}{n_{i\\cdot}}-\\frac{y^2_{\\cdot\\cdot\\cdot}}{n_{\\cdot\\cdot\\cdot}}, \\\\ \\text{SSB} &amp;=\\sum_{j=1}^t\\frac{y_{\\cdot j\\cdot}^2}{n_{\\cdot j}}-\\frac{y_{\\cdot\\cdot\\cdot}^2}{n_{\\cdot\\cdot\\cdot}}, \\\\ \\text{S} SAB&amp;=\\sum_{i=1}^s\\sum_{j=1}^t\\frac{y_{ij\\cdot}^2}{n_{ij}}-\\sum_{i=1}^s\\frac{y_{i\\cdot\\cdot}^2}{n_{i\\cdot}}-\\sum_{j=1}^t\\frac{y_{\\cdot j \\cdot}^2}{n_{\\cdot j}}+\\frac{y_{\\cdot\\cdot\\cdot}^2}{n_{\\cdot\\cdot}} \\end{aligned} \\]  18.1   (fitting-constants method) Hendersons methods III 10 25 \\[\\boldsymbol y=\\boldsymbol X_1\\boldsymbol b_1+\\boldsymbol X_2\\boldsymbol b_2+\\boldsymbol X_3\\boldsymbol b_3+\\boldsymbol\\varepsilon \\]  \\[R(\\boldsymbol b_1,\\boldsymbol b_2,\\boldsymbol b_3)=\\boldsymbol y^{\\prime}\\boldsymbol y-\\mathrm{SSERROR}(\\boldsymbol b_1,\\boldsymbol b_2,\\boldsymbol b_3)\\]  \\(\\mathrm{SSERROR}(\\boldsymbol b_1,\\boldsymbol b_2,\\boldsymbol b_3)\\)  \\(\\boldsymbol b_1\\)  \\(\\boldsymbol b_2\\)  \\(R(\\boldsymbol b_1,\\boldsymbol b_2)=\\boldsymbol y^{\\prime}\\boldsymbol y-{\\text{SSERROR}(\\boldsymbol b_1,\\boldsymbol b_2)}\\)  \\({\\text{SSERROR}(\\boldsymbol b_1,\\boldsymbol b_2)}\\)  \\(\\boldsymbol y=\\boldsymbol X_1 \\boldsymbol b_1+\\boldsymbol X_2 \\boldsymbol b_2 + \\boldsymbol \\varepsilon\\)   \\(\\boldsymbol b_1\\)  \\(\\boldsymbol b_2\\)  \\(\\boldsymbol b_3\\)  \\(R(\\boldsymbol b_3 |\\boldsymbol b_1 , \\boldsymbol b_2)\\)  \\(R(\\boldsymbol b_3 |\\boldsymbol b_l , \\boldsymbol b_2) = R(\\boldsymbol b_1 , \\boldsymbol b_2, \\boldsymbol b_3) - R(\\boldsymbol b_1 , \\boldsymbol b_2) = \\text{SSERROR}(\\boldsymbol b_1, \\boldsymbol b_2) - \\text{SSERROR}(\\boldsymbol b_1, \\boldsymbol b_2, \\boldsymbol b_3)\\) \\(\\boldsymbol b_2\\)  \\(\\boldsymbol b_1\\)  \\(R(\\boldsymbol b_1 |\\boldsymbol b_2) = R(\\boldsymbol b_1, \\boldsymbol b_2) - R(\\boldsymbol b_2) = \\text{SSERROR}(\\boldsymbol b_2)-\\text{SSERROR}(\\boldsymbol b_1, \\boldsymbol b_2)\\) \\(\\boldsymbol b_3\\)  \\(\\boldsymbol b_1\\)  \\(\\boldsymbol b_2\\)  \\(R(\\boldsymbol b_1 , \\boldsymbol b_2 |\\boldsymbol b_3) = R(\\boldsymbol b_1 , \\boldsymbol b_2, \\boldsymbol b_3) - R(\\boldsymbol b_3) = \\text{SSERROR}(\\boldsymbol b_3) - \\text{SSERROR}(\\boldsymbol b_1, \\boldsymbol b_2, \\boldsymbol b_3)\\). \\(E[R(\\boldsymbol b_1 , \\boldsymbol b_2 |\\boldsymbol b_3)]\\)  \\(\\boldsymbol b_3\\) \\(\\sigma^2_\\varepsilon\\) \\(\\boldsymbol b_3\\)  \\(\\boldsymbol b_1\\)  \\(\\boldsymbol b_2\\)  \\(\\boldsymbol b_1\\)  \\(\\boldsymbol b_2\\) 26  \\[\\boldsymbol y=\\boldsymbol j \\mu+\\boldsymbol X_1\\boldsymbol b+\\boldsymbol X_2\\boldsymbol t+\\boldsymbol X_3\\boldsymbol g+\\boldsymbol \\varepsilon \\]  \\(\\boldsymbol{b}\\sim N(0,\\sigma_b^2),\\boldsymbol{t}\\sim N(0,\\sigma_t^2),\\boldsymbol{g}\\sim N(0,\\sigma_g^2)\\)  \\(\\boldsymbol{\\varepsilon}\\sim N(0,\\sigma_\\varepsilon^2)\\) SAS-GLM  SAS-MIXED  I  \\[\\begin{aligned} &amp;R(\\boldsymbol b| \\mu)=R( \\mu,\\boldsymbol b)-R( \\mu) \\\\ &amp;R(\\boldsymbol t| \\mu,\\boldsymbol b)=R( \\mu,\\boldsymbol b,\\boldsymbol t)-R( \\mu,\\boldsymbol b) \\\\ &amp;R(\\boldsymbol g| \\mu,\\boldsymbol b,\\boldsymbol t)=R( \\mu,\\boldsymbol b,\\boldsymbol t,\\boldsymbol g)-R( \\mu,\\boldsymbol b,\\boldsymbol t) \\\\ &amp;\\mathrm{SSERROR}( \\mu,\\boldsymbol b,\\boldsymbol t,\\boldsymbol g)]=\\boldsymbol y^{\\prime}\\boldsymbol y-R( \\mu,\\boldsymbol b,\\boldsymbol t,\\boldsymbol g) \\end{aligned}\\]  \\[\\begin{aligned} &amp;E[\\text{SSERROR}( \\mu,\\boldsymbol b,\\boldsymbol t,\\boldsymbol g)]=(n-p)\\sigma_\\varepsilon^2 \\\\ &amp;E[R(\\boldsymbol g| \\mu,\\boldsymbol b,\\boldsymbol t)]=k_1\\sigma_\\varepsilon^2+k_2\\sigma_g^2 \\\\ &amp;E[R(\\boldsymbol t| \\mu,\\boldsymbol b)]=k_3\\sigma_\\varepsilon^2+k_4\\sigma_g^2+k_5\\sigma_t^2, \\\\ &amp;E[R(\\boldsymbol b| \\mu)]=k_6\\sigma_\\varepsilon^2+k_7\\sigma_g^2+k_8\\sigma_t^2+k_9\\sigma_b^2 \\end{aligned}\\]  \\(R(\\boldsymbol t| \\mu),R(\\boldsymbol b| \\mu, \\boldsymbol t),R(\\boldsymbol g| \\mu, \\boldsymbol b, \\boldsymbol t)\\)  \\(\\text{SSERROR}( \\mu,\\boldsymbol b,\\boldsymbol t, \\boldsymbol g)\\)  I  // 19  20  Hartley  (expected mean squares). 18.4   Hartleys  SAS  Hartleys  18.5  The general random effects model will have r random components representing the main effects and interactions for the random effect factors of the treatment structure and for those factors used to describe the design structure as well as possible interactions between components of the design and treatment structures used to describe the necessary error terms.  the sum of squares within levels of the random effect   the sum of squares between the levels of the random effect   \\(\\boldsymbol{b}\\sim N(0,\\sigma_b^2),\\boldsymbol{t}\\sim N(0,\\sigma_t^2),\\boldsymbol{g}\\sim N(0,\\sigma_g^2)\\) unless \\(\\boldsymbol b_3\\) denotes an interaction between \\(\\boldsymbol b_1\\) and \\(\\boldsymbol b_2\\) or an interaction with \\(\\boldsymbol b_1\\) or \\(\\boldsymbol b_2\\). "],["chap19.html", " 19   19.1  19.2  19.3  19.4 MIVQUE  19.5  JMP  19.6  19.7 ", "  19   By a small sample, we may judge of the whole piece. - Miguel de Cervantes from Don Quixote  (method of moments) (maximum likelihood, ML) (restricted, or residual maximum likelihood, REML)  MIVQUE.  REML  MIVQUE REML  MIVQUE REML  MIVQUE REML  19.1   Eisenhart (1947)  MODEL II  20 Searle, 1987; Graybill, 1976; Henderson 1984; Searle et al. 1992; Burdick and Graybill, 1992   \\[\\boldsymbol y=\\boldsymbol j_N\\boldsymbol\\mu+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_r\\boldsymbol u_r+\\boldsymbol \\varepsilon \\]  \\[\\begin{align} E(\\boldsymbol{u}_i)&amp;=\\boldsymbol{0},\\quad i=1,2,\\ldots,r\\\\\\operatorname{Var}(\\boldsymbol{u}_i)&amp;={\\sigma}_i^2\\boldsymbol{I}_{t_i},\\quad i=1,2,\\ldots,r\\\\E(\\boldsymbol{\\varepsilon})&amp;=\\boldsymbol{0},\\operatorname{Var}(\\boldsymbol{\\varepsilon})={\\sigma}_{\\boldsymbol{\\varepsilon}}^2\\boldsymbol{I}_N \\tag{19.1} \\end{align}\\] \\(\\boldsymbol u_1,\\boldsymbol u_2,\\cdots,\\boldsymbol u_r,\\boldsymbol \\varepsilon\\)   (19.1)    \\(\\boldsymbol \\mu\\)     (19.1)  \\(\\boldsymbol u_1,\\boldsymbol u_2,\\cdots,\\boldsymbol u_r,\\boldsymbol \\varepsilon\\)  (minimum variance unbiased) \\(\\boldsymbol u_1,\\boldsymbol u_2,\\cdots,\\boldsymbol u_r,\\boldsymbol \\varepsilon\\)  (minimum variance quadratic unbiased) (Graybill, 1976, p. 632).   18   r+1  \\(\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_r^2\\) r+1  \\(Q_0=\\boldsymbol y^\\prime \\boldsymbol A_0 \\boldsymbol y,Q_1=\\boldsymbol y^\\prime \\boldsymbol A_1 \\boldsymbol y,\\cdots,Q_r=\\boldsymbol y^\\prime \\boldsymbol A_r \\boldsymbol y\\) \\[\\begin{aligned}E(Q_i)=b_{i0}\\sigma_\\varepsilon^2+b_{i1}\\sigma_1^2+b_{i2}\\sigma_\\gamma^2+\\cdots+b_{ir}\\sigma_r^2,\\quad i=0,1,2,\\ldots,r\\end{aligned}\\] ~ \\[Q_i=b_{i0}\\tilde{\\sigma}_\\varepsilon^2+b_{i1}\\tilde{\\sigma}_1^2+b_{i2}\\tilde{\\sigma}_2^2+\\cdots+b_{ir}\\tilde{\\sigma}_r^2,\\quad i=0,1,2,\\ldots,r\\]  \\[\\begin{bmatrix}Q_0\\\\Q_1\\\\Q_2\\\\\\vdots\\\\Q_r\\end{bmatrix}=\\begin{bmatrix}b_{00}&amp;b_{01}&amp;b_{02}&amp;\\cdots&amp;b_{0r}\\\\b_{10}&amp;b_{11}&amp;b_{12}&amp;\\cdots&amp;b_{1r}\\\\b_{20}&amp;b_{21}&amp;b_{22}&amp;\\cdots&amp;b_{2r}\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\b_{r0}&amp;b_{r1}&amp;b_{r2}&amp;\\cdots&amp;b_{rr}\\end{bmatrix}\\begin{bmatrix}\\tilde{\\sigma}_\\varepsilon^2\\\\\\tilde{\\sigma}_1^2\\\\\\tilde{\\sigma}_2^2\\\\\\vdots\\\\\\tilde{\\sigma}_r^2\\end{bmatrix}\\]  \\(\\boldsymbol Q=\\boldsymbol B \\tilde {\\boldsymbol\\sigma}^2\\).  \\(\\boldsymbol B\\)  r+1 \\(\\boldsymbol B\\)  r+1 \\(\\boldsymbol B\\)  r+1 \\[\\tilde {\\boldsymbol\\sigma}^2=\\boldsymbol B^{-1}\\boldsymbol Q{=}\\boldsymbol C\\boldsymbol Q\\mathrm{~(say)}\\] \\(\\sigma_i^2\\)  \\(\\tilde \\sigma_i^2\\)  \\(\\hat \\sigma_i^2\\)  \\[\\hat{\\sigma}_i^2=\\begin{cases}\\tilde{\\sigma}_i^2&amp;\\mathrm{~if~}\\tilde{\\sigma}_i^2&gt;0\\\\0&amp;\\mathrm{~if~}\\tilde{\\sigma}_i^2\\leq0&amp;\\end{cases}\\quad i=0,1,2,\\ldots,r\\]  \\(\\boldsymbol B\\)  \\(\\boldsymbol B\\)   \\(Q_0,Q_1,Q_2,\\cdots,Q_r\\)  \\[\\tilde{\\sigma}_i^2=c_{i0}Q_0+c_{i1}Q_1+c_{i2}Q_2+\\cdots+c_{ir}Q_r\\quad i=0,1,2,\\ldots,r\\]  \\(c_i&#39;=[c_{i0}\\quad c_{i1}\\quad c_{i2}\\quad \\cdots\\quad c_{ir}]\\)  \\(\\boldsymbol C=\\boldsymbol B^{-1}\\)  \\(i\\) \\(\\tilde \\sigma_i^2\\)  \\[\\mathrm{Var}(\\tilde{\\sigma}_i^2)=\\mathrm{Var}(c_{i0}Q_0+c_{i1}Q_1+c_{i2}Q_2+\\cdots+c_{ir}Q_r)\\]  \\(Q_i,i=0,1,\\cdots,r\\) \\(\\tilde \\sigma_i^2\\)  \\[\\operatorname{Var}(\\tilde{\\sigma}_i^2)=c_{i0}^2\\operatorname{Var}(Q_0)+c_{i1}^2\\operatorname{Var}(Q_1)+c_{i2}^2\\operatorname{Var}(Q_2)+\\cdots+c_{ir}^2\\operatorname{Var}(Q_r)\\] Searle (1971, Chapter 11)  (uniformly minimum variance unbiased estimators) (Graybill, 1976).  19.1.1  19.1  18.2  \\[y_{ij}=\\mu+u_i+\\varepsilon_{ij}\\quad i=1,2,\\ldots,t\\mathrm{~and~}j=1,2,\\ldots,n_i\\]  \\(u_i\\)  0  \\(\\sigma^2_1\\)\\(\\varepsilon_{ij}\\)  0  \\(\\sigma^2_{\\varepsilon}\\) \\(u_i\\)  \\(\\varepsilon_{ij}\\)  (sum of squares within) \\(Q_0\\)  SSW  (sums of squares between) \\(Q_1\\)  SSB \\[\\begin{aligned}Q_0&amp;=\\sum_{i=1}^t\\sum_{j=1}^{n_i}(y_{ij}-\\bar{y}_{i\\cdot})^2=\\sum_{i=1}^t\\sum_{j=1}^{n_i}y_{ij}^2-\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2=SSW\\\\\\\\\\\\Q_1&amp;=\\sum_{i=1}^tn_i(\\bar{y}_{i\\cdot}-\\bar{y}_{\\cdot\\cdot})^2=\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2-\\left(\\sum_{i=1}^tn_i\\right)\\bar{y}_{\\cdot}^2=SSB\\end{aligned}\\] \\(Q_0,Q_1\\)  18  \\[\\begin{aligned}E(Q_0)&amp;=(N-t){\\sigma}_\\varepsilon^2\\\\\\\\E(Q_1)&amp;=(t-1){\\sigma}_\\varepsilon^2+\\left(N-\\frac{{\\sum}_{i=1}^t{n}_i^2}N\\right){\\sigma}_1^2\\end{aligned}\\]  \\(N=\\sum_{i=1}^tn_i\\).  \\[\\begin{aligned}&amp;Q_0=(N-t)\\tilde{{\\sigma}}_\\varepsilon^2\\\\\\\\&amp;Q_1=(t-1)\\tilde{{\\sigma}}_\\varepsilon^2+\\left(N-\\frac{\\sum_{i=1}^tn_i^2}N\\right)\\tilde{{\\sigma}}_1^2\\end{aligned}\\]  \\[\\begin{bmatrix}Q_0\\\\Q_1\\end{bmatrix}=\\begin{bmatrix}N-t&amp;0\\\\(t-1)&amp;N-\\frac{\\sum_{i=1}^tn_i^2}N\\end{bmatrix}\\begin{bmatrix}\\tilde{\\sigma}_\\varepsilon^2\\\\\\tilde{\\sigma}_1^2\\end{bmatrix}\\]  \\[\\begin{aligned}\\frac{Q_0}{N-t}&amp;=\\tilde{\\sigma}_\\varepsilon^2\\\\\\frac{Q_1}{t-1}&amp;=\\tilde{\\sigma}_\\varepsilon^2+\\frac{\\left(N-\\frac{\\sum_{i=1}^tn_i^2}N\\right)}{t-1}\\tilde{\\sigma}_1^2\\end{aligned}\\]  \\[\\begin{aligned}\\widetilde{\\sigma}_\\varepsilon^2&amp;=\\frac{Q_0}{N-t}\\\\\\tilde{\\sigma}_1^2&amp;=\\frac{Q_1-(t-1)\\tilde{\\sigma}_\\varepsilon^2}{N-\\frac{\\sum_{i=1}^tn_i^2}N}\\end{aligned}\\]  \\[\\hat{\\sigma}_\\varepsilon^2=\\tilde{\\sigma}_\\varepsilon^2\\]  \\[\\hat{{\\sigma}}_1^2=\\begin{cases}\\tilde{{\\sigma}}_1^2&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_1^2&gt;0\\\\0&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_1^2\\leq0&amp;\\end{cases}\\] 19.1.2  19.2  (plots)  20  0  10  0 10  20  19.1  \\(Q_0\\)  \\(Q_1\\)  19.1  0.056 0.067.  \\[\\hat{\\sigma}_{\\mathrm{Damage}}^2=\\hat{\\sigma}_{\\varepsilon}^2+\\hat{\\sigma}_{\\mathrm{Var}}^2=0.056+0.067=0.123\\]  19.1:  19.2  x  (intraclass correlation)  \\[\\hat{\\rho}=\\frac{\\hat{\\sigma}_\\mathrm{Var}^2}{\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_\\mathrm{Var}^2}=\\frac{0.067}{0.123}=0.545\\]  18  19.1.3  19.3 18.2   19.2  18.1  \\(Q_0,Q_1,Q_2\\)  \\(Q_3\\)  Hendersons method I  \\[\\begin{aligned} &amp;Q_0 =SSError=30.6666 \\\\ &amp;Q_1 =SSA=\\sum_{i=1}^2\\frac{y_{i\\cdot\\cdot}^2}{n_{i\\cdot}}-\\frac{y_{\\cdot\\cdot\\cdot}^2}{n_{\\cdot\\cdot}}=0.6428 \\\\ &amp;Q_2 =SSB=\\sum_{j=1}^3\\frac{y_{\\cdot j\\cdot}^2}{n_{\\cdot j}}-\\frac{y_{\\cdot\\cdot\\cdot}^2}{n_{\\cdot\\cdot}}=15.2143 \\\\ &amp;Q_3 =SSAB=\\sum_{i=1}^2\\sum_{j=1}^3\\frac{y_{ij\\cdot}^2}{n_{ij}}-\\sum_{i=1}^2\\frac{y_{i\\cdot\\cdot}^2}{n_{i\\cdot}}-\\sum_{j=1}^3\\frac{y_{\\cdot j\\cdot}^2}{n_{\\cdot j}}+\\frac{y_{\\cdot\\cdot\\cdot}^2}{n_{\\cdot\\cdot}}=108.6905 \\end{aligned}\\]  19.2:  19.3  x  \\[\\begin{aligned} &amp;E(Q_0)=8{\\sigma}_\\varepsilon^2 \\\\ &amp;E(Q_{1}) =\\sigma_\\varepsilon^2+0.1429\\sigma_b^2+2.4286\\sigma_c^2+7.0\\sigma_a^2 \\\\ &amp;E(Q_2) =2\\sigma_\\varepsilon^2+9.286\\sigma_b^2+4.77\\sigma_c^2+0.20\\sigma_a^2 \\\\ &amp;E(Q_3) =2\\sigma_\\varepsilon^2+6.37\\sigma_c^2 \\end{aligned}\\]  \\[\\begin{aligned} \\text{30.6666}&amp; =8\\tilde{\\sigma}_\\varepsilon^2 \\\\ \\text{0.6428}&amp; =\\tilde{{\\sigma}}_\\varepsilon^2+0.1429\\tilde{{\\sigma}}_b^2+2.4286\\tilde{{\\sigma}}_c^2+7.0\\tilde{{\\sigma}}_a^2 \\\\ \\text{15.2143}&amp; =2\\tilde{{\\sigma}}_\\varepsilon^2+9.286\\tilde{{\\sigma}}_b^2+4.77\\tilde{{\\sigma}}_c^2+0.20\\tilde{{\\sigma}}_a^2 \\\\ \\text{108.6905}&amp; =2\\tilde{{\\sigma}}_\\varepsilon^2+6.37\\tilde{{\\sigma}}_c^2 \\end{aligned}\\]  \\[\\begin{aligned} &amp;\\tilde{{\\sigma}}_\\varepsilon^2 =3.83325 \\\\ &amp;\\tilde{{\\sigma}}_c^2 =15.8593 \\\\ &amp;\\tilde{{\\sigma}}_b^2 =-10.8817 \\\\ &amp;\\tilde{{\\sigma}}_a^2 =-8.2523 \\end{aligned}\\]  \\[\\begin{aligned} &amp;\\hat{{\\sigma}}_\\varepsilon^2 =3.83325 \\\\ &amp;\\hat{{\\sigma}_c^2} \\text{=15.8593} \\\\ &amp;\\hat{{\\sigma}_b^2} =0.00 \\\\ &amp;\\hat{{\\sigma}_a^2} =0.00 \\end{aligned}\\]  19.3  Hendersons method III SAS® I SAS III  19.4  19.3  I  \\[\\begin{aligned} &amp;\\tilde{{\\sigma}}_\\varepsilon^2 =3.8333 \\\\ &amp;\\tilde{\\sigma}_c^2 =\\frac{109.1451-2(3.8333)}{4.5178}=22.4620 \\\\ &amp;\\tilde{{\\sigma}}_b^2 =\\frac{14.5797-2(3.8333)-4.6252(22.4620)}{9.1429}=-10.5877 \\\\ &amp;\\tilde{\\sigma}_{a}^{2} =\\frac{0.6429-3.833-0.1428(-10.71322)-2.4284(22.4620)}{7.00}=-8.0329 \\end{aligned}\\]  I  \\[\\begin{aligned} &amp;\\hat{{\\sigma}}_\\varepsilon^2 =3.8333 \\\\ &amp;\\hat{\\sigma}_c^2 =22.4620 \\\\ &amp;\\hat{{\\sigma}_b^2} =0 \\\\ &amp;\\hat{{\\sigma}_a^2} =0 \\end{aligned}\\] III  \\[\\begin{aligned} &amp;\\tilde{{\\sigma}}_\\varepsilon^2 =3.8333 \\\\ &amp;\\tilde{{\\sigma}}_c^2 =\\frac{109.1451-2(3.8333)}{4.5178}=22.4620 \\\\ &amp;\\tilde{{\\sigma}}_b^2 =\\frac{8.9098-2(3.8333)-4.5178(22.4620)}{9.0353}=-11.1080 \\\\ &amp;\\tilde{{\\sigma}}_a^2 =\\frac{0.677-3.833-2.2500(22.4620)}{6.75}=-8.0305 \\end{aligned}\\] III 27 \\[\\begin{aligned} &amp;\\hat{{\\sigma}}_\\varepsilon^2 =3.8333 \\\\ &amp;\\hat{{\\sigma}_c^2} =22.4620 \\\\ &amp;\\hat{{\\sigma}_b^2} =0 \\\\ &amp;\\hat{\\sigma}_a^2 =0 \\end{aligned}\\]  (mean square within)  (mean square between)  \\[\\begin{aligned}E(MSWithin)&amp;=\\sigma_\\varepsilon^2\\\\E(MSBetween)&amp;=\\sigma_\\varepsilon^2+c\\sigma_u^2\\end{aligned}\\] \\(\\sigma^2_u\\)  \\[\\tilde{\\sigma}_u^2=\\frac{MSBetween-MSWithin}c\\] MSWithin  MSBetween  \\(\\sigma^2_u=0\\) \\(\\sigma^2_\\varepsilon=0\\)\\(\\sigma^2_u\\)  0.50 \\[P(MSBetween&lt;MSWithin\\mid\\sigma_u^2=0)=0.50\\]  \\(\\sigma^2_u\\)  \\(\\hat\\sigma^2_u\\)  Searle et al. 1992 20  19.2   (method of maximum likelihood).  loge.  -2loge (19.1)  \\[\\{-\\infty&lt;\\mu&lt;+\\infty,\\quad0&lt;\\sigma_i^2&lt;+\\infty,\\quad i=1,2,\\ldots,k;\\quad0&lt;\\sigma_\\varepsilon^2&lt;\\infty\\}\\]  (19.1) \\[ \\boldsymbol y\\thicksim N(\\boldsymbol j_n\\mu,\\sigma_\\varepsilon^2\\boldsymbol I_n+\\sigma_1^2\\boldsymbol Z_1\\boldsymbol Z_1^{\\prime}+\\sigma_2^2\\boldsymbol Z_2\\boldsymbol Z_2^{\\prime}+\\cdots+\\sigma_k^2\\boldsymbol Z_k\\boldsymbol Z_k^{\\prime})\\quad\\mathrm{or}\\quad \\boldsymbol y\\thicksim N (\\boldsymbol j_n\\mu,\\boldsymbol \\Sigma) \\]  \\[L(\\boldsymbol\\mu,\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)=(2\\pi)^{-n/2}|\\boldsymbol{\\Sigma}|^{-1/2}\\exp[-\\frac12(\\boldsymbol{y}-\\boldsymbol{j}_n\\mu)^{\\prime}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{j}_n\\mu)]\\] -2loge \\[\\begin{aligned}\\ell(\\boldsymbol\\mu,\\sigma_e^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)&amp;=-2\\log_e[L(\\mu,\\sigma_e^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)]\\\\&amp;=n\\log_e(2\\pi)+\\log_e(|\\boldsymbol{\\Sigma}|)+(\\boldsymbol{y}-\\boldsymbol{j}_n{\\mu})^{\\prime}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{j}_n{\\mu})\\end{aligned}\\]  \\(\\ell(\\boldsymbol\\mu,\\sigma_e^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)\\)  \\(\\ell(\\boldsymbol\\mu,\\sigma_e^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)\\)   \\(n\\)  \\(\\sigma^2_i\\) \\(\\sigma^2_i\\)  \\(\\hat\\sigma^2_i=0\\) (Searle, 1971).  19.2.1  19.4  \\[y_{ij}=\\mu+u_i+\\varepsilon_{ij},\\quad i=1,2,\\ldots,t\\quad\\mathrm{and~}j=1,2,\\ldots,n\\]  \\(\\mu_i\\sim i.i.d.\\,N(0,\\sigma^2_u),\\varepsilon_{ij}\\sim i.i.d.\\,N(0,\\sigma^2_\\varepsilon)\\) \\(\\mu_i,\\varepsilon_{ij}\\)  \\(\\boldsymbol y\\sim N[(\\boldsymbol j_n\\otimes \\boldsymbol j_t)\\mu,\\boldsymbol \\Sigma]\\)  \\(\\boldsymbol \\Sigma=\\sigma^2_u \\boldsymbol j_n\\otimes \\boldsymbol j_t +\\sigma^2_\\varepsilon \\boldsymbol I_n\\otimes \\boldsymbol I_t\\).  \\(A \\otimes B\\)  \\(A,B\\)  Kronecker 28 (direct product) (Graybill, 1976).  \\(\\boldsymbol \\Sigma\\)  \\[\\boldsymbol{\\Sigma}={\\sigma}_\\varepsilon^2\\left[\\left(\\boldsymbol{I}_n-\\frac1n\\boldsymbol{J}_n\\right)\\otimes\\boldsymbol{I}_t\\right]+({\\sigma}_\\varepsilon^2+n{\\sigma}_u^2)\\left[\\left(\\frac1n\\boldsymbol{J}_n\\right)\\otimes\\boldsymbol{I}_t\\right]\\]  \\({\\sigma}_\\varepsilon^2\\)  \\({\\sigma}_\\varepsilon^2+n{\\sigma}_u^2\\)  \\(\\boldsymbol \\Sigma\\)  \\(\\left[\\left(\\boldsymbol{I}_n-\\frac1n\\boldsymbol{J}_n\\right)\\otimes\\boldsymbol{I}_t\\right]\\)  \\(\\left[\\left(\\frac1n\\boldsymbol{J}_n\\right)\\otimes\\boldsymbol{I}_t\\right]\\)   \\[\\boldsymbol{\\Sigma}^{-1}=\\frac1{{\\sigma}_\\varepsilon^2}{\\left[\\left(\\boldsymbol{I}_n-\\frac1n\\boldsymbol{J}_n\\right)\\otimes\\boldsymbol{I}_t\\right]}+\\frac1{{\\sigma}_\\varepsilon^2+n{\\sigma}_u^2}{\\left[\\left(\\frac1n\\boldsymbol{J}_n\\right)\\otimes\\boldsymbol{I}_t\\right]}\\]  \\[|\\boldsymbol{\\Sigma}|=(\\sigma_\\varepsilon^2)^{t(n-1)}(\\sigma_\\varepsilon^2+n\\sigma_u^2)^t\\]  \\[\\log_\\mathrm{e}|\\boldsymbol{\\Sigma}|=t(n-1)\\log_\\mathrm{e}(\\sigma_\\varepsilon^2)+t\\log_\\mathrm{e}(\\sigma_\\varepsilon^2+n\\sigma_u^2)\\]  \\[(\\boldsymbol y-\\boldsymbol j_{nt}\\mu)^{\\prime}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol y-\\boldsymbol j_{nt}\\mu)=\\frac{nt(\\bar{y}_{\\cdot\\cdot}-\\mu)^2}{\\sigma_\\varepsilon^2+n\\sigma_u^2}+\\frac{SSE}{\\sigma_\\varepsilon^2}+\\frac{SSU}{\\sigma_\\varepsilon^2+n\\sigma_u^2}\\]  \\[SSE=\\sum_{i=1}^t\\sum_{j=1}^n(y_{ij}-\\bar{y}_{i\\cdot})^2\\quad\\mathrm{~and~}\\quad SSU=n\\sum_{i=1}^t(\\bar{y}_{i\\cdot}-\\bar{y}_{\\cdot\\cdot})^2\\] \\(-2\\log_{\\mathrm{e}}(L(\\mu,\\sigma_{u}^2,\\sigma_{\\varepsilon}^2|\\boldsymbol y)\\)  \\[\\begin{aligned} \\ell(\\mu,{\\sigma}_u^2,{\\sigma}_\\varepsilon^2|\\boldsymbol{y}) =tn\\log_\\mathrm{e}(2\\pi)+t(n-1)\\log_\\mathrm{e}(\\sigma_\\varepsilon^2)+t\\log_\\mathrm{e}(\\sigma_\\varepsilon^2+n\\sigma_u^2) \\\\ +\\frac{nt(\\bar{y}_{\\cdot\\cdot}-\\mu)^2}{\\sigma_\\varepsilon^2+n\\sigma_u^2}+\\frac{SSE}{\\sigma_\\varepsilon^2}+\\frac{SSU}{\\sigma_\\varepsilon^2+n\\sigma_u^2} \\end{aligned}\\]  \\(\\mu,\\sigma_u^2,\\sigma_\\varepsilon^2\\)  \\(\\ell(\\mu,\\sigma_u^2,\\sigma_\\varepsilon^2|\\boldsymbol y)\\)  \\[\\begin{aligned} &amp;\\frac{\\partial\\ell(\\mu,\\sigma_u^2,\\sigma_\\varepsilon^2|\\boldsymbol y)}{\\partial\\mu} =\\frac{-2nt(\\bar{y}_{\\cdot\\cdot}-\\tilde{\\mu})}{\\sigma_\\varepsilon^2+n\\sigma_u^2}=0 \\\\ &amp;\\frac{\\partial\\ell(\\mu,\\sigma_u^2,\\sigma_\\varepsilon^2|\\boldsymbol y)}{\\partial\\sigma_\\varepsilon^2} =\\frac{t(n-1)}{\\tilde{\\sigma}_\\varepsilon^2}+\\frac t{\\tilde{\\sigma}_\\varepsilon^2+n\\tilde{\\sigma}_u^2}-\\frac{nt(\\bar{y}_{\\cdot\\cdot}-\\tilde{\\mu})^2}{(\\tilde{\\sigma}_\\varepsilon^2+n\\tilde{\\sigma}_u^2)^2}-\\frac{SSE}{(\\tilde{\\sigma}_\\varepsilon^2)^2}-\\frac{SSU}{(\\tilde{\\sigma}_\\varepsilon^2+n\\tilde{\\sigma}_u^2)^2}=0 \\\\ &amp;\\frac{\\partial\\ell(\\mu,\\sigma_u^2,\\sigma_\\varepsilon^2|\\boldsymbol y)}{\\partial\\sigma_u^2} =\\frac{nt}{\\tilde{\\sigma}_\\varepsilon^2+n\\tilde{\\sigma}_u^2}-\\frac{n^2t(\\bar{y}_{\\cdot\\cdot}-\\tilde{\\mu})^2}{(\\tilde{\\sigma}_\\varepsilon^2+n\\tilde{\\sigma}_u^2)^2}-\\frac{nSSU}{(\\tilde{\\sigma}_\\varepsilon^2+n\\tilde{\\sigma}_u^2)^2}=0 \\end{aligned}\\]  \\[\\tilde{\\mu}=\\bar{y}_{\\cdot\\cdot },\\quad\\tilde{\\sigma}_\\varepsilon^2=\\frac{SSE}{t(n-1)}=MSError,\\quad\\mathrm{and}\\quad\\tilde{\\sigma}_u^2=\\frac1n{\\left[\\frac{SSU}t-MSError\\right]}\\]  \\[\\hat{\\mu}=\\tilde{\\mu}=\\bar{y}_{\\cdot\\cdot },\\quad\\hat{\\sigma}_\\varepsilon^2=\\tilde{\\sigma}_\\varepsilon^2=\\frac{SSE}{t(n-1)}=MSError\\]  \\[\\hat{\\sigma}_u^2=\\begin{cases}\\tilde{\\sigma}_u^2&amp;\\mathrm{~if~}&amp;\\tilde{\\sigma}_u^2\\geq0\\\\0&amp;\\mathrm{~if~}&amp;\\tilde{\\sigma}_u^2&lt;0&amp;\\end{cases}\\]  \\({\\sigma}_u^2\\)  SSE  SSU  \\({\\sigma}_\\varepsilon^2\\)  \\[\\hat{\\sigma}_\\varepsilon^2=\\frac{SSE+SSU}{tn-1}\\]  \\({\\sigma}_\\varepsilon^2\\)  \\(u_i\\)  \\[\\boldsymbol{\\Sigma}={\\sigma}_A^2{\\rho}[c{J}_n\\otimes\\boldsymbol{I}_t]+{\\sigma}_A^2(1-{\\rho})[\\boldsymbol{I}_n\\otimes\\boldsymbol{I}_t]\\]  \\(\\sigma_{\\varepsilon}^{2}=\\sigma_{A}^{2}\\left(1-\\rho\\right)\\)  \\(\\sigma_{u}^{2}=\\sigma_{A}^{2}\\rho\\). (Hemmerle and Hartley, 1973; Corbeil and Searle, 1976). Searle (1971)  Searle et al. (1992)    SAS-Mixed 19.2  19.3  19.2  \\(\\sigma^2_\\varepsilon\\)  \\(\\sigma^2_u\\)  \\(\\hat\\sigma^2_\\varepsilon= 0.05749\\)  \\(\\sigma^2_u = 0.04855\\) 19.3  19.3  \\(\\hat\\sigma^2_\\varepsilon= 3.5989,\\hat\\sigma^2_c= 8.5604,\\hat\\sigma^2_a = 0\\)  \\(\\hat\\sigma^2_b = 0\\) 19.4 SAS-Mixed  ML  19.4  \\(\\hat\\sigma^2_a,\\hat\\sigma^2_b\\)   19.3: Proc Mixed  19.2  x  19.4: Proc Mixed  19.3  x 19.3   (Restricted or residual maximum likelihood estimates, REML).  \\(\\mu\\).  -2loge REML   (19.1) \\[L(\\mu,\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)=(2\\pi)^{-n/2}\\left|\\boldsymbol{\\Sigma}\\right|^{-1/2}e^{\\left[-(1/2)(\\boldsymbol{y}-\\boldsymbol{j}_n{\\mu})^{\\prime}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{j}_n{\\mu})\\right]}\\]  -2loge \\[\\begin{aligned} \\ell(\\mu,\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y) =&amp;-2\\log_e[L(\\mu,\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)] \\\\ =&amp;\\,n\\log_\\mathrm{e}(2\\pi)+\\log_\\mathrm{e}(|\\boldsymbol{\\Sigma}|)+(\\boldsymbol{y}-\\boldsymbol{j}_n{\\mu})^{\\prime}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{j}_n{\\mu}) \\\\ =&amp;\\,\\ell(\\mu,\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\bar{y}) \\\\ &amp;+\\ell(\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2| SSE,SSU_1,SSU_2,\\ldots,SSU_k) \\end{aligned}\\]  \\(SSE,SSU_1,SSU_2,\\ldots,SSU_k\\)  \\(\\mu\\) \\(\\ell(\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2| SSE,SSU_1,SSU_2,\\ldots,SSU_k)\\)  REML  19.3.1  19.5 REML   19.4 -2loge \\(\\bar y_{\\cdot\\cdot},SSE,SSU\\)  \\[\\begin{aligned} \\ell(\\mu,\\sigma_u^2,\\sigma_\\varepsilon^2|\\boldsymbol y) =&amp;\\,tn\\log_{\\mathrm{e}}(2\\pi)+t(n-1)\\log_{\\mathrm{e}}(\\sigma_{\\varepsilon}^2)+t\\log_{\\mathrm{e}}(\\sigma_{\\varepsilon}^2+n\\sigma_{u}^2) \\\\ &amp;+\\frac{nt(\\bar{y}_{\\cdot\\cdot}-\\mu)^2}{\\sigma_\\varepsilon^2+n\\sigma_u^2}+\\frac{SSE}{\\sigma_\\varepsilon^2}+\\frac{SSU}{\\sigma_\\varepsilon^2+n\\sigma_u^2} \\\\ =&amp;\\left[\\frac{nt(\\bar{y}_{\\cdot\\cdot}-\\mu)^2}{\\sigma_\\varepsilon^2+n\\sigma_u^2}+\\log_{\\mathrm{e}}(2\\pi)+\\log_{\\mathrm{e}}(\\sigma_\\varepsilon^2+n\\sigma_u^2)\\right] \\\\ &amp;+\\left[(tn-1)\\log_{\\mathrm{e}}(2\\pi)+t(n-1)\\log_e(\\sigma_e^2)+(t-1)\\log_{\\mathrm{e}}(\\sigma_\\varepsilon^2+n\\sigma_u^2)+\\frac{SSE}{\\sigma_\\varepsilon^2}+\\frac{SSU}{\\sigma_\\varepsilon^2+n\\sigma_u^2}\\right] \\\\ =&amp;\\,\\ell(\\mu,\\sigma_u^2,\\sigma_\\varepsilon^2\\mid\\bar{y}_{\\cdot\\cdot})+\\ell(\\sigma_u^2,\\sigma_\\varepsilon^2\\mid SSE,SSU) \\end{aligned}\\]  \\(\\ell(\\sigma_u^2,\\sigma_\\varepsilon^2|SSE,SSU)\\) \\[\\begin{aligned} \\ell(\\sigma_u^2,\\sigma_\\varepsilon^2|SSE,SSU) =&amp;\\left[(tn-1)\\log_{\\mathrm{e}}(2\\pi)+t(n-1)\\log_{\\mathrm{e}}(\\sigma_{\\varepsilon}^2)\\right. \\\\ &amp;\\left.+(t-1)\\log_{\\mathrm{e}}(\\sigma_\\varepsilon^2+n\\sigma_u^2)+\\frac{SSE}{\\sigma_\\varepsilon^2}+\\frac{SSU}{\\sigma_\\varepsilon^2+n\\sigma_u^2}\\right] \\end{aligned}\\]  \\(\\sigma^2_u,\\sigma^2_\\varepsilon\\)  \\(\\ell(\\sigma_u^2,\\sigma_\\varepsilon^2|SSE,SSU)\\)  \\[\\begin{aligned}\\frac{\\partial\\ell({\\sigma}_u^2,{\\sigma}_\\varepsilon^2|SSE,SS{U})}{\\partial{\\sigma}_\\varepsilon^2}&amp;=\\frac{t(n-1)}{{\\tilde{\\sigma}}_\\varepsilon^2}+\\frac{t-1}{{\\tilde{\\sigma}}_\\varepsilon^2+n{\\tilde{\\sigma}}_u^2}-\\frac{SS{E}}{({\\tilde{\\sigma}}_\\varepsilon^2)^2}-\\frac{SS{U}}{({\\tilde{\\sigma}}_\\varepsilon^2+n{\\tilde{\\sigma}}_u^2)^2}=0\\\\\\frac{\\partial\\ell({\\sigma}_u^2,{\\sigma}_\\varepsilon^2|{SSE},{SSU})}{\\partial{\\sigma}_u^2}&amp;=\\frac{n(t-1)}{{\\tilde{\\sigma}}_\\varepsilon^2+n{\\tilde{\\sigma}}_u^2}-\\frac{nSS{U}}{\\left({\\tilde{\\sigma}}_\\varepsilon^2+n{\\tilde{\\sigma}}_u^2\\right)^2}=0\\end{aligned}\\]  \\[\\tilde{\\sigma}_\\varepsilon^2=\\frac{SSE}{t(n-1)}=MSError,\\quad\\mathrm{and}\\quad\\tilde{\\sigma}_u^2=\\frac1n{\\left[\\frac{SSU}{t-1}-MSError\\right]}=\\frac1n[MSU-MSError]\\]  \\[\\hat{\\sigma}_\\varepsilon^2=\\tilde{\\sigma}_\\varepsilon^2=\\frac{SSE}{t(n-1)}=MSError\\]  \\[\\hat{\\sigma}_u^2=\\begin{cases}\\tilde{\\sigma}_u^2&amp;\\mathrm{~if~}\\tilde{\\sigma}_u^2\\geq0\\\\0&amp;\\mathrm{~if~}\\tilde{\\sigma}_u^2&lt;0&amp;\\end{cases}\\]  \\({\\sigma}_u^2\\)  SSE  SSU  \\({\\sigma}_\\varepsilon^2\\)  \\[\\hat{\\sigma}_\\varepsilon^2=\\frac{SSE+SSU}{tn-1}\\]  19.5  19.6  19.2  19.3  REML  SAS-Mixed   19.5: Proc Mixed  19.2  x  19.6: Proc Mixed  19.3  x 19.4 MIVQUE  Rao (1971)  (minimum variance quadratic unbiased estimators, MIVQUE)  18.2  \\[\\theta=C_0\\sigma_\\varepsilon^2+C_1\\sigma_1^2+C_2\\sigma_2^2+\\cdots+C_k\\sigma_k^2\\]  MIVQUE  \\(\\theta\\)  \\(\\theta\\)  MIVQUE  \\(C_0=1,C_1=C_2=\\cdots=C_k=0\\)  \\(\\theta=\\sigma^2_\\varepsilon\\). \\(C_i\\)  \\(\\theta=\\sigma^2_i\\)  19.4.1  \\(\\theta\\)  \\(\\boldsymbol y\\)  \\(\\boldsymbol A\\)\\(\\theta\\)  \\(\\boldsymbol y^\\prime\\boldsymbol A\\boldsymbol y\\). \\(\\boldsymbol y^\\prime\\boldsymbol A\\boldsymbol y\\)  \\[E(\\boldsymbol y^{\\prime}\\boldsymbol A\\boldsymbol y)=\\mathrm{tr}(\\boldsymbol{\\Sigma}\\boldsymbol A)+\\mu^2\\boldsymbol{j}_n^{\\prime}\\boldsymbol A\\boldsymbol{j}_n\\] \\(E(\\boldsymbol y^{\\prime}\\boldsymbol A\\boldsymbol y)=\\theta\\) \\(\\mu\\) \\(\\boldsymbol A\\)  \\(\\mu^2\\boldsymbol{j}_n^{\\prime}\\boldsymbol A\\boldsymbol{j}_n=0\\).  \\(\\mu^2\\boldsymbol{j}_n^{\\prime}\\boldsymbol A\\boldsymbol{j}_n=0\\) \\(\\boldsymbol y^{\\prime}\\boldsymbol A\\boldsymbol y\\)  \\[\\mathrm{Var}(\\boldsymbol{y}^{\\prime}A\\boldsymbol{y})=2\\mathrm{~tr}[\\boldsymbol{\\Sigma}A]^2\\] \\(\\theta\\)  MIVQUE  \\(\\boldsymbol y^{\\prime}\\boldsymbol A\\boldsymbol y\\) $ A$  $[A]=$  \\(\\operatorname{tr}[\\boldsymbol{\\Sigma}\\boldsymbol A]^2\\)  \\[\\{0&lt;\\sigma_\\varepsilon^2&lt;\\infty,\\quad0&lt;\\sigma_1^2&lt;\\infty,\\quad0&lt;\\sigma_2^2&lt;\\infty,\\ldots,0&lt;\\sigma_k^2&lt;\\infty\\}\\] Rao (1971) \\(\\boldsymbol \\sigma^2=[\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2]&#39;\\)  MIVQUE  \\(\\hat{\\boldsymbol \\sigma}^2=\\boldsymbol S^{-1}\\boldsymbol f\\) \\(\\boldsymbol S\\)  (k+1) × (k+1)  \\[s_{ii^{\\prime}}=\\mathrm{tr}[\\boldsymbol X_i\\boldsymbol X_i^{\\prime}\\boldsymbol R\\boldsymbol X_{i^{\\prime}}\\boldsymbol X_{i^{\\prime}}]\\quad i,i^{\\prime}=0,1,2,\\ldots,k\\] \\(\\boldsymbol f\\)  (k+1) × 1  \\[\\boldsymbol f_i=\\boldsymbol y^{\\prime}\\boldsymbol R\\boldsymbol X_i\\boldsymbol X_i^{\\prime}\\boldsymbol R\\boldsymbol y,\\quad i=0,1,2,\\ldots,k\\]  \\[\\boldsymbol R=\\boldsymbol\\Sigma^{-1}[\\boldsymbol I_n-\\boldsymbol j_n(\\boldsymbol j_n^{\\prime}\\boldsymbol\\Sigma^{-1}\\boldsymbol j_n)^{-1}\\boldsymbol j_n^{\\prime}]\\boldsymbol \\Sigma^{-1}\\] \\(\\hat\\sigma^2\\)  \\(\\boldsymbol \\Sigma\\)  \\(\\sigma^2\\)  MIVQUE \\(\\boldsymbol \\Sigma\\)  \\(\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2\\) \\(\\sigma^2\\)  MIVQUE \\(\\boldsymbol y\\)  \\(\\hat\\sigma^2\\)  \\(\\sigma^2\\)  MIVQUE\\(\\boldsymbol R\\)  1  0   \\(\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2\\)  \\(\\boldsymbol \\Sigma\\).  \\(\\sigma^2\\)  (zero iterations)  MIVQUE0  0 Swallow and Monahan (1984)  MIVQUE-A  (Brown, 1976) \\(\\sigma_{\\varepsilon0}^2,\\sigma_{10}^2,\\sigma_{20}^2,\\ldots,\\sigma_{k0})^2\\)  \\(\\boldsymbol \\Sigma\\) \\(\\hat\\sigma^2_{(0)}\\)\\(\\hat\\sigma^2_{(0)}\\)  \\(\\sigma^2_{(0)}\\)  \\(\\hat\\sigma^2_{(0)}\\)  \\(\\boldsymbol \\Sigma\\) \\(\\hat\\sigma^2_{(1)}\\).  \\(\\boldsymbol \\Sigma\\)  \\(\\boldsymbol y\\)  MIVQUE  \\(\\boldsymbol y\\)  \\(\\hat\\sigma^2_{i}\\)  m+1  \\(\\hat\\sigma^2_{(m)}\\)  MIVQUE. Swallow and Searle (1978) /Swallow and Searle (1978) REML, ML  MIVQUE0  MIVQUE  \\(\\sigma_i^2\\)  \\(\\boldsymbol y\\)  \\(\\boldsymbol y^{\\prime}\\boldsymbol A\\boldsymbol y\\)  \\(2\\, \\text{tr}(\\boldsymbol B\\boldsymbol \\Sigma)^2\\). Swallow and Searle (1978)  MIVQUE MIVQUE  \\(\\sigma_u^2\\)  \\(\\sigma^2_\\varepsilon\\)  \\(\\sigma^2_\\varepsilon\\)  MIVQUE  MIVQUE  4. \\(n_i\\) \\(\\sigma^2_u\\)  MIVQUE  10%. \\(\\sigma^2_u\\)  MIVQUE  60%.  \\(\\sigma^2_u\\)  \\(\\sigma^2_\\varepsilon\\) SAS-Mixed  MIVQUE0  MIVQUE   MIVQUE  19.4.2  19.6MIVQUE  Swallow and Searle (1978)  19.2  \\[y_{ij}=\\mu+u_i+\\varepsilon_{ij}\\quad i=1,2,\\ldots,t\\mathrm{~and~}j=1,2,\\ldots,n_i\\]  \\(\\boldsymbol{u}\\thicksim{N}(0,\\sigma_u^2\\boldsymbol{I}_t),\\boldsymbol{\\varepsilon}\\thicksim{N}(0,\\sigma_\\varepsilon^2\\boldsymbol{I}_N)\\)  \\(\\boldsymbol{u},\\boldsymbol{\\varepsilon}\\) \\(N=\\sum_{i=1}^tn_i\\).  \\[k_i=\\frac{n_i}{\\sigma_{\\varepsilon0}^2+n_i\\sigma_{u0}^2}\\quad\\mathrm{and}\\quad K=\\frac1{\\sum_{i=1}^tk_i}\\]  \\(\\boldsymbol \\Sigma\\)  \\[\\begin{aligned} S_{11}&amp; =\\sum_{i=1}^tk_i^2-2K\\sum_{i=1}^tk_i^3+K^2\\left(\\sum_{i=1}^tk_i^2\\right)^2 \\\\ S_{12}&amp; =\\sum_{i=1}^t\\frac{k_i^2}{n_i}-2K\\sum_{i=1}^t\\frac{k_i^3}{n_i}+K^2\\biggl(\\sum_{i=1}^tk_i^2\\biggr)\\biggl(\\sum_{i=1}^t\\frac{k_i^2}{n_i}\\biggr) \\\\ S_{22}&amp; =\\frac{N-t}{\\sigma_{\\varepsilon0}^4}+\\sum_{i=1}^t\\frac{k_i^2}{n_i^2}-2K\\sum_{i=1}^t\\frac{k_i^3}{n_i^2}+K^2\\left(\\sum_{i=1}^t\\frac{k_i^2}{n_i}\\right)^2 \\end{aligned}\\]  \\(\\boldsymbol f\\)  \\[\\begin{aligned}f_1&amp;=\\sum_{i=1}^tk_i^2\\bigg(\\bar{y}_i-K\\sum_{i=1}^tk_i\\bar{y}_{i\\cdot}\\bigg)^2\\\\f_2&amp;=\\frac{\\sum_{i=1}^t\\sum_{j=1}^{n_i}y_{ij}^2-\\sum_{i=1}^tn_i\\bar{y}_{i\\cdot}^2}{\\sigma_{\\epsilon0}^4}+\\sum_{i=1}^t\\frac{k_i^2\\left(\\bar{y}_{i\\cdot}-K\\sum_{i=1}^tk_i\\bar{y}_{i\\cdot}\\right)^2}{n_i}\\end{aligned}\\]  \\(\\sigma^2_{u0}\\)  \\(\\sigma^2_{\\varepsilon0}\\) \\(\\sigma^2_{u}\\)  \\(\\sigma^2_{\\varepsilon}\\)  MIVQUE  \\(\\hat{\\sigma}^2=\\boldsymbol S^{-1}\\boldsymbol f\\) \\[\\begin{aligned}\\hat{\\sigma}_\\varepsilon^2&amp;=\\frac{s_{11}f_2-s_{12}f_1}c\\\\\\hat{\\sigma}_u^2&amp;=\\frac{s_{22}f_1-s_{12}f_2}c\\end{aligned}\\]  \\(c=s_{11}s_{22}-s_{12}^2\\).  19.1  MIVQUE  19.7  19.2  MIVQUE  19.8  SAS Mixed  \\[\\mathrm{Var}(\\hat{\\sigma}_\\varepsilon^2)=\\frac{2s_{11}}c,\\quad\\mathrm{Var}(\\hat{\\sigma}_u^2)=\\frac{2s_{2}}c,\\quad\\mathrm{and}\\quad\\mathrm{Cov}(\\hat{\\sigma}_\\varepsilon^2,\\hat{\\sigma}_u^2)=\\frac{-2s_{12}}c\\]  19.7: Proc Mixed  19.2  MIVQUE0  x  19.8: Proc Mixed  19.3  MIVQUE0  x  \\(\\sigma^2_{u0}\\)  \\(\\sigma^2_{\\varepsilon0}\\)  \\(\\sigma^2_{u0}\\)  \\(\\sigma^2_{\\varepsilon0}\\)  19.9  19.1  MIVQUE0  \\(\\sigma^2_{u0}\\)  \\(\\sigma^2_{\\varepsilon0}\\)  \\(\\hat\\sigma^2_{u}\\)  \\(\\hat\\sigma^2_{\\varepsilon}\\)  \\(\\hat{\\sigma}_\\varepsilon^2=0.057003\\)  \\(\\hat{\\sigma}_u^2=0.073155\\) \\(\\mathrm{Var}(\\hat{\\sigma}_\\varepsilon^2)=0.000721,\\mathrm{Var}(\\hat{\\sigma}_u^2)=0.005694\\)  \\(\\mathrm{cov}(\\hat{\\sigma}_\\varepsilon^2,\\hat{\\sigma}_u^2)=-0.000235\\). \\(\\sigma^2_{u0}=2,\\sigma^2_{\\varepsilon0}=1\\)  \\(\\sigma^2_{u0}=50,\\sigma^2_{\\varepsilon0}=1000\\)   19.9:  19.2  MIVQUE0  x 19.5  JMP   JMP  (SAS Institute, Inc., 2005)  fit model  19.1  19.2  JMP  SAS  Analyze  fit model 19.2  fit model  Damage  Y  variety  attributes  variety  REML EMS  III  run model  19.3  19.5  SAS  Wald  Satterthwaite  variety  20   19.1:  19.2  JMP   19.2:  19.2  JMP fit model   19.3:  19.2  JMP REML   19.4  19.3  JMP fit model  19.5  row, col  row × col  REML  REML  19.6  19.6  SAS fit model  unbounded variance components  SAS Mixed  unbounded  19.7  unbounded variance components  19.8 row  col Wald JMP fit model SAS Mixed  19.4:  19.3  JMP   19.5:  19.3 REML  JMP fit model   19.6:  19.3  JMP REML   19.7:  19.3  unbounded variance components JMP fit model   19.8:  19.3  JMP REML  19.6   MIVQUE REML, MIVQUE0   SAS-MIXED  JMP  19.7   the type III solutions are  \\(\\boldsymbol A, \\boldsymbol B\\)  m × n  p × q  \\(\\boldsymbol A \\otimes \\boldsymbol B=\\begin{bmatrix}a_{11}\\boldsymbol B&amp;\\cdots&amp;a_{1n}\\boldsymbol B\\\\\\vdots&amp;\\ddots&amp;\\vdots\\\\a_{m1}\\boldsymbol B&amp;\\cdots&amp;a_{mn}\\boldsymbol B\\end{bmatrix}\\). Knronecker  \\(\\otimes\\)  "],["chap20.html", " 20   20.1  20.2  20.3  20.4  20.5 ", "  20   God not only plays dice. He also sometimes throws the dice where they cannot be seen. - Stephen William Hawking  \\(\\sigma_u^2\\)  A  \\(\\sigma_u^2&gt;0\\) 1 \\(H_0{:}\\sigma_u^2=0\\mathrm{~vs~}{H_a}{:}\\sigma_u^2&gt;0\\)2 \\(\\sigma_u^2\\)  3 \\(\\sigma_u^2\\)  20.1  20.2  Burdick and Graybill (1992)  20.1   \\(F\\) \\(F\\)  \\(F\\)  \\(F\\)  (likelihood rato test)\\(F\\)  20.1.1  29 \\(Q\\)  v  \\[E(Q/v)=\\sigma_\\varepsilon^2+k_1\\sigma_1^2+k_2\\sigma_2^2+k_3\\sigma_3^2\\]  \\[W=\\frac Q{\\sigma_\\varepsilon^2+k_1\\sigma_1^2+k_2\\sigma_2^2+k_3\\sigma_3^2}\\]  n  \\(H_0{:}\\sigma_1^2=0\\mathrm{~vs~}{H_a}{:}\\sigma_1^2&gt;0\\)  \\(Q_1\\)  \\(Q_2\\)  v1  v2  \\[\\begin{aligned}E(Q_1/n_1)&amp;=\\sigma_\\varepsilon^2+k_1\\sigma_1^2+k_2\\sigma_2^2+k_3\\sigma_3^2\\\\E(Q_2/n_2)&amp;=\\sigma_\\varepsilon^2+k_2\\sigma_2^2+k_3\\sigma_3^2\\end{aligned}\\]  \\(H_0{:}\\sigma_1^2=0\\mathrm{~vs~}{H_a}{:}\\sigma_1^2&gt;0\\)  \\[\\begin{aligned}H_0\\colon E\\left(Q_1/v_1\\right)&amp;=E(Q_2/v_2)\\text{ vs }H_a\\colon E(Q_1/v_1)&gt;E(Q_2/v_2)\\end{aligned}\\]  \\(F = (Q_1/v_1)/(Q_2/v_2)\\) \\(H_0\\)  v1  v2  \\(F\\)  \\(F\\)  20.1.2  20.1  \\[y_{ijk}=\\mu+a_i+b_j+c_{ij}+\\varepsilon_{ijk}\\quad\\mathrm{~for~}i=1,2,\\ldots,a,j=1,2,\\ldots,b,\\mathrm{~and~}k=1,2,\\ldots,n\\]  \\(a_i\\thicksim i.i.d.\\,N(0,\\sigma_a^2),b_j\\thicksim i.i.d.\\,N(0,\\sigma_b^2),c_{ij}\\thicksim i.i.d.\\,N(0,\\sigma_c^2),\\varepsilon_{ijk}\\thicksim i.i.d.\\,N(0,\\sigma_\\varepsilon^2)\\) \\(a_i,b_j,c_{ij},\\varepsilon_{ijk}\\)   20.1  \\(H_0{:}\\sigma_a^2=0\\mathrm{~vs~}{H_u}{:}\\sigma_a^2&gt;0\\)  \\(MSA\\)  \\(\\sigma_a^2=0\\)  \\(H_0\\)  \\(MSA\\)  \\(H_0{:}\\sigma_a^2=0\\mathrm{~vs~}{H_u}{:}\\sigma_a^2&gt;0\\) \\(MSAB\\) \\(H_0{:}\\sigma_b^2=0\\mathrm{~vs~}{H_u}{:}\\sigma_b^2&gt;0\\) \\(MSAB\\) \\(H_0{:}\\sigma_c^2=0\\mathrm{~vs~}{H_u}{:}\\sigma_c^2&gt;0\\) \\(MSResidual\\).  \\(H_0{:}\\sigma_a^2=0\\mathrm{~vs~}{H_u}{:}\\sigma_a^2&gt;0\\)  \\(F = MSA/MSAB&gt;F_{\\alpha,(a-1),(a-1)(b-1)}\\) \\(\\alpha\\)  I  \\(\\sigma_b^2\\)  \\(\\sigma_c^2\\)  20.1  \\(F\\)   20.1:  20.1  x 20.1.3  20.2  20.2:  20.2  x  20.2 A  B C  B  20.2  \\[\\begin{aligned}&amp;y_{ijkm}=\\mu+a_i+b_j+(ab)_{ij}+c_{k(j)}+(ac)_{ik(j)}+\\varepsilon_{ijkm}\\\\&amp;\\mathrm{for~}i=1,2,\\ldots,a,j=1,2,\\ldots,b,k=1,2,\\ldots,c,\\mathrm{~and~}m=1,2,\\ldots,n\\end{aligned}\\]  \\(\\mu\\) \\(a_i\\)  A  i \\(b_j\\)  B  j \\((ab)_{ij}\\)  A  B \\(c_{k(j)}\\)  B  j  C  k \\((ac)_{ik(j)}\\)  A  B  C  \\(\\varepsilon_{ijkm}\\) \\(a_i\\thicksim i.i.d.~N(0,\\sigma_a^2),~b_j\\thicksim i.i.d.~N(0,~\\sigma_b^2),~(ab)_{ij}\\thicksim i.i.d.~N(0,~\\sigma_{ab}^2),~(ac)_{ik(j)}\\thicksim i.i.d.~N(0,~\\sigma_{ac(b)}^2)\\)  \\(\\varepsilon_{ijkm}\\thicksim i.i.d.~N(0,~\\sigma_{\\varepsilon}^2)\\).  \\(a_i,b_j,(ab)_{ij},c_{k(j)},(ac)_{ik(j)}\\)  \\(\\varepsilon_{ijkm}\\)  20.3   20.3:  20.2  x  \\(F\\)   \\(H_0\\colon{\\sigma}_a^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_a^2&gt;0\\) \\(F_a=MSA/MSAB\\).  \\(H_0\\colon{\\sigma}_{ab}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{ab}^2&gt;0\\) \\(F_{ab}=MSAB/MSAC(B)\\).  \\(H_0\\colon{\\sigma}_{c(b)}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{c(b)}^2&gt;0\\) \\(F_{c(b)}=MSC(B)/MSAC(B)\\).  \\(H_0\\colon{\\sigma}_{ac(b)}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{ac(b)}^2&gt;0\\) \\(F_{ac(b)}=MSAC(B)/MSResidual\\).  \\(F\\)  \\(H_0\\colon{\\sigma}_b^2=0\\mathrm{~vs~}H_b\\colon{\\sigma}_a^2&gt;0\\) \\(\\sigma^2_b\\)  \\(\\sigma_\\varepsilon^2+n\\sigma_{ac(b)}^2+na\\sigma_{c(b)}^2+nc\\sigma_{ab}^2\\) \\(\\sigma^2_b=0\\)  \\(MSB\\)  \\(MSB\\)\\(E[MSC(B)+MSAB-MSAC(B)]=\\sigma_\\varepsilon^2+n\\sigma_{ac(b)}^2+na\\sigma_{c(b)}^2+nc\\sigma_{ab}^2\\).  \\(Q=MSC(B)+MSAB-MSAC(B)\\) \\(H_0\\colon{\\sigma}_b^2=0\\mathrm{~vs~}H_b\\colon{\\sigma}_a^2&gt;0\\)  \\(F_b=MSB/Q\\). \\(F_b\\)  b-1  r  \\(F\\)  r  2  Satterthwaite (1946)  \\(rQ/E(Q)\\) Satterthwaite  \\(Q = q_1MS_1 + q_2MS_2 + \\cdots + q_kMS_k\\)  \\(MS_i\\)  \\(f_i\\) \\(q_i\\)  \\(rQ/E(Q)\\)  r  \\[r=\\frac{(Q)^2}{\\sum_{i=1}^k\\frac{\\left(q_iMS_i\\right)^2}{f_i}}\\]  \\(U\\)  f  \\(MS_1,MS_2,\\cdots,MS_k\\) \\(E(U) = E(Q) + k_0\\sigma^2_0\\).  \\(H_0\\colon{\\sigma}_0^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_0^2&gt;0\\)  \\(F = U/Q\\) f  r  \\(F\\)   \\(H_0\\colon{\\sigma}_b^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_b^2&gt;0\\)  \\(F_b = MSB/Q\\) b-1  r  \\(F\\)  \\[r=\\frac{(Q)^2}{\\frac{[MSC(B)]^2}{b(c-1)}+\\frac{[MSAB]^2}{(a-1)(b-1)}+\\frac{[MSAC(B)]^2}{b(a-1)(c-1)}}\\]  20.4:  20.2  I  Proc Mixed  x  20.4  20.3  \\(F\\)  \\(H_0\\colon{\\sigma}_b^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_b^2&gt;0\\) \\[\\begin{aligned} Q&amp; =MSC(B)+MSAB-MSAC(B) \\\\ &amp;=12.0625+10.5625-0.8125=21.8125 \\end{aligned}\\] \\(Q\\)  \\[\\begin{aligned} r&amp; =\\frac{(21.8125)^2}{(12.0625)^2/2+(10.5625)^2/1+(0.8125)^2/2} \\\\ &amp;=\\frac{475.7852}{184.9785}=2.57 \\end{aligned}\\]  \\(F = 770.0625/21.8125 = 35.304\\)  1  2.57  0.0144 \\({\\sigma}_b^2 &gt; 0\\) B   \\(F\\) Satterthwaite   Satterthwaite  \\({\\sigma}_{{\\varepsilon}}^2+{k}_0{\\sigma}_0^2\\)  \\(U\\) \\(F_0 = U/MSResidual\\)  \\(H_0\\colon{\\sigma}_0^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_0^2&gt;0\\)  \\(H_0\\) \\(F\\)  u  v  \\(F\\)  u  \\(U\\) v  \\(MSResidual\\)   \\(F\\)  \\(F\\)  \\(F\\)  \\(F\\)   \\(H_0\\colon{\\sigma}_0^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_0^2&gt;0\\) \\(U_1\\) \\[E(U_1)=\\sigma_\\varepsilon^2+k_{1a}\\sigma_a^2+k_{1b}\\sigma_b^2+k_{1c}\\sigma_c^2\\]  \\(\\sigma_\\varepsilon^2+k_{1b}\\sigma_b^2+k_{1c}\\sigma_c^2\\) \\(Q=\\sum_{i=1}^kq_iMS_i\\)  \\(E(Q)=\\sigma_\\varepsilon^2+k_{1b}\\sigma_b^2+k_{1c}\\sigma_c^2\\). Satterthwaite  \\(Q\\)  r \\(rQ/E(Q)\\)  r  1) 2)  \\(Q\\)  SAS®-Mixed  III  19.2  20.5 variaty  \\(\\sigma_\\varepsilon^2+3.1795\\sigma_\\mathrm{var}^2\\).  \\(H_0\\colon\\sigma_{\\text{var}}^2=0\\text{ vs }H_a\\colon\\sigma_{\\text{var}}^2&gt;0\\) \\(F\\)  4.79.  \\(F\\)  3  9  \\(F\\)  0.0293.  I  III   20.5:  19.2  \\(F\\)  x  20.6:  19.3  I  \\(F\\)  x  20.6  19.3  I  SAS-Mixed  \\(H_0\\colon{\\sigma}_{\\mathrm{row}\\times\\mathrm{col}}^2=0\\text{ vs }H_a\\colon{\\sigma}_{\\mathrm{row}\\times\\mathrm{col}}^2&gt;0\\) \\(F\\)  14.24.  \\(F\\)  2  8  \\(F\\)  0.0023.  \\(H_0\\colon{\\sigma^2}_{\\text{row}}=0\\text{ vs }H_a\\colon{\\sigma^2}_{\\text{row}}&gt;0\\)  \\(H_0\\colon{\\sigma^2}_{\\text{col}}=0\\text{ vs }H_a\\colon{\\sigma^2}_{\\text{col}}&gt;0\\) \\(H_0\\colon{\\sigma^2}_{\\text{row}}=0\\text{ vs }H_a\\colon{\\sigma^2}_{\\text{row}}&gt;0\\)  \\(MS_{\\text{Row}}\\)  \\[\\begin{aligned} Q_{row} =&amp;\\,\\frac{0.1429}{4.5714}MSCol+\\frac1{2.2588}{\\left[2.4286-\\frac{0.1429}{4.5714}\\times2.3126\\right]}MSRow\\times Col \\\\ &amp;+\\left[1-\\frac{0.1429}{4.5714}-\\frac1{2.2588}{\\left(2.4286-\\frac{0.1429}{4.5714}\\times2.3126\\right)}\\right]MSResidual \\\\ =&amp;\\,0.0313\\times MSCol+1.0432 \\,MSRow\\times Col-0.0744\\,MSResidual\\\\ =&amp;\\,55.7806 \\end{aligned}\\]  \\(Q_{\\mathrm{row}}\\)  Satterthwaite  \\[\\begin{aligned}df_{Q_{\\mathrm{row}}}&amp;=\\frac{(Q_{\\mathrm{row}})^2}{\\frac{(0.0313\\times MSCol)^2}2+\\frac{(1.0432\\times MSRow\\times Col)^2}2+\\frac{(0.0744\\times MSResidual)^2}8}\\\\&amp;=1.9961\\end{aligned}\\]  \\(F\\)  \\(F_{\\mathrm{row}}=MSRow/Q_{\\mathrm{row}}=0.0113\\) 0.9251.  \\(H_0\\colon{\\sigma^2}_{\\text{col}}=0\\text{ vs }H_a\\colon{\\sigma^2}_{\\text{col}}&gt;0\\)  \\(MSCol\\)  \\[\\begin{aligned} Q_{\\text{col}}&amp; =\\frac{2.3126}{2.2588}MSRow\\times Col+\\left[1-\\frac{2.3126}{2.2588}\\right]MSResidual \\\\ &amp;=1.0238\\,MSRow\\times Col-0.0238\\,MSResidual \\\\ &amp;=56.8729 \\end{aligned}\\]  \\(Q_{\\mathrm{col}}\\)  Satterthwaite  \\[\\begin{aligned}df_{Q_{\\mathrm{col}}}&amp;=\\frac{(Q_{\\mathrm{col}})^2}{\\frac{(1.0238\\times MSRow\\times Col)^2}2+\\frac{(0.0238\\times MSResidual)^2}8}\\\\&amp;=1.9935\\end{aligned}\\]  \\(F\\)  \\(F_{\\mathrm{col}}=MSCol/Q_{\\mathrm{col}}=0.1323\\) 0.8832. 20.1.4   \\(H_0\\)   (18.3)  \\[\\boldsymbol y=\\boldsymbol j_n\\mu+\\boldsymbol Z_1 \\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_k\\boldsymbol u_k+\\boldsymbol\\varepsilon \\]  \\(\\boldsymbol{u}_1\\thicksim N(0,{\\sigma}_1^2\\boldsymbol{I}_{t_1}),\\boldsymbol{u}_2\\thicksim N(0,{\\sigma}_2^2\\boldsymbol{I}_{t_2}),...,\\boldsymbol{u}_r\\thicksim N(0,{\\sigma}_r^2\\boldsymbol{I}_{t_r}),{\\varepsilon}\\thicksim N(0,{\\sigma}_\\varepsilon^2\\boldsymbol{I}_N)\\)  \\(\\boldsymbol y\\)  \\(N(\\boldsymbol j_n\\mu,\\boldsymbol \\Sigma)\\)  \\(\\boldsymbol \\Sigma=\\sigma_\\varepsilon^2\\boldsymbol I_n+\\sigma_1^2\\boldsymbol Z_1\\boldsymbol Z_1^{\\prime}+\\sigma_2^2\\boldsymbol Z_2\\boldsymbol Z_2^{\\prime}+\\cdots+\\sigma_k^2\\boldsymbol Z_k\\boldsymbol Z_k^{\\prime}\\).  \\[L(\\mu,\\sigma_\\varepsilon^2,\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)=(2\\pi)^{-n/2}|\\boldsymbol \\Sigma|^{-1/2}\\exp\\left[-\\frac12(\\boldsymbol y-\\boldsymbol j_n\\mu)^{\\prime}\\boldsymbol\\Sigma^{-1}(\\boldsymbol y-\\boldsymbol j_n\\mu)\\right]\\] \\(H_0{:{\\sigma_1^2}}=0\\)  \\[L_0(\\mu,\\sigma_\\varepsilon^2,0,\\sigma_2^2,\\ldots,\\sigma_k^2|\\boldsymbol y)=(2\\pi)^{-n/2}\\left|\\boldsymbol \\Sigma_0\\right|^{-1/2}\\exp\\left[-\\frac12(\\boldsymbol y-\\boldsymbol j_n\\mu)^{\\prime}\\boldsymbol \\Sigma_0^{-1}(\\boldsymbol y-\\boldsymbol j_n\\mu)\\right]\\]  \\(\\boldsymbol \\Sigma_0=\\sigma_\\varepsilon^2\\boldsymbol I_n+\\sigma_2^2\\boldsymbol Z_2\\boldsymbol Z_2^{\\prime}+\\sigma_3^2\\boldsymbol Z_3\\boldsymbol Z_3^{\\prime}+\\cdots+\\sigma_k^2\\boldsymbol Z_k\\boldsymbol Z_k^{\\prime}\\).  \\[LR(\\sigma_1^2=0)=\\frac{L_0(\\hat{\\mu}_0,\\hat{\\sigma}_{\\varepsilon0}^2,0,\\hat{\\sigma}_{20}^2,\\hat{\\sigma}_{30}^2,\\ldots,\\hat{\\sigma}_{k0}^2|\\boldsymbol y)}{L(\\hat{\\mu},\\hat{\\sigma}_{\\varepsilon}^2,\\hat{\\sigma}_1^2,\\hat{\\sigma}_2^2,\\ldots,\\hat{\\sigma}_k^2|\\boldsymbol y)}\\]  \\(\\hat{\\sigma}_{i0}^2\\)  \\(H_0{:{\\sigma_1^2}}=0\\)  \\({\\sigma}_{i0}^2\\)  \\(H_0{:{\\sigma_1^2}}=0\\)  \\[\\begin{aligned}-2\\log[LR(\\sigma_1^2=0)]=&amp;-2\\log_{\\mathrm{e}}[L_0(\\hat{\\mu}_0,\\hat{\\sigma}_{\\varepsilon0}^2,0,\\hat{\\sigma}_{20}^2,\\hat{\\sigma}_{30}^2,\\ldots,\\hat{\\sigma}_{k0}^2| \\boldsymbol y)]\\\\&amp;+2\\log_{\\mathrm{e}}[L(\\hat{\\mu},\\hat{\\sigma}_{\\varepsilon}^2,\\hat{\\sigma}_1^2,\\hat{\\sigma}_2^2,\\ldots,\\hat{\\sigma}_k^2|\\boldsymbol y)]\\end{aligned}\\]  1  \\(L_0(·)\\)  \\(L_1(·)\\)  \\(-2\\log[LR(\\sigma_1^2=0)]&gt;\\chi_{\\alpha,1}^2\\) \\(H_0\\).  SAS-Mixed  METHOD = ML  20.1.5  20.3  20.7  SAS-Mixed  19.2  19.2  \\(\\hat{\\mu}=3.9909,\\hat{\\sigma}_\\varepsilon^2=0.05749\\)  \\(\\hat{\\sigma}_\\mathrm{var}^2=0.04855\\)  \\(-2\\log_{\\mathrm{e}}(\\hat{\\mu},\\hat{\\sigma}_{\\varepsilon^{}}^2,\\hat{\\sigma}_{\\mathrm{var}}^2|\\boldsymbol y)\\)  4.96762.  20.8  SAS-Mixed  20.7  Random Variety;. \\(H_0{:{\\sigma_1^2}}=0\\)  \\(\\hat{\\mu}=4.0269,\\hat{\\sigma}_\\varepsilon^2=0.1014\\)  \\(\\hat{\\sigma}_\\mathrm{var}^2=0\\)  \\(-2\\log_{\\mathrm{e}}(\\hat{\\mu},\\hat{\\sigma}_{\\varepsilon^{}}^2,\\hat{\\sigma}_{\\mathrm{var}}^2|\\boldsymbol y)\\)  7.13832.  \\(H_0\\)  -2loge  \\(7.13832 - 4.96762 = 2.1707\\).  2.171  0.1407 20.5  \\(F\\)  0.0293  \\(F\\)  \\(F\\)   20.7:  19.2  Method = ML  Proc Mixed  x  20.8:  19.2  Proc Mixed  Method = ML  \\(\\sigma^2_{\\text{var}} = 0\\)  x 20.1.6  20.4  19.3  \\(H_0\\) random  random  row × col  20.9  SAS-Mixed  20.9  SAS-Mixed  -2log(likelihood)  \\(H_0:\\sigma_{\\mathrm{~row\\times col}}^2=0\\mathrm{~vs~}H_a{:}\\sigma_{\\mathrm{~row\\times col}}^2&gt;0\\)  \\(73.4-68.7=4.7\\) \\(H_0\\)  0.030 \\(\\sigma_{\\mathrm{~row\\times col}}^2&gt;0\\).  random -2log(likelihood)   20.9:  x 20.2   20.2.1  \\(\\sigma^2_\\varepsilon\\) \\(\\sigma^2_\\varepsilon\\)  \\((1 - \\alpha)100\\%\\)  \\[\\frac{v\\hat{\\sigma}_\\varepsilon^2}{\\chi_{(\\alpha/2),v}^2}\\leq\\sigma_\\varepsilon^2\\leq\\frac{v\\hat{\\sigma}_\\varepsilon^2}{\\chi_{1-(\\alpha/2),v}^2}\\]  \\(\\hat{\\sigma}_\\varepsilon^2=\\text{SSRESIDUAL}/v\\)v  \\(\\hat{\\sigma}_\\varepsilon^2\\) \\(\\chi_{1-(\\alpha/2),v}^2,\\chi_{\\alpha/2,v}^2\\)  v  \\(\\alpha/2\\)  \\(\\alpha/2\\)  20.2.2  Satterthwaite   Satterthwaite  (general Satterthwaite approximation)  \\(r\\hat{{\\sigma}}_i^2/E(\\hat{{\\sigma}}_i^2)\\)  r  r  r.  \\(r\\hat{{\\sigma}}_i^2/E(\\hat{{\\sigma}}_i^2)\\)  r  r  r  2r.  \\(r\\hat{{\\sigma}}_i^2/E(\\hat{{\\sigma}}_i^2)\\)  r  \\[\\mathrm{Var}\\left(\\frac{r\\hat{\\sigma}_i^2}{E(\\hat{\\sigma}_i^2)}\\right)=2r\\quad\\mathrm{or}\\quad\\frac{r^2}{\\left[E(\\hat{\\sigma}_i^2)\\right]^2}\\mathrm{Var}(\\hat{\\sigma}_i^2)=2r\\]  \\[r=\\frac{2[\\operatorname{E}(\\hat{\\sigma}_i^2)]^2}{\\operatorname{Var}(\\hat{\\sigma}_i^2)}\\] r  \\(E(\\hat{\\sigma}_i^2)\\)  \\(\\hat{\\sigma}_i^2\\)  \\({\\operatorname{Var}(\\hat{\\sigma}_i^2)}\\)  REML  ML  (estimates of the variances of the estimated variance components). SAS-Mixed   20.10  covtest, cl  asycov  SAS-Mixed  Z  Satterthwaite  Lower  Upper 20.10  data step  Satterthwaite \\(\\hat{\\sigma}_{\\text{var}}^2\\)  \\(\\hat{\\sigma}_{\\varepsilon}^2\\)  1.758  8.828 SAS-Mixed   20.10: SAS-Mixed  Method = REML  Data Step  19.2  Satterthwaite  x  20.11  SAS-Mixed  20.1  REML  \\(df = 2(\\text{Z-value})^2\\)  0.50, 0.95, 0.84, 1.73, 0  8   20.11:  REML  Satterwaite  SAS-Mixed  x 20.2.3    (Kendall and Stuart, 1973)  Satterthwaite  \\(\\sigma\\) \\(\\text{Var}(\\sigma)\\)  \\({\\varphi}({\\sigma})\\) \\({\\varphi}({\\sigma})\\) \\({\\varphi}({\\sigma})\\)  \\({\\varphi}(\\hat{\\sigma})\\) \\(\\hat{\\sigma}\\)  \\(\\sigma\\)  \\(\\hat{{V}}(\\hat{{\\sigma}})\\) \\(\\text{Var}(\\sigma)\\)  \\({\\varphi}({\\sigma})\\)  \\(\\hat{\\sigma}\\)  \\({\\varphi}(\\hat{\\sigma})\\)  \\({\\sigma}_{{\\varphi}(\\hat{\\sigma})}^2=\\hat{\\boldsymbol{f}}^{\\prime}\\hat{\\boldsymbol{V}}(\\hat{{\\sigma}})\\hat{\\boldsymbol{f}}\\).  Satterthwaite  \\[r=\\frac{2[\\varphi(\\hat{\\sigma})]^2}{\\hat{\\sigma}_{\\varphi(\\hat{\\sigma})}^2}\\]  19.2  \\(\\varphi(\\sigma)=\\sigma^2_{\\text{var}}+\\sigma^2_{\\varepsilon}\\). \\(\\varphi(\\sigma)\\)  \\[\\boldsymbol f=\\begin{bmatrix}\\frac{\\partial\\varphi(\\sigma)}{\\partial\\sigma_\\mathrm{var}^2}\\\\\\frac{\\partial\\varphi(\\sigma)}{\\partial\\sigma_\\varepsilon^2}\\end{bmatrix}=\\begin{bmatrix}1\\\\1\\end{bmatrix}\\]  \\[\\hat{\\boldsymbol V}(\\hat{\\sigma})=\\begin{bmatrix}\\hat{\\sigma}_{\\hat{\\sigma}_{\\mathrm{var}}^2}^2&amp;\\hat{\\sigma}_{\\hat{\\sigma}_{\\mathrm{var}}^2,\\hat{\\sigma}_{\\hat{\\varepsilon}}^2}^2\\\\\\hat{\\sigma}_{\\hat{\\sigma}_{\\mathrm{var}}^2,\\hat{\\sigma}_{\\hat{\\varepsilon}}^2}^2&amp;\\hat{\\sigma}_{\\hat{\\sigma}_{\\hat{\\varepsilon}}^2}^2\\end{bmatrix}\\]  \\(\\varphi(\\hat{\\sigma})\\)  \\[\\hat{\\sigma}_{\\varphi(\\hat{\\sigma})}^2=\\hat{\\sigma}_{\\hat{\\sigma}_\\mathrm{var}^2}^2+\\hat{\\sigma}_{\\hat{\\sigma}_\\varepsilon^2}^2+2\\hat{\\sigma}_{\\hat{\\sigma}_\\mathrm{var}^2\\hat{\\sigma}_\\varepsilon^2}\\].  20.10  \\[\\varphi(\\hat{\\sigma})=0.07316+0.05700=0.13010\\]  \\[\\hat{\\sigma}_{\\varphi(\\hat{\\sigma})}^2=0.006087+0.000736-2(0.00031)=0.006203\\]  \\[r=\\frac{2(0.13010)^2}{0.006203}=5.46\\] \\(\\varphi(\\sigma)=\\sigma_{\\mathrm{var}}^2+\\sigma_{\\varepsilon}^2\\)  95%  \\[0.052287&lt;\\sigma_\\mathrm{var}^2+\\sigma_\\varepsilon^2&lt;0.70253\\]  \\[\\rho=\\frac{\\sigma_\\mathrm{var}^2}{\\sigma_\\varepsilon^2+\\sigma_\\mathrm{var}^2}\\]  \\[\\varphi(\\rho)=\\frac{\\sigma_\\mathrm{var}^2}{\\sigma_\\varepsilon^2+\\sigma_\\mathrm{var}^2}\\] \\(\\rho=\\frac{\\sigma_\\mathrm{var}^2}{\\sigma_\\varepsilon^2+\\sigma_\\mathrm{var}^2}\\)  \\[\\hat{\\boldsymbol f}^{\\prime}=\\left[\\frac{(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_\\mathrm{var}^2)-(\\hat{\\sigma}_\\mathrm{var}^2)}{(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_\\mathrm{var}^2)^2},\\frac{-(\\hat{\\sigma}_\\mathrm{var}^2)}{(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_\\mathrm{var}^2)^2}\\right]\\]  20.10  \\(\\hat\\rho = 0.5621\\) 0.2156 \\(r = 2.93\\).  (0.1785, 8.214) (0.1785, 1) 1.  20.2.3   Satterthwaite  (usual Satterthwaite approximation)  \\(\\hat{{\\sigma}}_s^2=\\sum_{i=1}^kc_{is}MS_i+c_{\\varepsilon s}MSResidual\\).  \\[r_s=\\frac{(\\hat{\\sigma}_s^2)^2}{\\sum_{i=1}^k\\frac{\\left(c_{is}MS_i\\right)^2}{df_{_{MS_i}}}+\\frac{\\left(c_{_{\\mathbf{\\varepsilon}s}}MSResidual\\right)^2}{df_{_{MSResidual}}}}\\] \\(\\sigma^2_s\\)  \\((1 - \\alpha)100\\%\\)  \\[\\frac{r_s\\hat{\\sigma}_s^2}{\\chi_{\\alpha/2,r_s}^2}\\leq\\sigma_s^2\\leq\\frac{r_s\\hat{\\sigma}_s^2}{\\chi_{1-(\\alpha/2),r_s}^2}\\]  SAS-Mixed  20.2  \\(\\sigma^2_a\\)  \\[\\hat{\\sigma}_a^2=\\frac18{\\left[MSA-MS(A\\times B)\\right]}=\\frac18(39.0625-10.5625)=3.5625\\]  \\[\\begin{aligned}r&amp;=\\frac{(3.5625)^2}{\\frac{[(1/8)39.0625]^2}1+\\frac{[(1/8)10.5625]^2}1}=0.305\\end{aligned}\\] \\(\\sigma^2_a\\)  (0.4226, 27556199203.09) (0.305)  20.2  \\(\\sigma^2_b\\)  \\[\\begin{aligned} \\hat{\\sigma}_b^2&amp; =\\frac18\\{MSB-[MS(A\\times B)+MS(C(B))-MS(A\\times C(B))]\\} \\\\ &amp;=\\frac18(770.0625-12.0625-10.5625+0.8125) \\\\ &amp;=93.5313 \\end{aligned}\\]  \\[\\begin{aligned}r&amp;=\\frac{(93.5313)^2}{\\frac{[(1/8)770.0625]^2}1+\\frac{[(1/8)12.0625]^2}2\\frac{[(1/8)10.5625]^2}{1}\\frac{[(1/8)0.8125]^2}2}\\\\ &amp;=0.944 \\end{aligned}\\] \\(\\sigma^2_b\\)  (18.1347, 141493.19) 20.2.4  Wald  Wald  \\(\\sigma^2_s\\)  \\((1 - \\alpha)100\\%\\) Wald  \\(\\hat{{\\sigma}}_s^2-Z_{\\alpha/2}\\sqrt{\\hat{\\sigma}_{\\hat{{\\sigma}}_s^2}^2}\\leq{\\sigma}_s^2\\leq\\hat{{\\sigma}}_s^2+Z_{\\alpha/2}\\sqrt{\\hat{\\sigma}_{\\hat{{\\sigma}}_s^2}^2}\\). Wald  \\(\\hat{{\\sigma}}_s^2\\) Wald Satterthwaite  SAS-Mixed  METHOD = TYPEx  Satterthwaite  Wald  20.2.5   \\(SSRESIDUAL\\) \\(\\sigma^2_1\\) \\(\\sigma_\\varepsilon^2+a\\sigma_1^2\\)  \\(1-\\alpha\\).  \\(Q_1=MSRESIDUAL\\)  u1  \\(Q_2\\)  u2  \\(\\sigma_\\varepsilon^2+a\\sigma_1^2\\).  \\(\\sigma_\\varepsilon^2\\)  \\(\\sigma_\\varepsilon^2+a\\sigma_1^2\\)  \\((1 - \\alpha)100\\%\\)  \\[\\begin{aligned}&amp;\\frac{u_1Q_1}{\\chi_{\\rho/2,u_1}^2}\\leq\\sigma_\\varepsilon^2\\leq\\frac{u_1Q_1}{\\chi_{1-(\\rho/2),u_1}^2}\\\\&amp;\\frac{u_2Q_2}{\\chi_{\\rho/2,u_2}^2}\\leq\\sigma_\\varepsilon^2+a\\sigma_1^2\\leq\\frac{u_2Q_2}{\\chi_{1-(\\rho/2),u_2}^2}\\end{aligned}\\]  \\(\\rho=1-\\sqrt{1-\\alpha}\\).  \\((\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\((\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\((1 - \\alpha)100\\%\\)  (simultaneous confidence region).  20.1  \\(\\sigma_1^2\\)  \\(\\sigma_1^2\\)  \\((1 - \\alpha)100\\%\\)  20.1  \\(\\sigma_1^2\\)  c  d  c  d  \\(\\sigma_1^2\\)  \\[\\begin{aligned}c&amp;=\\frac{u_2Q_2/\\chi_{\\rho/2,u_2}^2-u_2Q_2/\\chi_{1-(\\rho/2),u_2}^2}a\\\\d&amp;=\\frac{u_2Q_2/\\chi_{1-(\\rho/2),u_2}^2-u_1Q_1/\\chi_{\\rho/2,u_2}^2}a\\end{aligned}\\]  \\(c\\leq\\sigma_1^2\\leq d\\)  \\(\\sigma_1^2\\)  \\((1 - \\alpha)100\\%\\) c  \\(\\sigma_1^2\\)  \\[\\sigma_\\varepsilon^2=u_1Q_1/\\chi_{1-(\\rho/2),u_1}^2\\quad\\mathrm{and}\\quad\\sigma_\\varepsilon^2=-a\\sigma_1^2+u_2Q_2/\\chi_{\\rho/2,u_2}^2\\] d  \\(\\sigma_1^2\\)  \\[\\sigma_\\varepsilon^2=u_1Q_1/\\chi_{\\rho/2,u_1}^2\\quad\\mathrm{~and~}\\quad\\sigma_\\varepsilon^2=-a\\sigma_1^2+u_2Q_2/\\chi_{1-(\\rho/2),u_2}^2\\]  20.1: \\(\\sigma_{\\varepsilon}^2,\\sigma_1^2\\)   \\((\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\(\\sigma_{\\varepsilon^{}}^2\\)  \\(\\sigma_1^2\\)  \\(\\varphi(\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\(\\sigma_{\\varepsilon^{}}^2\\)  \\(\\sigma_1^2\\)  \\((\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\(\\mathfrak{R}_\\alpha(\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\(\\sigma_{\\varepsilon^{}}^2\\)  \\(\\sigma_1^2\\)  (joint confidence region). \\(\\varphi(\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\[L=\\min_{(\\sigma_\\varepsilon^2,\\sigma_1^2)\\in\\Re_\\alpha(\\sigma_\\varepsilon^2,\\sigma_1^2)}[\\varphi(\\sigma_\\varepsilon^2,\\sigma_1^2)]\\] \\(\\varphi(\\sigma_{\\varepsilon^{}}^2,\\sigma_1^2)\\)  \\[U=\\max_{(\\sigma_\\varepsilon^2,\\sigma_1^2)\\in\\Re_\\alpha(\\sigma_\\varepsilon^2,\\sigma_1^2)}[\\varphi(\\sigma_\\varepsilon^2,\\sigma_1^2)]\\]  \\[\\varphi(\\sigma_\\varepsilon^2,\\sigma_1^2)=\\frac{\\sigma_1^2}{\\sigma_\\varepsilon^2+\\sigma_1^2}\\]  \\((u_1Q_1/\\chi_{1-(\\alpha/2),{u_1}}^2C)\\) \\((u_1Q_1/\\chi_{\\alpha/2,u_1}^2,d)\\).  20.1  \\(\\frac{\\sigma_1^2}{\\sigma_\\varepsilon^2+\\sigma_1^2}\\)  \\[-0.048511&lt;\\frac{\\sigma_1^2}{\\sigma_\\varepsilon^2+\\sigma_1^2}&lt;1.89748\\]  \\[0&lt;\\frac{\\sigma_1^2}{\\sigma_\\varepsilon^2+\\sigma_1^2}&lt;1\\]  \\(\\frac{\\sigma_1^2}{\\sigma_\\varepsilon^2+\\sigma_1^2}\\)  0  1.  \\(\\varphi(\\sigma_\\varepsilon^2,\\sigma_1^2)\\)  Williams (1962)  \\(\\sigma_1^2\\)  \\[\\begin{aligned}c_1&amp;=\\frac{u_2[Q_2-Q_1F_{\\alpha/2,u_2,u_1}]}{a\\chi_{\\alpha/2,u_2}^2}\\quad\\text{and}\\quad d_1=\\frac{u_2[Q_2-Q_1F_{1-(\\alpha/2),u_2,u_1}]}{a\\chi_{1-(\\alpha/2),u_2}^2}\\end{aligned}\\]  \\(1 - 2\\alpha\\). Boardman, 1974 \\(\\rho=\\alpha\\)  \\(\\rho=1-(1-\\alpha)\\) \\(\\sigma_1^2s\\)  \\(1-\\alpha\\). Williams  \\(1-\\alpha\\). Williams  \\(c\\leq\\sigma_1^2\\leq d\\)  (c, d)  Williams  20.2.6  20.5  20.12:  20.5  x  20.12  \\[y_{ij}=\\mu+iv_i+\\varepsilon_{ij},\\quad i=1,2,\\ldots,5,j=1,2,3,w_i\\thicksim i.i.d.N(0,\\sigma_{w}^2)\\mathrm{~and~}\\varepsilon_{ij}\\thicksim i.i.d.N(0,\\sigma_{\\varepsilon}^2)\\]  20.13:  20.5  SAS-Mixed  x  20.13 \\(\\sigma_\\varepsilon^2\\)  95%  \\[\\frac{16}{20.483}\\leq\\sigma_\\varepsilon^2\\leq\\frac{16}{3.247}\\quad\\mathrm{or}\\quad0.781\\leq\\sigma_\\varepsilon^2\\leq4.928\\] \\(\\sigma_\\varepsilon^2+3\\sigma_w^2\\)  95%  \\[\\frac{128}{11.143}\\leq\\sigma_\\varepsilon^2+3\\sigma_w^2\\leq\\frac{128}{0.484}\\quad\\mathrm{or}\\quad11.487\\leq\\sigma_\\varepsilon^2+3\\sigma_w^2\\leq264.463\\]  \\(\\sigma_w^2\\)  95%  \\(c\\leq\\sigma_w^2\\leq d\\) \\[\\begin{aligned}c&amp;=\\frac{11.487-4.928}3=2.186\\quad\\mathrm{and}\\quad d=\\frac{264.463-0.781}3=87.818\\end{aligned}\\]  \\(2.186\\leq\\sigma_w^2\\leq 87.818\\)  \\(\\sigma_w^2\\)  95%   \\(\\sigma_1^2\\) \\(E(Q_2) = E(Q_1) + \\sigma_1^2\\)  \\(Q_1\\)  \\(Q_2\\) u1  u2  \\({\\sigma}_0^2=E(Q_1)\\)  \\(\\sigma^2_0\\)  \\(\\sigma^2_\\varepsilon\\) \\(\\sigma_1^2\\)  \\((1 - \\alpha)100\\%\\)  \\(c\\leq\\sigma_1^2\\leq d\\). Williams (1962)  (Graybill, 1976,  15.3.5). 20.2.7  20.6  20.2  \\(\\sigma_a^2\\)  90%  20.2  20.3  20.4.  \\(Q_2=MSA\\)  \\(Q_1=MSAB\\) 1  \\[E(Q_1)=\\sigma_\\varepsilon^2+2\\sigma_{ac(b)}^2+4\\sigma_{ab}^2\\quad\\mathrm{~and~}\\quad E(Q_2)=\\sigma_\\varepsilon^2+2\\sigma_{ac(b)}^2+4\\sigma_{ab}^2+8\\sigma_a^2,\\]  \\(\\sigma_0^2=\\sigma_\\varepsilon^2+2\\sigma_{ac(b)}^2+4\\sigma_{ab}^2,\\sigma_1^2=\\sigma_a^2\\)  \\(a=8\\).  \\(\\sigma_0^2\\)  \\[\\begin{aligned}c&amp;=\\frac{(1\\times39.0625/3.8415)-(1\\times10.5625/0.00393)}8=-334.69\\\\d&amp;=\\frac{(1\\times39.0625/0.00393)-(1\\times10.5625/3.8415)}8=1242.10\\end{aligned}\\]  \\[-334.69\\leq\\sigma_a^2\\leq1242.10\\]  20.1  c  \\(\\sigma_a^2\\) \\(\\sigma_a^2\\)  \\(0 \\le \\sigma_a^2 \\le 1242.10\\).  \\(\\sigma_{ab}^2,\\sigma_{ac(b)}^2\\)  \\(\\sigma_{c(b)}^2\\)  \\(\\sigma_b^2\\)  Burdick and Graybill (1992) Burdick and Graybill (1992)  Graybill and Wang (1980), Lu et al. (1989)  Ting et al. (1990) Burdick and Graybill  (one-fold nested design).  \\[\\begin{aligned}&amp;y_{ij}=\\mu+u_i+\\varepsilon_{ij},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,n\\\\&amp;u_i\\thicksim i.i.d.N(0,\\sigma_u^2),\\varepsilon_{ij}\\thicksim i.i.d.N(0,\\sigma_\\varepsilon^2)\\end{aligned}\\]  \\(u_i,\\varepsilon_{ij}\\)   \\[\\begin{aligned}\\mathrm{SSBetween}&amp;=n\\sum_{i=1}^t{(\\bar{y}_{i\\cdot}-\\bar{y}_{\\cdot\\cdot})^2}=(t-1)Q_1\\\\\\text{SSWithin}&amp;=\\sum_{i=1}^t\\sum_{j=1}^n{(y_{ij}-\\bar{y}_{i\\cdot})^2}=t(n-1)Q_2\\end{aligned}\\]  \\(Q_1\\)  \\(Q_2\\)  \\[\\begin{aligned}E(\\text{MSBetween})&amp;=E(Q_1)=\\sigma_\\varepsilon^2+n\\sigma_u^2\\quad\\mathrm{~and~}\\quad E(\\text{MSWITHIN})=E(Q_2)=\\sigma_\\varepsilon^2\\end{aligned}\\]  \\[\\frac{(t-1)Q_1}{\\sigma_\\varepsilon^2+n\\sigma_u^2}\\thicksim\\chi_{t-1}^2\\quad\\mathrm{and}\\quad\\frac{t(n-1)Q_2}{\\sigma_\\varepsilon^2}\\thicksim\\chi_{t(n-1)}^2\\] \\(\\sigma^2_\\varepsilon\\)  95%  \\[\\left[\\frac{Q_2}{F_{\\alpha/2,t(n-1),\\infty}}\\leq\\sigma_\\varepsilon^2\\leq\\frac{Q_2}{F_{1-(\\alpha/2),t(n-1),\\infty}}\\right]\\]  \\(F_{\\alpha/2,t(n-1),\\infty}\\)  \\(F_{1-(\\alpha/2),t(n-1),\\infty}\\)  \\(t(n-1)\\)  \\(\\infty\\)  \\(F\\)  \\(F_{\\alpha/2,t(n-1),\\infty}=\\chi_{\\alpha/2,t(n-1)}^2/[t(n-1)]\\)  \\(F_{1-(\\alpha/2),t(n-1),\\infty}=\\chi_{1-(\\alpha/2),t(n-1)}^2/[t(n-1)]\\).  \\(\\sigma^2_\\varepsilon\\)  20.2.1   Burdick and Graybill (1992)  \\(\\sigma^2_u\\)  \\((1-\\alpha)100\\%\\)  \\[\\left[\\frac{Q_1-Q_2-\\sqrt{V_L}}n\\leq\\sigma_u^2\\leq\\frac{Q_1-Q_2+\\sqrt{V_U}}n\\right]\\]  \\[V_L=G_1^2Q_1^2+H_2^2Q_2^2+G_{12}Q_1Q_2\\quad V_U=H_1^2Q_1^2+G_2^2Q_2^2+H_{12}Q_1Q_2\\]  \\[\\begin{aligned} G_{1} &amp;=1-\\frac1{F_{\\alpha/2,t-1,\\infty}},\\quad G_2=1-\\frac1{F_{\\alpha/2,t(n-1),\\infty}} \\\\ H_{1} &amp;=\\frac1{F_{1-(\\alpha/2),t-1,\\infty}}-1,~H_2=\\frac1{F_{1-(\\alpha/2),t(n-1),\\infty}}-1 \\\\ G_{12} &amp;=\\frac{(F_{\\alpha/2,t-1,t(n-1)}-1)^2-G_1^2F_{\\alpha/2,t-1,t(n-1)}^2-H_2^2}{F_{\\alpha/2,t-1,t(n-1)}} \\\\ H_{12} &amp;=\\frac{(1-F_{1-(\\alpha/2),t-1,t(n-1)})^2-H_1^2F_{1-(\\alpha/2),t-1,t(n-1)}^2-G_2^2}{F_{1-(\\alpha/2),t-1,t(n-1)}} \\end{aligned}\\]  0.  \\(Q_1/Q_2&lt;F_{\\alpha/2,t-1,t(n-1)}\\)   \\(Q_1/Q_2&gt;F_{\\alpha,t-1,t(n-1)}\\)  \\(H_0{:}\\sigma_u^2=0\\mathrm{~vs~}{H_a}{:}\\sigma_u^2&gt;0\\) (uniformly most powerful unbiased test) (Lehmann, 1986).  Burdick and Graybill (1992)  \\(\\sigma_\\varepsilon^2+\\sigma_u^2\\)  \\((1 - \\alpha)100\\%\\)  \\[\\left[\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_u^2-\\frac{\\sqrt{G_1^2Q_1^2+G_2^2(n-1)Q_2^2}}n\\leq\\sigma_\\varepsilon^2+\\sigma_u^2\\leq\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_u^2+\\frac{\\sqrt{H_1^2Q_1^2+H_2^2(n-1)Q_2^2}}n\\right]\\]  \\[\\begin{aligned}G_1&amp;=1-\\frac1{F_{\\alpha/2,t-1,\\infty}},\\quad G_2=1-\\frac1{F_{\\alpha/2,t(n-1),\\infty}}\\\\H_1&amp;=\\frac1{F_{1-(\\alpha/2),t-1,\\infty}}-1,\\quad H_2=\\frac1{F_{1-(\\alpha/2),t(n-1),\\infty}}-1\\end{aligned}\\]  \\(\\rho=\\frac{\\sigma_u^2}{\\sigma_e^2+\\sigma_u^2}\\)  \\((1 - \\alpha)100\\%\\)  \\[\\begin{aligned}\\left[\\frac{L^*-1}{L^*-1+n}\\le\\rho\\le\\frac{U^*-1}{U^*-1+n}\\right]\\end{aligned}\\]  \\[L^*=\\frac{Q_1}{Q_2F_{\\alpha/2,t-1,t(n-1)}}\\quad\\mathrm{and}\\quad U^*=\\frac{Q_1}{Q_2F_{1-(\\alpha/2),t-1,t(n-1)}}\\]  \\(\\sigma_{u}^2/\\sigma_{\\varepsilon}^2\\)  \\((1 - \\alpha)100\\%\\)  \\[\\left[\\frac{L^*-1}n\\leq\\frac{\\sigma_u^2}{\\sigma_\\varepsilon^2}\\leq\\frac{U^*-1}n\\right]\\] Burdick and Graybill (1992)  20.2.8  20.6   20.5  \\(\\sigma_\\varepsilon^2,\\sigma_w^2,\\sigma_w^2/\\sigma_\\varepsilon^2\\)  \\(\\rho\\)  \\(Q_1=32.0,Q_2=1.6\\) \\(n=3, t-1=4,t(n-1)=10,F_{0.025,3,10}=4.46834,F_{0.975,3,10}=0.11307,F_{0.025,3,\\infty}=2.78582,F_{0.025,10,\\infty}=2.04832, -0.11208,H_{12}=-8.15882,V_\\text{L}{ = 4 2 6 . 1 2 9 , V _\\text{U}{ = 5 3 5 1 5 7 1 , L }^{*}=}4.47593\\)  \\(U^{*}=176.878\\). \\(\\sigma_\\varepsilon^2,\\sigma_w^2,\\sigma_w^2/\\sigma_\\varepsilon^2\\)  \\(\\rho\\)  95%  \\([0.78113\\leq\\sigma_{\\varepsilon}^2\\leq4.92767],[3.25237\\leq\\sigma_{w^{}}^2\\leq87.2449],[4.78382\\leq\\sigma_{\\varepsilon}^2+\\sigma_{u}^2\\leq89.1765],[1.15864\\leq(\\sigma_{w^{}}^2/\\sigma_{\\varepsilon}^2)\\leq58.6259]\\)  \\([0.53675\\leq\\rho\\leq0.98323]\\). REML  Satterthwaite  20.14  \\(\\sigma^2_w\\)  95%  Burdick and Graybill \\((3.25237\\leq\\sigma_w^2\\leq87.2449)\\), REML \\((3.4964\\leq\\sigma_w^2\\leq99.2870)\\)  \\((2.186\\leq\\sigma_w^2\\leq 87.818)\\).   20.14:  20.5  SAS-Mixed  REML  x 20.3   20.15  SAS data step  20.5  20.15  20.5  REML  REML 96.63%  \\({\\sigma_w^2}\\) 95.26%  \\({\\sigma_\\varepsilon^2}\\)  95%  Satterthwaite   20.15:  Satterthwaite  x  20.4  SAS-Mixed  20.3  Satterthwaite SAS-Mixed  20.5  then sums of squares obtained by the usual analysis of variance are independently distributed as scalar multiples of chi-square random variables. "],["chap21.html", " 21   21.1  21.2  21.3  21.4  21.5  21.6  JMP  21.7  21.8 ", "  21   The aim of science is to seek the simplest explanation of complex facts Seek simplicity and distrust it. - A. N. Whitehead  21.1   (plants)  (sites)  (workers).  21.1  EFF_1, EFF_2,, EFF_5   21.1:  EFF_i  i  x  \\(i=1,2,3,j=1,2,3,4,k=1,2,3\\)  \\(l=1,\\ldots,n_{ijk}\\) \\[\\begin{align} y_{ijkl}=\\mu+p_i+s_{j(i)}+w_{k(i)}+(sw)_{jk(i)}+\\varepsilon_{ijkl} \\tag{21.1} \\end{align}\\]  \\(p_i\\)  i \\(s_{j(i)}\\)  i  j \\(w_{k(i)}\\)  i  k \\((sw)_{jk(i)}\\)  i \\(\\varepsilon_{ijkl}\\)   \\[\\begin{aligned}&amp;p_i\\thicksim i.i.d.N(0,\\sigma_p^2),s_{j(i)}\\thicksim i.i.d.N(0,\\sigma_\\mathrm{s}^2),w_{k(i)}\\thicksim i.i.d.N(0,\\sigma_w^2)\\\\ &amp;sw_{jk(i)}\\thicksim i.i.d.N(0,\\sigma_{sw}^2),\\varepsilon_{ijkl}\\thicksim i.i.d.N(0,\\sigma_\\varepsilon^2),\\end{aligned}\\]  \\(p_i,s_{j(i)},w_{k(i)},(sw)_{jk(i)},\\varepsilon_{ijkl}\\)  21.2   I-III REMLMIVQUE0 NOBOUND  21.2.  REML  SAS®-Mixed Method =  21.3  21.4  I  III \\(\\sigma_s^2\\)  REML, ML  MIVQUE0  nobound  MIVQUE0  I-III  \\(\\sigma_s^2\\)  nobound  MIVQUE0  \\(\\sigma_s^2\\)  MIVQUE0  0 \\(\\sigma_s^2\\)  \\(\\hat\\sigma_s^2=0\\).  \\(\\sigma_s^2\\)   21.2:  Proc Mixed  (21.1)  MVQ  MIVQUE0MVQNB  nobound  MIVQUEProc Mixed  Method = REML  x  21.3:  I  x  21.4:  III  x 21.3   I I  21.3   \\(H_0\\colon{\\sigma}_{sw}^2=0\\text{ vs }H_{a}\\colon{\\sigma}_{sw}^2&gt;0\\).  21.3  \\[F_{C_{\\mathrm{s}w}}=\\frac{MS[worker\\times site(plant)]}{MS(Residual)}=21.42\\left(\\text{which is in Table 2}1.5\\right)\\]  \\(F_{C_{\\mathrm{s}w}}\\)  18 82  \\(F\\)  0.0001 \\({\\sigma}_{sw}^2\\)   \\(H_0\\colon{\\sigma}_{s}^2=0\\text{ vs }H_{a}\\colon{\\sigma}_{s}^2&gt;0\\). \\(E\\{MS[site(plant)]\\}=\\sigma_\\varepsilon^2+3.4789\\sigma_{sw}^2+9.1928\\sigma_s^2\\)  \\(\\sigma_\\varepsilon^2+3.4789\\sigma_{sw}^2\\)  \\(MS(Residual)\\)  \\(MS[worker\\times site(lant)]\\)  \\(Q_s^*\\) \\(E(Q_s^*)=\\sigma_\\varepsilon^2+3.4789\\sigma_{sw}^2\\).  \\(Q_s^*\\)  \\[\\begin{aligned} Q_s^*&amp; =3.4789{\\left[\\frac{MS[worker\\times site(plant)]}{2.8569}\\right]}+{\\left[1-\\frac{3.4989}{2.8569}\\right]}MS(Residual) \\\\ &amp;=1.2177MS[worker\\times site(plant)]-0.2177MS(Residual) \\\\ &amp;=128.921 \\end{aligned}\\]  \\(r_sQ_s^*/(\\sigma_\\varepsilon^2+3.4789\\sigma_{sw}^2)\\)  Satterthwaite  \\[\\begin{aligned}r_s&amp;=\\frac{(Q_s^*)^2}{\\frac{\\{1.2177MS[worker\\times site(plant)]\\}^2}{18}+\\frac{[0.2177MS(Residual)]}{82}}\\\\&amp;=\\frac{\\left(128.921\\right)^2}{\\frac{[1.2177\\times106.738]^2}{18}+\\frac{[0.2177\\times4.983]^2}{82}}=17.7\\end{aligned}\\]  \\[F_{C_s}=\\frac{MS[site(plant)]}{Q_s^*}=0.65\\text{ (see Table 21.5)}\\]  9  17.7  \\(F\\)  0.7396 \\({\\sigma}_{s}^2\\)  \\(H_0\\colon{\\sigma}_{s}^2=0\\text{ vs }H_{a}\\colon{\\sigma}_{s}^2&gt;0\\).  21.5  21.6  III  \\(H_0\\colon{\\sigma}_{s}^2=0\\text{ vs }H_{a}\\colon{\\sigma}_{s}^2&gt;0\\)  \\(F\\)  0.67 18.1 0.7217. III  \\({\\sigma}_{s}^2\\)  I  site(plant)  \\({\\sigma}_{s}^2\\)  \\({\\sigma}_{s}^2\\)  \\(s_{j(t)}\\)   21.5:  I  x  21.6:  III  x 21.4   \\[\\begin{align} y_{ijkl}&amp;=\\mu+p_i+w_{k(i)}+(sw)_{jk(i)}+\\varepsilon_{ijkl}\\\\i&amp;=1,2,3,~j=1,2,3,4,~k=1,2,3,~l=1,\\ldots,n_{ijk} \\tag{21.2} \\end{align}\\]  \\(s_{j(i)}\\) SAS-Mixed  site(plant)  worker × site(plant)  21.7  worker×site(plant)  27  \\({\\sigma}_{s}^2=0\\)  21.3  21.4  \\(MS[site(plant)]\\)  \\(MS[worker \\times site(plant)]\\)  21.3 \\(E\\{MS[site(plant)]\\}=\\sigma_\\varepsilon^2+3.4789\\sigma_{sw}^2\\)  \\(E\\{MS[worker\\times site(plant)]\\}=\\sigma_\\varepsilon^2+2.8569\\sigma_{sw}^2\\) III   21.7:  I  x  21.7 I worker × site(plant)  \\(\\sigma_\\varepsilon^2+3.0643\\sigma_{sw}^2\\).  \\(3.0643 = [(9 \\times 3.4789) + (18\\times2.8561)/27]\\)  I  site(plant)  worker × site(plant)  \\({\\sigma}_{s}^2=0\\)  I  21.4, 21.6  21.8  III  REMLML MIVQUE0I-III  21.9  MIVIQUE0 6.61 4.98ML  \\({\\sigma}_{p}^2=0\\)  29.6 III  58.6.  47.6  53.1  plant \\({\\sigma}_{p}^2\\)  \\({\\sigma}_{p}^2\\)  \\({\\sigma}_{w}^2\\)  \\({\\sigma}_{sw}^2\\) \\({\\hat\\sigma}_{w}^2\\)  25.5  28.9\\({\\hat\\sigma}_{sw}^2\\)  25.4  30.7  21.8:  III  x  21.9:  x  \\(H_0\\colon{\\sigma}_{sw}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{sw}^2&gt;0\\)  \\[\\begin{aligned}F_{C_{sw}}=\\frac{MS[worker\\times site(plant)]}{MS(Residual)}=19.90\\end{aligned}\\]  27  82  \\(F\\)  0.0001. \\({\\sigma}_{sw}^2\\)  \\((sw)_{jk(i)}\\) \\({\\sigma}_{sw}^2\\)  (adaption variance component) \\(Q^*_w\\)  \\(H_0\\colon{\\sigma}_{w}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{w}^2&gt;0\\).  \\(Q^*_w\\)  \\(MS[worker\\times site(plant)\\)  \\(MS(Residual)\\)  \\(E(Q^*_w)=\\sigma_\\varepsilon^2+3.9015\\sigma_{sw}^2\\).  \\[\\begin{aligned} Q _{w}^{*}&amp; =3.9015{\\left[\\frac{MS[site\\times worker(plant)]}{3.0643}\\right]}+{\\left[1-\\frac{3.9015}{3.0643}\\right]}MS(Residual) \\\\ &amp;=1.2732MS[site\\times worker(plant)]-0.2732MS(Residual) \\\\ &amp;=124.9085 \\end{aligned}\\]  \\(F_{C_w}=456.9419/124.9085=3.66\\) 6  \\(r_w\\)  \\(F\\)  \\[\\begin{aligned} r_{w}&amp; =\\frac{(Q_w^*)}{\\{1.2732MS[site\\times worker(plant)]\\}^2/27+[0.2732\\times MS(Residual)]^2/82} \\\\ &amp;=\\frac{(124.9085)^2}{[1.2732\\times99.1752]^2/27+[0.2732\\times4.9831]^2/82} \\\\ &amp;=26.42 \\end{aligned}\\]  0.0089 \\({\\sigma}_{w}^2\\)   \\(MS[worker(plant)],MS[worker \\times site(plant)]\\)  \\(MS(Residual)\\)  \\(Q_p^*\\) \\[E(Q_p^*)=\\sigma_\\varepsilon^2+3.9277\\sigma_{sw}^2+13.136\\sigma_w^2\\]  \\(H_0\\colon{\\sigma}_{p}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{p}^2&gt;0\\).  \\(Q_p^*\\)  \\[\\begin{aligned} Q_p^*=&amp; =\\frac{13.136}{13.037}\\{MS[worker(plant)]\\} \\\\ &amp;+\\left[\\frac{3.9277-\\frac{13.136}{13.037}(3.0915)}{3.0643}\\right]\\{MS[site\\times worker(plant)]\\} \\\\ &amp;+\\left[1-\\frac{13.136}{13.037}-\\frac{3.9277-\\frac{13.136}{13.037}(3.0915)}{3.0643}\\right]MS(Residual) \\\\ &amp;=1.0076MS[worker(plant)]-0.0012MS[site\\times worker(plant)]-0.0065MS(Residul) \\\\ &amp;=460.2638 \\end{aligned}\\]  \\[F_{C_p}=\\frac{MS(plant)}{Q_p^*}=5.027\\]  2  \\(r_p\\)  \\(F\\)  \\(r_p=(Q_p^*)^2/D_p\\)  \\[\\begin{aligned} D_{p} =&amp;\\frac{\\{1.0076MS[worker(plant)]\\}^2}6+\\frac{\\{0.0012MS[site\\times worker(plant)]\\}^2}{27} \\\\ &amp;+\\frac{\\left[0.0065MS(Residual)\\right]^2}{82}=35,330.281 \\end{aligned}\\]  \\(r_p=5.9961\\).  0.0522 \\({\\sigma}_{p}^2\\)  \\({\\sigma}_{sw}^2\\)  \\({\\sigma}_{w}^2\\)  (21.2)  \\(\\alpha &lt; 0.10\\)   21.8  21.10  III  SAS-Mixed  Satterthwaite  \\(H_0\\colon{\\sigma}_{p}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{p}^2&gt;0,H_0\\colon{\\sigma}_{w}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{w}^2&gt;0\\)  \\(H_0\\colon{\\sigma}_{sw}^2=0\\mathrm{~vs~}H_a\\colon{\\sigma}_{sw}^2&gt;0\\)  III  0.0357, 0.0040  0.0001. III  I III  I  21.11  REML plant, worker(plant)  worker × site(plant)  \\(Z\\)   0.2118, 0.0869  0.0003.  I  III  \\(Z\\)  \\(Z\\)   21.10:  III  x plant worker(plant) worker × site(plant)  21.5   (21.2)  21.11  21.12  REML  I  20.2.2  REML  \\(df=2(Z\\text{-}value)^2\\). \\(\\hat{{\\sigma}_p^2},\\hat{{\\sigma}_w^2},\\hat{{\\sigma}_{sw}^2}\\)  1.28, 3.70  82.10.  21.13  REML 30I  20.2.4  Wald  \\(\\sigma^2_\\varepsilon\\) 20.2.2  81.93  I  20.2.2  \\(df=2(Z\\text{-}value)^2\\).  \\({\\hat{\\sigma}_p^2}\\) 1.4677 95%  \\([11.2668\\le {\\hat{\\sigma}_p^2} \\le 5984.61]\\).  \\({\\hat{\\sigma}_w^2}\\) 3.9682 95%  \\([9.1149\\le {\\hat{\\sigma}_p^2} \\le 212.97]\\).  \\({\\hat{\\sigma}_{sw}^2}\\) 20.8392 95%  \\([18.1625\\le {\\hat{\\sigma}_p^2} \\le 62.98]\\).  21.14   21.11:  REML  Satterthwaite  x  21.12:  I  Wald  x  21.13:  REML  x  21.14:  I  20.2.2  Satterthwaite  x  Satterthwaite  I  20.2.1  \\({{\\sigma}_{\\varepsilon}^2}\\) \\({{\\sigma}_{\\varepsilon}^2}\\)  95%  \\[\\frac{82[MS(Residual)]}{\\chi_{(\\alpha/2),82}^2}\\leq\\sigma_\\varepsilon^2\\leq\\frac{82[MS(Residual)]}{\\chi_{1-(\\alpha/2),82}^2}\\]  \\[\\frac{82(4.9831)}{108.937}\\leq\\sigma_\\varepsilon^2\\leq\\frac{82(4.9831)}{58.8446}\\]  \\[3.781\\leq\\sigma_\\varepsilon^2\\leq6.944\\]  \\({{\\sigma}_{\\varepsilon}^2}\\)  95%  21.11  Residual   21.7  \\({{\\sigma}_{sw}^2}\\)  Satterthwaite \\({{\\sigma}_{sw}^2}\\)  \\[\\hat{\\sigma}_{sw}^2=\\frac{MS[worker\\times site(plant)]}{3.064}-\\frac{MS(Residual)}{3.064}=30.7388\\]  \\(r_{sw}\\hat{\\sigma}_{sw}^2/\\sigma_{sw}^2\\)  \\(r_{sw}\\)  \\[r_{_{sw}}=\\frac{(\\hat{\\sigma}_{sw}^2)^2}{\\left[\\frac{MS[worker\\times site(plant)]}{3.064}\\right]\\Big/27+\\left[\\frac{MS(Residual)}{3.064}\\right]\\Big/82}=24.33\\] \\({{\\sigma}_{sw}^2}\\)  95%  \\[\\frac{r_{sw}\\hat{\\sigma}_{sw}^2}{\\chi_{.025,24.33}^2}\\leq\\sigma_{sw}^2\\leq\\frac{r_{sw}\\hat{\\sigma}_{sw}^2}{\\chi_{.975,24.33}^2}\\]  \\[18.80\\leq\\sigma_{sw}^2\\leq59.17\\]  21.15:  I  x  \\(\\sigma_{sw}^2\\)  \\(\\hat\\sigma_{sw}^2\\)  21.15  Error  \\[\\begin{aligned}\\hat{\\sigma}_w^2&amp;=\\{MS(worker)-1.2732MS[worker\\times site(plant)]+0.2732MS(Residual)\\}/13.037\\\\&amp;=25.4692\\end{aligned}\\]  \\(\\hat\\sigma_{sw}^2\\)  \\(r_w=3.12\\) 95%  \\([8.297\\le \\hat\\sigma_{sw}^2 \\le 327.87]\\).  \\(\\sigma_{p}^2\\)  95%  21.15  \\(\\sigma_{p}^2\\)  \\[ \\begin{aligned} \\hat\\sigma_p^2=&amp;\\{MS(plant)-1.0076MS[worker(plant)]+0.0012MS[worker\\times site(plant)\\\\&amp;+0.0065 MS(Residual)\\}/38.941\\\\ =&amp;47.60 \\end{aligned} \\]  \\(\\hat\\sigma_{p}^2\\)  \\(r_p=1.27\\).  95%  \\([10.58\\le \\sigma_{p}^2 \\le 12078.74]\\).  Satterthwaite  21.16   21.16:  I  Satterthwaite  x  20.2  \\(\\sigma^2_p,\\sigma^2_w,\\sigma^2_{sw}\\) \\(\\sigma^2_{sw}\\) 95%  \\(c_{sw},d_{sw}\\)  \\[c_{sw}=\\frac{27MS[worker\\times site(plant)]/\\chi_{.025,27}^2-82MS(Residual)/\\chi_{.975,82}^2}{3.064}=17.96\\]  \\[d_{sw}=\\frac{27MS[worker\\times site(plant)]/\\chi_{975,27}^2-82MS(Residual)/\\chi_{.025,82}^2}{3.064}=58.74\\]  \\(17.96\\le \\sigma^2_{sw} \\le 58.74\\).  \\(\\sigma^2_{w}\\)  95%  \\(c_{w},d_{w}\\) \\[c_w=\\frac{6MS[worker(plant)]/\\chi_{.025,6}^2-r_wQ_w^*/\\chi_{.975,26.42}^2}{13.037}=-3.335\\]  \\[d_w=\\frac{6MS[worker(plant)]/\\chi_{.975,6}^2-r_wQ_w^*/\\chi_{.025,26.42}^2}{13.037}=164.00\\]  \\(r_w=26.42\\)  \\(Q^*_w=124.9085\\).  \\(0\\leq\\sigma_w^2\\leq164.00\\).  \\(\\sigma^2_{p}\\)  95%  \\(c_p,d_p\\) \\[c_p=\\frac{2MS(plant)]/\\chi_{.025,2}^2-r_pQ_p^*/\\chi_{.975,5.9961}^2}{38.941}=-41.2471\\]  \\[d_p=\\frac{2MS(plant)]/\\chi_{.975,2}^2-r_pQ_p^*/\\chi_{.025,5.9961}^2}{38.941}=2341.94\\]  \\(r_p=5.9961\\)  \\(Q^*_p=460.2638\\).  \\(0\\leq\\sigma_p^2\\leq 2431.94\\).  21.17   21.17:  20.2.5  x  21.18   21.18:  95%  x 21.6  JMP   21.1  21  JMP®  plant, site  worker  21.2  fit model  plant, site(plant), worker(plant)  site×worker(plant)  REML  21.3  95%  21.2  REML  21.4  fit model  21.2  fit model  site(plant)  21.5  JMP  REML  21.11  SAS-Mixed JMP  fit model   21.1:  21 JMP   21.2:  21  JMP fit model   21.3:  21  JMP REML   21.4:  21  JMP fit model   21.5:  21  JMP REML  21.7  REML  Satterthwaite  I  Satterthwaite 31 19  20   SAS-Mixed  JMP  fit model  21.8  Table 21.13 contains the computed degrees of freedom for the REML confi dence intervals as well as intervals that are expressed in standard deviation units. The REML and usual Satterthwaite approximation are quite similar where the general Satterthwaite intervals using the type I sums of squares and confidence regions for the plant and worker variance components are quite variable. "],["chap22.html", " 22   22.1  22.2  22.3  22.4  22.5  22.6  22.7 ", "  22   Facts speak louder than statistics - Mr. Justice Streatfield (1950) - 2  18 - 21  18  (randomized complete blocks models) (incomplete blocks models) (split-plot-type models) (strip-plot-type models) (repeated measures type models) (random coefficients models) (multilevel models)  (hierarchical models). 123 22.1     A  B C  \\[y_{ijkm}=\\mu+\\alpha_i+\\beta_j+\\gamma_{ij}+c_k+d_{ik}+f_{jk}+g_{ijk}+\\varepsilon_{ijkm}\\]  \\(\\mu\\) \\(\\alpha_i\\)  A  i \\(\\beta_j\\)  B  j \\(\\gamma_{ij}\\)  A  B \\(c_k\\)  C  k \\(d_{ik}\\)  A  C \\(f_{jk}\\)  B  C \\(g_{ijk}\\)  A, B, C \\(\\varepsilon_{ijkm}\\)   \\(\\mu+\\alpha_i+\\beta_j+\\gamma_{ij}\\) \\(c_k+d_{ik}+f_{jk}+g_{ijk}\\) \\(\\varepsilon_{ijkm}\\).  \\(c_k\\thicksim i.i.d.N(0,\\sigma_c^2),d_{ik}\\thicksim i.i.d.N(0,\\sigma_d^2),f_{jk}\\sim i.i.d.N(0,\\sigma_f^2),g_{ijk}\\sim i.i.d.N(0,\\sigma_g^2),\\varepsilon_{ijkm}\\sim i.i.d.N(0,\\sigma_\\varepsilon^2)\\)  \\(c_k,d_{ik},f_{jk},g_{ijk},\\varepsilon_{ijkm}\\) A  B  \\(\\gamma_{ij}\\)  k  C.   \\[\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_k\\boldsymbol u_k+\\boldsymbol{\\varepsilon}\\]  \\(\\boldsymbol y\\)  N × 1 \\(\\boldsymbol X\\boldsymbol{\\beta}\\) \\(\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_k\\boldsymbol u_k\\)  \\(\\boldsymbol{\\varepsilon}\\)  \\(\\boldsymbol {u}_{i}\\thicksim N(\\boldsymbol0,{\\sigma}_{i}^{2}\\boldsymbol{I}_{n_{i}}),i=1,2,\\ldots,k;\\boldsymbol{\\varepsilon}\\thicksim N(\\boldsymbol{0},{\\sigma}_{\\varepsilon}^{2}\\boldsymbol{I}_{N})\\)  \\(\\boldsymbol{u}_i\\left(i=1,2,\\ldots,k\\right),\\boldsymbol \\varepsilon\\)   \\(\\boldsymbol u_1,\\boldsymbol u_2,\\ldots,\\boldsymbol u_k\\)  \\(\\boldsymbol y\\) \\(\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_k\\boldsymbol u_k+\\boldsymbol{\\varepsilon}\\)  \\(\\boldsymbol{\\varepsilon}\\thicksim N(\\boldsymbol{0},{\\sigma}_{\\varepsilon}^{2}\\boldsymbol{I}_{N})\\)  \\(\\boldsymbol u_1,\\boldsymbol u_2,\\ldots,\\boldsymbol u_k\\) \\(\\boldsymbol{y}\\)  \\(\\boldsymbol{y}\\thicksim N(\\boldsymbol{X\\beta},\\boldsymbol{\\Sigma})\\) \\(\\boldsymbol{\\Sigma}={\\sigma}_1^2\\boldsymbol{Z}_1\\boldsymbol{Z}_1&#39;+{\\sigma}_2^2\\boldsymbol{Z}_2\\boldsymbol{Z}_2&#39;+\\cdots+{\\sigma}_k^2\\boldsymbol{Z}_k\\boldsymbol{Z}_k&#39;+{\\sigma}_\\varepsilon^2\\boldsymbol{I}_N\\) \\(\\boldsymbol{y}=\\boldsymbol{X\\beta}+\\boldsymbol{e}\\)  \\(\\boldsymbol{e}\\thicksim N(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\).  \\(\\boldsymbol{\\beta},{\\sigma}_1^2,{\\sigma}_2^2,\\ldots,{\\sigma}_k^2\\)  \\({\\sigma}_\\varepsilon^2\\).  \\({\\sigma}_1^2,{\\sigma}_2^2,\\ldots,{\\sigma}_k^2\\)  \\({\\sigma}_\\varepsilon^2\\)  \\(\\boldsymbol \\beta\\)   \\(\\boldsymbol y\\)  \\(\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_k\\boldsymbol u_k+\\boldsymbol{\\varepsilon}\\) \\(\\boldsymbol u_i\\sim N(\\mathbf{0},\\boldsymbol{G}_i),i=1,2,\\ldots,k,\\boldsymbol{\\varepsilon}\\thicksim N(\\mathbf{0},\\boldsymbol{R})\\) \\(\\boldsymbol u_i\\,(i=1,2,\\ldots,k)\\)  \\(\\boldsymbol{\\varepsilon}\\) \\(\\boldsymbol y\\)  \\(\\boldsymbol{y}\\thicksim N(\\boldsymbol{X\\beta},\\boldsymbol{\\Sigma})\\)  \\(\\boldsymbol{\\Sigma}=\\boldsymbol{Z}_1\\boldsymbol{G}_1\\boldsymbol{Z}_1^{\\prime}+\\boldsymbol{Z}_2\\boldsymbol{G}_2\\boldsymbol{Z}_2^{\\prime}+\\cdots+\\boldsymbol{Z}_k\\boldsymbol{G}_k\\boldsymbol{Z}_k^{\\prime}+\\boldsymbol{R}\\) \\(\\boldsymbol{y}=\\boldsymbol{X\\beta}+\\boldsymbol{e}\\)  \\(\\boldsymbol{e}\\thicksim N(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\).  \\(\\boldsymbol G_1,\\boldsymbol G_1,\\ldots,\\boldsymbol G_k\\)  \\(\\boldsymbol R\\)  22.2   \\(\\boldsymbol y\\)  \\[\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol e\\quad\\mathrm{where~}\\boldsymbol e\\thicksim N(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\mathrm{~and~}\\boldsymbol{\\Sigma}=\\sigma_1^2\\boldsymbol{Z}_1\\boldsymbol{Z}_1^{\\prime}+\\sigma_2^2\\boldsymbol{Z}_2\\boldsymbol{Z}_2^{\\prime}+\\cdots+\\sigma_k^2\\boldsymbol{Z}_k\\boldsymbol{Z}_k^{\\prime}+\\sigma_\\varepsilon^2\\boldsymbol{I}_N\\] \\(\\boldsymbol \\beta\\)  \\(\\boldsymbol{\\hat{\\beta}}=(\\boldsymbol X^{\\prime}\\boldsymbol{X})^-\\boldsymbol{X^{\\prime}}\\boldsymbol{y}\\)  \\((\\boldsymbol X^{\\prime}\\boldsymbol{X})^-\\)  \\(\\boldsymbol X^{\\prime}\\boldsymbol{X}\\)  MoorePenrose  \\[\\boldsymbol r=\\boldsymbol y-\\boldsymbol X\\hat{\\boldsymbol{\\beta}}=(\\boldsymbol I-\\boldsymbol X\\boldsymbol X^-)\\boldsymbol y\\]  \\[\\boldsymbol r=(\\boldsymbol I-\\boldsymbol X\\boldsymbol X^-)\\boldsymbol Z_1\\boldsymbol u_1+(\\boldsymbol I-\\boldsymbol X\\boldsymbol X^-)\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+(\\boldsymbol I-\\boldsymbol X\\boldsymbol X^-)\\boldsymbol Z_k\\boldsymbol u_k+(\\boldsymbol I-\\boldsymbol X\\boldsymbol X^-)\\boldsymbol{\\varepsilon}\\]  \\(\\boldsymbol {Xb}\\) 18 - 20 REML  MINQUE  23  22.2.1   19  18.3   B  T  \\[y_{ijk}=\\mu+\\beta_i+t_j+g_{ij}+\\varepsilon_{ijk}\\quad i=1,2,\\ldots,b\\quad j=1,2,\\ldots,t\\quad k=1,2,\\ldots,n_{ij}\\]  \\(t_i \\thicksim i.i.d.N(0,\\sigma_t^2),g_{ij} \\thicksim i.i.d.N(0,\\sigma_g^2)\\)  \\(\\varepsilon_{ijk}\\thicksim i.i.d.N(0,\\sigma_\\varepsilon^2)\\).  \\(R(\\beta|\\mu),R(t|\\mu,\\beta),R(g|\\mu,\\beta,t)\\)  \\(SSERROR\\).  \\(k_1,k_2,k_3\\) \\[\\begin{aligned}E[MSR(t|\\mu,\\beta)]&amp;=\\sigma_\\varepsilon^2+k_1\\sigma_g^2+k_2\\sigma_\\varepsilon^2\\\\E[MSR(g|\\mu,\\beta,t)]&amp;=\\sigma_\\varepsilon^2+k_3\\sigma_g^2\\\\E[MSERROR]&amp;=\\sigma_\\varepsilon^2\\end{aligned}\\] \\(k_1,k_2,k_3\\)   \\(\\tilde{{\\sigma}}_{{\\varepsilon}}^2,\\tilde{{\\sigma}}_t^2\\)  \\(\\tilde{{\\sigma}}_g^2\\)  \\[\\begin{aligned} MSR(t|\\mu,\\beta)&amp; =\\tilde{{\\sigma}}_\\varepsilon^2+k_1\\tilde{{\\sigma}}_g^2+k_2\\tilde{{\\sigma}}_\\varepsilon^2 \\\\ MSR(g|\\mu,\\beta,t)&amp; =\\tilde{\\sigma}_\\varepsilon^2+k_3\\tilde{\\sigma}_g^2 \\\\ MSERROR&amp; =\\tilde{{\\sigma}}_\\varepsilon^2 \\end{aligned}\\]  \\[\\begin{aligned} \\tilde{{\\sigma}}_\\varepsilon^2 &amp; =MSERROR \\\\ \\tilde{{\\sigma}}_g^2&amp; =[MSR(g|\\mu,\\beta,t)-\\tilde{\\sigma}_\\varepsilon^2]/k_3 \\\\ \\tilde{{\\sigma}}_t^2&amp;=[MSR(t|\\mu,\\beta)-k_1\\tilde{\\sigma}_g^2-\\tilde{\\sigma}_\\varepsilon^2]/k_2 \\end{aligned}\\]  \\[\\begin{aligned} &amp;\\hat{{\\sigma}}_\\varepsilon^2 =\\tilde{\\sigma}_\\varepsilon^2 \\\\ &amp;\\hat{{\\sigma}}_g^2 =\\begin{cases}\\tilde{{\\sigma}}_g^2&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_g^2\\geq0\\\\0&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_g^2&lt;0&amp;\\end{cases} \\\\ &amp;\\hat{{\\sigma}}_t^2 =\\begin{cases}\\tilde{{\\sigma}}_t^2&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_t^2\\geq0\\\\0&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_t^2&lt;0&amp;\\end{cases} \\end{aligned}\\]  \\((1-\\alpha)100\\%\\)  \\[\\frac{df_{\\hat{\\sigma}_r^2}\\hat{\\sigma}_r^2}{\\chi^2_{\\alpha/2,df_{\\hat{\\sigma}_r^2}}}\\leq\\sigma_r^2\\leq\\frac{df_{\\hat{\\sigma}_r^2}\\hat{\\sigma}_r^2}{\\chi^2_{1-(\\alpha/2),df_{\\hat{\\sigma}_r^2}}},\\quad r=t,g,\\varepsilon \\]  \\[df_{\\hat{\\sigma}_\\varepsilon^2}=df_{MSERROR},\\quad df_{\\hat{\\sigma}_s^2}=\\frac{(\\hat{\\sigma}_g^2)^2}{\\frac{\\left[(1/k_3)MSR(g|\\mu,\\beta,t)\\right]^2}{df_{MSR(g|\\mu,\\beta,t)}}+\\frac{[(1/k_3)MSERROR]^2}{df_{MSERROR}}}\\]  \\[df_{\\hat{\\sigma}_t^2}=\\frac{(\\hat{\\sigma}_t^2)^2}{\\frac{\\left[(1/k_3)MSR(t|\\mu,\\beta)\\right]^2}{df_{MSR(t|\\mu,\\beta)}}+\\frac{\\left[(k_1/k_3k_2)MSR(g|\\mu,\\beta,t)\\right]^2}{df_{MSR(g|\\mu,\\beta,t)}}+\\frac{\\left[(1/k_2)(1-(k_1/k_3))MSERROR\\right]^2}{df_{MSERROR}}}\\]  \\(H_{0}\\colon{\\sigma}_{t}^{2}=0\\operatorname{vs}H_{a}\\colon{\\sigma}_{t}^{2}&gt;0\\)  \\[\\begin{aligned}F_{tc}&amp;=\\frac{MSR(t\\mid\\mu,\\beta)}{Q}\\quad\\mathrm{where~}Q=\\frac{k_1}{k_3}MSR(g|\\mu,\\beta,t)+\\left(1-\\frac{k_1}{k_3}\\right)MSERROR\\end{aligned}\\]  \\(F\\)  \\(df_{MSR(t|\\mu,\\beta)}\\) v \\[v=\\frac{Q^2}{\\frac{\\left[(k_1/k_3)MSR(g|\\mu,\\beta,t)\\right]^2}{df_{MSR(g|\\mu,\\beta,t)}}+\\frac{\\left[\\left(1-(k_1/k_3)\\right)MSERROR\\right]^2}{df_{MSERROR}}}\\]  Satterthwaite   \\(H_{0}\\colon{\\sigma}_{g}^{2}=0\\operatorname{vs}H_{a}\\colon{\\sigma}_{g}^{2}&gt;0\\)  \\[F_{gc}=\\frac{MSR(g|\\mu,\\beta,t)}{MSERROR}\\]  \\(F\\)  \\(df_{MSR(g|\\mu,\\beta,t)}\\) \\(df_{MSERROR}\\). 22.2.2   \\(L(\\boldsymbol{\\beta},\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2,\\sigma_\\varepsilon^2)=(2\\pi)^{-n/2}|\\boldsymbol{\\Sigma}|^{-1/2}\\exp[-\\frac12(\\boldsymbol{y}-\\boldsymbol X\\boldsymbol{\\beta})^{\\prime}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol X\\boldsymbol{\\beta})]\\).  \\(-2\\log[L(\\boldsymbol{\\beta},\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2,\\sigma_\\varepsilon^2)]\\) (Hartley and Rao, 1967).  \\[\\left.\\frac{\\partial l}{\\partial\\boldsymbol\\beta}\\right|_{\\boldsymbol\\beta=\\hat{\\boldsymbol\\beta},\\sigma=\\hat{\\sigma}}=0,\\quad\\left.\\frac{\\partial l}{\\partial\\sigma_1^2}\\right|_{\\boldsymbol\\beta=\\hat{\\boldsymbol\\beta},\\sigma=\\hat{\\sigma}}=0,\\quad\\left.\\frac{\\partial l}{\\partial\\sigma_2^2}\\right|_{\\boldsymbol\\beta=\\hat{\\boldsymbol\\beta},\\sigma=\\hat{\\sigma}}=0,\\ldots,\\quad\\left.\\frac{\\partial l}{\\partial\\sigma_k^2}\\right|_{\\boldsymbol\\beta=\\hat{\\boldsymbol\\beta},\\sigma=\\hat{\\sigma}}=0,\\quad\\left.\\frac{\\partial l}{\\partial\\sigma_\\varepsilon^2}\\right|_{\\boldsymbol\\beta=\\hat{\\boldsymbol\\beta},\\sigma=\\hat{\\sigma}}=0\\]  \\(l=-2\\log[L(\\boldsymbol{\\beta},{\\sigma}_1^2,{\\sigma}_2^2,\\ldots,{\\sigma}_k^2,{\\sigma}_\\varepsilon^2)],{\\sigma}^{\\prime}=[{\\sigma}_1^2,{\\sigma}_2^2,\\ldots,{\\sigma}_k^2,{\\sigma}_\\varepsilon^2]\\)  \\(\\hat{{\\sigma}}^{\\prime}=[\\hat{{\\sigma}}_1^2,\\hat{{\\sigma}}_2^2,\\ldots,\\hat{{\\sigma}}_k^2,\\hat{{\\sigma}}_\\varepsilon^2]\\).  \\[y_{ijk}=\\mu_i+a_j+g_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,a,\\quad k=1,2,\\ldots,n\\]  \\(\\mu_i\\)  T  i \\(\\alpha_j\\)  A  j \\(\\gamma_{ij}\\) \\(\\varepsilon_{ijk}\\) \\(a_j\\thicksim i.i.d.N(0,\\sigma_a^2),g_{ij}\\thicksim i.i.d.N(0,\\sigma_g^2),\\varepsilon_{ijk}\\thicksim i.i.d.N(0,\\sigma_e^2)\\) \\(a_j,g_{ij},\\varepsilon_{ijk}\\)  \\[\\begin{aligned} \\boldsymbol{\\Sigma}=&amp;\\,{\\sigma}_a^2[\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_a\\otimes\\boldsymbol{J}_t]+{\\sigma}_g^2[\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_a\\otimes\\boldsymbol{I}_t]+{\\sigma}_\\varepsilon^2[\\boldsymbol{I}_n\\otimes\\boldsymbol{I}_a\\otimes\\boldsymbol{I}_t] \\\\ =&amp;\\,(\\sigma_\\varepsilon^2+n\\sigma_g^2+nt\\sigma_a^2)\\left[\\frac1{n}\\boldsymbol J_n\\otimes \\boldsymbol I_a\\otimes\\frac1t\\boldsymbol J_t\\right]+(\\sigma_\\varepsilon^2+n\\sigma_g^2)\\left[\\frac1{n}\\boldsymbol J_n\\otimes \\boldsymbol I_a\\otimes(\\boldsymbol I_t-\\frac1t\\boldsymbol J_t)\\right] \\\\ &amp;+\\sigma_\\varepsilon^2\\left[(\\boldsymbol I_n-\\frac1n\\boldsymbol J_n)\\otimes \\boldsymbol I_a\\otimes \\boldsymbol I_t\\right] \\\\ =&amp;\\,\\lambda_1\\boldsymbol V_1+\\lambda_2\\boldsymbol V_2+\\lambda_3\\boldsymbol V_3\\text{ (say)} \\end{aligned}\\]  \\(\\lambda_1=\\sigma_\\varepsilon^2+n\\sigma_g^2+nt\\sigma_a^2,\\lambda_2=\\sigma_\\varepsilon^2+n\\sigma_g^2,\\lambda_3=\\sigma_\\varepsilon^2\\)  \\(\\boldsymbol V_1,\\boldsymbol V_2,\\boldsymbol V_3\\)  \\(\\boldsymbol A\\otimes \\boldsymbol B\\)  \\(\\boldsymbol A,\\boldsymbol B\\)  (direct product) (Graybill 1976). \\(|\\boldsymbol{\\Sigma}|=\\lambda_1^{a}\\lambda_2^{a(t-1)}\\lambda_3^{at(n-1)}\\)  \\(\\boldsymbol{\\Sigma}^{-1}=(1/\\lambda_1)\\boldsymbol{V}_1+(1/\\lambda_2)\\boldsymbol{V}_2+(1/\\lambda_3)\\boldsymbol{V}_3\\). \\(l=-2\\log (L)\\)  \\(l=nta\\log(2\\pi)+a\\log(\\lambda_1)+a(t-1)\\log(\\lambda_2)+at(n-1)\\log(\\lambda_3)+Q\\)  \\(Q=[\\boldsymbol{y}-(\\boldsymbol{j}_n\\otimes\\boldsymbol{j}_a\\otimes\\boldsymbol{I}_t)\\boldsymbol{\\mu}]&#39;\\boldsymbol{\\Sigma}^{-1}[\\boldsymbol{y}-(\\boldsymbol{j}_n\\otimes\\boldsymbol{j}_a\\otimes\\boldsymbol{I}_t)\\boldsymbol{\\mu}]\\). \\(Q\\)  \\[Q=\\frac1{\\lambda_1}\\boldsymbol y^{\\prime}\\boldsymbol A_1\\boldsymbol y+\\frac1{\\lambda_2}\\boldsymbol y^{\\prime}\\boldsymbol A_2\\boldsymbol y+\\frac1{\\lambda_3}\\boldsymbol y^{\\prime}\\boldsymbol A_3\\boldsymbol y+\\frac1{\\lambda_1}nat(\\bar{y}_{\\cdot\\cdot\\cdot}-\\bar{\\mu}_{\\cdot})^2+\\frac{na}{\\lambda_2}\\sum_{i=1}^t(\\bar{y}_{i\\cdot\\cdot}-\\bar{y}_{\\cdot\\cdot\\cdot}+\\bar{\\mu}_{\\cdot}-\\mu_{i})^2\\]  \\[\\begin{aligned} &amp;\\boldsymbol{y^{\\prime}}\\boldsymbol A_1\\boldsymbol{y} \\left.=\\boldsymbol y^{\\prime}{\\left[\\frac1n\\boldsymbol J_n\\right.}\\otimes\\left(\\boldsymbol I_a-\\frac1a\\boldsymbol J_a\\right)\\otimes\\frac1t\\boldsymbol J_t\\right]\\boldsymbol{y}=SSA \\\\ &amp;\\boldsymbol{y&#39;A}_2\\boldsymbol{y} \\left.=\\boldsymbol y^{\\prime}{\\left[\\frac1n\\boldsymbol J_n\\right.}\\otimes\\left(\\boldsymbol I_a-\\frac1a\\boldsymbol J_a\\right)\\otimes\\left(\\boldsymbol I_t-\\frac1t\\boldsymbol J_t\\right)\\right]\\boldsymbol{y}=SSTA \\\\ &amp;\\boldsymbol{y&#39;A_3}\\boldsymbol{y} =\\boldsymbol y^{\\prime}\\bigg[\\left(\\boldsymbol I_n-\\frac1n\\boldsymbol J_n\\right)\\otimes \\boldsymbol I_a\\otimes \\boldsymbol I_t\\bigg]\\boldsymbol{y}=SSERROR \\end{aligned}\\] \\(-2 \\log(\\text{likelihood})\\)  \\[\\begin{aligned} l =&amp;\\,nta\\log(2\\pi)+a\\log(\\lambda_1)+a(t-1)\\log(\\lambda_2)+at(n-1)\\log(\\lambda_3) \\\\ &amp;+\\frac1{\\lambda_3}SSERROR+\\frac1{\\lambda_1}SSA+\\frac1{\\lambda_2}SSTA+\\frac1{\\lambda_1}nat(\\bar{y}_{\\cdot\\cdot\\cdot}-\\bar{\\mu}_{\\cdot})^2 \\\\ &amp;+\\frac{na}{\\lambda_2}\\sum_{i=1}^{t}(\\bar{y}_{i\\cdot\\cdot}-\\bar{y}_{\\cdot\\cdot\\cdot}+\\bar{\\mu}_{\\cdot}-\\mu_i)^2 \\end{aligned}\\]  \\(\\lambda_1,\\lambda_2,\\lambda_3,\\bar\\mu_{\\cdot}\\)  \\((\\mu_i-\\bar\\mu_{\\cdot})\\)  \\(l\\)  \\[\\begin{aligned} &amp;\\left.\\frac{\\partial l}{\\partial\\lambda_3}\\right|_{{\\mu}=\\hat{{\\mu}},{\\lambda}=\\hat{{\\lambda}}} =-\\frac{at(n-1)}{\\hat{\\lambda}_3}+\\frac{SSERROR}{\\hat{\\lambda}_3^2}=0\\Longrightarrow\\hat{\\lambda}_3^2=\\frac{SSERROR}{at(n-1)}=\\hat{\\sigma}_\\varepsilon^2 \\\\ &amp;\\left.\\frac{\\partial l}{\\partial\\lambda_2}\\right|_{{\\mu}=\\hat{{\\mu}},{\\lambda}=\\hat{{\\lambda}}} =-\\frac{a(n-1)}{\\hat{\\lambda}_2}+\\frac{SSTA}{\\hat{\\lambda}_2^2}=0\\Longrightarrow\\hat{\\lambda}_2^2=\\frac{SSTA}{a(n-1)} \\\\ &amp;\\left.\\frac{\\partial l}{\\partial\\lambda_1}\\right|_{{\\mu}=\\hat{{\\mu}},{\\lambda}=\\hat{{\\lambda}}} =-\\frac a{\\hat{\\lambda}_1}+\\frac{SSA}{\\hat{\\lambda}_1^2}=0\\Longrightarrow\\hat{\\lambda}_1^2=\\frac{SSA}a \\\\ &amp;\\left.\\frac{\\partial l}{\\partial\\bar{\\mu}.}\\right|_{{\\mu}=\\hat{{\\mu}},{\\lambda}=\\hat{{\\lambda}}} =\\frac{-2nat(\\bar{y}_{\\cdot\\cdot\\cdot}-\\hat{\\bar{\\mu}}_{\\cdot\\cdot\\cdot})}{\\hat{\\lambda}_1^2}=0\\Longrightarrow\\hat{\\bar{\\mu}}_{\\cdot\\cdot\\cdot}=\\bar{y}_{\\cdot\\cdot\\cdot} \\end{aligned}\\]  \\[\\left.\\frac{\\partial l}{\\partial\\mu_i-\\bar{\\mu}_{\\cdot}}\\right|_{{\\mu}=\\hat{{\\mu}},{\\lambda}=\\hat{{\\lambda}}}=\\frac{-2na(\\bar{y}_{i\\cdot\\cdot}-\\bar{y}_{\\cdot\\cdot\\cdot}+(\\hat{\\mu}_i-\\hat{\\bar{\\mu}}_\\cdot))}{\\hat{\\lambda}_2}=0\\Longrightarrow(\\hat{\\mu}_i-\\hat{\\bar{\\mu}}_{\\cdot})=\\bar{y}_{i\\cdot\\cdot}-\\bar{y}_{\\cdot\\cdot\\cdot}\\]  \\(\\hat{\\bar{{\\mu}}_i}=\\bar{y}_{i\\cdot\\cdot}\\).  \\(\\lambda_1=\\sigma_\\varepsilon^2+n\\sigma_g^2+nt\\sigma_a^2,\\lambda_2=\\sigma_\\varepsilon^2+n\\sigma_g^2\\)  \\(\\lambda_3=\\sigma_\\varepsilon^2\\)  \\[\\hat{\\sigma}_\\varepsilon^2=\\hat{\\lambda}_g,\\quad\\hat{\\sigma}_g^2=\\begin{cases}\\dfrac{\\hat{\\lambda}_2-\\hat{\\lambda}_3}n&amp;\\mathrm{if~}\\hat{\\lambda}_2\\geq\\hat{\\lambda}_3\\\\0&amp;\\mathrm{if~}\\hat{\\lambda}_2&lt;\\hat{\\lambda}_3\\end{cases},\\quad\\mathrm{and}\\quad\\hat{\\sigma}_a^2=\\begin{cases}\\dfrac{\\hat{\\lambda}_1-\\hat{\\lambda}_2}{nt}&amp;\\mathrm{if~}\\hat{\\lambda}_1\\geq\\hat{\\lambda}_2\\\\0&amp;\\mathrm{if~}\\hat{\\lambda}_1&lt;\\hat{\\lambda}_2\\end{cases}\\] \\(\\hat{\\sigma}_\\varepsilon^2\\)  \\({\\sigma}_\\varepsilon^2\\)  \\(\\hat{\\sigma}_a^2,\\hat{\\sigma}_g^2\\)  \\({\\sigma}_a^2,{\\sigma}_g^2\\)  22.2.3  Corbeil and Searle (1976)  (restricted maximum likelihood estimators)  REML  \\(\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_k\\boldsymbol u_k+\\boldsymbol{\\varepsilon}\\)  22.1  \\(\\boldsymbol X\\)  p.  \\(H\\)  N-p  N × (N - p)  \\(\\boldsymbol {HH}^\\prime = (\\boldsymbol I - \\boldsymbol X\\boldsymbol X^- )\\) \\[\\boldsymbol z=\\begin{bmatrix}\\boldsymbol z_1\\\\\\boldsymbol z_2\\end{bmatrix}=\\begin{bmatrix}\\boldsymbol X^{\\prime}\\\\\\boldsymbol H^{\\prime}\\end{bmatrix}\\boldsymbol y\\]  \\[\\begin{bmatrix}\\boldsymbol X^{\\prime}\\\\\\boldsymbol H^{\\prime}\\end{bmatrix}\\]  N × N  \\(\\boldsymbol y\\)  \\(\\boldsymbol z\\)  \\[\\boldsymbol z=\\begin{bmatrix}\\boldsymbol{z}_1\\\\\\boldsymbol{z}_2\\end{bmatrix}\\]  \\[\\left.\\begin{bmatrix}\\boldsymbol z_1\\\\\\boldsymbol z_2\\end{bmatrix}\\thicksim N\\left[\\begin{bmatrix}\\boldsymbol X^{\\prime}\\boldsymbol X\\boldsymbol{\\beta}\\\\\\boldsymbol 0\\end{bmatrix}\\right.,\\begin{bmatrix}\\boldsymbol X^{\\prime}\\boldsymbol{\\Sigma}\\boldsymbol X&amp;\\boldsymbol X^{\\prime}\\boldsymbol{\\Sigma}\\boldsymbol H\\\\\\boldsymbol H^{\\prime}\\boldsymbol{\\Sigma}\\boldsymbol X&amp;\\boldsymbol H^{\\prime}\\boldsymbol{\\Sigma}\\boldsymbol H\\end{bmatrix}\\right]\\] \\[\\boldsymbol z=\\begin{bmatrix}\\boldsymbol{z}_1\\\\\\boldsymbol{z}_2\\end{bmatrix}\\]  \\(\\boldsymbol z_2\\)  \\(\\boldsymbol z_1\\)  \\(\\boldsymbol z_2\\) \\(\\boldsymbol z_2\\) \\(\\boldsymbol z_2\\)  \\[L_{\\boldsymbol H}(\\boldsymbol z_2)=L_{\\boldsymbol H}(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2,\\sigma_\\varepsilon^2)=(2\\pi)^{-(n-p)/2}|\\boldsymbol{H^{\\prime}\\Sigma H}|^{-1/2}\\exp\\left[-\\frac12\\boldsymbol{yH}(\\boldsymbol H^{\\prime}\\boldsymbol \\Sigma \\boldsymbol H)^{-1}\\boldsymbol H^{\\prime}\\boldsymbol y\\right]\\]  REML  \\(L_{\\boldsymbol H}(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2,\\sigma_\\varepsilon^2)\\)  \\(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2,\\sigma_\\varepsilon^2\\)  \\(\\boldsymbol z_2\\).  22.2  \\(\\boldsymbol r = \\boldsymbol H \\boldsymbol z_2\\) \\(\\boldsymbol z_2\\)   \\(l_R=\\log[L_{\\boldsymbol H}(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2,\\sigma_\\varepsilon^2)]\\)   22.2.2  \\[\\begin{aligned} L(\\mu,\\lambda_1,\\lambda_2,\\lambda_3) =&amp;\\,\\left[\\left((2\\pi)^{1/2}\\lambda_1^{1/2}\\right)^{-1}\\exp\\biggl(-\\frac{nat}{2\\lambda_1}(\\bar{y}_{\\cdot\\cdot\\cdot}-\\bar{\\mu}_{\\cdot})^2\\biggr)\\biggr]\\times\\biggl[(2\\pi)^{(t-1)/2}\\lambda_2^{(t-1)/2}\\biggr]^{-1}\\right. \\\\ &amp;\\times\\exp\\left[-\\frac{na}{2\\lambda_2}\\sum_{i=1}^t(\\bar{y}_{i\\cdot\\cdot}-\\bar{y}_{\\cdot\\cdot\\cdot}-\\mu_i+\\bar{\\mu}_{\\cdot})^2\\right]\\times\\left[(2\\pi)^{(nat-t)/2}\\lambda_1^{(a-1)/2}\\lambda_2^{(a-1)(t-1)/2}\\lambda_3^{at(n-1)/2}\\right]^{-1} \\\\ &amp;\\times\\exp\\left[-\\frac12{\\left(\\frac{SSERROR}{\\lambda_3}+\\frac{SSA}{\\lambda_1}+\\frac{SSTA}{\\lambda_2}\\right)}\\right] \\\\ =&amp;\\,L(\\bar{\\mu}_\\cdot)\\times L(\\mu_i-\\bar{\\mu}_\\cdot)\\times L(\\lambda_1,\\lambda_2,\\lambda_3)\\mathrm{~(say)} \\end{aligned}\\] \\(\\lambda_1,\\lambda_2,\\lambda_3\\)  REML  \\(-2\\log[L(\\lambda_1,\\lambda_2,\\lambda_3)]\\)  \\(l_R\\)  \\(\\lambda_1,\\lambda_2,\\lambda_3\\)  \\[\\begin{aligned} &amp;\\left.\\frac{\\partial l_R}{\\partial\\lambda_1}\\right|_{\\lambda=\\hat{\\lambda}} =\\frac{(a-1)}{\\hat{\\lambda}_1}-\\frac{SSA}{\\hat{\\lambda}_1^2}=0\\Rightarrow\\hat{\\lambda}_1=\\frac{SSA}{a-1} \\\\ &amp;\\left.\\frac{\\partial l_R}{\\partial\\lambda_2}\\right|_{\\lambda=\\hat{\\lambda}} =\\frac{(a-1)(t-1)}{\\hat{\\lambda}_2}-\\frac{SSTA}{\\hat{\\lambda}_2^2}=0\\Rightarrow\\hat{\\lambda}_2=\\frac{SSTA}{(a-1)(t-1)} \\\\ &amp;\\left.\\frac{\\partial l_R}{\\partial\\lambda_3}\\right|_{\\lambda=\\hat{\\lambda}} =\\frac{at(n-1)}{\\hat{\\lambda}_3}-\\frac{SSERROR}{\\hat{\\lambda}_3^2}=0\\Rightarrow\\hat{\\lambda}_3=\\frac{SSERROR}{at(n-1)} \\end{aligned}\\]  \\[\\hat{\\sigma}_\\varepsilon^2=\\hat{\\lambda}_3,\\quad\\hat{\\sigma}_g^2=\\begin{cases}\\frac{\\hat{\\lambda}_2-\\hat{\\lambda}_3}n&amp;\\mathrm{~if~}\\hat{\\lambda}_2\\geq\\hat{\\lambda}_3\\\\0&amp;\\mathrm{~if~}\\hat{\\lambda}_2&lt;\\hat{\\lambda}_3\\end{cases},\\quad\\mathrm{~and~}\\quad\\hat{\\sigma}_a^2=\\begin{cases}\\frac{\\hat{\\lambda}_1-\\hat{\\lambda}_2}n&amp;\\mathrm{~if~}\\hat{\\lambda}_1\\geq\\hat{\\lambda}_2\\\\0&amp;\\mathrm{~if~}\\hat{\\lambda}_1&lt;\\hat{\\lambda}_2&amp;\\end{cases}\\] REML  22.2.4 MINQUE   MINQUE  19.3  \\(\\boldsymbol j_n\\mu\\) \\(\\boldsymbol{Xb}\\).  (Swallow and Searle, 1978) \\(\\boldsymbol \\sigma=(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2,\\sigma_\\varepsilon^2)^{\\prime}\\)  MINQUE  \\(\\boldsymbol{\\hat{\\sigma}}=\\boldsymbol{S}^{-1}\\boldsymbol{q}\\)  \\(\\boldsymbol S\\)  \\(s_{ii^{\\prime}}=\\mathrm{tr}[\\boldsymbol{Z}_i\\boldsymbol{Z}_i^{\\prime}\\boldsymbol{R}\\boldsymbol{Z}_{i^{\\prime}}\\boldsymbol{Z}_i^{\\prime}],i,i^{\\prime}=1,2,\\ldots,k+1\\) \\(i=k+1\\)  \\(\\boldsymbol \\varepsilon\\)  \\(\\boldsymbol Z_{k+1}=\\boldsymbol I_n\\) \\[\\boldsymbol R=\\boldsymbol{\\Sigma}^{-1}[\\boldsymbol I_n-\\boldsymbol{X}(\\boldsymbol X^{\\prime}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{X})^-\\boldsymbol{X}^{\\prime}]\\boldsymbol{\\Sigma}^{-1}\\]  \\(\\boldsymbol q\\)  \\(\\boldsymbol{q}_i=\\boldsymbol{y}^{\\prime}\\boldsymbol{R}\\boldsymbol{Z}_i\\boldsymbol{Z}_i^{\\prime}\\boldsymbol{R}\\boldsymbol{y},{i}=1,{2},\\ldots,{k}+1\\).  \\(\\boldsymbol \\Sigma\\)  MINQUE  1 0.  \\(\\boldsymbol \\Sigma\\)  (One-iteration) MINQUE  (zero iteration) 23  22.3   22.3.1   \\(\\boldsymbol \\beta\\)  \\[\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol \\varepsilon\\quad\\mathrm{~where~Var}(\\boldsymbol \\varepsilon)=\\boldsymbol{\\Sigma}\\]  \\[\\boldsymbol{\\Sigma}={\\sigma}_1^2\\boldsymbol{Z}_1\\boldsymbol{Z}_2^{\\prime}+{\\sigma}_2^2\\boldsymbol{Z}_2\\boldsymbol{Z}_2^{\\prime}+\\cdots+{\\sigma}_k^2\\boldsymbol{Z}_k\\boldsymbol{Z}_k^{\\prime}+{\\sigma}_\\varepsilon^2\\boldsymbol{I}_N\\]  \\(\\boldsymbol a^\\prime \\boldsymbol \\beta\\)  \\(\\boldsymbol c\\)  \\(E(\\boldsymbol c^\\prime \\boldsymbol y) = \\boldsymbol a^\\prime \\boldsymbol \\beta\\)  6 \\(\\boldsymbol a^\\prime \\boldsymbol \\beta\\)  \\(\\boldsymbol a^\\prime \\hat {\\boldsymbol \\beta}\\) \\(\\boldsymbol \\beta\\)  \\(\\hat {\\boldsymbol \\beta}\\)  \\(\\boldsymbol \\beta\\)  \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  (ordinary least squares estimator)  \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_{LS}\\)  \\(\\boldsymbol{\\hat{\\beta}}_{LS}=(\\boldsymbol{X}^{\\prime}\\boldsymbol{X})^-\\boldsymbol{X}^{\\prime}\\boldsymbol{y}\\)  \\(\\boldsymbol{X&#39;X\\hat{\\boldsymbol{\\beta}}}=\\boldsymbol{X&#39;y}\\)  \\(\\hat{\\boldsymbol \\beta}\\)32\\(\\boldsymbol \\beta\\)  \\(\\boldsymbol y\\)  \\(\\boldsymbol \\Sigma\\).  \\(\\boldsymbol \\Sigma\\)  \\(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_k^2\\)  \\(\\sigma_\\varepsilon^2\\)  \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  (best linear unbiased estimator, BLUE)  \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_{BLUE}\\) \\(\\hat{\\boldsymbol\\beta}_{BLUE} = \\left(\\boldsymbol{X&#39;\\Sigma}^{-1}\\boldsymbol{X}\\right)^-\\boldsymbol{X&#39;\\Sigma}^{-1}\\boldsymbol{y}\\)  \\(\\boldsymbol{X&#39;\\Sigma^{-1}}\\boldsymbol{X\\hat{\\beta}}_{BLUE}\\boldsymbol{=X&#39;\\Sigma^{-1}y}\\)  \\(\\hat{\\boldsymbol \\beta}_{BLUE}\\). \\(\\boldsymbol{\\hat{\\beta}}_{BLUE}=\\boldsymbol{\\hat{\\beta}}_{LS}\\). \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  BLUE  \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_{LS}\\) \\(\\hat{\\boldsymbol{\\beta}}_{LS}=(\\boldsymbol{X}^{\\prime}\\boldsymbol{X})^{-}\\boldsymbol{X}^{\\prime}\\boldsymbol{y}\\)  (life is not so easy).  BLUE  (weighted least squares estimator) \\(\\hat{\\boldsymbol\\Sigma}\\)  \\[\\hat{\\boldsymbol{\\Sigma}}=\\hat{{\\sigma}}_1^2\\boldsymbol Z_1\\boldsymbol Z_1^{\\prime}+\\hat{{\\sigma}}_2^2\\boldsymbol Z_2\\boldsymbol Z_2^{\\prime}+\\cdots+\\hat{{\\sigma}}_k^2\\boldsymbol Z_k\\boldsymbol Z_k^{\\prime}+\\hat{{\\sigma}}_\\varepsilon^2\\boldsymbol I_N\\] \\(\\hat{{\\sigma}}_1^2,\\hat{{\\sigma}}_2^2,\\ldots,\\hat{{\\sigma}}_k^2\\)  \\(\\hat{{\\sigma}}_\\varepsilon^2\\)  22.2 \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  (estimated BLUE, EBLUE)  \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_W\\) \\(\\boldsymbol{\\hat{\\beta}}_W=\\left(\\boldsymbol{X}^{\\prime}{\\hat{\\boldsymbol{\\Sigma}}}^{-1}\\boldsymbol{X}\\right)^{-}\\boldsymbol{X&#39;}{\\hat{\\boldsymbol{\\Sigma}}}^{-1}\\boldsymbol{y}\\)  \\({\\boldsymbol X&#39;\\hat{\\boldsymbol\\Sigma}^{-1}}\\boldsymbol{X\\hat{\\beta}}_{W}={\\boldsymbol X&#39;\\hat{\\boldsymbol\\Sigma}^{-1}\\boldsymbol y}\\)  \\(\\boldsymbol{\\hat{\\beta}}_W\\). \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_W\\)  \\(\\boldsymbol a^\\prime {\\boldsymbol\\beta}\\). \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_W\\)  \\(\\mathrm{Var}(\\boldsymbol a^{\\prime}\\boldsymbol{\\hat{\\beta}}_W)=\\boldsymbol a^{\\prime}\\left(\\boldsymbol{X&#39;\\hat{\\Sigma}}^{-1}\\boldsymbol{X}\\right)^-\\boldsymbol{a}\\).  \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_W\\) Kackar and Harville (1984) \\(\\boldsymbol a^{\\prime}\\left(\\boldsymbol{X&#39;\\hat{\\Sigma}}^{-1}\\boldsymbol{X}\\right)^-\\boldsymbol{a}\\) Kackar and Harville (1984)  Kenward and Roger (1997)  SAS-Mixed  DDFM = KR  Satterthwaite  KR   \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\) \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_{ML}\\) \\(\\hat{\\boldsymbol\\beta}_{ML}\\)  (unrestricted likelihood equations) \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_{ML}\\)  \\(\\boldsymbol a^{\\prime} \\boldsymbol W \\boldsymbol a\\) \\(\\boldsymbol W\\)  \\(\\hat{\\boldsymbol\\beta}_{ML}\\) 33 23  22.3.2   \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_W\\)  \\(\\boldsymbol a^{\\prime}\\boldsymbol{\\hat{\\beta}}_W\\thicksim N\\left[\\boldsymbol a^{\\prime}\\boldsymbol{\\beta},\\boldsymbol{a}^{\\prime}\\left(\\boldsymbol X^{\\prime}\\boldsymbol{\\hat{\\Sigma}}^{-1}\\boldsymbol X\\right)^-\\boldsymbol{a}\\right]\\) \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  \\((1 - \\alpha)100\\%\\)  \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  \\(\\boldsymbol\\beta\\) \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_W\\)  \\(\\widehat{s.e.}\\left(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_W\\right)=\\sqrt{\\boldsymbol{a}^{\\prime}\\left(\\boldsymbol X^{\\prime}\\boldsymbol{\\hat{\\Sigma}}^{-1}\\boldsymbol X\\right)^-\\boldsymbol{a}}\\).  Kackar-Harville  Satterthwaite  (Geisbrecht and Burns, 1985)  \\[\\hat{v}=\\frac{2\\left[\\boldsymbol a^{\\prime}\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol \\Sigma}^{-1}\\boldsymbol X\\right)^-\\boldsymbol a\\right]^2}{\\widehat{\\mathrm{Var}}\\left[\\boldsymbol a^{\\prime}\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol \\Sigma}^{-1}\\boldsymbol X\\right)^-\\boldsymbol a\\right]}\\]  \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  \\((1 - \\alpha)100\\%\\)  \\[{\\boldsymbol a&#39;\\hat{\\boldsymbol{\\beta}}}_W\\pm\\left(t_{\\alpha/2,\\hat{v}}\\right)\\sqrt[]{\\boldsymbol{a&#39;}\\left(\\boldsymbol{X&#39;\\hat{\\boldsymbol{\\Sigma}}}^{-1}\\boldsymbol{X}\\right)^-\\boldsymbol{a}}\\]  \\(\\boldsymbol a_1^\\prime \\hat{\\boldsymbol\\beta},\\boldsymbol a_2^\\prime \\hat{\\boldsymbol\\beta},\\ldots,\\boldsymbol a_m^\\prime \\hat{\\boldsymbol\\beta}\\)  3  22.3.3   \\(H_0{:\\boldsymbol{H\\beta}}=\\boldsymbol{b}\\mathrm{~vs~}H_a{:\\boldsymbol{H\\beta}}\\neq\\boldsymbol{b}\\)  \\[Q=(\\boldsymbol H\\hat{\\boldsymbol \\beta}_W-\\boldsymbol b)^{\\prime}\\left[\\boldsymbol H\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol \\Sigma}^{-1}\\boldsymbol X\\right)^{-}\\boldsymbol H^{\\prime}\\right]^{-1}(\\boldsymbol H\\hat{\\boldsymbol \\beta}_W-\\boldsymbol b)\\] \\(Q\\)  \\(\\chi^2_q\\) \\(q=\\text{rank}(\\boldsymbol H)\\).  \\(q\\)  \\(\\boldsymbol H\\)  \\(\\boldsymbol \\beta\\)  \\(F_c = Q/v\\) v  \\(\\boldsymbol H\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol \\Sigma}^{-1}\\boldsymbol X\\right)^{-}\\boldsymbol H^{\\prime}\\)  (SAS Institute, Inc., 1999)  \\(\\boldsymbol H\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol \\Sigma}^{-1}\\boldsymbol X\\right)^{-}\\boldsymbol H^{\\prime}\\) \\(\\boldsymbol H\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol \\Sigma}^{-1}\\boldsymbol X\\right)^{-}\\boldsymbol H^{\\prime}=\\boldsymbol P^{\\prime}\\boldsymbol \\Delta \\boldsymbol P\\) \\(\\boldsymbol \\Delta\\)  q × q   \\(\\boldsymbol H\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol \\Sigma}^{-1}\\boldsymbol X\\right)^{-}\\boldsymbol H^{\\prime}\\) \\(\\boldsymbol P\\)  q × q  \\(\\boldsymbol h_s\\)  \\(\\boldsymbol{PH}\\)  s  \\(v_s=2d_s^2/(\\boldsymbol \\xi_s^{\\prime}\\boldsymbol \\Omega\\boldsymbol \\xi_s)\\)34  \\[\\boldsymbol \\xi_s=\\frac{\\partial\\left[\\boldsymbol{h&#39;}_s\\left(\\boldsymbol{X&#39;\\Sigma}^{-1}\\boldsymbol{X}\\right)^-\\boldsymbol{h}_s\\right]}{\\partial\\boldsymbol{\\sigma}}\\]  \\(\\boldsymbol\\Omega\\)  \\(\\hat{\\boldsymbol \\sigma}\\)  \\[\\zeta=\\sum_{s=1}^q\\frac{V_s}{V_s-2}\\mathrm{In}(v_s&gt;2)\\]  \\(\\mathrm{In}(v_s &gt; 2)\\)  \\(v_s \\le 2\\)  \\(F_c\\)  \\[v=\\begin{cases}\\frac{2\\zeta}{\\zeta-q}&amp;\\mathrm{if~}\\zeta&gt;q\\\\0&amp;\\mathrm{if~}\\zeta&gt;q&amp;\\end{cases}\\]  23  22.4   \\(\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol \\varepsilon\\) \\(\\mathrm{Var}(\\varepsilon) = \\boldsymbol \\Sigma\\).  \\(\\boldsymbol\\omega\\) \\(\\boldsymbol\\omega\\thicksim N(\\boldsymbol k^\\prime\\boldsymbol\\beta,\\boldsymbol \\sigma_\\omega^2)\\)  \\(\\operatorname{Cov}(\\boldsymbol y,\\boldsymbol\\omega)=\\boldsymbol c\\) \\(\\boldsymbol\\omega\\) \\(\\boldsymbol\\omega\\)  (best linear unbiased predictor, BLUP) \\(\\tilde{\\boldsymbol{\\omega}}=\\boldsymbol{a&#39;y}+b\\) \\(E(\\tilde{\\boldsymbol\\omega})=\\boldsymbol k^{\\prime}{\\boldsymbol\\beta}\\)  \\(E(\\tilde{\\boldsymbol\\omega}-\\boldsymbol\\omega)^2\\)   \\(\\boldsymbol\\omega\\)  BLUP  \\(\\tilde{\\boldsymbol{\\omega}}=\\boldsymbol{c&#39;\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\hat{\\beta}}_{BLUE})+\\boldsymbol{k&#39;}\\boldsymbol{\\hat{\\beta}}_{BLUE}\\).  \\(\\boldsymbol \\Sigma\\) \\(\\boldsymbol\\omega\\)  (estimated BLUP, EBLUP)  \\[\\hat{\\tilde{\\boldsymbol \\omega}}=c^{\\prime}\\boldsymbol{\\hat{\\Sigma}}^{-1}(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\hat{\\beta}}_W)+\\boldsymbol{k}^{\\prime}\\boldsymbol{\\hat{\\beta}}_W\\]  \\(\\boldsymbol{k}^{\\prime}\\boldsymbol{\\beta}=0\\)  \\(\\hat{\\boldsymbol{\\tilde{\\omega}}}=\\boldsymbol{c}^{\\prime}\\boldsymbol{\\hat{\\Sigma}}^{-1}(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\hat{\\beta}}_W)\\) \\(\\boldsymbol{y}=\\boldsymbol{X\\beta}+\\boldsymbol{Z}\\boldsymbol{u}+\\boldsymbol{\\varepsilon}\\)  \\(\\boldsymbol u \\thicksim N(\\boldsymbol 0,\\boldsymbol G)\\)  \\(\\boldsymbol \\varepsilon \\thicksim N(\\boldsymbol 0, \\boldsymbol R)\\)\\(\\boldsymbol y\\)  \\(\\boldsymbol u\\)  \\(\\operatorname{Cov}(\\boldsymbol y,\\boldsymbol u)=\\boldsymbol G\\boldsymbol{Z}^{\\prime}\\)  \\(\\boldsymbol u\\)  BLUP  \\(\\tilde{\\boldsymbol{u}}=\\boldsymbol G\\boldsymbol{Z}^{\\prime}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\hat{\\beta}})\\). 22.5  Henderson (1984)  (mixed model equations) \\(\\boldsymbol \\beta\\)  \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\)  BLUE  \\(\\boldsymbol u=(\\boldsymbol u_1^{\\prime},\\boldsymbol u_2^{\\prime},\\ldots,\\boldsymbol u_k^{\\prime})^{\\prime}\\)  BLUPs.  \\(\\boldsymbol{y}=\\boldsymbol{X\\beta}+\\boldsymbol{Z}\\boldsymbol{u}+\\boldsymbol{\\varepsilon}\\) \\[\\begin{aligned} \\boldsymbol{Z}\\boldsymbol u&amp;=\\boldsymbol{Z}_1\\boldsymbol u_1+\\boldsymbol{Z}_2\\boldsymbol u_2+\\cdots+\\boldsymbol{Z}_k\\boldsymbol u_k \\\\ \\boldsymbol u_i&amp;\\thicksim N(\\boldsymbol 0,\\sigma_i^2\\boldsymbol I_{n_i}),\\quad i=1,2,\\ldots,k \\\\ \\boldsymbol{\\varepsilon}&amp;\\thicksim N(\\boldsymbol{0},{\\sigma}_\\varepsilon^2\\boldsymbol{I}_N) \\end{aligned}\\]  \\(\\boldsymbol{u}_1,\\boldsymbol{u}_2,\\ldots,\\boldsymbol{u}_k,\\boldsymbol{\\varepsilon}\\)   \\[\\boldsymbol{u}=\\begin{bmatrix}\\boldsymbol{u}_1\\\\\\boldsymbol{u}_2\\\\\\vdots\\\\\\boldsymbol{u}_k\\end{bmatrix}\\thicksim N(\\boldsymbol{0},\\boldsymbol{G})\\]  \\[\\boldsymbol{G}=\\begin{bmatrix}{\\sigma}_1^2\\boldsymbol{I}_{n_1}&amp;0&amp;\\cdots&amp;0\\\\0&amp;{\\sigma}_2^2\\boldsymbol{I}_{n_2}&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;0&amp;\\cdots&amp;{\\sigma}_k^2\\boldsymbol{I}_{n_k}\\end{bmatrix}\\] \\(\\boldsymbol y\\)  \\(\\boldsymbol y\\thicksim N(\\boldsymbol X\\boldsymbol{\\beta},\\boldsymbol{\\Sigma})\\)  \\[\\mathrm{Var}(\\boldsymbol y)=\\boldsymbol{\\Sigma}=\\sum_{i=1}^k{\\sigma}_i^2\\boldsymbol{Z}_i\\boldsymbol{Z}_i^{\\prime}+\\boldsymbol{\\sigma}_\\varepsilon^2\\boldsymbol{I}=\\boldsymbol{Z}\\boldsymbol{G}\\boldsymbol{Z}^{\\prime}={\\sigma}_\\varepsilon^2\\boldsymbol{I}_N\\]  \\(\\operatorname{Cov}(\\boldsymbol{y},\\boldsymbol{u})=\\boldsymbol{G}\\boldsymbol{Z}^{\\prime}\\). \\(\\boldsymbol y\\)  \\(\\boldsymbol u\\)  \\[\\begin{bmatrix}\\boldsymbol{u}\\\\\\boldsymbol{y}\\end{bmatrix}\\thicksim N\\left(\\begin{bmatrix}\\boldsymbol{0}\\\\\\boldsymbol{X}\\boldsymbol{\\beta}\\end{bmatrix},\\begin{bmatrix}\\boldsymbol{G}&amp;\\boldsymbol{G}\\boldsymbol{Z}^{\\prime}\\\\\\boldsymbol{Z}\\boldsymbol{G}^{\\prime}&amp;\\boldsymbol{\\Sigma}\\end{bmatrix}\\right)\\]  \\(\\boldsymbol u\\)  \\(\\boldsymbol y\\)  \\(\\boldsymbol{y}|\\boldsymbol{u}\\sim N(\\boldsymbol{X\\beta}+\\boldsymbol{Zu},\\sigma_\\varepsilon^2\\boldsymbol{I})\\)  \\(\\boldsymbol u\\)  \\(\\boldsymbol{u}\\thicksim N(\\boldsymbol{0},\\boldsymbol{G})\\). \\(\\boldsymbol y\\)  \\(\\boldsymbol u\\)  \\(\\boldsymbol u\\)  \\(\\boldsymbol y\\)  \\(\\boldsymbol u\\)  \\[\\begin{aligned} h(\\boldsymbol y,\\boldsymbol u)&amp;=f(\\boldsymbol y|\\boldsymbol u)g(\\boldsymbol u) \\\\ &amp;=[2\\pi\\sigma_\\varepsilon^2]^{-(N/2)}\\exp\\left[-\\frac1{2\\sigma_\\varepsilon^2}\\left(\\boldsymbol y-\\boldsymbol X\\boldsymbol{\\beta}-\\boldsymbol Z\\boldsymbol{u}\\right)^{\\prime}\\left(\\boldsymbol y-\\boldsymbol X\\boldsymbol{\\beta}-\\boldsymbol Z\\boldsymbol{u}\\right)\\right][2\\pi]^{-(q/2)}|\\boldsymbol{G}|^{-1/2}\\exp(-\\frac12\\boldsymbol{u}\\boldsymbol G^{-1}\\boldsymbol{u}) \\end{aligned}\\]  \\(q=n_1+n_2+\\ldots,n_k\\).  \\(\\boldsymbol \\beta\\)  BLUE  \\(\\boldsymbol u\\)  BLUPsHenderson (1984)  \\(\\boldsymbol \\beta\\)  \\(\\boldsymbol u\\)  \\(-2\\log[f(\\boldsymbol y|\\boldsymbol u)g(\\boldsymbol u)]\\) 35 \\[\\begin{aligned} -2\\log[f(\\boldsymbol y|\\boldsymbol u)g(\\boldsymbol u)] =&amp;\\,(N+q)\\mathrm{log}(2\\pi)+N\\mathrm{log}(\\sigma_\\varepsilon^2)+\\mathrm{log}|\\boldsymbol G| \\\\ &amp;+\\frac1{\\sigma_\\varepsilon^2}(\\boldsymbol y-\\boldsymbol X\\boldsymbol{\\beta}-\\boldsymbol Z\\boldsymbol{u})^{\\prime}(\\boldsymbol y-\\boldsymbol X\\boldsymbol{\\beta}-\\boldsymbol Z\\boldsymbol{u})+\\boldsymbol u^{\\prime}\\boldsymbol G^{-1}\\boldsymbol{u} \\\\ =&amp;\\,h\\mathrm{~(say)} \\end{aligned}\\\\ \\frac{\\partial h}{\\partial\\boldsymbol{\\beta}}=\\frac2{\\sigma_\\varepsilon^2}\\boldsymbol X^{\\prime}(\\boldsymbol y-\\boldsymbol X\\boldsymbol{\\beta}-\\boldsymbol Z\\boldsymbol{u}),\\quad\\frac{\\partial h}{\\partial\\boldsymbol{u}}=\\frac2{\\sigma_\\varepsilon^2}\\boldsymbol Z^{\\prime}(\\boldsymbol y-\\boldsymbol X\\boldsymbol{\\beta}-\\boldsymbol Z\\boldsymbol{u})+2\\boldsymbol G^{-1}\\boldsymbol{u}\\]  \\[\\begin{bmatrix}\\boldsymbol X^{\\prime}\\boldsymbol X&amp;\\boldsymbol X^{\\prime}\\boldsymbol{Z}\\\\\\boldsymbol{Z^{\\prime}}\\boldsymbol X&amp;(\\boldsymbol{Z^{\\prime}}\\boldsymbol{Z}+\\sigma_\\varepsilon^2\\boldsymbol{G^{-1}})\\end{bmatrix}{\\begin{bmatrix}\\hat{\\boldsymbol \\beta}_{BLUE}\\\\\\tilde{\\boldsymbol u}\\end{bmatrix}}={\\begin{bmatrix}\\boldsymbol X^{\\prime}\\boldsymbol y\\\\\\boldsymbol Z^{\\prime}\\boldsymbol{u}\\end{bmatrix}}\\]  \\(\\boldsymbol \\varepsilon\\) \\(\\boldsymbol R\\) \\[\\begin{bmatrix}\\boldsymbol X^{\\prime}\\boldsymbol R^{-1}\\boldsymbol X&amp;\\boldsymbol X^{\\prime}\\boldsymbol R^{-1}\\boldsymbol Z\\\\\\boldsymbol Z^{\\prime}\\boldsymbol R^{-1}\\boldsymbol X&amp;(\\boldsymbol Z^{\\prime}\\boldsymbol R^{-1}\\boldsymbol Z+\\boldsymbol G^{-1})\\end{bmatrix}\\begin{bmatrix}\\hat{\\boldsymbol\\beta}_{BLUE}\\\\\\tilde{\\boldsymbol u}\\end{bmatrix}=\\begin{bmatrix}\\boldsymbol X^{\\prime}\\boldsymbol R^{-1}\\boldsymbol y\\\\\\boldsymbol Z^{\\prime}\\boldsymbol R^{-1}\\boldsymbol u\\end{bmatrix}\\]  \\[\\hat{\\boldsymbol{\\beta}}=\\left(\\boldsymbol X^{\\prime}{\\boldsymbol{\\Sigma}}^{-1}\\boldsymbol X\\right)^{-}\\boldsymbol X^{\\prime}{\\boldsymbol{\\Sigma}}^{-1}\\boldsymbol y\\quad\\mathrm{and}\\quad\\tilde{\\boldsymbol{u}}=\\boldsymbol G\\boldsymbol Z^{\\prime}{\\boldsymbol{\\Sigma}}^{-1}(\\boldsymbol y-\\boldsymbol X\\hat{\\boldsymbol{\\beta}})\\] \\(\\boldsymbol{\\Sigma}\\)  BLUEEBLUE BLUPEBLUP \\[\\boldsymbol{\\hat{\\beta}_W}=\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol{\\Sigma}}^{-1}\\boldsymbol X\\right)^-\\boldsymbol{X}^{\\prime}\\boldsymbol{\\hat{\\Sigma}}^{-1}\\boldsymbol{y}\\quad\\mathrm{and}\\quad\\hat{\\tilde{\\boldsymbol u}}=\\boldsymbol{\\hat{G}}\\boldsymbol{Z}^{\\prime}\\boldsymbol{\\hat{\\Sigma}}^{-1}(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\hat{\\beta}})\\] 22.6   \\(F\\)  Satterthwaite  22.7  The ordinary least squares estimator of \\(\\boldsymbol a^\\prime \\boldsymbol\\beta\\) is \\(\\boldsymbol a^\\prime \\hat{\\boldsymbol\\beta}_{LS}\\) where \\(\\boldsymbol{\\hat{\\beta}}_{LS}=(\\boldsymbol{X}^{\\prime}\\boldsymbol{X})^-\\boldsymbol{X}^{\\prime}\\boldsymbol{y}\\) or some other solution for \\(\\hat{\\boldsymbol \\beta}\\) to the normal equations \\(\\boldsymbol{X&#39;X\\hat{\\boldsymbol{\\beta}}}=\\boldsymbol{X&#39;y}\\). where \\(\\boldsymbol W\\) is the partition of the generalized inverse of the information matrix corresponding to \\(\\hat{\\boldsymbol\\beta}_{ML}\\).  \\(d_s\\)  Henderson (1984) differentiated \\(-2\\log[f(\\boldsymbol y|\\boldsymbol u)g(\\boldsymbol u)]\\) with respect to \\(\\boldsymbol \\beta\\) and \\(\\boldsymbol u\\) to derive the mixed model equations whose solution provides the BLUE of estimable functions of \\(\\boldsymbol \\beta\\) and BLUPs of \\(\\boldsymbol u\\) as "],["chap23.html", " 23   23.1  23.2  23.3  JMP  23.4  23.5 ", "  23   Natural selection is a mechanism for generating an exceedingly high degree of improbability. - R. A. Fisher  22  23.1   23.1: - x 23.1   (machine)  (person)  n  t  b  \\[y_{ijk}=\\mu+\\tau_i+p_j+(\\tau p)_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b,\\quad k=1,2,\\ldots,n\\] \\(\\mu\\) \\(\\tau_i\\)  i \\(p_j\\)  j \\((\\tau p)_{ij}\\)  j  i \\(\\varepsilon_{ijk}\\)  j  k  i  \\(p_j,(\\tau p)_{ij},\\varepsilon_{ijk}\\)   \\[\\begin{aligned}p_j&amp;\\sim i.i.d.N(0,\\sigma_{person}^2)\\\\(\\tau p)_{ij}&amp;\\sim i.i.d.N(0,\\sigma_{m\\times p}^2)\\\\\\varepsilon_{ijk}&amp;\\sim i.i.d.N(0,\\sigma_{\\varepsilon}^2)\\end{aligned}\\]  \\({\\varepsilon}_{ijk}\\thicksim i.i.d.N(0,{\\sigma}_{\\varepsilon}^2)\\)  machine × person  SAS®-Mixed REML MINQUE0 III  23.2  23.3 REML MINQUE0  23.4  SAS-Mixed  REML  Method=ML, Method=MIVQUE0  Method=type3   23.2:  III  x  23.3:  REML, ML, MIVQUE0 III  x  23.4:  REML  SAS Mixed  x  \\(H_0\\colon{\\sigma}_{m\\times p}^2=0\\text{ vs }H_a\\colon{\\sigma}_{m\\times p}^2&gt;0\\).  23.2  \\[F_{m\\times p}=\\frac{MSPerson\\times Machine}{MSResidual}=46.13\\]  \\(F\\)  0.0001 \\({\\sigma}_{m\\times p}^2\\)  machine × person   machine × person  machine × person  pearson 6  machine 1  2  pearson 6  machine 3  \\(H_0\\colon{\\sigma}_{p}^2=0\\text{ vs }H_a\\colon{\\sigma}_{p}^2&gt;0\\).  23.2  \\[F_p=\\frac{MSPerson}{MSPerson\\times Machine}\\]  \\(H_0\\colon{\\sigma}_{p}^2=0\\text{ vs }H_a\\colon{\\sigma}_{p}^2&gt;0\\)  0.0089  23.3  REMLMIVQUE0  III  person  machine × person ML  Satterthwaite  23.2 \\({{\\sigma}}_p^2\\)  \\(\\hat{{\\sigma}}_p^2=\\frac19{ MSPerson }-\\frac19{ MSPerson }\\times Machine=22.8584\\).  Satterthwaite  \\[v=\\frac{(\\hat{\\sigma}_p^2)^2}{\\frac{[\\frac19MSPerson]^2}5+\\frac{[\\frac19MSPerson\\times Machine]^2}{10}}=3.38035\\] 95%  \\[\\chi_{.025,3.38}^2=10.0467\\quad\\mathrm{~and~}\\quad\\chi_{.975,3.38}^2=0.30725\\] \\({{\\sigma}}_p^2\\)  95%  \\[\\frac{3.38035(22.8584)}{10.0467}\\leq\\sigma_p^2\\leq\\frac{3.38035(22.8584)}{0.30725}\\]  \\[7.69102\\leq\\sigma_p^2\\leq251.486\\] \\({{\\sigma}}_p^2\\)  95%  \\(2.773\\leq\\sigma_p^2\\leq15.858\\).  23.5  III Z-value Pr Z  Z-value Lower  Upper  Wald \\(\\hat{{\\sigma}}^2\\pm Z_{0.025}[\\widehat{s.e.}(\\hat{{\\sigma}}^2)]\\). Wald  \\({\\sigma}_{{\\varepsilon}}^{{2}}\\)  36  23.6  REML   23.5:  III  x  23.6:  REML  x  23.5  23.6  Pr Z  23.6  \\(df=2(\\text{Z-value})^2\\)  36 REMLMIVQUE0  Wald  person  machine × person  REML  MIVQUE0 Satterthwaite   22.3   \\[\\boldsymbol y=\\boldsymbol X\\boldsymbol{\\beta}+\\boldsymbol Z_1\\boldsymbol u_1+\\boldsymbol Z_2\\boldsymbol u_2+\\cdots+\\boldsymbol Z_k\\boldsymbol u_k+\\boldsymbol{\\varepsilon}\\]  \\(\\boldsymbol{X}=[\\boldsymbol{j},\\boldsymbol{X}_1],\\boldsymbol{\\beta}=({\\mu},\\tau_1,\\tau_2,\\ldots,\\tau_t)&#39;\\)  \\[\\boldsymbol{\\Sigma}={\\sigma}_1^2\\boldsymbol{Z}_1\\boldsymbol{Z}_1&#39;+{\\sigma}_2^2\\boldsymbol{Z}_2\\boldsymbol{Z}_2&#39;+\\cdots+{\\sigma}_k^2\\boldsymbol{Z}_k\\boldsymbol{Z}_k&#39;+{\\sigma}_\\varepsilon^2\\boldsymbol{I}\\]  \\(\\boldsymbol a&#39;\\boldsymbol \\beta\\)  BLUE (best linear unbiased estimate)  \\[\\boldsymbol a&#39;\\hat{\\boldsymbol\\beta}_{BLUE} = \\boldsymbol a&#39;\\left(\\boldsymbol{X&#39;\\Sigma}^{-1}\\boldsymbol{X}\\right)^-\\boldsymbol{X&#39;\\Sigma}^{-1}\\boldsymbol{y}\\] \\(\\boldsymbol a&#39;\\boldsymbol \\beta\\)  \\[\\boldsymbol a&#39;\\hat{\\boldsymbol\\beta}_{BLUE} = \\boldsymbol a&#39;\\left(\\boldsymbol{X&#39;}\\boldsymbol{X}\\right)^-\\boldsymbol{X&#39;}\\boldsymbol{y}\\]  \\[y_{ijk}=\\mu_i+p_j+(\\tau p)_{ij}+\\varepsilon_{ijk}\\]  \\(\\mu_i=\\mu+\\tau_i\\)  \\(\\boldsymbol X_1\\)  \\(\\boldsymbol{\\mu}=(\\mu_1,\\mu_2,\\ldots,\\mu_t)^{\\prime}\\)  nbt × t   \\[\\boldsymbol{X}_1=\\begin{bmatrix}\\boldsymbol{j}_{nb}&amp;0&amp;0&amp;\\cdots&amp;0\\\\0&amp;\\boldsymbol{j}_{nb}&amp;0&amp;\\cdots&amp;0\\\\0&amp;0&amp;\\boldsymbol{j}_{nb}&amp;\\cdots&amp;0\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;0&amp;0&amp;\\cdots&amp;\\boldsymbol{j}_{nb}\\end{bmatrix}=\\boldsymbol{j}_n\\otimes\\boldsymbol{j}_b\\otimes\\boldsymbol{I}_t\\]  \\[\\boldsymbol{\\Sigma}=\\sigma_p^2(\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_b\\otimes\\boldsymbol{J}_t)+\\sigma_{m\\times p}^2(\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_b\\otimes\\boldsymbol{I}_t)+\\sigma_\\varepsilon^2(\\boldsymbol{I}_n\\otimes\\boldsymbol{I}_b\\otimes\\boldsymbol{I}_t)\\]  \\[\\boldsymbol{\\Sigma}=\\lambda_1\\left(\\frac1n\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_b\\otimes\\frac1t\\boldsymbol{J}_t\\right)+\\lambda_2\\left[\\frac1n\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_b\\otimes\\left(\\boldsymbol{I}_t-\\frac1t\\boldsymbol{J}_t\\right)\\right]+\\lambda_3\\left[\\left(\\boldsymbol{I}_n-\\frac1n\\boldsymbol{J}_n\\right)\\otimes\\boldsymbol{I}_b\\otimes\\boldsymbol{I}_t\\right]\\]  \\(\\lambda_1=nt\\sigma_p^2+n\\sigma_{m\\times p}^2+\\sigma_\\varepsilon^2,\\lambda_2=n\\sigma_{m\\times p}^2+\\sigma_\\varepsilon^2\\)  \\(\\lambda_3=\\sigma_\\varepsilon^2\\).  \\[\\boldsymbol{\\Sigma}^{-1}=\\frac1{\\lambda_1}\\bigg(\\frac1n\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_b\\otimes\\frac1t\\boldsymbol{J}_t\\bigg)+\\frac1{\\lambda_2}\\bigg[\\frac1n\\boldsymbol{J}_n\\otimes\\boldsymbol{I}_b\\otimes\\bigg(\\boldsymbol{I}_t-\\frac1t\\boldsymbol{J}_t\\bigg)\\bigg]+\\frac1{\\lambda_3}\\bigg[\\bigg(\\boldsymbol{I}_n-\\frac1n\\boldsymbol{J}_n\\bigg)\\boldsymbol{\\otimes}\\boldsymbol{I}_b\\otimes\\boldsymbol{I}_t\\bigg]\\]  \\(\\boldsymbol{X&#39;\\Sigma}^{-1}\\boldsymbol{X}_1\\)  \\(\\boldsymbol{X&#39;\\Sigma}^{-1}\\boldsymbol{y}\\)  \\[\\begin{aligned}\\boldsymbol{X}_1^{\\prime}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{X}_1&amp;=\\frac{n{b}}{{\\lambda}_1}\\bigg(\\frac1t\\boldsymbol{J}_t\\bigg)+\\frac{n{b}}{{\\lambda}_2}{\\bigg(\\boldsymbol{I}_t-\\frac1t\\boldsymbol{J}_t\\bigg)}\\\\\\boldsymbol{X}_1^{\\prime}\\boldsymbol{\\Sigma}^{-1}&amp;=\\frac1{{\\lambda}_1}\\boldsymbol{j}_n^{\\prime}\\otimes\\boldsymbol{j}_b^{\\prime}\\otimes\\frac1t\\boldsymbol{J}_t+\\frac1{{\\lambda}_2}\\boldsymbol{j}_n^{\\prime}\\otimes\\boldsymbol{j}_b^{\\prime}\\otimes\\bigg(\\boldsymbol{I}_t-\\frac1t\\boldsymbol{J}_t\\bigg)\\end{aligned}\\]  \\[(\\boldsymbol X_1^{\\prime}\\boldsymbol \\Sigma^{-1}\\boldsymbol X_1)^{-1}=\\frac{\\lambda_1}{nb}{\\left(\\frac1t\\boldsymbol J_t\\right)}+\\frac{\\lambda_2}{nb}{\\left(\\boldsymbol I_t-\\frac1t\\boldsymbol J_t\\right)}\\]  \\(\\boldsymbol \\mu\\) 36 \\[\\hat{\\boldsymbol\\mu}=(\\boldsymbol X_1^{\\prime}\\boldsymbol\\Sigma^{-1}\\boldsymbol X_1)^{-1}\\boldsymbol X_1^{\\prime}\\boldsymbol\\Sigma^{-1}\\boldsymbol y=\\left(\\frac1n\\boldsymbol j^{\\prime}_n\\otimes\\frac1b\\boldsymbol{j}_b^{\\prime}\\otimes\\boldsymbol{I}_t\\right)\\boldsymbol{y}=(\\boldsymbol X_1^{\\prime}\\boldsymbol{X}_1)^{-1}\\boldsymbol{X}_1^{\\prime}\\boldsymbol{y}\\] \\({\\mu}\\)  \\(\\hat{\\mu}_i=\\bar{y}_{i\\cdot\\cdot},i=1,2,\\ldots,t\\). \\(\\hat{\\boldsymbol\\mu}\\)  \\[\\mathrm{Var}(\\hat{\\boldsymbol\\mu})=(\\boldsymbol X_1^{\\prime}\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{X}_1)^{-1}=\\frac{{\\sigma}_\\varepsilon^2+n{\\sigma}_{m\\times p}^2+nt{\\sigma}_p^2}{nb}\\biggl(\\frac1t\\boldsymbol{J}_t\\biggr)+\\frac{{\\sigma}_\\varepsilon^2+n{\\sigma}_{m\\times p}^2}{nb}\\biggl(\\boldsymbol{I}_t-\\frac1t\\boldsymbol{J}_t\\biggr)\\]  \\(\\hat{\\mu}_i\\)  \\[\\mathrm{Var}(\\hat{\\mu}_i)=\\frac{\\sigma_\\varepsilon^2+n\\sigma_{m\\times p}^2+n\\sigma_p^2}{nb}\\] - \\[\\mathrm{Var}(\\hat{\\mu}_i)=\\frac{\\sigma_\\varepsilon^2+3\\sigma_{m\\times p}^2+3\\sigma_p^2}{18}\\]  \\(\\boldsymbol{a}^{\\prime}\\boldsymbol{\\mu}\\) \\(\\boldsymbol{a&#39;j}_t=\\boldsymbol{0}\\) \\(\\boldsymbol{a}^{\\prime}\\hat{\\boldsymbol{\\mu}}\\) \\[\\operatorname{Var}(\\boldsymbol a^{\\prime}\\hat{\\boldsymbol \\mu})=\\frac{\\sigma_\\varepsilon^2+n\\sigma_{m\\times p}^2}{nb}\\boldsymbol{a&#39;a}\\]  \\(\\mu_i-\\mu_{i^{\\prime}}\\left(i\\neq i^{\\prime}\\right)\\)  \\(\\hat{\\mu_i}-\\hat{\\mu}_{i^{\\prime}}\\) \\[\\mathrm{Var}(\\hat{\\mu}_i-\\hat{\\mu}_{i^{\\prime}})=2{\\left[\\frac{\\sigma_\\varepsilon^2+n\\sigma_{m\\times p}^2}{nb}\\right]}\\]  \\[\\widehat{s.e.}_{\\mu_i-\\mu_{i^\\prime}}=\\sqrt{\\frac{2(MSPerson\\times Machine)}{18}}=2.177\\]  23.7 \\(t\\)  23.8 \\(t\\)  \\(LSD_{0.05}\\)  \\[LSD_{0.05}=(t_{0.025,10})(\\widehat{s.e}._{\\hat{\\mu}_i-\\hat{\\mu}_{i^\\prime}})=2.228(2.177)=4.85\\]  23.7:  x  23.8:  x  4.85 LSD  \\(H_0\\colon\\mu_1=\\mu_2=\\mu_3\\mathrm{~vs~ }H_a\\colon(\\text{not }H_0)\\) 23.2  \\[F_{mc}=\\frac{MSMachine}{MSPerson\\times Machine}=20.58\\]  0.0004 23.2   23.1  23.1  \\[y_{ijk}=\\mu+\\tau_i+p_j+(\\tau p)_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,t,\\quad j=1,2,\\ldots,b,\\quad k=1,2,\\ldots,n_{ij}\\]  23.9  I  \\[\\begin{aligned}SSMachine&amp;=R(\\tau|\\mu)\\\\SSPerson&amp;=R(p|\\mu,\\tau)\\\\SSPerson\\times Machine&amp;=R((\\tau p)|\\mu,\\tau,p)\\end{aligned}\\]  23.9   23.9:  I  x  \\(\\sigma_p^2\\). MSPerson  MSPerson × Machine  \\(\\sigma_{m\\times p}^2\\)  \\(\\sigma_p^2\\) \\(\\sigma_p^2\\).  \\[\\begin{aligned} \\tilde{\\mathcal{\\sigma}}_p^2 &amp;=\\frac1{7.219}{\\left[(\\tilde{\\sigma}_\\varepsilon^2+2.5866\\tilde{\\sigma}_{m\\times p}^2+7.2190\\tilde{\\sigma}_p^2)-\\frac{2.5866}{2.3162}(\\tilde{\\sigma}_\\varepsilon^2+2.3162\\tilde{\\sigma}_{m\\times p}^2)+\\left(\\frac{2.5866}{2.3162}-1\\right)\\tilde{\\sigma}_\\varepsilon^2\\right]} \\\\ &amp;=\\frac1{7.219}{\\left[(\\tilde{\\sigma}_\\varepsilon^2+2.5866\\tilde{\\sigma}_{m\\times p}^2+7.2190\\tilde{\\sigma}_p^2)-1.1167(\\tilde{\\sigma}_\\varepsilon^2+2.3162\\tilde{\\sigma}_{m\\times p}^2)+(0.1167)\\tilde{\\sigma}_\\varepsilon^2\\right]} \\\\ &amp;=\\frac1{7.219}[{E}(MSPerson)-1.1167{E}(MSPerson\\times\\text{}SMachine)+(0.1167){E}(MSResidual)] \\end{aligned}\\] I  \\[\\begin{aligned} \\text{MSPerson}&amp; =\\tilde{\\sigma}_\\varepsilon^2+2.5866\\tilde{\\sigma}_{m\\times p}^2+7.2190\\tilde{\\sigma}_p^2 \\\\ \\text{MSPerson × Machine}&amp; =\\tilde{\\sigma}_\\varepsilon^2+2.3162\\tilde{\\sigma}_{m\\times p}^2 \\\\ MSResidual&amp;=\\tilde{\\sigma}_\\varepsilon^2 \\end{aligned}\\]  I  \\[\\begin{aligned} \\tilde{{\\sigma}}_p^2&amp; =\\frac1{7.219}[MSPerson-1.1167 MSPerson\\times Machine+0.1167MSResidual] \\\\ &amp;=\\frac1{7.219}{\\left[201.7527-1.1167(40.4315)+0.1167(0.8726)\\right]}=21.7073 \\\\ \\tilde{{\\sigma}}_{m\\times p}^2&amp; =\\frac1{2.3162}[MSPerson\\times Machine-MSResidual] \\\\ &amp;=\\frac1{2.3162}{\\left[40.4315-0.8726\\right]}{=17.0792} \\\\ \\tilde{{\\sigma}}_\\varepsilon^2&amp;=MSResidual=0.8726 \\end{aligned}\\]  23.10  23.13  REML, ML, MIVQUE0, I , II  III  MIVQUE0  0. SAS-Mixed  nobound  23.13 REML   23.10:  x  23.11:  Person  x  23.12:  Person × machine  x  23.13:  x  SAS-Mixed  23.14  Method=REML  ML, MIVQUE0, type1, type2  type3 Satterthwaite REML, ML  MIVQUE0  \\(df=2(\\text{Z-value})^2\\) lower  newlower  upper  newupper  Method  I II  III  Wald newlower  newupper   23.14:  REML  SAS Mixed  x  23.9  \\(F\\)  \\(H_0\\colon{\\sigma}_{p}^2=0\\text{ vs }H_a\\colon{\\sigma}_{p}^2&gt;0\\)  \\(F=4.48\\) 5 9.9549.  0.0003.  \\(H_0\\colon{\\sigma}_{m\\times p}^2=0\\text{ vs }H_a\\colon{\\sigma}_{m\\times p}^2&gt;0\\)  \\(F=46.34\\) 10 26.  0.0001.  ML  -2 log(full likelihood function) 23.15  \\(H_0\\colon{\\sigma}_{m\\times p}^2=0\\text{ vs }H_a\\colon{\\sigma}_{m\\times p}^2&gt;0\\) person × machine  -2 log(reduced likelihood function).  LR test = -2 log(reduced likelihood function) - [-2 log(full likelihood function)] 55.5665 1  0.0001.  \\(H_0\\colon{\\sigma}_{m\\times p}^2=0\\text{ vs }H_a\\colon{\\sigma}_{m\\times p}^2&gt;0\\) person  -2 log(reduced likelihood function).  LR test = -2 log(reduced likelihood function) - [-2 log(full likelihood function)] 6.4226 1  0.0113.  23.15:  \\({\\sigma}_{p}^2\\)  \\({\\sigma}_{g}^2\\)  ML  x  \\[\\hat{\\boldsymbol{\\beta}}_W=\\left(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol{\\Sigma}}^{-1}\\boldsymbol X\\right)^{-}\\boldsymbol X^{\\prime}\\hat{\\boldsymbol{\\Sigma}}^{-1}\\boldsymbol y\\]  \\(\\hat{\\boldsymbol{\\Sigma}}\\) 37 \\(\\hat{\\boldsymbol{\\beta}}\\) - \\(\\mathrm{Var}({\\hat{\\boldsymbol\\beta}})=\\left({\\boldsymbol{X&#39;\\Sigma}}^{-1}\\boldsymbol{X}\\right)^-\\).  23.16  III MIVQUE0 REML  10.1 10ML  IIII   23.16:  III  x  23.17 - 23.19 REML  I II  III  23.20  23.22  REML  10REML   23.17: Machine 1  x  23.18: Machine 2  x  23.19: Machine 3  x  23.20: Machine 1  2  x  23.21: Machine 1  3  x  23.22: Machine 2  3  x  23.23  REML  \\(H_0{:}\\mu_1=\\mu_2=\\mu_3\\mathrm{~vs~}H_a{:}(\\text{not }H_a)\\)  2  10.1  \\(F\\)  19.96.  10 machine × person  10.1   23.23:  III  x  23.20  23.22  REML  10.2, 10.1  10 10 23.3  JMP   JMP®  23.1  machine, person  rep  rating fit model  23.2  rating  Y machine person  person  machine  REML  REML  Wald  23.3  \\(H_0{:}\\mu_1=\\mu_2=\\mu_3\\mathrm{~vs~}H_a{:}(\\text{not }H_a)\\)  23.4  2  10.11  \\(F\\)  19.9639.  23.1: JMP   23.2: JMP fit model   23.3: JMP  REML   23.4: JMP   23.5  LSD  95%  23.6  JMP  estimate  REML  SAS Mixed  Wald  Satterthwaite   23.5:   23.6:  LSD  23.4  REML, MIVQUE0 REML  REML 38 REML  JMP  REML  SAS-Mixed  Wald  Satterthwaite  Wald  23.5   \\(\\boldsymbol\\mu\\)  \\(\\mu\\)  where \\(\\hat{\\boldsymbol{\\Sigma}}\\) is the estimated covariance matrix evaluated at the estimates of the variance components from the specified method of estimating the variance components. The main indicator is that the error degrees of freedom for comparing the machine means using the REML estimates of the variance components were similar to those for the balanced data set. "],["chap24.html", " 24   24.1  24.2  24.3  24.4  24.5  24.6  24.7  JMP  24.7 24.8  24.9 ", "  24   Numerical quantities focus on expected values, graphical summaries on unexpected values. - John Tukey 24.1   (split-plot type design)  5  (class of hierarchal design structures). / (estimates of the standard errors of estimated means)  26  5   24.1  24.2  24.3  24.4  24.5  24.6  SAS®-Mixed  JMP®  JMP  24.7   5  (associated variance) 26  REML REML  24.1.1  24.1  (recipe)  (oven)  (temperature)  24.1  (day)   24.1:  24.1  (cm3) x  24.1  \\[y_{ik}^o=\\mu_i^o+d_k^o+o_{ik}^o\\]  \\(y_{ik}^o\\) \\(\\mu_{i}^o\\)  i \\(d_{k}^o\\)  k \\(o_{ik}^o\\)  i  k  \\(d_{k}^o\\thicksim i.i.d.N(0,\\sigma_d^2),o_{ik}^o\\thicksim i.i.d.N(0,\\sigma_o^2)\\)  \\(d_{k}^o,o_{ik}^o\\)  24.2   24.1:   24.2:  x  24.2   24.2:   325°F 340°F 355°F 325°F  24.3  325°F  \\[y_{jk}^+=\\mu_j^++o_k^++\\varepsilon_{jk}^+\\]  \\(y_{jk}^+\\)  k  j  325°F \\(\\mu_{j}^+\\)  j \\(o_{ik}^o\\)  k  \\(\\varepsilon_{jk}^+\\)  j  k  \\(o_k^+\\thicksim i.i.d.N(0,\\sigma_0^2),\\varepsilon_{jk}^+\\thicksim i.i.d.N(0,\\sigma_\\varepsilon^2)\\)  \\(o_k^+,\\varepsilon_{jk}^+\\)  24.3   24.3: 325°F   24.3: 325°F  x  (The error term that measures the loaf to loaf variability is computed by pooling the recipe by day interaction across the three temperatures) Error(loaf)=Recipe × Day(Temperature).  \\[y_{ijk}=\\mu_{ij}+d_k+o_{ik}+\\varepsilon_{ijk},\\quad i=1,2,3,\\quad j=1,2,3,4,\\quad k=1,2,3\\]  \\({\\mu}_{ij}={\\mu}+T_i+R_j+(TR)_{ij}\\)\\(T_i\\)  i \\(R_i\\)  j \\((TR)_{ij}\\) \\(d_k\\)  k \\(o_{ik}\\)  k  i  \\(\\varepsilon_{ijk}\\)  \\(d_k\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{day}}^2),o_{ik}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{oven}}^2),\\varepsilon_{ijk}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{loaf}}^2)\\) \\(d_k,o_{ik},\\varepsilon_{ijk}\\)  (whole plot)  (subplot)  (split-plot)   \\[\\begin{aligned}y_{ijk}=&amp;\\mu_{ij}+d_k+T_i+o_{ik} &amp;&amp;\\}\\quad\\text{whole-plot or oven part of the model} \\\\&amp;+R_j+(TR)_{ij}+\\varepsilon_{ijk}&amp;&amp;\\}\\quad\\text{subplot or loaf part of the model}\\end{aligned}\\]  24.2  24.3  24.4 Error(oven) Error(loaf)  24.5  SAS-Mixed  (p = 0.0021) temperature × recipe  24.2   24.4:  24.1  x  24.5:  24.1  SAS-Mixed  x 24.1.2  24.2  24.4  (fertility regimes) A1, A2, A3  A4B1  B2 (blocks) (whole plots).  (fertilizer) subplots \\[y_{ijk}=\\mu_{ij}+b_k+w_{ik}+\\varepsilon_{ijk},\\quad i=1,2,3,4,\\quad j=1,2,k=1,2\\] \\(\\mu_{ij}\\)  i  j \\(y_{ijk}\\)  k  j \\(b_k\\)  \\(i.i.d.N(0,\\sigma_{\\mathrm{block}}^2)\\) \\(w_{ik}\\)  \\(i.i.d.~N(0,~\\sigma_{wp}^2)\\)  \\(\\varepsilon_{ijk}\\)  \\(i.i.d.~N(0,~\\sigma_{\\varepsilon}^2)\\)  \\(b_k,w_{ik},\\varepsilon_{ijk}\\)  \\(\\mu_{ij}=\\mu+F_i+V_j+(FV)_{ij}\\).  24.6.  \\(F\\) Error(whole plot) Error(subplot)  24.7  SAS Mixed  III  24.8  REML  \\(F\\)   24.4:   24.6:  24.2  x  24.7:  24.2  III  x  24.8:  24.2  REML  x 24.2   r  A  a  C  c  \\[y_{ijk}=\\mu+\\alpha_i+b_k+w_{ik}+\\gamma_j+(\\alpha\\gamma)_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,a,\\quad j=1,2,\\ldots,c,\\quad k=1,2,\\ldots,r\\] \\(y_{ijk}\\) \\(b_k\\)  k  \\(N(0,\\sigma_B^2)\\)\\(w_{ik}\\)  \\(N(0,\\sigma_w^2)\\)\\(\\varepsilon_{ijk}\\)  \\(N(0,\\sigma_\\varepsilon^2)\\).  \\(b_k,w_{ik},\\varepsilon_{ijk}\\)  \\(b_k,w_{ik},\\varepsilon_{ijk}\\)  \\(\\mu\\)A \\(\\alpha_i\\)C \\(\\gamma_j\\) \\((\\alpha\\gamma)_{ij}\\).  \\(\\mu_{ij}=\\mu+\\alpha_i+\\gamma_j+(\\alpha\\gamma)_{ij}\\).  24.9   24.9: 24.1  x  Block × A  A  Block × C  Block × C(A).  \\[\\begin{aligned} \\text{MSBlock}&amp; =\\tilde{{\\sigma}}_\\varepsilon^2+c\\tilde{{\\sigma}}_w^2+ac\\tilde{{\\sigma}}_B^2 \\\\ \\text{MSError(whole plot)}&amp; =\\tilde{\\sigma}_\\varepsilon^2+c\\tilde{\\sigma}_w^2 \\\\ MSError(subplot)&amp;=\\tilde{\\sigma}_\\varepsilon^2 \\end{aligned}\\]  \\[\\begin{aligned} \\tilde{{\\sigma}}_\\varepsilon^2&amp; =MSError(subplot) \\\\ \\tilde{{\\sigma}}_w^2&amp; =\\frac{MSError(wholeplot)-MSError(subplot)}c \\\\ \\tilde{{\\sigma}}_B^2&amp; =\\frac{MSBlock-MSError(wholeplot)}{ac} \\end{aligned}\\]  \\[\\begin{aligned} &amp;\\hat{{\\sigma}}_\\varepsilon^2 =\\tilde{\\sigma}_\\varepsilon^2 \\\\ &amp;\\hat{{\\sigma}_w^2} =\\begin{cases}\\tilde{{\\sigma}}_w^2&amp;\\operatorname{~if~}\\tilde{{\\sigma}}_w^2&gt;0\\\\0&amp;\\operatorname{~if~}\\tilde{{\\sigma}}_w^2\\leq0&amp;\\end{cases} \\\\ &amp;\\hat{{\\sigma}}_{B}^{2} =\\begin{cases}\\tilde{{\\sigma}}_B^2&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_B^2&gt;0\\\\0&amp;\\mathrm{~if~}\\tilde{{\\sigma}}_B^2\\leq0&amp;\\end{cases} \\end{aligned}\\] \\(\\mu_{ij},\\bar{\\mu}_{i\\cdot},\\bar{\\mu}_{\\cdot j}\\)  \\(\\bar{{y}}_{ij\\cdot},\\bar{{y}}_{i{\\cdot\\cdot}},\\bar{{y}}_{\\cdot j\\cdot}\\). A  (between whole plot comparisons) A  \\(F\\)  \\(F_A=MSA/MSError(whole plot)\\). C  A × C  (within whole plot comparisons)  (between subplot comparisons within a whole plot) \\(F\\)  \\(F_C=MSC/MSError(subplot)\\)  \\(F_{A×C}=MSA×C/MSError(subplot)\\).  \\(F\\)  24.9   \\(F\\)  24.3   24.4   \\[y_{ijk}=\\mu+\\alpha_i+b_k+iv_{ik}+\\gamma_j+(\\alpha\\gamma)_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,a,\\quad j=1,2,\\ldots,c,\\quad k=1,2,\\ldots,r\\]  \\[y_{ijk}=\\mu_{ij}+b_k+w_{ik}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,a,~j=1,2,\\ldots,c,~k=1,2,\\ldots,r\\]  24.1   A  C  A  C   C  \\(\\bar{\\mu}_{\\cdot j}\\) \\(\\bar{{y}}_{\\cdot j\\cdot}\\)  \\(\\bar{{y}}_{\\cdot j\\cdot}\\) i  k 39C  j  \\(\\bar{y}_{{\\cdot}j{\\cdot}}=\\bar{{\\mu}}_{{\\cdot}j}+\\bar{b}_{{\\cdot}}+\\bar{{w}}_{{\\cdot}\\cdot}+\\bar{{\\varepsilon}}_{{\\cdot}j{\\cdot}}\\).  \\(\\bar{{\\mu}}_{\\cdot1}-\\bar{{\\mu}}_{\\cdot2}\\)  \\(\\bar{y}_{\\cdot 1\\cdot}-\\bar{y}_{\\cdot 2\\cdot}\\) C  \\(\\bar{y}_{\\cdot1\\cdot}-\\bar{y}_{\\cdot2\\cdot}=\\bar{\\mu}_{\\cdot1}-\\bar{\\mu}_{\\cdot2}+\\bar{\\varepsilon}_{\\cdot1\\cdot}-\\bar{\\varepsilon}_{\\cdot2\\cdot}\\) \\(\\bar{b}_{{\\cdot}}+\\bar{{w}}_{{\\cdot}\\cdot}\\)  \\(\\bar{y}_{\\cdot1\\cdot}-\\bar{y}_{\\cdot2\\cdot}\\) \\(\\bar{y}_{\\cdot1\\cdot}-\\bar{y}_{\\cdot2\\cdot}\\)  \\[\\mathrm{Var}(\\bar{y}_{\\cdot1\\cdot}-\\bar{y}_{\\cdot2\\cdot})=\\mathrm{Var}(\\bar{\\varepsilon}_{\\cdot1\\cdot}-\\bar{\\varepsilon}_{\\cdot2\\cdot})=\\frac{2\\sigma_\\varepsilon^2}{ar}\\]  \\(\\bar{\\varepsilon}_{\\cdot1\\cdot}\\)  \\(\\mathrm{Var}(\\bar{{\\varepsilon}}_{\\cdot1\\cdot})=\\sigma_\\varepsilon^2/ar\\)  ar  \\(j\\ne j^\\prime\\)\\(\\mathrm{Var}(\\bar{y}_{\\cdot j\\cdot}-\\bar{y}_{\\cdot j^\\prime\\cdot})=2\\sigma_\\varepsilon^2/ar\\)\\(\\bar{y}_{\\cdot j\\cdot}-\\bar{y}_{\\cdot j^\\prime\\cdot}\\)  \\[\\widehat{s.e.}(\\bar{y}_{.j.}-\\bar{y}_{.j&#39;.})=\\sqrt{\\frac{2\\hat{\\sigma}_{\\varepsilon}^2}{ar}}=\\sqrt{\\frac{2MSError(subplot)}{ar}}\\quad\\text{for all }j\\neq j&#39;\\]  a(c-1)(r-1)  3 a(c-1)(r-1)  LSD  LSD  LSD  \\[\\mathrm{LSD}_\\alpha=[t_{\\alpha/2,a(c-1)(r-1)}]\\widehat{s.e.}(\\bar{y}_{\\cdot j\\cdot}-\\bar{y}_{\\cdot j^{\\prime}\\cdot})\\]  A  \\(\\bar{{y}}_{i\\cdot \\cdot}\\)  \\(\\bar{{\\mu}}_{i\\cdot}\\).  \\(\\bar{{\\mu}}_{i\\cdot}\\)  j  k  \\(\\bar{y}_{i\\cdot\\cdot}=\\bar{\\mu}_{i\\cdot}+\\bar{b}_{\\cdot}+\\bar{w}_{i\\cdot}+\\bar{\\varepsilon}_{ij\\cdot\\cdot}\\)  \\(\\bar{{\\mu}}_{1\\cdot}-\\bar{{\\mu}}_{2\\cdot}\\)  \\(\\bar{{y}}_{1\\cdot \\cdot}-\\bar{{y}}_{2\\cdot \\cdot}\\) \\(\\bar{{y}}_{i\\cdot \\cdot}\\)  \\(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot}=\\bar{\\mu}_{1\\cdot}-\\bar{\\mu}_{2\\cdot}+\\bar{w}_{1\\cdot}-\\bar{w}_{2\\cdot}+\\bar{\\varepsilon}_{1\\cdot\\cdot}-\\bar{\\varepsilon}_{2\\cdot\\cdot}\\). \\(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot}\\)  \\[\\begin{aligned} \\mathrm{Var}(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot}) &amp;=\\operatorname{Var}(\\bar{w}_{1\\cdot}-\\bar{w}_{2\\cdot}+\\bar{\\varepsilon}_{1\\cdot\\cdot}-\\bar{\\varepsilon}_{2\\cdot\\cdot}) \\\\ &amp;=\\frac{2\\sigma_w^2}r+\\frac{2\\sigma_\\varepsilon^2}{rc} \\\\ &amp;=\\frac{2(\\sigma_\\varepsilon^2+c\\sigma_w^2)}{rc} \\end{aligned}\\] \\(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot}\\)  \\[\\widehat{s.e.}(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot})=\\sqrt{\\frac{2(\\hat{\\sigma}_\\varepsilon^2+c\\hat{\\sigma}_w^2)}{rc}}=\\sqrt{\\frac{2MSError(wholeplot)}{rc}}\\]  (r-1)(a-1)  LSD  \\(\\mathrm{LSD}_\\alpha=[t_{\\alpha/2,(a-1)(r-1)}]\\widehat{\\mathrm{s.e.}}(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot})\\)  A × C AC \\(\\mu_{11}-\\mu_{12}\\). \\(\\mu_{11}-\\mu_{12}\\)  \\(\\bar{y}_{11\\cdot}-\\bar{y}_{12\\cdot}\\).  k \\(\\bar{y}_{ij\\cdot}\\)  \\({\\bar{y}}_{ij{\\cdot}}={\\mu}_{ij}+\\bar{b}_\\cdot+\\bar{w}_{i{\\cdot}}+{\\bar{\\varepsilon}}_{ij{\\cdot}}\\) \\(\\bar{y}_{11\\cdot}-\\bar{y}_{12\\cdot}\\)  \\(\\mathrm{Var}(\\bar{y}_{11\\cdot}-\\bar{y}_{12\\cdot})=\\mathrm{Var}(\\bar{w}_{1{\\cdot}}+\\bar{{\\varepsilon}}_{11{\\cdot}}-\\bar{w}_{1{\\cdot}}\\bar{{\\varepsilon}}_{12\\cdot})=2{\\sigma}_{{\\varepsilon}}^2/r\\). \\(\\bar{y}_{11\\cdot}-\\bar{y}_{12\\cdot}\\)  \\[\\widehat{s.e.}(\\bar{y}_{11\\cdot}-\\bar{y}_{12\\cdot})=\\sqrt{\\frac{2\\hat{\\sigma}_\\varepsilon^2}r}=\\sqrt{\\frac{2MSError(subplot)}r}\\]  LSD  \\(\\mathrm{LSD}_{\\alpha}=[t_{\\alpha/2,a(r-1)(c-1)}]\\widehat{s.e.}(\\bar{y}_{1\\cdot}-\\bar{y}_{1\\cdot2})\\).  LSD   \\(\\mu_{11}-\\mu_{21}\\)  \\(\\mu_{11}-\\mu_{22}\\). \\(\\mu_{11}-\\mu_{21}\\)  \\(\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}\\) \\(\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}={\\mu}_{11}-{\\mu}_{21}+\\bar{{w}}_{1\\cdot}-\\bar{{w}}_{2{\\cdot}}+\\bar{{\\varepsilon}}_{11{\\cdot}}-\\bar{{\\varepsilon}}_{21{\\cdot}}\\).  \\[\\begin{aligned} \\mathrm{Var}(\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}) =&amp;\\operatorname{Var}(\\bar{w}_{1\\cdot}-\\bar{w}_{2\\cdot}+\\bar{\\varepsilon}_{11\\cdot}-\\bar{\\varepsilon}_{21\\cdot}) \\\\ =&amp;\\frac{2\\sigma_w^2}r+\\frac{2\\sigma_\\varepsilon^2}r \\\\ =&amp;\\frac{2(\\sigma_\\varepsilon^2+\\sigma_w^2)}r \\end{aligned}\\]  \\(\\sigma_\\varepsilon^2+\\sigma_w^2\\)  \\[\\widehat{\\sigma_\\varepsilon^2+\\sigma_w^2}=\\frac{MSError(wholeplot)+(c-1)MSError(subplot)}c\\]  \\(\\widehat{\\sigma_\\varepsilon^2+\\sigma_w^2}\\)  \\(\\widehat{\\sigma_\\varepsilon^2+\\sigma_w^2}\\)  Satterthwaite  \\[\\hat{v}=\\frac{\\left(\\widehat{\\sigma_\\varepsilon^2+\\sigma_w^2}\\right)^2}{\\frac{\\begin{bmatrix}MSE(wholeplot)/c\\end{bmatrix}^2}{(r-1)(a-1)}+\\frac{\\left[\\frac{c-1}cMSE(subplot)\\right]^2}{a(r-1)(c-1)}}\\]  LSD  \\[\\mathrm{LSD}_\\alpha=(t_{\\alpha/2,\\hat{v}})\\sqrt{\\frac{2(\\widehat{\\sigma_\\varepsilon^2+\\sigma_w^2})}r}\\]  24.1 24.1 24.10   24.10:  24.1  x  \\[\\widehat{s.e.}(\\bar{y}_{\\cdot1\\cdot}-\\bar{y}_{\\cdot2\\cdot})=\\sqrt{\\frac{2(657.87)}{3(3)}}=12.09\\]  18  \\(t_{0.025,18}=2.101\\) 5% LSD  \\(\\text{LSD}_{0.05}=2.101(12.09)=25.40\\).  \\[\\widehat{s.e.}(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot})=\\sqrt{\\frac{2\\left(4096.42\\right)}{3(4)}}=26.13\\]  4  \\(t_{0.025,4}=2.776\\)  5% LSD  \\(\\text{LSD}_{0.05}=2.776(26.13) = 72.55\\).  \\[\\widehat{s.e.}(\\bar{y}_{11\\cdot}-\\bar{y}_{12\\cdot})=\\sqrt{\\frac{2(657.87)}3}=20.94\\]  18  5% LSD  \\(LSD _{0.05}=2.101(20.94)=43.99\\).  \\[\\widehat{s.e.}(\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot})=\\sqrt{\\frac{2\\left[\\frac144096.42+\\frac{(4-1)}4657.87\\right]}3}=\\sqrt{\\frac{2\\left[1517.51\\right]}3}=31.80\\]  \\[\\hat{v}=\\frac{\\left(1517.51\\right)^2}{\\frac{\\left(\\frac144096.42\\right)^2}4+\\frac{\\left(\\frac34657.87\\right)^2}{18}}=8.35\\]  \\(t_{0.025,8.35}=2.289\\) 5% LSD  \\(LSD _{0.05}=2.289(31.80) = 72.79\\).  24.4   (casual reader)  \\[y_{ijk}=\\mu+\\alpha_i+b_k+w_{ik}+\\gamma_j+(\\alpha\\gamma)_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,a,\\quad j=1,2,\\ldots,c,\\quad k=1,2,\\ldots,r\\]  (components) \\({\\mu_{11}}-{\\mu_{21}}\\)  \\[\\mu_{11}-\\mu_{21}=(\\bar{\\mu}_{1\\cdot}-\\bar{\\mu}_{2\\cdot})+[(\\mu_{11}-\\bar{\\mu}_{1\\cdot})-(\\mu_{21}-\\bar{\\mu}_{2\\cdot})]\\]  \\((\\bar{\\mu}_{1\\cdot}-\\bar{\\mu}_{2\\cdot})\\)  \\([(\\mu_{11}-\\bar{\\mu}_{1\\cdot})-(\\mu_{21}-\\bar{\\mu}_{2\\cdot})]\\)  \\(\\hat{\\bar{{\\mu}}}_{1\\cdot}-\\hat{\\bar{{\\mu}}}_{2\\cdot}=\\bar{{y}}_{1\\cdot\\cdot}-\\bar{{y}}_{2\\cdot\\cdot}\\)  \\((\\hat{\\mu}_{11}-\\hat{\\bar{\\mu}}_{1\\cdot})-(\\hat{{\\mu}}_{21}-\\hat{\\bar{\\mu}}_{2\\cdot})=(\\bar{y}_{11\\cdot}-\\bar{y}_{1\\cdot\\cdot})-(\\bar{y}_{21\\cdot}-\\bar{y}_{2\\cdot\\cdot})\\). \\({\\mu_{11}}-{\\mu_{21}}\\)  \\[\\begin{aligned} \\hat{{\\mu}}_{11}-\\hat{{\\mu}}_{21}&amp; =\\hat{\\bar{\\mu}}_{1\\cdot}-\\hat{\\bar{\\mu}}_{2\\cdot}+(\\hat{\\mu}_{11}-\\hat{\\bar{\\mu}}_{1\\cdot})-(\\hat{\\mu}_{21}-\\hat{\\bar{\\mu}}_{2\\cdot}) \\\\ &amp;=\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot} \\end{aligned}\\]  \\(\\hat{{\\mu}}_{11}-\\hat{{\\mu}}_{21}\\)  \\[\\mathrm{Var}(\\hat{\\mu}_{11}-\\hat{\\mu}_{21})=\\mathrm{Var}(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot})+\\mathrm{Var}[(\\bar{y}_{11\\cdot}-\\bar{y}_{1\\cdot\\cdot})-(\\bar{y}_{21\\cdot}-\\bar{y}_{2\\cdot\\cdot})]\\]  \\(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot}\\)  \\(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot}=\\bar{\\mu}_{1\\cdot}-\\bar{\\mu}_{2\\cdot}+\\bar{w}_{1\\cdot}-\\bar{w}_{2\\cdot}+\\bar{\\varepsilon}_{1\\cdot\\cdot}-\\bar{\\varepsilon}_{2\\cdot\\cdot}\\) \\[\\begin{aligned} \\mathrm{Var}(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot}) &amp;=\\operatorname{Var}(\\bar{w}_{1\\cdot}-\\bar{w}_{2\\cdot}+\\bar{\\varepsilon}_{1\\cdot\\cdot}-\\bar{\\varepsilon}_{2\\cdot\\cdot}) \\\\ &amp;=\\frac2{rc}(\\sigma_\\varepsilon^2+c\\sigma_w^2) \\end{aligned}\\] \\(\\mathrm{Var}(\\bar{y}_{1\\cdot\\cdot}-\\bar{y}_{2\\cdot\\cdot})\\)  \\((2/rc) MSError(WholePlot)\\).  \\((\\bar{y}_{11\\cdot}-\\bar{y}_{1\\cdot\\cdot})-(\\bar{y}_{21\\cdot}-\\bar{y}_{2\\cdot\\cdot})\\)  \\[\\begin{aligned}(\\bar{y}_{11}.-\\bar{y}_{1\\cdot\\cdot})-(\\bar{y}_{21\\cdot}-\\bar{y}_{2\\cdot\\cdot})=&amp;(\\mu_{11}+\\bar{b}_{\\cdot}+\\bar{w}_{1\\cdot}+\\bar{\\varepsilon}_{11\\cdot})-(\\bar{\\mu}_{1\\cdot}+\\bar{b}_{\\cdot}+\\bar{w}_{1\\cdot}+\\bar{\\varepsilon}_{1\\cdot\\cdot})\\\\&amp;-(\\mu_{21}+\\bar{b}_{\\cdot}+\\bar{w}_{2\\cdot}+\\bar{\\varepsilon}_{21\\cdot})+(\\bar{\\mu}_{2\\cdot}+\\bar{b}_{\\cdot}+\\bar{w}_{2\\cdot}+\\bar{\\varepsilon}_{2\\cdot\\cdot})\\\\ =&amp;[(\\mu_{11}-\\bar{\\mu}_{1\\cdot})-(\\mu_{21}-\\bar{\\mu}_{2\\cdot})]+[(\\bar{\\varepsilon}_{11\\cdot}-\\bar{\\varepsilon}_{1\\cdot\\cdot})-(\\bar{\\varepsilon}_{21\\cdot}-\\bar{\\varepsilon}_{2\\cdot\\cdot})] \\end{aligned}\\]  \\[\\begin{aligned} \\mathrm{Var}[(\\bar{y}_{11\\cdot}-\\bar{y}_{1\\cdot\\cdot})-(\\bar{y}_{21\\cdot}-\\bar{y}_{2\\cdot\\cdot})]&amp; =\\mathrm{Var}[(\\bar{{\\varepsilon}}_{11{\\cdot}}-\\bar{{\\varepsilon}}_{1{\\cdot\\cdot}})-(\\bar{{\\varepsilon}}_{21{\\cdot}}-\\bar{{\\varepsilon}}_{2{\\cdot\\cdot}})] \\\\ &amp;=\\frac{2(c-1)}{cr}\\sigma_\\varepsilon^2 \\end{aligned}\\] \\(\\mathrm{Var}[(\\bar{y}_{11\\cdot}-\\bar{y}_{1\\cdot\\cdot})-(\\bar{y}_{21\\cdot}-\\bar{y}_{2\\cdot\\cdot})]\\)  \\[\\widehat{\\mathrm{Var}}[(\\bar{y}_{11\\cdot}-\\bar{y}_{1\\cdot\\cdot})-(\\bar{y}_{21\\cdot}-\\bar{y}_{2\\cdot\\cdot})]=\\frac{2(c-1)}{rc}MSError(subplot)\\]  \\[\\mathrm{Var}[\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}]=\\left(\\frac2{rc}\\right)(\\sigma_\\varepsilon^2+c\\sigma_w^2)+\\frac{2(c-1)}{rc}\\sigma_\\varepsilon^2\\] \\(\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}\\)  \\[s.e.[\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}]=\\sqrt{\\left(\\frac2{rc}\\right)MSE(wholeplot)+\\frac{2(c-1)}{rc}MSE(subplot)}\\]  \\(s.e.[\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}]\\)  Satterthwaite  \\[\\begin{aligned}\\hat{v}&amp;=\\frac{\\left\\{\\left(\\frac2{rc}\\right)[MSE(wholeplot)]+\\frac{2(c-1)}{rc}[MSE(subplot)]\\right\\}^2}{\\frac{\\left\\{\\left(\\frac2{rc}\\right)[MSE(wholeplot)]\\right\\}^2}{(a-1)(r-1)}+\\frac{\\left\\{\\frac{2(c-1)}{rc}[MSE(subplot)]\\right\\}^2}{a(r-1)(c-1)}}\\end{aligned}\\]  \\(s.e.[\\bar{y}_{11\\cdot}-\\bar{y}_{21\\cdot}]\\)  24.2  24.4.1   24.2 C  \\(\\bar\\mu_{\\cdot j}\\)  \\[\\theta=d_1\\bar{\\mu}_{\\cdot1}+d_2\\bar{\\mu}_{\\cdot2}+\\cdots+d_c\\bar{\\mu}_{\\cdot c}\\mathrm{~where~}\\sum_{j=1}^cd_j=0\\]  \\(\\hat\\theta=d_1\\bar{y}_{\\cdot1\\cdot}+d_2\\bar{y}_{\\cdot2\\cdot}+\\cdots+d_c\\bar{y}_{\\cdot c\\cdot}\\) \\[\\mathrm{Var}(\\hat{\\theta})=\\frac{\\sigma_\\varepsilon^2}{ar}\\sum_{j=1}^cd_j^2\\] \\(\\hat\\theta\\)  \\[\\widehat{s.e.}(\\hat{\\theta})=\\sqrt{\\frac{MSError(subplot)}{ar}\\sum_{j=1}^cd_j^2}\\] A  \\({\\bar{\\mu}}_{i\\cdot}\\)  \\({\\tau}={h}_1{\\bar{\\mu}}_{1\\cdot}+{h}_2{\\bar{\\mu}}_{2\\cdot}+\\cdots+{h}_a{\\bar{\\mu}}_{a\\cdot}\\) \\(\\sum_{i=1}^a{h}_i=0\\) \\(\\hat{\\tau}={h}_1{\\bar{y}}_{1\\cdot\\cdot}+{h}_2{\\bar{y}}_{2\\cdot\\cdot}+\\cdots+{h}_a{\\bar{y}}_{a\\cdot\\cdot}\\) \\[\\mathrm{Var}(\\hat{\\tau})=\\left(\\frac{\\sigma_\\varepsilon^2+c\\sigma_w^2}{rc}\\right)\\sum_{i=1}^ah_i^2\\] \\(\\hat{\\tau}\\)  \\[\\widehat{s.e.}(\\hat{\\tau})=\\sqrt{\\left(\\frac{MSError(wholeplot)}{rc}\\right)\\sum_{i=1}^ah_i^2}\\] \\(\\mu_{i1},\\mu_{i2},\\ldots,\\mu_{ic}\\)  \\(\\delta_i=s_1\\mu_{i1}+s_2\\mu_{i2}+\\cdots+s_c\\mu_{ic}\\) \\(\\Sigma_{j=1}^cs_j=0\\).  \\(\\hat\\delta_i=s_1\\bar y_{i1\\cdot}+s_2\\bar y_{i2\\cdot}+\\cdots+s_c\\bar y_{ic\\cdot}\\) \\[\\mathrm{Var}(\\hat{\\delta}_i)=\\frac{\\sigma_\\varepsilon^2}r\\sum_{j=1}^cs_j^2\\] \\(\\hat{\\delta}_i\\)  \\[\\widehat{s.e.}(\\hat{\\delta}_i)=\\sqrt{\\frac{MSError(subplot)}r\\sum_{j=1}^cs_j^2}\\] \\({\\mu}_{1{j}},{\\mu}_{2{j}},\\ldots,{\\mu}_{{a}{j}}\\)  \\({\\lambda}_j={u}_1{\\mu}_{1{j}}+{u}_2{\\mu}_{2{j}}+\\cdots+{u}_a{\\mu}_{{a}{j}}\\) \\({\\Sigma}_{i=1}^a{u}_i=0\\).  \\(\\hat\\lambda_j=u_1\\bar y_{1j\\cdot}+u_2\\bar y_{2j\\cdot}+\\cdots+u_a\\bar y_{aj\\cdot}\\) \\[\\mathrm{Var}(\\hat{\\lambda}_j)=\\frac{(\\sigma_\\varepsilon^2+\\sigma_w^2)}r\\sum_{i=1}^au_i^2\\] \\(\\hat{\\lambda}_j\\)  \\[\\widehat{s.e.}(\\hat{\\lambda}_j)=\\sqrt{\\frac{(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_w^2)}r\\sum_{i=1}^au_i^2}\\]  \\[\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_w^2=\\frac{MSError(wholeplot)+(c-1)MSError(subplot)}c\\]  \\(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_w^2\\)  Satterthwaite  24.2  \\[\\hat{v}=\\frac{(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_w^2)^2}{\\frac{\\left[\\frac1cMSE(wholeplot)\\right]^2}{(r-1)(a-1)}+\\frac{\\left[\\frac{c-1}cMSE(subplot)\\right]^2}{a(r-1)(c-1)}}\\]  \\(\\mu_{ij}\\)  \\(\\sum_{i=1}^a\\sum_{j=1}^cg_{ij}\\mu_{ij}\\).  8  j  \\({\\sum}_{i=1}^{{a}}{g}_{ij}={0}\\)  i  \\({\\sum}_{j=1}^{{c}}{g}_{ij}={0}\\) \\[\\begin{aligned} \\mathrm{Var}\\left(\\sum_{i=1}^a\\sum_{j=1}^cg_{ij}\\bar{y}_{ij\\cdot}\\right)&amp; =\\mathrm{Var}\\left(\\sum_{i=1}^a\\sum_{j=1}^cg_{{ij}}\\left(\\bar{b}_\\cdot+\\bar{w}_{i\\cdot}+\\bar{\\varepsilon}_{{ij\\cdot}}\\right)\\right)=\\mathrm{Var}\\left[\\sum_{i=1}^a\\sum_{j=1}^c\\left(g_{{ij}}\\bar{b}_\\cdot+g_{_{ij}}\\bar{w}_{{i\\cdot}}+g_{{ij}}\\bar{\\varepsilon}_{{ij\\cdot}}\\right)\\right] \\\\ &amp;=\\mathrm{Var}\\left[\\sum_{i=1}^a\\sum_{j=1}^c(g_{ij}\\bar{b}_\\cdot)\\right]+\\mathrm{Var}\\left[\\sum_{i=1}^a\\sum_{j=1}^c(g_{ij}\\bar{w}_{i\\cdot})\\right]+\\mathrm{Var}\\left[\\sum_{i=1}^a\\sum_{j=1}^c(g_{ij}\\bar{\\varepsilon}_{ij.})\\right] \\\\ &amp;=(g_{\\cdot\\cdot})^2\\frac{\\sigma_B^2}r+\\left[\\sum_{i=1}^a(g_{i\\cdot})^2\\right]\\frac{\\sigma_W^2}r+\\left[\\sum_{i=1}^a\\sum_{j=1}^c(g_{ij})^2\\right]\\frac{\\sigma_\\varepsilon^2}r \\end{aligned}\\]  \\(\\sum_{i=1}^a\\sum_{j=1}^cg_{ij}\\mu_{ij}\\)  \\[\\mathrm{Var}\\Bigg(\\sum_{i=1}^a\\sum_{j=1}^cg_{ij}\\bar{y}_{ij\\cdot}\\Bigg)=\\Bigg[\\sum_{i=1}^a\\sum_{j=1}^c(g_{ij})^2\\Bigg]\\frac{\\sigma_\\varepsilon^2}r\\]  \\[\\mathrm{Var}\\left(\\sum_{i=1}^a\\sum_{j=1}^cg_{ij}\\bar{y}_{ij\\cdot}\\right)=\\left[\\sum_{i=1}^a\\sum_{j=1}^c(g_{ij})^2\\right]\\frac{\\hat{\\sigma}_\\varepsilon^2}r\\]  a(r-1)(c-1).  \\(\\bar y_{i\\cdot}\\)  \\(A_{i\\cdot}\\)  \\(\\sum_{i=1}^a\\sum_{j=1}^cg_{ij}\\bar{y}_{ij\\cdot}\\)  \\[g_{ij}=\\begin{cases}\\frac1c\\quad\\mathrm{if~}i=i^{\\prime}\\quad\\mathrm{~for~}j=1,2,...,c\\\\0\\quad\\mathrm{otherwise}\\end{cases}\\]  \\((g_{\\cdot\\cdot})^2=1\\)  \\(\\sum_{i=1}^a(g_{i\\cdot})^2=(g_{i^\\prime \\cdot})^2=1\\) \\[\\sum_{i=1}^a\\sum_{j=1}^c(g_{ij})^2=\\sum_{j=1}^c(g_{i&#39;j})^2=\\sum_{j=1}^c(\\frac1c)^2=\\frac1c\\]  \\[\\mathrm{Var}(\\bar{y}_{i\\cdot\\cdot})=\\frac{\\sigma_B^2}r+\\frac{\\sigma_W^2}r+\\frac{\\sigma_\\varepsilon^2}{rc}=\\frac1{rc}(\\sigma_\\varepsilon^2+c\\sigma_W^2+c\\sigma_B^2)\\]  A  C  \\(\\bar y_{\\cdot j\\cdot}\\)  \\[\\mathrm{Var}(\\bar{y}_{\\cdot j\\cdot})=\\frac{\\sigma_B^2}r+\\frac{\\sigma_W^2}r+\\frac{\\sigma_\\varepsilon^2}{ra}=\\frac1{ra}(\\sigma_\\varepsilon^2+a\\sigma_W^2+a\\sigma_B^2)\\] \\(\\mu_{ij}\\)  \\(\\bar y_{ij\\cdot}\\) \\[\\mathrm{Var}(\\bar{y}_{ij\\cdot})=\\frac{\\sigma_B^2}r+\\frac{\\sigma_W^2}r+\\frac{\\sigma_\\varepsilon^2}r=\\frac1r(\\sigma_\\varepsilon^2+\\sigma_W^2+\\sigma_B^2)\\]  Satterthwaite  \\(\\delta_i\\)  \\[\\begin{aligned} {\\delta}_i&amp; =\\sum_{j=1}^cs_j\\mu_{ij} \\\\ &amp;=\\sum_{j=1}^cs_j[\\mu+\\alpha_i+\\gamma_j+(\\alpha\\gamma)_{ij}] \\\\ &amp;=\\sum_{j=1}^cs_j\\mu+\\sum_{j=1}^cs_j\\alpha_i+\\sum_{j=1}^cs_j\\gamma_j+\\sum_{j=1}^cs_j(\\alpha\\gamma)_{ij} \\\\ &amp;=\\mu\\sum_{j=1}^cs_j+\\alpha_i\\sum_{j=1}^cs_j+\\sum_{j=1}^cs_j\\gamma_j+\\sum_{j=1}^cs_j(\\alpha\\gamma)_{ij} \\\\ &amp;=\\sum_{j=1}^cs_j\\gamma_j+\\sum_{j=1}^cs_j(\\alpha\\gamma)_{ij}\\quad\\mathrm{~since~}\\sum_{j=1}^cs_j=0 \\end{aligned}\\]  \\(\\gamma_j\\)  \\((\\alpha\\gamma)_{ij}\\).  SAS Mixed   \\(t\\) / 24.5  24.5.1  24.3  24.11:  24.3  x  24.11  (moisture)  (fertilizer)  (amount of dry matter).  48  (peat pots)  12  (plastic trays) 10, 20, 30  40  2, 4, 6  8  12 30  i  j  k  \\[y_{ijk}=\\mu_{ij}+t_{ik}+p_{ijk},\\quad i=1,2,3,4;~j=1,2,3,4;~k=1,2,3\\] \\(\\mu_{ij}\\)  i  j \\(t_{ik}\\)  \\(i.i.d.N(0,\\sigma^2_{\\text{tray}})\\) \\(p_{ijk}\\)  \\(i.i.d.N(0,\\sigma^2_{\\text{plot}})\\) \\(p_{ijk}\\)  24.12 24.13  i  \\[\\begin{aligned}\\delta_{LinF|{M}_i}&amp;=-3\\mu_{i1}-\\mu_{i2}+\\mu_{i3}+3\\mu_{i4},\\quad &amp;&amp;i=1,2,3,4\\\\\\delta_{QuadF|{M}_i}&amp;=\\mu_{i1}-\\mu_{i2}-\\mu_{i3}+\\mu_{i4},\\quad &amp;&amp;i=1,2,3,4\\end{aligned}\\]  \\[\\begin{aligned}\\hat{\\delta}_{LinF|M_i}&amp;=-3\\bar{y}_{i\\cdot1}-\\bar{y}_{i\\cdot2}+\\bar{y}_{i\\cdot3}+3\\bar{y}_{i\\cdot4},\\quad &amp;&amp;i=1,2,3,4,\\\\\\hat{\\delta}_{QuadF|M_i}&amp;=\\bar{y}_{i\\cdot1}-\\bar{y}_{i\\cdot2}-\\bar{y}_{i\\cdot3}+\\bar{y}_{i\\cdot4},\\quad &amp;&amp;i=1,2,3,4\\end{aligned}\\]  \\[\\begin{aligned} \\mathrm{Var}(\\hat{\\delta}_{LinF|M_i})&amp; =\\frac{\\sigma_p^2}3[(-3)^2+(-1)^2+1^2+3^2] \\\\ &amp;=\\frac{20{\\sigma}_p^2}3 \\\\ \\mathrm{Var}(\\hat{\\delta}_{QuadF|M_i})&amp; =\\frac{\\sigma_p^2}3[(-1)^2+(-1)^2+1^2+1^2] \\\\ &amp;=\\frac{4{\\sigma}_p^2}3 \\end{aligned}\\]  24.12:  x  24.13:  x  \\(\\sigma^2_p\\)  \\(MSError(pot)\\)  24.14  SAS-Mixed  24.15  \\(t\\)   24.14:  estimate  SAS-Mixed  x  24.15:  x :  2.239  1.001.  \\(t\\)  \\(t_{lpha/2,24}\\)   \\[\\begin{aligned}\\lambda_{LinM|F_j}&amp;=-3\\mu_{1j}-\\mu_{2j}+\\mu_{3j}+3\\mu_{4j},\\quad &amp;&amp;j=1,2,3,4\\\\ \\lambda_{QuadM|F_j}&amp;=\\mu_{1j}-\\mu_{2j}-\\mu_{3j}+\\mu_{4j},\\quad &amp;&amp;j=1,2,3,4\\end{aligned}\\]  \\[\\begin{aligned}\\hat{\\lambda}_{LinM|F_j}&amp;=-3\\bar{y}_{1j\\cdot}-\\bar{y}_{2j\\cdot}+\\bar{y}_{3j.}+3\\bar{y}_{4j\\cdot},\\quad &amp;&amp;j=1,2,3,4\\\\\\hat{\\lambda}_{QuadM|F_k}&amp;=\\bar{y}_{1j\\cdot}-\\bar{y}_{2j\\cdot}-\\bar{y}_{3j\\cdot}+\\bar{y}_{4j\\cdot},\\quad &amp;&amp;j=1,2,3,4\\end{aligned}\\]  \\[\\begin{aligned} \\mathrm{Var}(\\hat{\\lambda}_{LinM|F_k}) &amp;=\\frac{\\sigma_{\\mathrm{pot}}^2+\\sigma_{\\mathrm{tray}}^2}3(3^2+1^2+1^2+3^2) \\\\ &amp;=\\frac{20(\\sigma_{\\mathrm{pot}}^2+\\sigma_{\\mathrm{tray}}^2)}3 \\\\ \\mathrm{Var}(\\hat{\\lambda}_{QuadM|F_k}) &amp;=\\frac{\\sigma_{\\mathrm{pot}}^2+\\sigma_{\\mathrm{tray}}^2}3(1^2+1^2+1^2+1^2) \\\\ &amp;=\\frac{4(\\sigma_{\\mathrm{pot}}^2+\\sigma_{\\mathrm{tray}}^2)}3 \\end{aligned}\\]  \\(\\sigma_{\\mathrm{pot}}^2+\\sigma_{\\mathrm{tray}}^2\\)  \\(\\hat{\\sigma}_{\\mathrm{pot}}^2+\\hat{\\sigma}_{\\mathrm{tray}}^2=\\frac{MSError(tray)+(4-1)MSError(pot)}4\\). Satterthwaite  \\(\\hat{\\sigma}_{\\mathrm{pot}}^2+\\hat{\\sigma}_{\\mathrm{tray}}^2\\)  \\[\\hat{\\sigma}_{\\mathrm{pot}}^2+\\hat{\\sigma}_{\\mathrm{tray}}^2=\\frac{3.406+(4-1)0.752}4=1.416\\]  \\(\\hat v\\)  \\[\\hat{v}=\\frac{[3.406+(4-1)0.752]^2}{\\frac{[3.406]^2}8+\\frac{[(4-1)0.752]^2}{24}}=19.3\\]  24.15  \\(t\\)  24.15  24.16  24.5  24.6  Satterthwaite  24.16   24.5:   24.6:   24.16:  x :  3.072  1.374.  \\(t\\)  \\(t_{lpha/2,19.3}\\)  24.5.2  24.4  24.17:  SAS  x  24.3  (correlated) random  class Mst mstblk mst class  24.17  SAS-Mixed  model mstfrrandom  24.17  24.18 SAS-Mixed  \\[DM_{ijk}=\\beta_0+\\beta_1mst_i+\\beta_2fr_j+\\beta_3(mst_i)(fr_j)+\\beta_4(mst_i)^2(fr_j)+\\beta_5(mst_i)(fr_j)^2+t_{ik}+p_{ijk}\\]  (test for lack of fit).  frx=fr frx  class  mstblk × frx 24.19  24.20  mstblk × frx  \\(F\\)  0.5561 24.21  24.22 24.7  24.8   24.18:  x  24.19:  SAS-Mixed  x  24.20:  MSTBLK × FXR  x  24.21:  SAS  x  24.22:  x  24.7:   24.8:  24.5.3  24.5  24.23:  x  (variates)  (herbicides)  1  2  (combined analysis ) 5 14  24.23  Vx × y  y  x.  1  4  \\[y_{ijkl}=\\mu_{kl}+b_i+w_{ij}+\\varepsilon_{ijkl}\\]  \\(\\mu_{kl}\\)  k  l \\(b_i\\thicksim i.i.d.~N(0,\\sigma_{blk}^2)\\)  (large block effects)\\(w_{ij}\\thicksim i.i.d.~N(0,~\\sigma_{wp}^2)\\)  \\({\\varepsilon_{ijkl}}\\thicksim{i.i.d.N(0,\\sigma_\\varepsilon^2)}\\)  24.24  24.25SAS-Mixed  24.26. model VHrandom  24.27  24.28  3.33 26.1.  3.26 24.7.  24.24:  24.5  1  H  V  x  24.25:  24.5  2  H  V  x  24.26:  24.5  SAS-Mixed  x  24.27:  24.5  x  24.28:  24.5  x 24.5.4  24.6- - (split-split-plot design)  (whole plot) (subplot)  (subsubplot) (rations)3°C  6°C (steers)  10  (side)  10  (packaging)  7  7  (cores) 24.29   24.29:  24.6  x  (shear forces) (\\(f_{ijkl}\\)) \\[f_{ijkl}=\\mu_{ikl}+a_{ij}+s_{ijk}+\\varepsilon_{ijkl}\\quad i=1,2,j=1,2,\\ldots,10,k=1,2,l=1,2,3\\]  \\(\\mu_{ikl}\\)  i  k  l \\(a_{ij}\\thicksim i.i.d.~N(0,\\sigma_{\\mathrm{animal}}^2)\\) \\(s_{ijk}\\thicksim i.i.d.~N(0,\\sigma_{\\mathrm{side}}^2)\\) \\({\\varepsilon_{ijkl}}\\thicksim i.i.d.~N(0,\\sigma_{\\mathrm{steak}}^2)\\)   10  (the animal error term is computed as the variation among animals treated alike within a ration pooled across rations) animal(ration).  1  1  2 1  10  (side error term is computed as the temperature by animal interaction within a ration pooled across rations) temp × animal(ration).  1  3°C  1  3°C  1  3°C  10  package × animal(temp ration).  18, 18, 72. - SAS-Mixed  24.30  random  animal(ration) temp × animal(ration) 24.30  24.31  ration × temperature  ration × packagingration × temperature  24.32  24.33  lsmeans  adjust = Tukey  Tukey  \\(p\\)  0.45 0.679.  (within-animal comparisons) (between-animal comparisons) 24.34  24.35  ration × packaging  0.49 0.71.   24.30:  24.6  SAS-Mixed  x  24.31:  24.6  x  24.32:  24.6  x  24.33:  Tukey  x  24.34:  24.6  x  24.35:  Tukey  x 24.6   \\(\\delta\\)  \\(2\\sigma^2 /n\\)\\(\\hat\\sigma^2\\)  v  \\(\\sigma^2\\)  \\(\\alpha\\) \\(\\beta\\) \\[n=\\frac{2\\hat{\\sigma}^{2}}{\\delta^{2}}[t_{\\alpha/2,v}+t_{\\beta,v}]^{2}\\]  \\(t_{\\beta,v}\\) \\(1-\\beta\\) \\(t_{\\beta,v}\\)  \\[t_{\\beta,v}=\\sqrt{\\frac{n\\delta^2}{2\\hat{\\sigma}^2}}-t_{\\alpha/2,v}\\]  24.6 1.5  \\(\\bar{{\\mu}}_{11\\cdot}-\\bar{{\\mu}}_{21\\cdot}\\).  \\(\\bar{{\\mu}}_{11\\cdot}-\\bar{{\\mu}}_{21\\cdot}\\)  \\(\\bar{{f}}_{1\\cdot1\\cdot}-\\bar{{f}}_{2\\cdot2\\cdot}\\). \\(\\bar{{f}}_{i\\cdot k}\\)  \\(\\bar{f}_{i\\cdot k\\cdot}=\\bar{\\mu}_{ik\\cdot}+\\bar{a}_{i\\cdot}+\\bar{s}_{i\\cdot k}+\\bar{\\varepsilon}_{i\\cdot k\\cdot}\\)  \\(\\bar{{f}}_{1\\cdot1\\cdot}-\\bar{{f}}_{2\\cdot2\\cdot}\\)  \\(\\bar{{\\mu}}_{11{\\cdot}}-\\bar{{\\mu}}_{21{\\cdot}}+\\bar{{a}}_{1{\\cdot}}-\\bar{{a}}_{2{\\cdot}}+\\bar{s}_{1\\cdot1}-\\bar{s}_{2\\cdot1}+\\bar{\\varepsilon}_{1\\cdot1\\cdot}-\\bar{\\varepsilon}_{2\\cdot1\\cdot}\\)  2  3. \\(\\bar{{f}}_{1\\cdot1\\cdot}-\\bar{{f}}_{2\\cdot2\\cdot}\\)  \\[\\begin{aligned} \\mathrm{Var}(\\bar{f}_{1{\\cdot}1{\\cdot}}-\\bar{f}_{2{\\cdot}1{\\cdot}})&amp; =\\frac{2\\sigma_{\\mathrm{animal}}^2}n+\\frac{2\\sigma_{\\mathrm{side}}^2}n+\\frac{2\\sigma_{\\mathrm{steak}}^2}{3n} \\\\ &amp;=\\frac2{3n}(\\sigma_{\\mathrm{steak}}^2+3\\sigma_{\\mathrm{side}}^2+3\\sigma_{\\mathrm{animal}}^2) \\end{aligned}\\]  \\(\\alpha,\\beta\\) \\(\\delta\\)  \\[n=\\frac23(\\hat{\\sigma}_{\\mathrm{steak}}^2+3\\hat{\\sigma}_{\\mathrm{side}}^2+3\\hat{\\sigma}_{\\mathrm{animal}}^2)[t_{\\alpha/2,\\hat{v}}+t_{\\beta,\\hat{v}}]^2/\\delta^2\\]  \\[\\hat{{\\sigma}}_{\\mathrm{steak~}}^2+3\\hat{{\\sigma}}_{\\mathrm{side~}}^2+3\\hat{{\\sigma}}_{\\mathrm{animal}}^2\\]  \\({{\\sigma}}_{\\mathrm{steak~}}^2+3{{\\sigma}}_{\\mathrm{side~}}^2+3{{\\sigma}}_{\\mathrm{animal}}^2\\)  \\(\\hat v\\)  \\[\\begin{aligned} E[MSAnimal(Ration)]&amp;=\\sigma_{\\text{steak}}^2+3\\sigma_{\\text{side}}^2+6\\sigma_{\\text{animal}}^2\\\\ E[MSTemp\\times Animal(Ratin)]&amp;=\\sigma_\\mathrm{steak}^2+3\\sigma_\\mathrm{side}^2 \\\\ E[MSPack\\times Animal(mp* Ratin)]&amp;=\\sigma_{\\mathrm{steak}}^2 \\end{aligned}\\] \\({{\\sigma}}_{\\mathrm{steak~}}^2+3{{\\sigma}}_{\\mathrm{side~}}^2+3{{\\sigma}}_{\\mathrm{animal}}^2\\)  \\[\\hat{\\sigma}_{\\mathrm{steak}}^2+3\\hat{\\sigma}_{\\mathrm{side}}^2+3\\hat{\\sigma}_{\\mathrm{animal}}^2=\\frac12MSAnimal(Ration)+\\frac12MSTemp\\times Animal(Ration)\\]  Satterthwaite  \\[\\hat{v}=\\frac{(\\hat{\\sigma}_{\\mathrm{steak}}^2+3\\hat{\\sigma}_{\\mathrm{side}}^2+3\\hat{\\sigma}_{\\mathrm{animal}}^2)^2}{\\frac{[\\frac12\\textit{MSAnimal}(Ration)]^2}{18}+\\frac{[\\frac12\\textit{MSTemp}\\times Animal(Ration)]^2}{18}}\\]  REML  \\(f(\\sigma_\\varepsilon^2,\\sigma_\\mathrm{side}^2,\\sigma_\\mathrm{animal}^2)\\) \\(f(\\sigma_\\varepsilon^2,\\sigma_\\mathrm{side}^2,\\sigma_\\mathrm{animal}^2)\\)  \\(f(\\hat\\sigma_\\varepsilon^2,\\hat\\sigma_\\mathrm{side}^2,\\hat\\sigma_\\mathrm{animal}^2)\\) \\[\\mathrm{Var}\\Bigl[f(\\hat{\\sigma}_\\varepsilon^2,\\hat{\\sigma}_\\mathrm{side}^2,\\hat{\\sigma}_\\mathrm{animal}^2)\\Bigr]=\\begin{bmatrix}\\frac{\\partial f}{\\partial\\sigma_\\varepsilon^2}\\quad\\frac{\\partial f}{\\partial\\sigma_\\mathrm{side}^2}\\quad\\frac{\\partial f}{\\partial\\sigma_\\mathrm{animal}^2}\\end{bmatrix}\\mathrm{Var}\\Bigl[\\hat{\\sigma}_\\varepsilon^2,\\hat{\\sigma}_\\mathrm{side}^2,\\hat{\\sigma}_\\mathrm{animal}^2\\Bigr]\\begin{bmatrix}\\frac{\\partial f}{\\partial\\sigma_\\varepsilon^2}\\\\\\frac{\\partial f}{\\partial\\sigma_\\mathrm{side}^2}\\\\\\frac{\\partial f}{\\partial\\sigma_\\mathrm{animal}^2}\\end{bmatrix}\\]  REML  \\(\\mathrm{Var}\\Bigl[f(\\hat{\\sigma}_\\varepsilon^2,\\hat{\\sigma}_\\mathrm{side}^2,\\hat{\\sigma}_\\mathrm{animal}^2)\\Bigr]\\) \\[\\begin{aligned}Z=\\frac{f(\\hat{\\sigma}_\\varepsilon^2,\\hat{\\sigma}_\\mathrm{side}^2,\\hat{\\sigma}_\\mathrm{animal}^2)}{\\sqrt{\\widehat{\\text{Var}}\\left[f(\\hat{\\sigma}_\\varepsilon^2,\\hat{\\sigma}_\\mathrm{side}^2,\\hat{\\sigma}_\\mathrm{animal}^2)\\right]}}\\end{aligned}\\]  \\(f(\\hat\\sigma_\\varepsilon^2,\\hat\\sigma_\\mathrm{side}^2,\\hat\\sigma_\\mathrm{animal}^2)\\)  Satterthwaite  \\(\\hat v=2Z^2\\).  24.6 1.5  0.05  0.05.  24.30  \\(\\hat{\\sigma}_{\\mathrm{animal}}^2=1.2434,\\hat{\\sigma}_{\\mathrm{side}}^2=0.1992,\\hat{\\sigma}_{\\mathrm{steak}}^2=1.7529\\). \\({\\sigma}_\\mathrm{steak}^2+3{\\sigma}_\\mathrm{side}^2+3{\\sigma}_{\\mathrm{animal}}^2\\)  6.08086.  24.36  \\[\\widehat{\\text{Var}}\\begin{bmatrix}\\hat{{\\sigma}}_\\mathrm{arimal}^2\\\\\\hat{{\\sigma}}_\\mathrm{side}^2\\\\\\hat{{\\sigma}}_\\mathrm{steak}^2\\end{bmatrix}=\\begin{bmatrix}0.3723&amp;-0.06154&amp;0.002209\\\\-0.06154&amp;0.1305&amp;-0.05370\\\\0.002209&amp;-0.05370&amp;0.1296\\end{bmatrix}=\\hat{\\boldsymbol V}\\]  24.36:  24.6  x  \\({\\hat\\sigma}_\\mathrm{steak}^2+3{\\hat\\sigma}_\\mathrm{side}^2+3{\\hat\\sigma}_{\\mathrm{animal}}^2\\)  \\[\\widehat{\\mathrm{Var}}(\\hat{\\sigma}_{\\mathrm{steak}}^2+3\\hat{\\sigma}_{\\mathrm{side}}^2+3\\hat{\\sigma}_{\\mathrm{animal}}^2)=\\begin{bmatrix}3&amp;3&amp;1\\end{bmatrix}\\hat{\\boldsymbol V}\\begin{bmatrix}3\\\\3\\\\1\\end{bmatrix}=3.23805\\]  \\(Z\\)  \\[Z=\\frac{\\hat{\\sigma}_\\mathrm{steak}^2+3\\hat{\\sigma}_\\mathrm{side}^2+3\\hat{\\sigma}_\\mathrm{animal}^2}{\\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\sigma}_\\mathrm{steak}^2+3\\hat{\\sigma}_\\mathrm{side}^2+3\\hat{\\sigma}_\\mathrm{animal}^2)}}=3.379\\]  \\(\\hat{\\sigma}_{\\mathrm{steak}}^2+3\\hat{\\sigma}_{\\mathrm{side}}^2+3\\hat{\\sigma}_{\\mathrm{animal}}^2\\)  \\(2(3.379)^2=22.8\\).  \\(n=\\frac23(6.08086)[t_{0.025,22.8}+t_{0.05,22.8}]^2/1.5^2=25.8\\)  \\(n=26\\).  10  1.5 40 \\[t_{\\beta,\\hat{v}}=\\sqrt{\\frac{10\\delta^2}{3(\\hat{\\sigma}_{\\mathrm{seak}}^2+3\\hat{\\sigma}_{\\mathrm{side}}^2+3\\hat{\\sigma}_{\\mathrm{animal}}^2)}}-t_{\\alpha/2,\\hat{v}}=\\sqrt{\\frac{10(1.5)^2}{3(6.08086)}}-2.069=0.2869\\]  \\(\\alpha=0.05\\)  \\(\\beta=0.388\\) \\(1-\\beta=0.612\\)  10  1.5  61%   1.5 41 \\(\\bar{{\\mu}}_{\\cdot11}-\\bar{{\\mu}}_{\\cdot21}\\).  \\(\\bar{f}_{\\cdot\\cdot kl}=\\bar{\\mu}_{\\cdot kl}+\\bar{a}_{\\cdot\\cdot}+{\\bar{s}}_{\\cdot\\cdot k}+{\\bar{\\varepsilon}}_{\\cdot\\cdot jk}\\).  \\[\\begin{aligned} \\mathrm{Var}(\\bar{f}_{\\cdot\\cdot11}-\\bar{f}_{\\cdot\\cdot21}) =\\text{ Var}(\\bar{s}_{{\\cdot\\cdot}1}-\\bar{s}_{\\cdot\\cdot2}+\\bar{{\\varepsilon}}_{\\cdot\\cdot11}-\\bar{{\\varepsilon}}_{\\cdot\\cdot21}) \\\\ =\\frac{2{\\sigma_\\mathrm{side}}^2}{2n}+\\frac{2{\\sigma_\\mathrm{steak}}^2}{2n} \\\\ =\\frac2{2n}(\\sigma_{\\mathrm{side}}^2+\\sigma_{\\mathrm{steak}}^2) \\end{aligned}\\]  \\(n=\\frac22(\\hat{\\sigma}_{\\mathrm{steak}}^2+\\sigma_{\\mathrm{side}}^2)[t_{0.025,49.9}+t_{0.05,49.9}]^2/1.5^2=11.8\\) 49.9.  24.7  JMP  24.7  24.9:  24.7  32   24.10:  24.7  16   24.9  24.10  JMP  block, variety, fert  rate (varieties)  (fertilizer)  (seeding rate)  24.37  (4-1)(4-1) = 9  1  24.38  6  6  6  (4)(6) = 24  \\[y_{ijkl}=\\mu_{ijl}+b_k+zv_{ijk}+\\varepsilon_{ijkl}\\quad i=1,2,j=1,2,k=1,2,3,4,l=1,2,3\\]  \\(b_k\\thicksim i.i.d.N(0,\\sigma_{blk}^2),w_{ijk}\\thicksim i.i.d.N(0,\\sigma_{ivp}^2),\\varepsilon_{ijkl}\\thicksim i.i.d.N(0,\\sigma_{sp}^2)\\)  \\(\\mu_{ijl}\\)  i,  j  l   24.37:  24.7  x  24.38:  1  1  x  24.39 JMP fit model  24.11  attributes  block  block × variety × fert  random  REML method  III  run model  24.12  SAS-Mixed  Waldner  Satterthwaite  variety × fert × rate  effects  24.13 - 24.15 least square means  24.16 tables plots contrasts Tukey HSD  Tukey slice  24.17  Tukey HSD  2, 2, 10  2, 2, 6  A  B 2, 2, 10  1, 2, 4  C 2, 2, 6  1, 2, 4 42  24.39:  24.7  x  24.11:  24.7 fit model   24.12:  24.7  (REML)   24.13:  24.7   24.14:   24.15:   24.16:  least square means   24.17:  Tukeys method  24.18  Tukey HSD  Variety × Fert  95%  24.19   24.18:  24.7 Tukeys method   24.19:  contrast   JMP  JMP  fit model  24.8   SAS Mixed  JMP  24.9  The process of determining the appropriate standard error involves expressing \\(\\bar{{y}}_{\\cdot j\\cdot}\\) in terms of the quantities in the model obtained by summing over i and k.  \\(\\beta\\) R  pt(0.2869,22.8)  The second sample size problem is to determine the number of animals required to detect a difference of 1.5 shear force units between two temperature means at the same level of packaging averaged over the two levels of ration. Missing data cause the variances of comparisons to be different, which in turn can provide multiple comparisons that are not completely ordered as demonstrated above. "],["chap25.html", " 25   25.1  25.2  25.3  25.4  1 25.5  2 25.6  3 25.7  4 25.8 - JMP7 25.9  25.10 ", "  25   Statistics are the heart of democracy. - Simeon Strunsky  (strip-plot)  5  (row) (column) - (strip-strip-plot)  25.1   a  a A c  c C A  A  C  C  25.1  A  C  r  (blocked replicates).  A  C  A × C   25.1:   C  A  25.2  \\[y_{ik}=\\mu_i^r+b_k^r+e_{ik}^r,\\quad i=1,2,\\ldots,a,\\quad k=1,2,\\ldots,r\\]  \\(b_k^r\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{block}}^2)\\) \\(e_{ik}^r\\thicksim i.i.d.~N(0,\\sigma_{\\mathrm{row}}^2)\\).  25.2:  A   25.1  rectangle × A   25.1:  x  A  C  25.3  \\[y_{jk}=\\mu_j^c+b_k^c+e_{jk}^c\\quad i=1,2,\\ldots,c,k=1,2,\\ldots,r\\]  25.3:  C   \\(b_k^c\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{block}}^2)\\) \\(e_{ik}^c\\thicksim i.i.d.~N(0,\\sigma_{\\mathrm{column}}^2)\\).  25.2  rectangle × C  A  (between-row comparisons) C  (between-column comparisons) A × C  A × C 43  25.2:  x  \\[y_{ijk}=\\mu+b_k+\\alpha_i+r_{ik}+\\gamma_j+c_{jk}+(\\alpha\\gamma)_{ij}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,a,\\quad j=1,2,\\ldots,c,\\quad k=1,2,\\ldots,r\\]  \\(\\mu\\) \\(\\alpha_i\\)  A  i \\(\\gamma_j\\)  C  j \\((\\alpha\\gamma)_{ij}\\)  A  C \\(b_k\\)  k  \\(b_k\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{block}}^2)\\)\\(r_{ik}\\)  k  i  \\(r_{ik}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{row}}^2)\\)\\(c_{jk}\\)  k  j  \\(c_{jk}\\thicksim i.i.d.N(0,\\sigma_{\\mathrm{column}}^2)\\) \\(\\varepsilon_{ijk}\\)  k  ij  \\({\\varepsilon}_{ijk}\\thicksim i.i.d.~N(0,{\\sigma}_{\\mathrm{cell}}^2)\\).   25.3:  x  A  C  A  C  25.3  25.1  25.2  AC \\[y_{ijk}=\\mu_{ij}+b_k+r_{ik}+c_{jk}+\\varepsilon_{ijk},\\quad i=1,2,\\ldots,a,j=1,2,\\ldots,c,\\quad k=1,2,\\ldots,r\\]  \\(\\mu_{ij}=\\mu+\\alpha_i+\\gamma_j+(\\alpha\\gamma)_{ij}\\).  \\(\\hat{\\mu}_{ij}=\\bar{y}_{ij\\cdot}\\) \\(\\mu_{ij}\\)  \\(\\hat \\mu_{ij}\\)  25.3  \\[\\begin{aligned} \\tilde{\\sigma}_{\\mathrm{cell}}^2&amp; =\\text{MSError(cell)} \\\\ \\tilde{{\\sigma}}_{\\mathrm{row}}^2&amp; =\\frac{MSError(row)-MSError(cell)}c \\\\ \\tilde{{\\sigma}}_{\\mathrm{column}}^2&amp; =\\frac{MSError(column)-MSError(cell)}a \\\\ \\tilde{{\\sigma}}_{\\mathrm{block}}^2&amp; =\\frac{MSBlock-MSError(column)-MSError(row)+MSError(cell)}{ac} \\end{aligned}\\]  \\[\\begin{aligned} \\hat{{\\sigma}}_{\\mathrm{cell}}^2&amp;= \\tilde{{\\sigma}}_{\\mathrm{cell}}^2 \\\\ \\hat{\\sigma}_{\\mathrm{row}}^2&amp;= \\begin{cases}\\tilde{{\\sigma}}_\\mathrm{row}^2&amp;&amp;\\mathrm{if~}\\tilde{{\\sigma}}_\\mathrm{row}^2&gt;0\\\\0&amp;&amp;\\mathrm{if~}\\tilde{{\\sigma}}_\\mathrm{row}^2\\leq0\\end{cases} \\\\ \\hat{{\\sigma}}_{\\mathrm{column}}^2&amp;= \\begin{cases}\\tilde{{\\sigma}}_\\mathrm{column}^2&amp;&amp;\\mathrm{if~}\\tilde{{\\sigma}}_\\mathrm{column}^2&gt;0\\\\0&amp;&amp;\\mathrm{if~}\\tilde{{\\sigma}}_\\mathrm{column}^2\\leq0\\end{cases} \\\\ \\hat{{\\sigma}}_{\\mathrm{block}}^2&amp;= \\begin{cases}{\\tilde{\\sigma}}_\\mathrm{block}^2&amp;&amp;\\mathrm{if~}{\\tilde{\\sigma}}_\\mathrm{block}^2&gt;0\\\\0&amp;&amp;\\mathrm{if~}{\\tilde{\\sigma}}_\\mathrm{block}^2\\leq0\\end{cases} \\end{aligned}\\]  25.2   25.3  \\(H_{0AC}\\colon\\mu_{ij}-\\mu_{ij}-\\mu_{ij}+\\mu_{ij}=0\\text{ for all }i\\neq i&#39;\\text{ and }j\\neq j&#39;\\text{ vs }H_{aAC}:\\text{ (not }H_{0AC})\\) A × C  MSError(cell).  A  \\(H_{0A}\\colon\\bar{{\\mu}}_{1\\cdot}=\\bar{{\\mu}}_{2\\cdot}=\\cdots=\\bar{{\\mu}}_{a\\cdot}\\mathrm{~vs~}H_{aA}{:}(\\text{nt }H_{0A})\\) A  MSError(row).  C  \\(H_{0C}\\colon\\bar{{\\mu}}_{\\cdot 1}=\\bar{{\\mu}}_{\\cdot2}=\\cdots=\\bar{{\\mu}}_{\\cdot c}\\mathrm{~vs~}H_{aC}{:}(\\text{nt }H_{0C})\\) C  MSError(column).  24  25.4  24  A  C  \\(\\mu_{12}-\\mu_{34}\\) \\(\\hat\\mu_{ij}=\\bar y_{ij\\cdot}\\)  \\(\\hat{{\\mu}}_{ij}={\\mu}_{ij}+\\bar{{b}}_\\cdot+\\bar{{r}}_{i{\\cdot}}+\\bar{{c}}_{j{\\cdot}}+\\bar{{\\varepsilon}}_{i{j}}\\).  \\(\\hat\\mu_{12}-\\hat\\mu_{34}\\)  \\[\\hat{\\mu}_{12}-\\hat{\\mu}_{34}=\\bar{y}_{12\\cdot}-\\bar{y}_{34\\cdot}=\\mu_{12}-\\mu_{34}+\\bar{r}_{1\\cdot}-\\bar{r}_{3\\cdot}+\\bar{c}_{2\\cdot}-\\bar{c}_{4\\cdot}+\\bar{\\varepsilon}_{12\\cdot}-\\bar{\\varepsilon}_{34\\cdot}\\]  25.4:  \\(i \\ne m\\)  \\(j \\ne n\\) x \\(\\mu_{12}-\\mu_{34}\\)  \\(\\bar y_{12\\cdot}-\\bar y_{34\\cdot}\\)\\(\\hat\\mu_{12}-\\hat\\mu_{34}\\)  \\[\\begin{aligned} \\mathrm{Var}(\\hat{\\mu}_{12}-\\hat{\\mu}_{34})&amp; =\\mathrm{Var}(\\bar{r}_1.-\\bar{r}_3.+\\bar{c}_2.-\\bar{c}_4.+\\bar{\\varepsilon}_{12.}-\\bar{\\varepsilon}_{34.}) \\\\ &amp;=\\frac{2\\sigma_\\mathrm{row}^2}r+\\frac{2\\sigma_\\mathrm{column}^2}r+\\frac{2\\sigma_\\mathrm{cell}^2}r \\\\ &amp;=\\frac{2(\\sigma_{\\mathrm{cell}}^2+\\sigma_{\\mathrm{column}}^2+\\sigma_{\\mathrm{row}}^2)}{r} \\end{aligned}\\] \\(\\hat\\mu_{12}-\\hat\\mu_{34}\\)  \\[\\widehat{\\mathrm{Var}}(\\hat\\mu_{12}-\\hat\\mu_{34}) =\\frac{2(\\hat\\sigma_{\\mathrm{cell}}^2+\\hat\\sigma_{\\mathrm{column}}^2+\\hat\\sigma_{\\mathrm{row}}^2)}{r}\\]  \\(\\tilde{\\sigma}_{\\mathrm{row}}^2&gt;0\\)  \\(\\tilde{\\sigma}_{\\mathrm{column}}^2&gt;0\\)  \\[\\widehat{\\mathrm{Var}}(\\hat{\\mu}_{12}-\\hat{\\mu}_{34})=\\frac2{acb}\\left[aMSError(row)+cMSError(column)+(ac-a-c)MSError(cell)\\right]\\]  25.4  25.5  Satterthwaite  \\[\\begin{aligned} \\hat{{\\omega}}_{1}&amp;=\\frac{\\left[MSError(column)+(c-1)MSError(cell)\\right]^2}{\\left[MSError(column)\\right]^2}+\\frac{\\left[(c-1)MSError(cell)\\right]^2}{(a-1)(c-1)(r-1)} \\\\ \\hat{{\\omega}} _2&amp;=\\frac{[MSError(row)+(a-1)MSError(cell)]^2}{\\frac{[MSError(row)]^2}{(a-1)(r-1)}+\\frac{[(a-1)MSError(cell)]^2}{(a-1)(c-1)(r-1)}} \\\\ \\hat{{\\omega}}_{3} &amp;=\\frac{[aMSError(row)+cMSError(column)+(ac-a-c)MSError(cell)]^2}{\\frac{[aMSError(row)]^2}{(a-1)(r-1)}+\\frac{[cMSError(column)]^2}{(c-1)(r-1)}+\\frac{[(ac-a-c)MSError(cell)]^2}{(a-1)(c-1)(r-1)}} \\end{aligned}\\]  25.5:  \\(i \\ne m\\)  \\(j \\ne n\\) x  25.3   25.4:   (irrigation)  (nitrogen)  25.4  SAS®-Mixed  III  25.6 \\(F\\)  60.13, 52.18  33.12.  25.7  25.8  REML  SAS-Mixed  25.9  25.9  25.6  III  25.7  SAS-Mixed  estimate  25.10   25.6:  III  SAS-Mixed  x  25.7:  \\(i \\ne m\\)  \\(j \\ne n\\) x  25.8:  REML  SAS-Mixed  x  25.9:  REML  x  25.10:  SAS-Mixed REML  Estimate  x  LSD  25.4  1  25.5:   25.3  (varieties)  25.5  25.5  (plots)  25.3  25.6  (subplots) (within-cell or between-subplot comparisons).  \\[y_{ijkl}=\\mu_{ijk}+b_l+r_{il}+c_{jl}+d_{ijl}+\\varepsilon_{ijkl},\\quad i=1,2,j=1,2,3,k=1,2,3,l=1,2,3,4\\]  \\(\\mu_{ijk}\\)  i  j  k \\(b_l\\)  l  \\(b_l\\sim i.i.d.N(0,\\sigma_{\\mathrm{block}}^2)\\)\\(c_{jl}\\)  l  i  \\(c_{jl}\\sim i.i.d.N(0,\\sigma_{\\mathrm{column}}^2)\\)\\(d_{ijl}\\)  l  ij  \\(d_{ijl}\\sim i.i.d.N(0,\\sigma_{\\mathrm{cell}}^2)\\) \\(\\varepsilon_{ijkl}\\)  l  ij  k  \\({\\varepsilon}_{ijkl}\\thicksim i.i.d.N(0,{\\sigma}_{\\mathrm{subplot}}^2)\\).  25.11  25.12  SAS-Mixed  block × nit block × irr block × nit × irr.  variety  block  nit  irr  (the variety by block interaction pooled across the levels of nit and irr).  25.11:  x  25.12:  25.4 - (strip-split-plot)  SAS-Mixed  x 25.5  2  25.6:   25.4  25.6 44 25.3  25.13  (subrow)  1/3  block × variety  1  25.14  (subcell)  block × irrigation × variety  6  18 nitrogen × irrigation × variety block × nitrogen × irrigation × variety  12  30  25.15   25.13:  25.5  x  25.14:  25.5  x  25.15:  25.5 - (strip-split-plot)  x 25.6  3  25.7:   25.7  (herbicide)  (seeding rates) 45 25.16  block × herbicide, block c nitrogen  block × herbicide × nitrogen  block × variety  block × variety × herbicide, block × variety × nitrogen  block × variety × herbicide × nitrogen  18  herbicide, nitrogen  variaty  block × seeding  herbicide, nitrogen  variety 46 72   25.16:  25.5 - x 25.7  4  25.8:   25.8  (squares).  block × variety, block × seeding rate  block × variety × seeding rate  9  SAS-Mixed  variety × seeding × block  (big block)  25.17  1  1 25.18  Error(row/block), Error(column/block) Error(cell/block) 12 SAS-Mixed  25.19 Error(big squares) = Variety × Seeding × Block, Error(row/ block) = Herbicide × Block(Variety Seeding), Error(column/block) = Nitrogen × Block(Variety Seeding), and Error(cell/block) = Nitrogen × Herbicide × Block(Variety Seeding).  25.17:  25.7  x  25.18:  25.7  1  1  x  25.19:  25.7  SAS Mixed  x 25.8 - JMP7  25.9:   25.10:  25.9   (tiers) --- (split-split plot)  (silicon wafer) 20  0.2  (polishing)  (cleaning) (washing off)  25.9  25.10  clean × block  wash × block  clean × wash × block  temperature × block  temperature × wash × block  temperature × clean × block  temperature × clean × wash × block  \\[y_{ijkl}=\\mu_{ijk}+b_l+r_{il}+c_{jl}+t_{kl}+w_{ijl}^{2W}+w_{ikl}^{2C}+w_{jkl}^{2T}+\\varepsilon_{ijkl},\\quad i=1,2,j=1,2,k=1,2,l=1,2,3,4\\] \\(\\mu_{ijk}\\)  i  j  k  \\[\\begin{aligned}&amp;b_{l}\\sim i.i.d.N(0,\\sigma_{\\mathrm{block}}^{2}),\\quad r_{il}\\sim i.i.d.N(0,\\sigma_{\\mathrm{row}}^{2}),\\quad c_{jl}\\sim i.i.d.N(0,\\sigma_{\\mathrm{column}}^{2})\\\\&amp;t_{kl}\\sim i.i.d.N(0,\\sigma_{\\mathrm{tier}}^{2}),\\quad w_{ijl}^{2W}\\sim i.i.d.N(0,\\sigma_{2\\text{washwafer}}^{2})\\\\&amp;w_{ikl}^{2\\text{}} \\sim i . i . d . N ( 0 , \\sigma _ { 2\\text{cleanwafer}}^{2}),\\quad w_{jkl}^{2T}\\sim i.i.d.N(0,\\sigma_{2\\text{tempwafer}r}^{2})\\end{aligned}\\]  \\[\\varepsilon_{ijkl}\\sim i.i.d.~N(0,\\sigma_{\\mathrm{wafer}}^2)\\]  25.20  w, 2Tw, 2Cw  2Ww   25.20:  25.8 - x  25.11  25.12  JMP model specification  Attributes  block  25.13  REML  III  temperature × clean × wash  25.14  25.15  25.4 -  25.11:  25.8   25.12:  25.8  fit model   25.13:   25.14:   25.15:  25.9   25  25.10  Thus the size of the experimental unit on which the A × C interaction is measured is the intersection of a row and a column which corresponds to a cell within the rectangle. The levels of variety are subplots for the levels of nitrogen, but the levels of variety and the levels of nitrogen are strip-plots with the levels of irrigation. The varieties form a strip plot with the combination of levels of nitrogen and herbicide. The subplot error is obtained by computing the block × seeding rate interaction for each combination of herbicide, nitrogen, and variety and then pooling these interactions across the levels of herbicide, nitrogen, and variety. "],["chap26.html", " 26   26.1  26.2  26.3  SAS-Mixed  26.4  26.5 ", "  26   [Statistics are] the only tools by which an opening can be cut through the formidable thicket of difficulties that bars the path of those who pursue the science of man. - Sir Francis Galton  (repeated measures designs)  (subject47)  48  (split-plot in time analysis).  26.1  (split-plot in time analysis of variance)  26.2  27  26.1   26.1  5, 10, 15  20  \\(n_i\\)  i p  26.1   26.1:  x  \\[\\begin{equation} y_{ijk}=\\mu+\\alpha_i+\\delta_{ik}+\\tau_j+(\\alpha\\tau)_{ij}+\\varepsilon_{ijk} \\tag{26.1} \\end{equation}\\]  \\[y_{ijk}=\\mu_{ij}+\\delta_{ik}+\\varepsilon_{ijk}\\]  \\(\\mu+\\alpha_i+\\delta_{ik}\\) \\(\\tau_j+(\\alpha\\tau)_{ij}+\\varepsilon_{ijk}\\)  j  i  \\[\\mu_{ij}=\\mu+\\alpha_i+\\tau_j+(\\alpha\\tau)_{ij}\\] \\(\\delta_{ik}\\) \\(\\varepsilon_{ijk}\\)  (within-subject) \\(\\delta_{ik}\\)  \\(N(0,\\sigma_{\\delta}^{2})\\) \\(\\varepsilon_{ijk}\\)  \\(N(0,\\sigma_\\varepsilon^2)\\)  \\(\\delta_{ik}\\)  \\(\\varepsilon_{ijk}\\)   24  27   26.3  10  7  0 6  12  6  \\[\\begin{aligned} Y_{ijkm}&amp; =\\mu+\\alpha_{i}+f_{im} &amp;&amp;\\text{family experimental unit}\\\\ &amp;+\\beta_j+(\\alpha\\beta)_{ij}+p_{ijm} &amp;&amp;\\text{person experimental unit}\\\\ &amp;+\\tau_k+(\\alpha\\tau)_{ik}+(\\beta\\tau)_{jk}+(\\alpha\\beta\\tau)_{ijk}+\\varepsilon_{ijkm}&amp;&amp;\\text{time interval experimental unit} \\end{aligned}\\]  \\[\\begin{equation} y_{ijkm}=\\mu_{ijk}+f_{im}+p_{ijm}+\\varepsilon_{ijkm} \\tag{26.2} \\end{equation}\\] \\(i=1,2;j=1,2,3;k=1,2,3;m=1,2,\\ldots,n_i\\) \\(n_1=10,n_2=7\\). \\(f_{im}\\) \\(p_{ijm}\\) \\(\\varepsilon_{ijkm}\\) 49 \\(f_{im}\\)  \\(N(0,\\sigma_f^2)\\). \\(p_{ijm}\\)  \\(N(0,\\sigma_p^2)\\). \\(\\varepsilon_{ijkm}\\)  \\(N(0,\\sigma_\\varepsilon^2)\\).  \\(f_{im},p_{ijm}\\)  \\(\\varepsilon_{ijkm}\\)   27  26.2   24  25  \\(F\\)   24  26.2.1  26.1  t  p n  (26.1)  \\[y_{ijk}=\\mu+\\alpha_i+\\delta_{ik}+\\tau_j+(\\alpha\\tau)_{ij}+\\varepsilon_{ijk},~i=1,2,\\ldots,t;~j=1,2,\\ldots,p;~k=1,2,\\ldots,n\\] \\(\\delta_{ik}\\) \\(\\varepsilon_{ijk}\\)  \\(\\delta_{ik}\\)  \\(N(0,\\sigma_\\delta^2)\\). \\(\\varepsilon_{ijk}\\)  \\(N(0,\\sigma_\\varepsilon^2)\\).  \\(\\delta_{ik}\\)  \\(\\varepsilon_{ijk}\\)   26.2  26.1   26.2:  26.1  x  26.2 \\(Q_{Drug},Q_{Time}\\)  \\(Q_{Drug\\times Time}\\)  ×  \\(Q\\)   \\(H_{01}\\colon Q_{Drug}=0\\) \\(H_{01}\\)  \\[F=\\frac{MSDrug}{MSError(Subject)}&gt;F_{\\alpha,t-1,t(n-1)}\\]  \\(H_{02}\\colon Q_{Time}=0\\) \\(H_{02}\\)  \\[F=\\frac{MSTime}{MSError(Time)}&gt;F_{\\alpha,p-1,t(p-1)(n-1)}\\]  \\(H_{03}\\colon Q_{Drug\\times Time}=0\\) \\(H_{03}\\)  \\[F=\\frac{MSDrug\\times Time}{MSError(Time)}&gt;F_{\\alpha,(t-1)(p-1),t(p-1)(n-1)}\\]  \\[\\begin{aligned}\\tilde{{\\sigma}}_\\varepsilon^2&amp;=MSError(Time)\\\\\\tilde{{\\sigma}}_\\delta^2&amp;=\\frac{MSError(Subject)-\\tilde{{\\sigma}}_\\varepsilon^2}p\\end{aligned}\\]  \\[\\begin{aligned}\\hat{\\sigma}_\\varepsilon^2&amp;=\\tilde{\\sigma}_\\varepsilon^2\\\\\\hat{\\sigma}_\\delta^2&amp;=\\begin{cases}\\tilde{\\sigma}_\\delta^2&amp;\\mathrm{if~}\\tilde{\\sigma}_\\delta^2&gt;0\\\\0&amp;\\mathrm{if~}\\tilde{\\sigma}_\\delta^2\\leq0&amp;\\end{cases}\\end{aligned}\\] \\(\\mu_{ij},\\bar{\\mu}_{i\\cdot},\\bar{\\mu}_j\\)  \\(\\bar{\\mu}_{\\cdot\\cdot}\\)  \\(\\hat{{\\mu}}_{ij}=\\bar{{y}}_{ij\\cdot},\\hat{\\bar{{\\mu}}}_{i\\cdot}=\\bar{{y}}_{i\\cdot\\cdot},\\hat{\\bar{{\\mu}}}_{\\cdot j}=\\bar{{y}}_{\\cdot j\\cdot}\\)  \\(\\hat{{\\bar{\\mu}}}_{\\cdot\\cdot}=\\bar{{y}}_{\\cdot\\cdot\\cdot}\\).  26.3   26.3:  x \\(\\mu_{ij}-\\mu_{i&#39;j}-\\mu_{ij&#39;}+\\mu_{i&#39;j&#39;}\\)  \\(\\hat{\\mu}_{ij}-\\hat{\\mu}_{i&#39;j}-\\hat{\\mu}_{ij&#39;}+\\hat{\\mu}_{i&#39;j&#39;}\\) \\(i\\ne i&#39;,j\\ne j&#39;\\)  \\(\\sqrt{(4\\hat{\\sigma}_{\\varepsilon}^{2}/n)}\\).  \\(t\\)  \\(t\\)  \\(\\hat \\sigma^2_\\varepsilon\\)  \\(t\\)  t(n - 1)(p - 1).  \\(\\sqrt{(\\hat{\\sigma}_{\\varepsilon}^{2}+p\\hat{\\sigma}_{\\delta}^{2})}\\)  \\(t\\)  t(n - 1).  \\(\\sqrt{(\\hat{\\sigma}_{\\varepsilon}^{2}+\\hat{\\sigma}_{\\delta}^{2})}\\)  \\(t\\)  Satterthwaite   \\({\\varphi}=\\sum_{i=1}^{t}{\\sum}_{j=1}^{p}{c}_{i{j}}{\\mu}_{i{j}}\\)  \\(\\mu_{ij}\\)  \\(\\hat \\mu_{ij}\\)  \\({\\hat\\varphi}=\\sum_{i=1}^{t}{\\sum}_{j=1}^{p}{c}_{i{j}}{\\hat\\mu}_{i{j}}\\)  \\(k,c_1,c_2\\) \\(\\hat \\phi\\)  \\(k[c_1{\\hat{\\sigma}}_1^2+c_2{\\hat{\\sigma}}_2^2]\\) \\(v_i\\hat{\\sigma}_i^2/\\sigma_i^2\\)  \\(\\chi^2(v_i)\\) \\(i=1,2\\).  \\({(\\widehat{\\phi}-\\phi)}\\widehat{s.e.}(\\widehat{\\phi})\\)  \\(t(\\hat v)\\) \\[\\hat{v}=\\frac{(c_1\\hat{\\sigma}_1^2+c_2\\hat{\\sigma}_2^2)^2}{(c_1^2\\hat{\\sigma}_1^2/v_1)+(c_2^2\\hat{\\sigma}_2^2/v_2)}\\] \\(\\hat{{\\sigma}}_1^2\\)  \\(v_1=t(n-1)\\)  MSError(Subject)\\(\\hat{{\\sigma}}_2^2\\)  \\(v_2=t(n-1)(p-1)\\)  MSError(Time).  \\(\\hat{{\\sigma}}_\\varepsilon^2+\\hat{{\\sigma}}_\\delta^2\\)  \\(c_1 = 1/p\\)  \\(c_2 = (p - 1)/p\\).  \\(\\sum_{i=1}^tc_i\\bar{\\mu}_{i\\cdot}\\) \\[\\sqrt{\\frac{(\\hat{\\sigma}_\\varepsilon^2+p\\hat{\\sigma}_\\delta^2)\\sum_{i=1}^tc_i^2}{np}}\\]  \\[\\frac{\\sum_{i=1}^tc_i\\hat{\\bar{{\\mu}}}_{i\\cdot}-\\sum_{i=1}^tc_i\\bar{{\\mu}}_{i\\cdot}}{\\sqrt{\\frac{(\\hat{{\\sigma}}_\\varepsilon^2+p\\hat{{\\sigma}}_\\delta^2)\\sum_{i=1}^tc_i^2}{np}}}\\sim t[t(n-1)]\\]  \\(\\sum_{i=1}^td_j\\bar{\\mu}_{\\cdot j}\\) \\[\\sqrt{\\frac{\\hat{{\\sigma}}_\\varepsilon^2\\sum_{j=1}^pd_j^2}{nt}}\\]  \\[\\frac{\\sum_{j=1}^pd_j\\hat{{\\bar{\\mu}}}_{\\cdot j}-\\sum_{j=1}^pd_j{{\\bar{\\mu}}}_{\\cdot j}}{\\sqrt{\\frac{{\\hat{\\sigma}}_\\varepsilon^2\\sum_{j=1}^pd_j^2}{nt}}}\\sim t[t(n-1)(p-1)]\\]   × / j  \\(\\mu_{ij}\\) / i  \\(\\mu_{ij}\\)  j \\[\\frac{\\sum_{i=1}^tc_i\\hat{{\\mu}}_{ij}-\\sum_{i=1}^tc_i\\mu_{ij}}{\\sqrt{\\frac{(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_\\delta^2)\\sum_{i=1}^tc_i^2}n}}\\]  \\(\\hat v\\)  \\(t\\)  i \\[\\frac{\\sum_{i=1}^td_j{\\hat{\\mu}}_{ij}-\\sum_{i=1}^td_j{\\mu}_{ij}}{\\sqrt{\\frac{{\\hat{\\sigma}}_\\varepsilon^2\\sum_{i=1}^td_j^2}n}}\\]  t(n - 1)(p - 1)  t  \\(\\mu_{ij}\\)   26.4  26.5.   26.4:  26.1  x : \\(T_i\\)  i   26.5:  26.4  x : Q   26.3 \\[\\widehat{s.e.}(\\hat{\\mu}_{ij}-\\hat{\\mu}_{ij})=\\sqrt{2\\hat{\\sigma}_\\varepsilon^2/n}=\\sqrt{2(7.45)/8}=1.365\\]  5% LSD  \\[\\mathrm{LSD}_{0.05}=t_{0.025,63}[\\widehat{s.e.}(\\hat{\\mu}_{ij}-\\hat{\\mu}_{i^{\\prime}j})]=(2.00)(1.365)=2.730\\]  26.6   26.6:  26.6  x :  5% \\(\\text{LSD}_{0.05}=2.730\\).  \\(\\theta_{LT_1}=-3\\mu_{11}-1\\mu_{12}+1\\mu_{13}+3\\mu_{14}\\) \\[\\hat{\\theta}_{LT_1}=-3(70.50)-1(80.50)+1(81.00)+3(73.13)=8.39\\]  \\[\\widehat{s.e.}(\\hat{{\\theta}}_{LT_1})=\\sqrt{\\frac{{\\hat{\\sigma}}_\\varepsilon^2\\sum_{i=1}^td_j^2}n}=\\sqrt{\\frac{7.45(9+1+1+9)}8}=4.316\\]  \\(t\\)  \\(t_c=8.39/4.316=1.94\\).  \\[\\theta_{QT_1}=1{\\mu}_{11}-1{\\mu}_{12}-1{\\mu}_{13}+1{\\mu}_{14}\\]  \\[\\hat{\\theta}_{QT_1}=1\\hat{\\mu}_{11}-1\\hat{\\mu}_{12}-1\\hat{\\mu}_{13}+1\\hat{\\mu}_{14}=70.50-80.50-81.00+73.13=-17.87\\]  \\[\\widehat{s.e.}(\\hat{\\theta}_{LT_1})=\\sqrt{\\frac{\\hat{{\\sigma}}_\\varepsilon^2\\sum_{i=1}^td_j^2}n}=\\sqrt{\\frac{7.45(1+1+1+1)}8}=1.930\\]  \\(t\\)  \\(t_c=-17.87/1.930=9.259\\).  26.7:  26.4  x :  \\(t\\)   26.1:   26.7  BWW9  AX23  26.1  \\(\\widehat{s.e.}(\\hat{{\\mu}}_{ij}-\\hat{{\\mu}}_{i&#39;j})=\\sqrt{[2(\\hat{{\\sigma}}_\\varepsilon^2+\\hat{{\\sigma}}_\\delta^2)/n]}\\).  \\[\\hat{{\\sigma}}_\\varepsilon^2=MSError(Time)=7.45\\]  \\[\\hat{\\sigma}_\\delta^2=\\frac{MSError(Subject)-\\tilde{\\sigma}_\\varepsilon^2}p=\\frac{111.33-7.45}4=25.97\\]  \\[\\widehat{s.e.}(\\hat{\\mu}_{ij}-\\hat{\\mu}_{i^{\\prime}j})=\\sqrt{2(\\hat{\\sigma}_\\varepsilon^2+\\hat{\\sigma}_\\delta^2)/n}=\\sqrt{\\frac{2(7.45+25.97)}8}=2.891\\]  Satterthwaite  \\[\\hat{v}=\\frac{[c_1\\hat{\\sigma}_1^2+c_2\\hat{\\sigma}_2^2]^2}{\\frac{c_2^2\\hat{\\sigma}_1^4}{v_1}+\\frac{c_2^2\\hat{\\sigma}_2^4}{v_2}}=\\frac{[\\frac14(111.33)+\\frac34(7.45)]^2}{\\frac{\\frac1{16}(111.33)^2}{21}+\\frac{\\frac9{16}(7.45)^2}{63}}=\\frac{(33.42)^2}{36.888+0.496}=29.9\\]  5%  LSD  \\[\\mathrm{LSD}_{0.05}=t_{0.025,29.9}\\times\\widehat{s.e.}(\\hat{\\mu}_{ij}-\\hat{\\mu}_{i^{\\prime}j})=(2.042)(2.891)=5.903\\]  26.8   26.8:  26.4  x :  5% \\(\\text{LSD}_{0.05}=5.903\\)  AX23  BWW9  1 \\(\\theta=\\mu_{11}+\\mu_{21}-2\\mu_{31}\\).  \\({\\hat{\\theta}}=70.5+81.75-2\\times72.75=6.75\\) \\[\\widehat{s.e.}\\left(\\hat{\\theta}\\right)=\\sqrt{\\frac{(\\hat{\\sigma}_{\\varepsilon}^{2}+\\hat{\\sigma}_{\\delta}^{2})\\sum_{i=1}^{t}c_{i}^{2}}n}=\\sqrt{\\frac{(7.45+25.97)(1+1+4)}8}=5.006\\]  \\(t\\)  \\(t_c=6.75/4.088=1.651\\).  \\(H_0{:{\\theta}}=0\\)  \\(t_{0.025,29.9}=2.042\\).  26.9  5%  1   26.9:  AX23  BWW9  x : *  5% \\(t_{0.025,29.9}=2.042\\) 26.2.2  26.2  (environments)  (clothing).  (sex)  (chamber) 1 2.  1 2  3  26.10  (person).  ×  1  (hour).  36 1   26.10:  26.2  x  \\[\\begin{aligned} Y_{ijkmn} =&amp;\\,{\\mu}+E_{i}+{r}_{in} &amp;&amp; \\text{Chamber part} \\\\ &amp;+S_j+C_k+(SC)_{jk}+(ES)_{ij}+(EC)_{ik}+(ESC)_{ijk}+p_{ijkn}&amp;&amp; \\text{Person part} \\\\ &amp;+T_m+(ET)_{im}+(ST)_{jm}+(CT)_{km}+(SCT)_{jkm}+(EST)_{ijm}+(ECT)_{ikm}&amp;&amp;\\text{Hour part} \\\\ &amp;+(ESCT)_{ijkm}+E_{ijkmn} \\end{aligned}\\] E S C T \\(r_{in}\\)  \\(i.i.d. N(0, \\sigma_r^2)\\)\\(p_{ijkn}\\)  \\(i.i.d. N(0, \\sigma_p^2)\\)\\(\\varepsilon_{ijkmn}\\)  \\(i.i.d. N(0, \\sigma_\\varepsilon^2)\\) \\(r_{in},p_{ijkn},\\varepsilon_{ijkmn}\\)   26.11 \\(F\\)   26.11:  26.2  x : \\(Q_\\ell\\)   26.11  \\[ \\begin{aligned} SSERROR(PERSON) =&amp;\\,Replication \\times Sex \\times Clothing(Environment) SS\\\\ &amp;+ Replication \\times Sex(Environment) SS\\\\ &amp;+ Replication \\times Clothing(Environment) SS \\end{aligned} \\]  \\[SSERROR(CHAMBER)=Chamber(Environment)SS\\]  \\(\\alpha = 0.01\\)  I Environment × Time  Sex × Clothing.  Sex × Clothing  Sex × Clothing   \\[\\begin{aligned}\\mu_{ijkm}=&amp;\\,\\mu+E_i+S_j+C_k+(SC)_{jk}+(ES)_{ij}+(EC)_{ik}+(ESC)_{ijk}+T_m+(ET)_{im}\\\\&amp;+(ST)_{jm}+(CT)_{km}+(SCT)_{jkm}+(EST)_{ijm}+(ECT)_{ikm}+(ESCT)_{ijkm}\\end{aligned}\\]  \\(\\bar{{\\mu}}_{\\cdot jk{\\cdot}}-\\bar{{\\mu}}_{\\cdot j&#39;{k&#39;\\cdot}}\\)  \\(\\bar{Y}_{\\cdot jk\\cdot\\cdot}-\\bar{Y}_{\\cdot j^{\\prime}k^{\\prime}\\cdot\\cdot}\\)\\(\\bar{Y}_{\\cdot jk\\cdot\\cdot}-\\bar{Y}_{\\cdot j^{\\prime}k^{\\prime}\\cdot\\cdot}\\)  \\[\\widehat{s.e.}(\\bar{Y}_{\\cdot jk\\cdot\\cdot}-\\bar{Y}_{\\cdot j^{\\prime}k^{\\prime}\\cdot\\cdot})=\\sqrt{\\frac{2MSERROR(PERSON)}{3\\cdot3\\cdot3}}=\\sqrt{\\frac{2\\cdot(0.58)}{27}}=0.207\\]  18. 1%  Fishers LSD  \\[(t_{0.005,18})\\mathrm{~}\\widehat{s.e.}(\\bar{Y}_{\\cdot jk\\cdot\\cdot}-\\bar{Y}_{\\cdot j^{\\prime}k^{\\prime}\\cdot\\cdot})=2.878\\cdot0.207=0.596\\]  26.12  Sex × Clothing   26.12:  26.2  LSD  Sex × Clothing  x : \\(\\text{LSD}_{0.01} = 0.595\\).  27  Environment × Time   \\[s.e.(\\bar{Y}_{i\\cdot\\cdot m\\cdot}-\\bar{Y}_{i\\cdot\\cdot m^{\\prime}\\cdot})=s.e.\\left[(\\bar{r}_{i\\cdot}-\\bar{r}_{i\\cdot})+(\\bar{p}_{i\\cdot\\cdot\\cdot}-\\bar{p}_{i\\cdot\\cdot\\cdot})+(\\bar{\\varepsilon}_{i\\cdot\\cdot m\\cdot}-\\bar{\\varepsilon}_{i\\cdot\\cdot{m^{\\prime}}\\cdot})\\right]=s.e.\\left[(\\bar{\\varepsilon}_{i\\cdot\\cdot m\\cdot}-\\bar{\\varepsilon}_{i\\cdot\\cdot{m^{\\prime}}\\cdot})\\right]=\\sqrt{\\frac{2\\sigma_\\varepsilon^2}{2\\cdot2\\cdot3}}\\]  \\[\\widehat{s.e.}\\left(\\bar{Y}_{i\\cdot\\cdot m\\cdot}-\\bar{Y}_{i\\cdot\\cdot m^{\\prime}\\cdot}\\right)=\\sqrt{\\frac{2\\hat{\\sigma}_\\varepsilon^2}{2\\cdot2\\cdot3}}=\\sqrt{\\frac{2(0.06)}{12}}=0.01\\]  1% LSD  \\(t_{0.005,48}(0.01)=2.682(0.01) = 0.268\\).  26.13  Environment × Time   26.13:  26.2  Environment × Time  x : \\(\\text{LSD}_{0.01}=0.268\\)  1  \\(\\hat{\\theta}_{LT_1}=-\\bar{Y}_{1\\cdot\\cdot1\\cdot}+0\\bar{Y}_{1\\cdot\\cdot2\\cdot}+\\bar{Y}_{1\\cdot\\cdot3\\cdot}=-15.11+12.01=-3.10\\)  \\[s.e.\\left(\\hat{\\theta}_{LT_1}\\right)=\\sqrt{\\frac{\\hat{\\sigma}_\\varepsilon^2[(-1)^2+(1)^2]}{12}}=\\sqrt{\\frac{(0.06)(2)}{12}}=0.1\\]  \\(t\\)  \\(t_c = -3.10/0.1 = -31.0\\) 48.  1  \\(\\hat{{\\theta}}_{QT_{1}}=1\\bar{Y}_{1{\\cdot\\cdot}1{\\cdot}}-2\\bar{Y}_{1{\\cdot\\cdot}2{\\cdot}}+1\\bar{Y}_{1{\\cdot\\cdot}3{\\cdot}}=15.11 - 2(9.11) + 12.01 = 8.90\\)  \\[s.e.\\left(\\hat{\\theta}_{{Q}T_1}\\right)=\\sqrt{\\frac{\\hat{\\sigma}_{\\varepsilon}^2[(1)^2+(-2)^2+(1)^2]}{12}}=\\sqrt{\\frac{(0.06)(6)}{12}}=0.173\\]  \\(t\\)  \\(t_c = 8.90/0.173 = -51.45\\) 48.  26.14  1  2  3  26.2   26.14:  26.2  x : \\(t\\)   26.2:   Environment × Time  \\[\\begin{aligned} s.e.\\left(\\bar{Y}_{i\\cdot\\cdot m\\cdot}-\\bar{Y}_{i^{\\prime}\\cdot\\cdot m\\cdot}\\right)&amp; =s.e.\\left[(\\bar{r}_{i\\cdot}-\\bar{r}_{i&#39;\\cdot})+(\\bar{p}_{i\\cdot\\cdot m}-\\bar{p}_{i&#39;\\cdot\\cdot m})+(\\bar{\\varepsilon}_{i\\cdot\\cdot m\\cdot}-\\bar{\\varepsilon}_{i&#39;\\cdot\\cdot m\\cdot})\\right] \\\\ &amp;=\\sqrt{\\frac{2\\sigma_r^2}3+\\frac{2\\sigma_p^2}{2\\cdot2\\cdot3}+\\frac{2\\sigma_\\varepsilon^2}{2\\cdot2\\cdot3}}=\\sqrt{\\frac2{12}(\\sigma_\\varepsilon^2+\\sigma_p^2+4\\sigma_r^2)} \\end{aligned}\\]  \\(\\sigma_\\varepsilon^2+\\sigma_p^2+4\\sigma_r^2\\)  \\((1/3) MSERROR(CHAMBER) + (2/3) MSERROR(HOUR)\\)  Satterthwaite  \\[\\hat{v}=\\frac{[c_1\\hat{\\sigma}_1^2+c_2\\hat{\\sigma}_2^2]^2}{\\frac{c_1^2\\hat{\\sigma}_1^4}{v_1}+\\frac{c_2^2\\hat{\\sigma}_2^4}{v_2}}=\\frac{[\\frac13(29.21)+\\frac23(0.06)]^2}{\\frac{\\frac19(29.21)^2}{6}+\\frac{\\frac49(0.06)^2}{48}}=\\frac{(9.777)^2}{15.800+0.006}=6.05\\]  \\[\\sqrt{\\frac{2\\left[\\frac13MSERROR(Chamber)+\\frac23MSERROR(Hour)\\right]}{12}}=\\sqrt{\\frac{2\\left[\\frac13(29.21)+\\frac23(0.06)\\right]}{12}}=1.276\\]  1% LSD  \\(\\mathrm{LSD}_{0.01}=t_{0.005,6}(1.276)=(3.707)(1.276) = 4.73\\).  26.15 Fisher LSD Environment × Time  LSD  0.268  4.73.  LSD 0.01  LSD0.01  17   26.15:  Environment × Time  x : \\(\\text{LSD}_{0.01}=4.73\\)  24.3  \\(t\\)  LSD  \\(\\bar{{\\mu}}_{11{\\cdot}1}-\\bar{{\\mu}}_{22{\\cdot}1}\\).  \\(\\bar{Y}_{11{\\cdot}1{\\cdot}}-\\bar{Y}_{22{\\cdot}1{\\cdot}}=8.04\\).  \\[\\begin{aligned} \\mathrm{Var}(\\bar{Y}_{11{\\cdot}1{\\cdot}}-\\bar{Y}_{22{\\cdot}1{\\cdot}})&amp; =\\mathrm{Var}[(\\bar{r}_{1\\cdot}-\\bar{r}_{2\\cdot})+(\\bar{p}_{11\\cdot\\cdot}-\\bar{p}_{22\\cdot\\cdot})+(\\bar{\\varepsilon}_{11\\cdot\\cdot}-\\bar{\\varepsilon}_{22\\cdot\\cdot})] \\\\ &amp;=\\frac{2\\sigma_r^2}3+\\frac{2\\sigma_p^2}{2\\cdot3}+\\frac{2\\sigma_\\varepsilon^2}{2\\cdot3}=\\frac26(\\sigma_\\varepsilon^2+\\sigma_p^2+2\\sigma_r^2) \\end{aligned}\\]  \\[\\begin{aligned}(1/6)&amp;MSERROR(CHAMBER)+(1/6)MSERROR(PERSON)\\\\&amp;+(2/3)MSERROR(HOUR)=(1/6)(29.21)+(1/6)(0.58)+(2/3)(0.06)=5.005\\end{aligned}\\] \\(\\bar{Y}_{11{\\cdot}1{\\cdot}}-\\bar{Y}_{22{\\cdot}1{\\cdot}}\\)  \\(\\widehat{s.e.}(\\bar{Y}_{11\\cdot1\\cdot}-\\bar{Y}_{22\\cdot1\\cdot})=\\sqrt{[2(5.005)/6]}=1.2916\\).  Satterthwaite  \\[\\frac{\\left[(\\frac16)(29.21)+(\\frac16)(0.58)+(\\frac23)(0.06)\\right]^2}{\\frac{(\\frac16)^2(29.21)^2}6+\\frac{(\\frac16)^2(0.58)^2}{18}+\\frac{(\\frac23)^2(0.06)^2}{48}}=\\frac{(5.005)^2}{3.9501+0.0005+0.00003}=\\frac{25.05}{3.9506}=6.34\\]  26.2.3  26.3  7  10  26.16  (26.2)  26.1  27   26.16:  26.3  x  26.17  (26.2)  \\(\\alpha=0.05\\) Area, Person, Time  Area × Time.  26.17:  26.3  x : \\(Q_\\ell\\)    \\[\\begin{aligned} \\mathrm{Var}(\\bar{y}_{\\cdot j\\cdot\\cdot}-\\bar{y}_{\\cdot j&#39;\\cdot\\cdot}) &amp;=\\mathrm{Var}[(\\bar{f}_{\\cdot\\cdot}-\\bar{f}_{\\cdot\\cdot})+(\\bar{p}_{\\cdot j\\cdot}-\\bar{p}_{\\cdot j^{\\prime}\\cdot})+(\\bar{\\varepsilon}_{\\cdot j\\cdot\\cdot}-\\bar{\\varepsilon}_{\\cdot j^{\\prime}\\cdot\\cdot})] \\\\ &amp;=\\frac2{17}\\sigma_p^2+\\frac2{3\\cdot17}\\sigma_\\varepsilon^2=\\frac2{51}(\\sigma_\\varepsilon^2+3\\sigma_p^2) \\end{aligned}\\]  \\[\\widehat{s.e.}(\\bar{y}_{\\cdot j\\cdot\\cdot}-\\bar{y}_{\\cdot j&#39;\\cdot\\cdot})=\\sqrt{\\frac2{51}MSError(\\text{Person})}=\\sqrt{\\frac2{51}(25.512)}=0.9906\\] 5% LSD  \\(LSD_{0.05}=2.042(0.99)=2.022\\).  26.18  \\[\\mathrm{Var}(\\bar{y}_{i\\cdot k\\cdot}-\\bar{y}_{i\\cdot k^{\\prime}\\cdot})=\\mathrm{Var}\\left[(\\bar{f}_{i\\cdot}-\\bar{f}_{i\\cdot})+(\\bar{p}_{i\\cdot}-\\bar{p}_{i\\cdot})+(\\bar{\\varepsilon}_{i\\cdot k}.-\\bar{\\varepsilon}_{i\\cdot k^{\\prime}\\cdot})\\right]=\\frac2{3n_{i}}\\sigma_{\\varepsilon}^{2}\\]  \\(n_i\\)  i   26.18:  26.3  x : \\(\\text{LSD}_{0.05}=2.022\\)  \\[\\widehat{s.e.}(\\bar{y}_{1\\cdot k\\cdot}-\\bar{y}_{1\\cdot k^{\\prime}\\cdot})=\\sqrt{\\frac2{3n_1}\\hat{\\sigma}_\\varepsilon^2}=\\sqrt{\\frac2{30}(0.370)}=0.157\\]  \\[\\widehat{\\mathrm{s.e.}}(\\bar{y}_{2\\cdot k\\cdot}-\\bar{y}_{2\\cdot k^{\\prime}\\cdot})=\\sqrt{\\frac2{3n_2}\\hat{\\sigma}_\\varepsilon^2}=\\sqrt{\\frac2{21}(0.370)}=0.188\\]  5% LSD  \\(LSD_{0.05}(\\text{Urban})=1.987(0.157)=0.312\\)  \\(LSD_{0.05}(\\text{Rural})=1.987(0.188) = 0.374\\) 26.19   26.19:  26.3  x :  \\(\\text{LSD}_{0.05}=2.022\\) \\(\\text{LSD}_{0.05}=0.312\\)  \\[\\begin{aligned} \\mathrm{Var}(\\bar{y}_{1\\cdot k\\cdot}-\\bar{y}_{2\\cdot k\\cdot})&amp; =\\text{Var}\\left[(\\bar{f}_{1\\cdot}-\\bar{f}_{2\\cdot})+(\\bar{p}_{1\\cdot}-\\bar{p}_{2\\cdot})+(\\bar{\\varepsilon}_{1\\cdot k\\cdot}-\\bar{\\varepsilon}_{2\\cdot k\\cdot})\\right] \\\\ &amp;=\\sigma_f^2\\left(\\frac1{10}+\\frac17\\right)+\\sigma_p^2\\left(\\frac1{3\\cdot10}+\\frac1{3\\cdot7}\\right)+\\sigma_\\varepsilon^2\\left(\\frac1{3\\cdot10}+\\frac1{3\\cdot7}\\right)=\\left(\\frac1{30}+\\frac1{21}\\right)(\\sigma_\\varepsilon^2+\\sigma_p^2+3\\sigma_f^2) \\end{aligned}\\]  \\[(1/3)MSError(Family)+(2/3)MSError(Time)=(1/3)(54.155)+(2/3)(0.370)=18.2983\\]  \\[\\widehat{s.e.}(\\bar{y}_{1\\cdot k\\cdot}-\\bar{y}_{2\\cdot k\\cdot})=\\sqrt{\\left(\\frac1{30}+\\frac1{21}\\right)(18.2983)}=1.217\\]  Satterthwaite  \\[\\frac{\\left[(\\frac13)(54.155)+(\\frac23)(0.370)\\right]^2}{\\frac{(\\frac13)^2(54.155)^2}{15}+\\frac{(\\frac23)^2(0.370)^2}{90}}=\\frac{(18.2983)^2}{21.7242+0.0007}=\\frac{334.8278}{21.7249}=15.41\\]  5% LSD  \\(LSD_{0.05}=2.131(1.217)=2.59\\) 26.20  26.1   26.20:  26.3  x : \\(\\text{LSD}_{0.05}=2.59\\) 26.3  SAS-Mixed   SAS®-Mixed  26.4  26.2  26.21  SAS   26.21:  26.4  SAS-Mixed  x 26.3.1  26.1  \\(\\sigma^2_\\varepsilon,\\sigma^2_\\delta\\)  26.22 \\(\\hat\\sigma^2_\\varepsilon=7.45,\\hat\\sigma^2_\\delta=25.97\\).  26.22:  26.4  x  26.23  26.5  ANOVA MIXED  26.5  \\(F\\)   26.23:  26.4  ×  x  26.24  26.25 - 26.27  26.28  MIXED  estimate  26.29   26.24:  26.4  ×  x  26.25:  26.4  x  26.26:  26.4  x  26.27:  26.4  x  26.28:  26.4  Estimate  x  26.29:  26.4  x 26.3.2  26.2  Mixed  26.30  SAS  26.2  26.31  III  26.32  26.33  1  1  2  2  26.34  Sex × Clothing  Environment × Time  26.35 - 26.37   26.30:  SAS  x  26.31:  x  26.32:  III  x  26.33:  x  26.34:  Sex × Clothing  Environment × Time  x  26.35:  Sex × Clothing  x  26.36:  x  26.37:  x 26.3.3  26.3  Mixed  26.38  SAS  26.3  26.39  III  26.40  26.41  Area × Time  26.42   26.38:  SAS  x  26.39:  x  26.40:  III  x  26.41:  ×  x  26.42:  ×  x 26.4   26.3  SAS-Mixed  26.2  26.5   subject  The smaller unit is the interval of time during which the subject is exposed to a treatment or an interval just between time measurements. family member designation cannot be randomly assigned to family members.      "],["chap27.html", " 27   27.1  27.2 MANOVA  27.3 \\(p\\)  27.4  27.5  27.6 ", "  27   He uses statistics as a drunken man uses lamp-postsfor support rather than illumination. - Andrew Lang  1  2  26  26  26  27.1   26.1  \\(y_{ijk}\\)  i 50 k  j  \\[\\boldsymbol{y}_{ik}=\\begin{bmatrix}{y}_{i1k}\\\\{y}_{i2k}\\\\\\vdots\\\\{y}_{ipk}\\end{bmatrix}\\]  i  k   \\[y_{ijk}=\\mu+\\alpha_i+\\tau_j+\\gamma_{ij}+\\varepsilon_{ijk}^*,i=1,2,\\ldots,t;~j=1,2,\\ldots,p;~k=1,2,\\ldots,n_i\\]  \\[\\boldsymbol{\\varepsilon}_{ik}^*=\\begin{bmatrix}{\\varepsilon}_{i1k}^*\\\\{\\varepsilon}_{i2k}^*\\\\\\vdots\\\\{\\varepsilon}_{ipk}^*\\end{bmatrix}\\]  i  k  \\(\\boldsymbol{\\varepsilon}_{ik}^*\\)  \\(\\boldsymbol 0\\)  \\(\\boldsymbol \\Sigma\\)  p  \\(\\boldsymbol \\varepsilon_{ik}^*\\sim i.i.d.N(\\boldsymbol{0},\\boldsymbol{\\Sigma}),i=1,2,\\ldots,t;k=1,2,\\ldots,n_i\\)  \\[\\boldsymbol{\\Sigma}=\\begin{bmatrix}{\\sigma}_{11}&amp;{\\sigma}_{12}&amp;\\cdots&amp;{\\sigma}_{1p}\\\\{\\sigma}_{21}&amp;{\\sigma}_{22}&amp;\\cdots&amp;{\\sigma}_{2p}\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\{\\sigma}_{p1}&amp;{\\sigma}_{p2}&amp;\\cdots&amp;{\\sigma}_{pp}\\end{bmatrix}\\]   27.1   \\(\\boldsymbol{\\Sigma}={\\lambda}\\boldsymbol{I}_t+\\boldsymbol{\\eta}\\boldsymbol{j}&#39;+\\boldsymbol{j}\\boldsymbol{\\eta}&#39;\\) \\(\\boldsymbol j\\)  1  p × 1 \\(\\boldsymbol \\eta\\)  p × 1  HuynhFeldt (HF)  Huynh and Feldt, 1970  27.1 \\(\\boldsymbol{\\Sigma}\\)  \\[\\boldsymbol{\\Sigma}=\\begin{bmatrix}\\lambda+2{\\eta}_1&amp;{\\eta}_1+{\\eta}_2&amp;\\cdots&amp;{\\eta}_1+{\\eta}_p\\\\{\\eta}_2+{\\eta}_1&amp;\\lambda+2{\\eta}_2&amp;\\cdots&amp;{\\eta}_2+{\\eta}_p\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\{\\eta}_p+{\\eta}_1&amp;{\\eta}_p+{\\eta}_2&amp;\\cdots&amp;\\lambda+2{\\eta}_p\\end{bmatrix}\\] H-F  (compound symmetry covariance structure, CS) \\(\\sigma^2,\\rho\\)  \\[\\boldsymbol{\\Sigma}={\\sigma}^2{\\begin{bmatrix}1&amp;{\\rho}&amp;\\cdots&amp;{\\rho}\\\\{\\rho}&amp;1&amp;\\cdots&amp;{\\rho}\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\{\\rho}&amp;{\\rho}&amp;\\cdots&amp;1\\end{bmatrix}}\\]  26.1  (split-plot-in-time analysis)  \\(\\sigma^2=\\sigma_\\delta^2+\\sigma_\\varepsilon^2\\)  \\(\\rho=\\sigma_\\delta^2/(\\sigma_\\delta^2+\\sigma_\\varepsilon^2)\\).  \\(\\rho\\)   H-F  26.1  26  27.1  H-F  ×   \\(\\rho&gt;0\\) \\(\\varepsilon_{ik}^*=\\delta_{ik}+\\varepsilon_{ijk}\\) \\(\\delta_{ik}\\sim i.i.d.N(0,\\sigma_\\delta^2),\\varepsilon_{ijk}\\sim i.i.d.N(0,\\sigma_\\varepsilon^2)\\) \\(\\delta_{ik}\\)  \\(\\varepsilon_{ijk}\\)   H-F   HF  (multivariate analysis of variance, MANOVA)  \\(p\\) 51 SAS®-Mixed  SAS®-Gilimix   27.2  27.3  27.4  27.2 MANOVA   \\[\\boldsymbol\\varepsilon_{ik}^*\\sim i.i.d.\\mathrm{~}N(\\boldsymbol0,\\boldsymbol{\\Sigma}),\\quad i=1,2,\\ldots,t;\\mathrm{~}k=1,2,\\ldots,n_i\\] MANOVA  @chap(6)   26.1  (26.1)  \\[\\begin{equation} \\boldsymbol Y=\\boldsymbol {XB}+\\boldsymbol E \\tag{27.1} \\end{equation}\\]  \\(\\boldsymbol Y\\)  \\(\\boldsymbol Y\\)  \\(\\boldsymbol Y\\)  N × p  \\(N=\\sum_{i=1}^t n_i\\).  \\(\\boldsymbol X\\)  t  N × r \\(\\boldsymbol B\\)  r × 1  \\(\\boldsymbol E\\)  N × p  \\(\\boldsymbol E\\)  \\(N(\\boldsymbol{0},\\boldsymbol{\\Sigma})\\).  \\(\\boldsymbol E\\)  (correlated)   (27.1) \\[\\begin{equation} H_0{:\\boldsymbol{CBM}}=0\\mathrm{~vs~}H_a{:\\boldsymbol{CBM}}\\neq0 \\tag{27.2} \\end{equation}\\]  \\(\\boldsymbol C\\)  g  g × r \\(\\boldsymbol M\\)  q  p × q   (27.2)  \\(\\boldsymbol B\\)  (cross-products matrix)52 \\(\\hat{\\boldsymbol B}\\)  \\(\\hat{\\boldsymbol E}\\)  \\[\\begin{equation} \\hat{\\boldsymbol B}=(\\boldsymbol X^{\\prime}\\boldsymbol X)^-\\boldsymbol X^{\\prime}\\boldsymbol Y\\quad\\mathrm{and}\\quad\\hat{\\boldsymbol E}=\\boldsymbol Y^{\\prime}[\\boldsymbol I-\\boldsymbol X(\\boldsymbol X^{\\prime}\\boldsymbol X)^-\\boldsymbol X^{\\prime}]\\boldsymbol Y \\tag{27.3} \\end{equation}\\]  (27.2)  (likelihood ratio test statistic)  \\[\\begin{equation} \\Lambda=\\frac{|\\boldsymbol R|}{\\left|\\boldsymbol H+\\boldsymbol R\\right|} \\tag{27.4} \\end{equation}\\]  \\[\\boldsymbol R=\\boldsymbol M&#39;\\hat{\\boldsymbol E}\\boldsymbol M,\\quad \\boldsymbol H=\\boldsymbol M^{\\prime}\\hat{\\boldsymbol B}\\boldsymbol C^{\\prime}\\left[\\boldsymbol C(\\boldsymbol X^{\\prime}\\boldsymbol X)^{-}\\boldsymbol C^{\\prime}\\right]^{-1}\\boldsymbol C \\hat{\\boldsymbol B} \\boldsymbol M\\]  \\(|\\boldsymbol W|\\)  \\(\\boldsymbol W\\)   Wilks  (likelihood ratio criterion) (Morrison, 1976). \\(\\Lambda\\)  \\(\\alpha\\)  \\(H_0\\)  \\[-\\left(N-t-\\frac{|q-g|+1}2\\right)\\mathrm{log}_{\\mathrm{e}}(\\Lambda)&gt;\\chi_{\\alpha,qg}^2\\]  \\(q\\)  \\(g\\)  \\(2\\)  \\(H_0\\)  \\[F&gt;F_{\\alpha,qg,ab-c}\\]  \\[F=\\frac{(1-\\Lambda^{1/b})(ab-c)}{qg\\Lambda^{1/b}}\\]  \\[\\begin{align} &amp;a=N-t-\\frac{|q-s|+1}2 \\\\ &amp;b=\\left(\\frac{q^{2}s^{2}-4}{q^{2}+s^{2}-5}\\right)^{1/2} \\\\ &amp; c=\\frac{qs-2}2 \\\\ &amp;s=\\min(q,g) \\tag{27.5} \\end{align}\\]  \\(q = 1, 2\\)  \\(g = 1, 2\\) (27.2)  \\(F\\)   \\(g = 1\\)  \\(q\\) \\(H_0\\)  \\[\\begin{equation} F=\\left(\\frac{1-\\Lambda}\\Lambda\\right)\\left(\\frac{N-t-q+1}q\\right)&gt;F_{\\alpha,q,N-t-q+1} \\tag{27.6} \\end{equation}\\]  \\(q = 1\\)  \\(g\\) \\(H_0\\)  \\[\\begin{equation} F=\\left(\\frac{1-\\Lambda}\\Lambda\\right)\\left(\\frac{N-t}g\\right)&gt;F_{\\alpha,g,N-t} \\tag{27.7} \\end{equation}\\]  \\(g = 2\\)  \\(q &gt; 1\\) \\(H_0\\)  \\[\\begin{equation} F=\\left(\\frac{1-\\sqrt{\\Lambda}}{\\sqrt{\\Lambda}}\\right){\\left(\\frac{N-t-q+1}q\\right)}{&gt;F_{\\alpha,2q,2(N-t-q+1)}} \\tag{27.8} \\end{equation}\\]  \\(q = 2\\)  \\(g &gt; 1\\) \\(H_0\\)  \\[\\begin{equation} F=\\left(\\frac{1-\\sqrt{\\Lambda}}{\\sqrt{\\Lambda}}\\right)\\left(\\frac{N-t-1}g\\right)&gt;F_{\\alpha,2g,2(N-t-1)} \\tag{27.9} \\end{equation}\\]  \\(p &lt; N  t\\).  \\(p \\ge N  t\\)  \\(p^*\\)  \\(p^*\\)  \\(p^* &lt; N  t\\).  (sorghum)  (fertilizer) 53 (leaf area index)  V1, V2, V3  V4  1, 2, 3, 4  5  20  ×  20  (plots). 54 ×  27.1   27.1:  x  27.1  \\[\\boldsymbol Y=\\begin{bmatrix}5.00&amp;4.84&amp;4.02&amp;3.75&amp;3.13\\\\4.42&amp;4.30&amp;3.67&amp;3.29&amp;2.83\\\\4.42&amp;4.10&amp;3.46&amp;3.09&amp;2.82\\\\4.01&amp;3.89&amp;3.21&amp;2.89&amp;2.56\\\\3.36&amp;3.10&amp;2.67&amp;2.47&amp;2.16\\\\5.82&amp;5.60&amp;5.05&amp;4.72&amp;4.46\\\\5.73&amp;5.59&amp;5.00&amp;4.65&amp;4.42\\\\5.31&amp;5.19&amp;4.86&amp;4.44&amp;4.22\\\\4.92&amp;4.66&amp;4.56&amp;4.16&amp;3.99\\\\3.96&amp;3.86&amp;3.50&amp;3.13&amp;2.95\\\\5.65&amp;5.97&amp;5.27&amp;5.07&amp;4.52\\\\5.39&amp;5.49&amp;5.08&amp;4.87&amp;4.32\\\\5.15&amp;5.28&amp;4.93&amp;4.67&amp;4.15\\\\4.50&amp;4.89&amp;4.74&amp;4.49&amp;4.10\\\\3.75&amp;3.74&amp;3.55&amp;3.28&amp;3.00\\\\5.86&amp;5.60&amp;5.37&amp;5.00&amp;4.37\\\\5.82&amp;5.55&amp;5.29&amp;4.95&amp;4.07\\\\5.26&amp;5.06&amp;4.76&amp;4.48&amp;3.94\\\\4.87&amp;4.75&amp;4.55&amp;4.33&amp;3.83\\\\3.96&amp;3.76&amp;3.56&amp;3.18&amp;2.96\\end{bmatrix}\\]  \\[\\boldsymbol{B}=\\begin{bmatrix} \\mu^{(1)}&amp;\\mu^{(2)}&amp;\\mu^{(3)}&amp;\\mu^{(4)}&amp;\\mu^{(5)}\\\\ \\tau_1^{(1)}&amp;\\tau_1^{(2)}&amp;\\tau_1^{(3)}&amp;\\tau_1^{(4)}&amp;\\tau_1^{(5)}\\\\ \\tau_2^{(1)}&amp;\\tau_2^{(2)}&amp;\\tau_2^{(3)}&amp;\\tau_2^{(4)}&amp;\\tau_2^{(5)}\\\\ \\tau_3^{(1)}&amp;\\tau_3^{(2)}&amp;\\tau_3^{(3)}&amp;\\tau_3^{(4)}&amp;\\tau_3^{(5)}\\\\ \\tau_4^{(1)}&amp;\\tau_4^{(2)}&amp;\\tau_4^{(3)}&amp;\\tau_4^{(4)}&amp;\\tau_4^{(5)}\\\\ \\beta_1^{(1)}&amp;\\beta_1^{(2)}&amp;\\beta_1^{(3)}&amp;\\beta_1^{(4)}&amp;\\beta_1^{(5)}\\\\ \\beta_2^{(1)}&amp;\\beta_2^{(2)}&amp;\\beta_2^{(3)}&amp;\\beta_2^{(4)}&amp;\\beta_2^{(5)}\\\\ \\beta_3^{(1)}&amp;\\beta_3^{(2)}&amp;\\beta_3^{(3)}&amp;\\beta_3^{(4)}&amp;\\beta_3^{(5)}\\\\ \\beta_4^{(1)}&amp;\\beta_4^{(2)}&amp;\\beta_4^{(3)}&amp;\\beta_4^{(4)}&amp;\\beta_4^{(5)}\\\\ \\beta_5^{(1)}&amp;\\beta_5^{(2)}&amp;\\beta_5^{(3)}&amp;\\beta_5^{(4)}&amp;\\beta_5^{(5)}\\\\ \\end{bmatrix}\\]  \\(\\tau\\) \\(\\beta\\)  \\[\\boldsymbol X=\\begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] \\(\\boldsymbol B\\)  \\(\\boldsymbol Y\\)  \\(j(j=1,2,3,4,5)\\)  \\(\\boldsymbol X\\)  20 × 10  8 \\(N = 20,p = 10\\)  \\(t = 8\\) (27.3)  \\(\\hat{\\boldsymbol B}\\)  \\[\\hat{\\boldsymbol{B}}=\\begin{bmatrix}3.350&amp;3.283&amp;3.003&amp;2.788&amp;2.150\\\\0.222&amp;0.106&amp;-0.198&amp;-0.260&amp;-0.312\\\\1.128&amp;1.040&amp;0.990&amp;0.874&amp;0.996\\\\0.868&amp;1.134&amp;1.110&amp;1.130&amp;1.006\\\\1.134&amp;1.004&amp;1.102&amp;1.042&amp;0.822\\\\1.395&amp;1.398&amp;1.173&amp;1.115&amp;0.982\\\\1.152&amp;1.128&amp;1.006&amp;0.940&amp;0.772\\\\0.847&amp;0.803&amp;0.748&amp;0.685&amp;0.645\\\\0.387&amp;0.443&amp;0.511&amp;0.483&amp;0.482\\\\-0.430&amp;-0.489&amp;-0.434&amp;-0.470&amp;-0.370\\end{bmatrix}\\]  (27.3)  \\(\\boldsymbol E\\)  \\[\\hat{\\boldsymbol{E}}=\\begin{bmatrix}0.237&amp;0.171&amp;0.162&amp;0.228&amp;0.129\\\\0.171&amp;0.247&amp;0.163&amp;0.231&amp;0.135\\\\0.162&amp;0.163&amp;0.268&amp;0.303&amp;0.184\\\\0.228&amp;0.231&amp;0.303&amp;0.392&amp;0.241\\\\0.129&amp;0.135&amp;0.184&amp;0.241&amp;0.247\\end{bmatrix}\\]  (27.4)  \\[\\boldsymbol{C}=\\begin{bmatrix}0&amp;1&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{M}=\\begin{bmatrix}1\\\\1\\\\1\\\\1\\\\1\\\\1\\end{bmatrix}\\]  \\(\\Lambda= 0.04345,g = 3,q = 1\\).  \\(q = 1\\) (27.7) \\[F=\\frac{1-0.04345}{0.04345}\\times\\frac{12}3=88.06\\]  3  12  \\(\\hat\\alpha\\)  0.0001.  (27.4)  \\[\\boldsymbol{C}=\\begin{bmatrix}1&amp;\\frac14&amp;\\frac14&amp;\\frac14&amp;\\frac14&amp;\\frac15&amp;\\frac15&amp;\\frac15&amp;\\frac15&amp;\\frac15\\\\\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{M}=\\begin{bmatrix}1&amp;1&amp;1&amp;1\\\\-1&amp;0&amp;0&amp;0\\\\0&amp;-1&amp;0&amp;0\\\\0&amp;0&amp;-1&amp;0\\\\0&amp;0&amp;0&amp;-1\\end{bmatrix}\\]  \\(\\Lambda= 0.04345,g=1,q=4\\).  \\(g = 1\\) (27.6) \\[\\begin{aligned}F=&amp;\\frac{1-0.00502}{0.00502}\\times\\frac94=445.96\\end{aligned}\\]  4  9  \\(\\hat\\alpha\\)  0.0001.  ×  (27.4)  \\[\\boldsymbol{C}=\\begin{bmatrix}0&amp;1&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\\\0&amp;1&amp;0&amp;0&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{M}=\\begin{bmatrix}1&amp;1&amp;1&amp;1\\\\-1&amp;0&amp;0&amp;0\\\\0&amp;-1&amp;0&amp;0\\\\0&amp;0&amp;-1&amp;0\\\\0&amp;0&amp;0&amp;-1\\end{bmatrix}\\]  \\(\\Lambda= 0.01426,g=1,q=4\\).  g  q  1 (27.5) \\(s = 3,a = 11,b = 2.646\\)  \\(c = 5\\).  \\[F=\\frac{(1-0.01426^{1/2.646})(11\\times2.646-5)}{4\\times3\\times0.01426^{1/2.646}}=\\frac{(1-0.2006)(24.1060)}{12(0.2006)}=8.00\\]  12  24.1  \\(\\hat\\alpha\\)  0.0001. \\(F=94.36\\) × \\(F=1.91\\) \\(\\boldsymbol{B}\\) \\(\\boldsymbol{B}\\)  \\(\\boldsymbol{c&#39;Bm}\\)  \\(\\boldsymbol{c}\\)  r × 1 \\(\\boldsymbol{m}\\)  p × 1  6  \\(\\boldsymbol{u}\\)  \\(\\boldsymbol{X^{\\prime}}\\boldsymbol{X}\\boldsymbol{u}=\\boldsymbol{c}\\) \\(\\boldsymbol{c&#39;Bm}\\)  \\(\\boldsymbol m\\)  \\(\\boldsymbol{c&#39;Bm}\\)  \\(\\boldsymbol{c&#39;\\hat Bm}\\) \\(\\boldsymbol{\\hat B}\\)  (27.3)  \\(\\boldsymbol{c&#39;\\hat Bm}\\)  \\[\\widehat{s.e.}(\\boldsymbol c^{\\prime}\\hat{\\boldsymbol B}\\boldsymbol m)=\\sqrt{\\boldsymbol c^{\\prime}(\\boldsymbol X^{\\prime}\\boldsymbol X)^-\\boldsymbol c\\cdot\\frac{{\\boldsymbol m^{\\prime}\\hat{\\boldsymbol E}\\boldsymbol m}}{N-t}}\\]  N-t. \\(\\boldsymbol{c&#39;Bm}\\)  \\((1 - \\alpha)100\\%\\)  \\[\\begin{equation} \\boldsymbol{c^{\\prime}\\hat{B}m}\\pm t_{\\alpha,N-t}\\left[\\widehat{s.e.}(\\boldsymbol{c^{\\prime}\\hat{B}m})\\right] \\tag{27.10} \\end{equation}\\]  \\(H_0:\\boldsymbol{c&#39;Bm}=a_0\\)  \\(t\\)  \\[\\begin{equation} t=\\frac{\\boldsymbol{c&#39;\\hat Bm}-a_0}{\\widehat{s.e.}(\\boldsymbol{c&#39;\\hat Bm})} \\tag{27.11} \\end{equation}\\]  \\(t&gt;t_{\\alpha/2,N-t}\\)  \\(H_0\\).  V1  \\[\\boldsymbol c&#39;=\\begin{bmatrix}1&amp;1&amp;0&amp;0&amp;0&amp;0.2&amp;0.2&amp;0.2&amp;0.2&amp;0.2\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{m}=\\begin{bmatrix}0.2\\\\0.2\\\\0.2\\\\0.2\\\\0.2\\end{bmatrix}\\] \\(\\boldsymbol{c&#39;\\hat Bm}\\)  3.496 0.0594.  (27.10)  V1  95%  3.496 ± (2.179) (0.0594).  27.1  1   \\[\\boldsymbol c^{\\prime}=[1\\quad0.25\\quad0.25\\quad0.25\\quad0.2\\quad0.2\\quad0.2\\quad0.2\\quad0.2]\\quad\\mathrm{and}\\quad\\boldsymbol{m}=\\begin{bmatrix}1\\\\0\\\\0\\\\0\\\\0\\end{bmatrix}\\] \\(\\boldsymbol{c&#39;\\hat Bm}\\)  4.858 0.0315.  V1  V2  \\[\\boldsymbol c^{\\prime}=\\begin{bmatrix}0&amp;1&amp;-1&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{m}=\\begin{bmatrix}0.2\\\\0.2\\\\0.2\\\\0.2\\\\0.2\\end{bmatrix}\\] \\(\\boldsymbol{c&#39;\\hat Bm}\\)  -1.094 0.0840.  \\(t\\)  \\(t = -1.094/0.0840 = 13.02\\) \\(\\hat\\alpha &lt; 0.0001\\).  MANOVA  M =  SAS®-GLM  27.2  SAS  27.1  MANOVA  E^ MANOVA M = (0.2 0.2 0.2 0.2 0.2)  MANOVA  ×  ×  MANOVA  \\(\\boldsymbol M\\)  4 × 5   27.2:  MANOVA  27.1  SAS-GLM  x  27.3  27.2  \\(\\hat{\\boldsymbol E}\\)  27.4  MANOVA  27.5  MANOVA   27.3:  x  27.4:  x  27.5: MANOVA  x MANOVA  CONTRAST  \\(H_0{:\\boldsymbol{c&#39;Bm}}=0\\)  27.2  SAS  CONTRAST V1-V2 VARIETY 1 -1 0 0; MANOVA M=(.2 .2 .2 .2 .2) / PRINTE; MANOVA M=(1 0 0 0 0) / PRINTE;  MANOVA  1  2  Wilks  MANOVA  1  1  2  Wilks  MANOVA  PRINTE  \\(\\boldsymbol {m&#39;\\hat E m}\\)  27.6  1  2  (\\(F = 169.4\\))169.4  \\(t\\)  \\({\\boldsymbol m}&#39; = [0.2 0.2 0.2 0.2 0.2]\\) \\(\\boldsymbol {m&#39;\\hat E m} = 0.2115\\).  27.6:  1  2  x 27.3 \\(p\\)   26  H-F  27.2  MANOVA  H-F  \\(p\\)   \\[\\boldsymbol{\\Sigma}=\\begin{bmatrix}{\\sigma}_{11}&amp;{\\sigma}_{12}&amp;\\cdots&amp;{\\sigma}_{1p}\\\\{\\sigma}_{21}&amp;{\\sigma}_{22}&amp;\\cdots&amp;{\\sigma}_{2p}\\\\\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\{\\sigma}_{p1}&amp;{\\sigma}_{p2}&amp;\\cdots&amp;{\\sigma}_{pp}\\end{bmatrix}\\]  \\[\\begin{equation} \\theta=\\frac{p^2(\\bar{\\sigma}_{ii}-\\bar{\\sigma}_{\\cdot\\cdot})^2}{(p-1)\\left[\\sum_{i=1}^p\\sum_{j=1}^p\\sigma_{ij}^2-2p\\sum_{i=1}^p\\bar{\\sigma}_{i\\cdot}^2+p^2\\bar{\\sigma}_{\\cdot\\cdot}^2\\right]} \\tag{27.12} \\end{equation}\\]  \\[\\bar{\\sigma}_{ii}=\\frac1p{\\sum_{j=1}^p\\sigma_{ij}},\\quad\\bar{\\sigma}_{i\\cdot}=\\frac1p{\\sum_{j=1}^p\\sigma_{ij}},\\quad\\mathrm{and}\\quad\\bar{\\sigma}_{\\cdot\\cdot}=\\frac1{p^2}{\\sum_{i=1}^p{\\sum_{j=1}^p\\sigma_{ij}}}\\] Box (1954)  \\(\\theta\\)  \\(\\boldsymbol \\Sigma\\)  \\(1/(p - 1) &lt; \\theta &lt; 1\\). \\(\\theta\\)\\(\\boldsymbol \\Sigma\\)  \\(F_{TIME}\\)  \\(F_{TIME × TRT}\\)  ×  26.1 Box  \\(\\boldsymbol \\Sigma\\)  \\(\\theta\\)  \\[\\begin{equation} F_{TIME}\\text{ is approximately distributed as }F[\\theta(p-1),\\theta(N-t)(p-1)] \\tag{27.13} \\end{equation}\\]  \\[\\begin{equation} F_{TIME\\times TRT}\\text{ is approximately distributed as F}[\\theta(t-1)(p-1),\\theta(N-t)(p-1)] \\tag{27.14} \\end{equation}\\]  \\(\\sigma_{ij}\\)  \\(\\theta\\)  \\(\\sigma_{ij}\\) \\(\\theta\\).  \\(\\theta\\)  Box Box (1954)  \\(\\theta\\)  \\(\\theta = 1/(p - 1)\\).  Greenhouse  Geisser (1959)  \\(\\hat{\\boldsymbol{Q}}=\\boldsymbol{C\\hat{\\boldsymbol{\\Sigma}}}\\boldsymbol{C&#39;}\\)  \\(\\boldsymbol{C}\\)  \\(\\boldsymbol{Cj} = \\boldsymbol 0\\)  \\(\\boldsymbol{CC&#39;} = \\boldsymbol I_{p-1}\\)  \\((p - 1) × p\\)  \\(\\boldsymbol j\\)  1  p × 1  \\(\\boldsymbol I_{p-1}\\)  (p - 1) × ( p - 1)  \\[\\hat{{\\theta}}~=~\\frac{\\left(\\sum_{i=1}^{p-1}\\hat{{q}}_{ii}\\right)^2}{(p-1)\\sum_{i=1}^{p-1}\\sum_{j=1}^{p-1}\\hat{{q}}_{ij}^2}=\\frac{\\left[\\operatorname{tr}(\\hat{\\boldsymbol{Q}})\\right]^2}{(p-1)\\operatorname{tr}(\\hat{\\boldsymbol{Q}}\\hat{\\boldsymbol{Q}}^{\\prime})}\\]  \\(\\theta\\)  Greenhouse and Geisser (GG)  \\(\\text{tr}(\\boldsymbol B)\\)  \\(\\boldsymbol B\\)  Huynh and Feldt (1976)  \\(\\theta\\)  \\(\\theta\\)  \\[\\tilde{{\\theta}}=\\frac{N(p-1)\\hat{{\\theta}}-2}{(p-1)(N-r-(p-1)\\hat{{\\theta}})}\\]  N N - r  Box  HF  \\(\\theta\\)  1 \\(p\\)  (27.13)  (27.14)  1  \\(\\theta\\)  \\(\\boldsymbol{\\Sigma}\\)  H-F  \\(\\lambda\\)\\(\\boldsymbol{C\\Sigma C&#39;}=\\lambda \\boldsymbol{I}\\).  \\(\\boldsymbol{C\\Sigma C&#39;}\\)  \\(H_0{:\\boldsymbol{C\\Sigma C&#39;}}=\\lambda\\boldsymbol{I}\\)  \\[\\begin{equation} \\boldsymbol{\\Lambda}=\\frac{|\\hat{\\boldsymbol{Q}}|}{\\left[\\frac1{p-1}\\mathrm{tr}(\\hat{\\boldsymbol{Q}})\\right]^{p-1}} \\tag{27.15} \\end{equation}\\]  \\(-2\\log_{\\mathrm{e}}(\\Lambda)&gt;\\chi_{\\alpha,p(p-1)/2-1}^2\\)  \\(H_0\\).  \\(\\boldsymbol C\\)  $ = $  \\(\\boldsymbol{CC&#39;} = \\boldsymbol I_{p-1}\\). \\(\\Lambda\\)  \\(\\boldsymbol C\\)   27.1  \\[\\hat{\\boldsymbol E}=\\begin{bmatrix}0.237&amp;0.171&amp;0.162&amp;0.228&amp;0.129\\\\0.171&amp;0.247&amp;0.163&amp;0.231&amp;0.135\\\\0.162&amp;0.163&amp;0.268&amp;0.303&amp;0.184\\\\0.228&amp;0.231&amp;0.303&amp;0.392&amp;0.241\\\\0.129&amp;0.135&amp;0.184&amp;0.241&amp;0.247\\end{bmatrix}\\]  12   \\[\\begin{aligned} \\boldsymbol{\\hat{\\Sigma}}=\\frac1{12}\\boldsymbol{\\hat{E}}&amp; =\\frac{1}{12}\\begin{bmatrix}0.237&amp;0.171&amp;0.162&amp;0.228&amp;0.129\\\\0.171&amp;0.247&amp;0.163&amp;0.231&amp;0.135\\\\0.162&amp;0.163&amp;0.268&amp;0.303&amp;0.184\\\\0.228&amp;0.231&amp;0.303&amp;0.392&amp;0.241\\\\0.129&amp;0.135&amp;0.184&amp;0.241&amp;0.247\\end{bmatrix} \\\\\\\\ &amp;=\\begin{bmatrix}0.0198&amp;0.0143&amp;0.0135&amp;0.0190&amp;0.0108\\\\0.0143&amp;0.0206&amp;0.0136&amp;0.0193&amp;0.0113\\\\0.0135&amp;0.0136&amp;0.0223&amp;0.0253&amp;0.0153\\\\0.0190&amp;0.0193&amp;0.0253&amp;0.0327&amp;0.0201\\\\0.0108&amp;0.0113&amp;0.0153&amp;0.0201&amp;0.0206\\end{bmatrix} \\end{aligned}\\]  \\[\\boldsymbol{C}=\\begin{bmatrix}\\frac1{\\sqrt{2}}&amp;-\\frac1{\\sqrt{2}}&amp;0&amp;0&amp;0\\\\\\frac1{\\sqrt{6}}&amp;\\frac1{\\sqrt{6}}&amp;-\\frac2{\\sqrt{6}}&amp;0&amp;0\\\\\\frac1{\\sqrt{12}}&amp;\\frac1{\\sqrt{12}}&amp;\\frac1{\\sqrt{12}}&amp;-\\frac3{\\sqrt{12}}&amp;0\\\\\\frac1{\\sqrt{20}}&amp;\\frac1{\\sqrt{20}}&amp;\\frac1{\\sqrt{20}}&amp;\\frac1{\\sqrt{20}}&amp;-\\frac4{\\sqrt{20}}\\end{bmatrix}\\]  \\[\\boldsymbol{Q}=\\boldsymbol{C}\\boldsymbol{\\hat{\\Sigma}}\\boldsymbol{C}^{\\prime}=\\begin{bmatrix}0.00592&amp;-0.00019&amp;-0.00003&amp;0.00013\\\\-0.00019&amp;0.00830&amp;0.00399&amp;0.00178\\\\-0.00003&amp;0.00399&amp;0.00486&amp;0.00078\\\\0.00013&amp;0.00178&amp;0.00078&amp;0.00875\\end{bmatrix}\\]  \\(\\hat{{\\theta}}=0.795\\)  \\(\\tilde{{\\theta}}=1.747\\).  \\(H_0{:\\boldsymbol{C\\Sigma C&#39;}}=\\lambda\\boldsymbol{I}\\)  \\[\\Lambda=\\frac{|\\hat{\\boldsymbol{Q}}|}{\\left[\\frac1{p-1}\\mathrm{tr}(\\hat{\\boldsymbol{Q}})\\right]^{p-1}}=\\frac{1.20895(10)^{-9}}{\\left(\\frac{0.027831}4\\right)^4}=0.5159\\]  \\(-2\\log_e(\\Lambda)=1.32\\) \\(\\chi_{0.05,9}^2=16.919\\)  \\(H_0{:\\boldsymbol{C\\Sigma C&#39;}}=\\lambda\\boldsymbol{I}\\).  27.1  SAS-GLM  27.7  SAS   27.7:  27.1  SAS-GLM  x  27.8  27.9  ×  ×  GG \\(\\hat\\theta\\)  27.8  27.8  \\(F\\)  MANOVA  27.9  0.0001.  27.8:  x  27.9:  G-G  x SAS-GLM  repeated  MANOVA  27.10  27.1  SAS   27.10:  repeated  27.1  SAS-GLM  x  27.11  Orthogonal components  \\(H_0{:\\boldsymbol{C\\Sigma C&#39;}}=\\lambda\\boldsymbol{I}\\)  HF  27.12  MANOVA  27.13  MANOVA  27.14  27.15  \\(p\\)  \\(p\\) , GreenhouseGeisser (G-G)  \\(p\\)  HuyhnFeldt (HF)  \\(p\\)  \\(\\hat \\theta=0.7954\\)  \\(\\tilde\\theta=1.7473\\).  27.11:  \\(H_0{:\\boldsymbol{C\\Sigma C&#39;}}=\\lambda\\boldsymbol{I}\\) x  27.12:  MONOVA  x  27.13:  MONOVA  x  27.14:  x  27.15:  \\(p\\)  x 27.4   27.1  \\[\\boldsymbol y_{ik}=\\begin{bmatrix}y_{i1k}\\\\y_{i2k}\\\\\\vdots\\\\y_{ipk}\\end{bmatrix}\\]  i  k  \\[\\begin{equation} \\boldsymbol \\varepsilon_{ik}^*\\thicksim\\mathrm{independent~}N(\\boldsymbol 0,\\boldsymbol{\\Sigma}_i),\\quad i=1,2,\\ldots,t;\\quad k=1,2,\\ldots,n_i \\tag{27.16} \\end{equation}\\]  \\(\\boldsymbol y\\)  \\[\\boldsymbol y^{\\prime}=[\\boldsymbol y_{11}^{\\prime}\\quad \\boldsymbol y_{12}^{\\prime}\\quad\\ldots\\quad \\boldsymbol y_{1n_{1}}^{\\prime}\\quad \\boldsymbol y_{21}^{\\prime}\\quad \\boldsymbol y_{22}^{\\prime}\\quad\\ldots\\quad \\boldsymbol y_{2n_{2}}^{\\prime}\\quad\\ldots\\quad \\boldsymbol y_{t1}^{\\prime}\\quad \\boldsymbol y_{t2}^{\\prime}\\quad \\boldsymbol y_{t2}^{\\prime}\\quad\\ldots\\quad \\boldsymbol y_{tn_{t}}^{\\prime}]\\]  (27.16)  \\[\\boldsymbol V=\\mathrm{Cov}(\\boldsymbol y)=\\begin{bmatrix}\\boldsymbol{\\Sigma}_1&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}\\\\ \\boldsymbol{0}&amp;\\boldsymbol{\\Sigma}_1&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}\\\\ \\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots\\\\ \\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{\\Sigma}_1&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}\\\\ \\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{\\Sigma}_2&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}\\\\\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{\\Sigma}_2&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\ddots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{\\Sigma}_2&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}\\\\\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\ddots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{\\Sigma}_t&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}\\\\\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{\\Sigma}_t&amp;\\cdots&amp;\\boldsymbol{0}\\\\\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\cdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\boldsymbol{0}&amp;\\cdots&amp;\\boldsymbol{\\Sigma}_t\\end{bmatrix}\\]  \\(\\boldsymbol{y}\\sim N(\\boldsymbol{X}\\boldsymbol{\\beta},V)\\) \\(\\boldsymbol{y}=\\boldsymbol{X\\beta}+\\boldsymbol{\\varepsilon}\\)  \\(\\boldsymbol{\\varepsilon}\\sim N(\\boldsymbol{0},V)\\).  \\(\\boldsymbol V\\)  \\(\\boldsymbol\\ell&#39;\\boldsymbol \\beta\\)  \\(\\boldsymbol\\ell&#39;\\boldsymbol \\beta\\)  \\(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol \\beta}_\\boldsymbol V\\)  \\(\\boldsymbol{\\hat{\\beta}}_V=(\\boldsymbol{X}^{\\prime}\\boldsymbol{V}^{-1}\\boldsymbol{X})^{-}\\boldsymbol{X&#39;}\\boldsymbol{V}^{-1}\\boldsymbol{y}\\). \\(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol \\beta}_\\boldsymbol V\\)  \\(\\boldsymbol\\ell&#39;(\\boldsymbol{X&#39;V}^{-1}\\boldsymbol{X})^-\\boldsymbol\\ell\\).  \\(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol \\beta}_\\boldsymbol V\\)  \\(\\boldsymbol\\ell&#39;\\boldsymbol \\beta\\)  (generalized least squares estimator). \\(\\boldsymbol V\\)  \\(\\boldsymbol V\\)  \\(\\hat {\\boldsymbol V}\\) \\(\\boldsymbol\\ell&#39;\\boldsymbol \\beta\\)  \\(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol \\beta}_\\boldsymbol V\\) \\(\\hat{\\boldsymbol \\beta}_\\boldsymbol V=\\left(\\boldsymbol{X}^{\\prime}\\hat {\\boldsymbol{V}}^{-1}\\boldsymbol{X}\\right)^{-}\\boldsymbol{X&#39;}\\hat {\\boldsymbol{V}}^{-1}\\boldsymbol{y}\\) \\(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol \\beta}_\\boldsymbol V\\)  \\(\\widehat{s.e.}(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol{\\beta}}_{\\hat{\\boldsymbol V}})=\\boldsymbol\\ell&#39;\\left(\\boldsymbol{X&#39;}\\hat{\\boldsymbol{V}}^{-1}\\boldsymbol{X}\\right)^{-}\\boldsymbol\\ell\\).  \\(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol \\beta}_\\boldsymbol V\\)  \\(\\boldsymbol\\ell&#39;\\boldsymbol \\beta\\)  (estimated generalized least squares estimator).  \\(\\boldsymbol{\\ell&#39;\\beta}=0\\)  \\(t\\)  \\[\\begin{equation} t=\\frac{\\boldsymbol\\ell^{\\prime}\\hat{\\boldsymbol\\beta}_{\\hat{\\boldsymbol V}}}{\\boldsymbol\\ell^{\\prime}(\\boldsymbol X^{\\prime}\\hat{\\boldsymbol V}^{-1}\\boldsymbol X)\\boldsymbol\\ell} \\tag{27.17} \\end{equation}\\]  \\(H_0{:\\boldsymbol{H\\beta}}=\\boldsymbol0\\mathrm{~vs~}H_a{:\\boldsymbol{H\\beta}}\\ne\\boldsymbol0\\) \\(\\boldsymbol{H}\\)  q  q × p  \\(H_0\\)  \\(F\\)  \\[\\begin{equation} F=\\frac{(\\boldsymbol H\\boldsymbol{\\hat{\\beta}}_{\\hat{\\boldsymbol V}})^{\\prime}\\left[\\boldsymbol H(\\boldsymbol X\\hat{\\boldsymbol V}^{-1}\\boldsymbol{\\boldsymbol X})^{-}\\boldsymbol{H}^{\\prime}\\right]^{-1}(\\boldsymbol H{\\hat{\\boldsymbol \\beta}}_{\\hat{\\boldsymbol V}})}q \\tag{27.18} \\end{equation}\\]  \\(F\\)  q  Satterthwaites method  Satterthwaites method  Giesbrecht and Burns (1985), McLean and Sanders (1988)  Fai and Cornelius (1996).  KenwardRogers method.  Kenward and Roger (1997).  \\(\\boldsymbol\\Sigma_i\\)  \\(\\boldsymbol V\\).  (27.16)  \\(\\boldsymbol y\\) \\(\\boldsymbol\\Sigma_i\\)  \\(\\boldsymbol\\Sigma_i\\)  (CS)  HyuhnFeldt AR(1)  (heterogeneous compound symmetry, HCS)  AR(1).  \\(\\boldsymbol\\Sigma_i\\)  (unstructured, UN)  \\(\\boldsymbol V\\) \\(\\boldsymbol\\ell&#39;\\hat{\\boldsymbol \\beta}_\\boldsymbol V\\)  27.16  27.16  t  \\(\\boldsymbol\\Sigma_i\\)   27.16:  x  \\[\\begin{equation} y_{ijk}=\\mu+\\alpha_i+\\tau_j+\\gamma_{ij}+\\varepsilon_{ijk}^*,\\quad i=1,2,\\ldots,t;~j=1,2,\\ldots,p;~k=1,2,\\ldots,n_i \\tag{27.19} \\end{equation}\\]  \\[\\boldsymbol{\\varepsilon}_{ik}^*=\\begin{bmatrix}{\\varepsilon}_{i1k}^*\\\\{\\varepsilon}_{i2k}^*\\\\\\vdots\\\\{\\varepsilon}_{ipk}^*\\end{bmatrix}\\]  i  k  \\(i=1,2,\\ldots,t;k=1,2,\\ldots,n_i\\)\\(\\boldsymbol{\\varepsilon}_{ik}^*\\)  \\(N(\\boldsymbol 0,\\boldsymbol \\Sigma_i)\\).  (27.19)  (random subject component) \\[\\begin{equation} y_{ijk}=\\mu+\\alpha_i+\\delta_{ik}+\\tau_j+\\gamma_{ij}+\\varepsilon_{ijk}^*,i=1,2,\\ldots,t;~j=1,2,\\ldots,p;~k=1,2,\\ldots,n_i \\tag{27.20} \\end{equation}\\]  \\(\\delta_{ik}\\thicksim i.i.d.N(0,\\sigma_\\delta^2),i=1,2,\\ldots,t;k=1,2,\\ldots,n_i\\).  \\[\\left.\\mathrm{Cov}(y_{ik})=\\mathrm{Cov}\\left(\\begin{bmatrix}y_{i1k}\\\\y_{i2k}\\\\\\vdots\\\\y_{ipk}\\end{bmatrix}\\right.\\right)=\\sigma_\\delta^2\\boldsymbol{J}_p+\\boldsymbol{\\Sigma}_i\\]  \\(\\boldsymbol{J}_p\\)  1  p × p  \\(\\Sigma_i\\)  \\(\\Sigma_i\\)   (27.16)  (27.17)  (maximum likelihood, ML) (restricted maximum likelihood estimates, REML).  27.4.1   \\(\\boldsymbol y\\)  \\(\\boldsymbol V\\)  \\(\\boldsymbol \\beta\\)  \\(\\boldsymbol P&#39;\\boldsymbol\\beta\\)ML - I  22  27.4.2   ML  REML  ML - I  \\(\\boldsymbol{y}=\\boldsymbol{X\\beta}+\\boldsymbol{\\varepsilon}\\) \\(\\boldsymbol{\\varepsilon}\\sim N(\\boldsymbol{0},\\boldsymbol{V})\\).  \\(\\boldsymbol L\\)  \\(\\boldsymbol{LX} = \\boldsymbol 0\\)  \\(\\text{rank}(\\boldsymbol L) = n-\\text{rank}(\\boldsymbol X)\\) n  \\(\\boldsymbol y\\)   \\(\\boldsymbol y^* = \\boldsymbol {Ly}\\).  \\(\\boldsymbol y^*\\sim N(\\boldsymbol 0,\\boldsymbol{LVL}^{\\prime})\\).  \\(\\boldsymbol y^*\\) -- REML  \\(\\boldsymbol y^*\\) - \\(\\boldsymbol V\\) (27.17)  (27.18)   REML - REML  22   SAS-Mixed  Akaike (1974)  Akaikis Information Criterion (AIC).  Schwarz (1978)  Schwarz Bayesian Criterion (BIC).  Hurvich and Tsai (1989)  AICC.  \\(-2\\log_{\\mathrm{e}}(\\hat{{L}})\\)  \\(\\hat{\\boldsymbol{L}}\\)  \\(-2\\log_{\\mathrm{e}}(\\hat{{L}})\\)  \\(d\\) \\(N\\) \\(N^*\\)  \\(\\boldsymbol X\\)  \\[\\begin{align} \\mathrm{AIC}&amp;=-2\\log_\\mathrm{e}(\\hat{\\boldsymbol{L}})+2d\\\\\\mathrm{BIC}&amp;=-2\\log_\\mathrm{e}(\\hat{\\boldsymbol{L}})+d[\\log_\\mathrm{e}(N)]\\\\\\mathrm{AICC}&amp;=-2\\log_\\mathrm{e}(\\hat{\\boldsymbol{L}})+2d[N^*/(N^*-d-1)] \\tag{27.21} \\end{align}\\]  (LRT)  HF  LRT  HF  AR (1)  LRT  AR(1)  H-F  LRT  AR(1)  H-F 55 (27.21)   27.4  SAS-Mixed  SAS  27.17 -Repeated Type = CS  Subject = Person  Person Person 1-24  Person  1-8 Subject = Person(Drug)R  Person = 1  24  \\(\\boldsymbol \\Sigma\\) 1, 9, 17  R = 1, 9, 17  R.  27.17:  repeated  27.4  SAS-Mixed  x  27.18  repeated  ODS RTF SELECT R;  RTF  \\(\\boldsymbol R\\)  ODS output FITSTATISTICS=FIT1;  AIC, AICC  BIC \\(-2\\log_{\\mathrm{e}}(\\hat{L})\\)   27.18:  repeated  x  27.18  repeated  27.16  repeated  Group = Drug  1, 9  17 R = 1,9,17   27.19 \\(\\hat{{\\sigma}}^2=33.4182\\)  \\[\\hat{\\rho}=\\frac{25.9702}{33.4182}=0.777\\]  27.20  HF  \\[\\begin{aligned} \\hat{\\sigma}^2+2\\hat{\\eta}_1 &amp;=28.5296 \\\\ \\hat{\\sigma}^2+2\\hat{\\eta}_2 &amp;=40.2442 \\\\ \\hat{\\eta}_1+\\hat{\\eta}_2 &amp;=26.9390 \\end{aligned}\\]  \\(\\hat{\\sigma}^2,\\hat{\\eta}_1,\\hat{\\eta}_2\\)  \\[\\hat{\\sigma}^2=7.4479,\\quad\\hat{\\eta}_1=10.5409,\\quad\\mathrm{and}\\quad\\hat{\\eta}_2=16.3982\\]  27.19:  (CS)  \\(\\hat{\\boldsymbol \\Sigma}\\) x  27.20: H-F  \\(\\hat{\\boldsymbol \\Sigma}\\) x  27.21:  (UN)  \\(\\hat{\\boldsymbol \\Sigma}\\) x  27.22: AR(1)  \\(\\hat{\\boldsymbol \\Sigma}\\) x  \\(\\boldsymbol \\Sigma\\)  \\[\\hat{\\eta}_3=15.2671,\\quad\\mathrm{~and~}\\quad\\hat{\\eta}_4=11.6326\\]  27.21  SAS-GLM  MANOVA/PRINTE   27.22  AR(1)  \\(\\hat{\\sigma}^2=32.4945\\)  \\(\\hat{\\rho}=26.7309/32.4945=0.8226\\).  27.23  \\[\\begin{aligned} &amp;\\hat{\\sigma}_1^2 =31.1038_{\\prime} \\\\ &amp;\\hat{\\sigma}_2^2 =38.6218, \\\\ &amp;\\hat{\\sigma}_3^2=29.3752, \\\\ &amp;\\hat{\\sigma}_4^2=34.7840 \\end{aligned}\\]  \\[\\hat{\\rho}=\\frac{27.0585}{\\sqrt{31.1038\\cdot38.6218}}=0.7807\\]  27.23:  \\(\\hat{\\boldsymbol \\Sigma}\\) x  27.24  AR(1)  \\[\\begin{aligned} \\hat{\\sigma}_1^2 &amp;=30.7872 \\\\ \\hat{\\sigma}_2^2 &amp;=39.3259 \\\\ \\hat{\\sigma}_3^2 &amp;=31.0182 \\\\ \\hat{\\sigma}_4^2 &amp;=32.4256 \\end{aligned}\\]  \\[\\hat{\\rho}=\\frac{29.0118}{\\sqrt{30.7872\\cdot39.3256}}=0.8338\\]  27.24:  AR(1)  \\(\\hat{\\boldsymbol \\Sigma}\\) x  27.25 - 27.28  27.25  27.26  HF  27.27  27.28  AR(1)   27.25:  x  27.26: H-F  x  27.27:  x  27.28: AR (1)  x  27.29  AIC AIC  488.603 AR(1)  AIC AR(1)   27.29:  AIC x  27.30  AICC AICC  488.751 AR(1)  AICC AR(1)   27.30:  AICC x  27.31  BIC BIC  490.959 AR(1)  BIC AR(1)  AIC, AICC  BIC  AR(1).  27.31:  BIC x  27.32  \\(-2\\log_{\\mathrm{e}}(\\hat{L})\\)  H-F  H-F  \\(H_0:\\boldsymbol \\Sigma\\)  CS  \\(H_a:\\boldsymbol \\Sigma\\) HF LRT  \\(-2\\log_{\\mathrm{e}}(\\hat{L})\\)  \\(H_0\\)  p = 4 CS  HF  5  \\(\\chi^2=488.797-487.034=1.763\\) 5 - 2 = 3 \\(\\hat\\alpha = 0.6230\\) \\(H_0\\)   27.32:  \\(-2\\log_{\\mathrm{e}}(\\hat{L})\\) x  LRT  AR(1)  ARH(1)  p = 4  2  5 \\(\\chi^2=484.603-482.767=1.836\\) 3  \\({\\chi}_{0.05,3}^2=7.815\\) 1.836 &lt; 7.815 AR(1)  ARH(1)   AR(1)  UN AR(1)  2 p = 4 UN  p(p + 1)/2 = 10 \\(\\chi^2=484.603-477.372=7.231\\)  10 - 2 = 8  \\(\\hat \\alpha = 0.5119\\) AR(1)  UN   AR(1)  CS  LRT ARH(1)  CSH  LRT.  AR(1)  AR(1)  (27.20)  \\[\\boldsymbol{\\Sigma}={\\sigma}_\\delta^2\\begin{bmatrix}1&amp;1&amp;1&amp;1\\\\1&amp;1&amp;1&amp;1\\\\1&amp;1&amp;1&amp;1\\\\1&amp;1&amp;1&amp;1\\\\1&amp;1&amp;1&amp;1\\end{bmatrix}+{\\sigma}^2\\begin{bmatrix}1&amp;{\\rho}&amp;{\\rho}^2&amp;{\\rho}^3\\\\{\\rho}&amp;1&amp;{\\rho}&amp;{\\rho}^2\\\\{\\rho}^2&amp;{\\rho}&amp;1&amp;{\\rho}\\\\{\\rho}^3&amp;{\\rho}^2&amp;{\\rho}&amp;1\\end{bmatrix}\\]  27.33  AR(1)  SAS-Mixed  27.34  27.33 AIC, AICC  BIC  AR(1)  LRT  \\(\\chi^2=484.6-483.7=0.9\\).  1\\(\\chi^2=484.6-483.7=0.9\\)  1  \\(\\chi_{0.05,1}^2=3.84\\)  27.33:  SAS-Mixed  x  27.34:  x  SAS-Mixed  27.35  27.36  (27.18)  ×  ×  27.37  27.38  27.39   27.35:  SAS-Mixed  x  27.36: III  x  27.37:  x  27.38:  Tukey-Kramer  x  27.39:  Tukey-Kramer  x 27.5   \\(p\\)  \\(p\\)  27.6   subject  but adjust the p-values by adjusting the degrees of freedom corresponding to relevant effect mean squares. one first needs the least squares estimates of the parameters in B and an observed residual sum-of-squares and cross-products matrix.   =  /   7     x&lt;y  x  y   &lt; H-F &lt; H-F &lt; AR(1) &lt;  AR(1) AR(1)  H-F  LRT  27.16  "],["chap28.html", " 28   28.1  28.2  28.3  28.4 ", "  28   The only relevant test of the validity of a hypothesis is comparison of its predictions with experience. - Milton Friedman  28.1   (environments)  (clothing).  (person)  (chambers) 1  2  12  3  28.1  ×  1  (Hour) 36  3 1  (Time).  28.1:  x  \\[\\begin{align} y_{ijkm\\ell}=&amp;\\,[\\mu+E_i+\\eta_{i\\ell\\ell}]+[S_j+C_k+(SC)_{jk}+(ES)_{ij}+(EC)_{ik}+(ESC)_{ijk}+\\delta_{ijk\\ell}]+[T_m+(ET)_{im}\\\\&amp;+(ST)_{jm}+(CT)_{km}+(SCT)_{jkm}+(EST)_{ijm}+(ECT)_{ikm}+(ESCT)_{ijkm}+\\varepsilon_{ijkm\\ell}] \\tag{28.1} \\end{align}\\]  \\(E_i\\)  i \\(S_j\\)  j \\(C_k\\)  k \\(T_m\\)  m \\(\\eta_{i\\ell}\\)  \\(\\eta_{i\\ell}\\thicksim i.i.d.N(0,\\sigma_{\\eta}^{2})\\)\\(\\delta_{ijk\\ell}\\)  \\({\\delta_{ijk\\ell}}\\sim N(0,{\\sigma_\\delta^2})\\)\\(\\varepsilon_{ijkm\\ell}\\)  \\({\\varepsilon_{ijkm\\ell}}\\sim i.i.d.N(0,{\\sigma_{\\varepsilon}^2})\\).  (28.1)  \\[\\begin{align} y_{ijkm\\ell}=&amp;\\,\\mu+E_i+\\eta_{i\\ell}+S_j+C_k+(SC)_{jk}+(ES)_{ij}+(EC)_{ik}+(ESC)_{ijk}+T_m+(ET)_{im}+(ST)_{jm}\\\\&amp;+(CT)_{km}+(SCT)_{jkm}+(EST)_{ijm}+(ECT)_{ikm}+(ESCT)_{ijkm}+\\varepsilon_{ijkm\\ell} \\tag{28.2} \\end{align}\\]  \\(\\eta_{i\\ell}\\thicksim i.i.d.N(0,\\sigma_\\eta^2)\\)  \\[\\left.{\\boldsymbol\\varepsilon}_{ijk\\ell}=\\begin{bmatrix}{\\varepsilon}_{ijk1\\ell}\\\\{\\varepsilon}_{ijk2\\ell}\\\\{\\varepsilon}_{ijk3\\ell}\\end{bmatrix}\\thicksim N_3\\left(\\begin{bmatrix}0\\\\0\\\\0\\end{bmatrix}\\right.,\\begin{bmatrix}{\\sigma}_{11}&amp;{\\sigma}_{12}&amp;{\\sigma}_{13}\\\\{\\sigma}_{21}&amp;{\\sigma}_{22}&amp;{\\sigma}_{23}\\\\{\\sigma}_{31}&amp;{\\sigma}_{32}&amp;{\\sigma}_{33}\\end{bmatrix}\\right)\\thicksim N_3(0,{\\boldsymbol\\Sigma})\\text{ (say)}\\]  \\(\\boldsymbol\\Sigma\\)  (28.2)  (28.1)  \\(\\delta_{ijk\\ell}\\) \\(\\boldsymbol\\Sigma\\)  \\(\\boldsymbol\\Sigma\\)  AR(1)   SAS®-Mixed  28.2 -  28.2:  28.1  SAS Mixed  x  28.3  SAS-Mixed Sex × Clo × Rep × Env   28.3:  `repeated``  28.1  SAS Mixed  x AR(1) AR(1)  28.3  repeated Type = random  repeated  RANDOM REP(ENV) SEX*CLO*REP*ENV; REPEATED TIME/SUBJECT=SEX*CLO*REP*ENV TYPE=AR(1);  28.4   28.4:  x  28.4  AIC, AICC  BIC  \\(\\chi^2=117.7-107.5=10.2\\) 6-2=4 \\(\\hat\\alpha=0.0372\\). 28.5  SAS-Mixed  28.5  28.6  28.6  \\(\\hat{{\\sigma}}_{{\\eta}}^{2}=2.4047\\) \\[\\boldsymbol{\\Sigma}=\\begin{bmatrix}0.2157&amp;0.2256&amp;0.1248\\\\0.2256&amp;0.3525&amp;0.1894\\\\0.1248&amp;0.1894&amp;0.1462\\end{bmatrix}\\]  28.5:  `repeated``  28.1  SAS Mixed  x  28.6:  28.5  x  28.7 28.7 \\(\\hat\\alpha&lt;0.05\\)Sex, Clo, Env × Clo, Sex × Clo, Env × Sex × Clo, Time  Env × Time.  Env × Sex × Clo  28.5  SAS-Mixed  28.8  28.9 - 28.16   28.7:  x  28.8:  SAS-Mixed  x  28.9  Sex × Clothing  Reps  28.9  1  2 3   28.9:  x  28.10  Environment × Sex × Clothing  Reps  Time  28.11  Environment × Time  Reps, Clothing  Sex  12  Environment × Sex × Clothing  12  66  Environment × Sex  Clothing  Environment × Clothing  Sex Sex × Clothing  Environment12 66  24  28.12 - 28.14   28.10: Environment × Sex × Clothing  x  28.11: Environment  Time  x  28.12  Environment × Sex Clothing  28.13  Environment × Clothing  28.14  Sex = 1  Clo = 2 Environment 1  2 Sex = 2  Clo = 1   28.12:  Environment × Sex  Clothing  x  28.13:  Environment × Clothing  Sex  x  28.14:  Sex × Clothing  Environment  x  Environment × Time  36  18  28.15  reps, Sex  clothing  Environment  28.16  reps, Sex  clothing  28.15  time 1 Environment 1  2, 3  Environment 2  3  time 2  3  Environment  28.16  Environment 1 2  time  Environment 3  time   28.15:  x  28.16:  x  time  28.1  28.17  SAS  28.16  time   28.1:   28.17:  SAS  x 28.2   28.18   28.18:  x AMT1, 2, 3 \\[\\begin{align} y_{ijk\\ell}&amp;=\\mu+A_i+\\eta_{i\\ell}+M_j+(AM)_{ij}+\\delta_{ij\\ell}+T_k+(AT)_{ik}+(MT)_{jk}+(AMT)_{ijk}+\\varepsilon_{ijk\\ell}\\\\&amp;i=1,2;~j=1,2,3;~k=1,2,3 \\tag{28.3} \\end{align}\\]  \\(\\eta_{i\\ell}\\)  \\(\\eta_{i\\ell}\\thicksim i.i.d.~N(0,~\\sigma_\\eta^2)\\)\\({\\delta_{ijk\\ell}}\\)  \\({\\delta_{ijk\\ell}}\\sim{N}(0,{\\sigma_\\delta^2})\\)\\({\\varepsilon}_{ijk\\ell}\\)  \\({\\varepsilon_{ijk\\ell}}\\sim i.i.d.N(0,{\\sigma_{\\varepsilon}^{2}})\\).  SAS-Mixed  28.19  28.19  24.5  28.19:  28.18  SAS  x  \\[\\begin{align} y_{ijk\\ell}&amp;=\\mu+A_i+M_j+(AM)_{ij}+T_k+(AT)_{ik}+(MT)_{jk}+(AMT)_{ijk}+\\varepsilon_{ijk\\ell}\\\\&amp;i=1,2;~j=1,2,3;~k=1,2,3 \\tag{28.4} \\end{align}\\]  \\[ \\boldsymbol \\varepsilon_{i\\ell}=\\begin{bmatrix}\\varepsilon_{i11\\ell}\\\\ \\varepsilon_{i12\\ell}\\\\ \\varepsilon_{i13\\ell}\\\\ \\varepsilon_{i21\\ell}\\\\ \\varepsilon_{i22\\ell}\\\\ \\varepsilon_{i23\\ell}\\\\ \\varepsilon_{i31\\ell}\\\\ \\varepsilon_{i32\\ell}\\\\ \\varepsilon_{i33\\ell}\\end{bmatrix} \\]  i  \\(\\ell\\)   \\(\\boldsymbol \\varepsilon_{i\\ell}\\sim N(\\boldsymbol 0,\\boldsymbol \\Sigma)\\) \\(\\boldsymbol \\Sigma\\)  \\(\\boldsymbol \\Sigma\\)  9 × 9  27  \\[ \\boldsymbol \\varepsilon_{i\\ell}=\\operatorname{Var}\\left(\\begin{bmatrix}\\varepsilon_{i11\\ell}\\\\ \\varepsilon_{i12\\ell}\\\\ \\varepsilon_{i13\\ell}\\\\ \\varepsilon_{i21\\ell}\\\\ \\varepsilon_{i22\\ell}\\\\ \\varepsilon_{i23\\ell}\\\\ \\varepsilon_{i31\\ell}\\\\ \\varepsilon_{i32\\ell}\\\\ \\varepsilon_{i33\\ell}\\end{bmatrix}\\right)=\\begin{bmatrix}{\\theta}_{11}\\boldsymbol{V}&amp;{\\theta}_{12}\\boldsymbol{V}&amp;{\\theta}_{13}\\boldsymbol{V}\\\\{\\theta}_{21}\\boldsymbol{V}&amp;{\\theta}_{22}\\boldsymbol{V}&amp;{\\theta}_{23}\\boldsymbol V\\\\{\\theta}_{31}\\boldsymbol{V}&amp;{\\theta}_{32}\\boldsymbol{V}&amp;{\\theta}_{33}\\boldsymbol{V}\\end{bmatrix}=\\boldsymbol{\\Theta}\\otimes\\boldsymbol{V}\\mathrm{~(say)} \\]  \\(\\boldsymbol{\\Theta}\\otimes\\boldsymbol{V}\\)  (direct product) \\[\\boldsymbol{\\Theta}=\\begin{bmatrix}\\theta_{11}&amp;\\theta_{12}&amp;\\theta_{13}\\\\\\theta_{21}&amp;\\theta_{22}&amp;\\theta_{23}\\\\\\theta_{31}&amp;\\theta_{32}&amp;\\theta_{33}\\end{bmatrix}\\quad\\mathrm{and}\\quad\\boldsymbol{V}=\\begin{bmatrix}v_{11}&amp;v_{12}&amp;v_{13}\\\\v_{21}&amp;v_{22}&amp;v_{23}\\\\v_{31}&amp;v_{32}&amp;v_{33}\\end{bmatrix}\\]  \\(\\boldsymbol{\\Theta}\\)  \\(\\boldsymbol{V}\\) AR(1) SAS-Mixed  \\(\\boldsymbol{\\Theta}\\)  \\(\\boldsymbol{V}\\)   28.18 AR(1)  9 × 9  28.20  SAS-Mixed  28.21  DDFM = BETWITHIN DDFM = KR DDFM = KR  9 × 9  28.22  \\(\\boldsymbol{V}\\)  AR(1) Mixed  Mixed  PARMS  Mixed  PARMS 10, 1, 10, 1, 1, 10, .5;  \\[{\\boldsymbol\\Theta}=\\begin{bmatrix}{\\theta}_{11}&amp;{\\theta}_{12}&amp;{\\theta}_{13}\\\\{\\theta}_{21}&amp;{\\theta}_{22}&amp;{\\theta}_{23}\\\\{\\theta}_{31}&amp;{\\theta}_{32}&amp;{\\theta}_{33}\\end{bmatrix}\\quad\\mathrm{and}\\quad{\\boldsymbol V}=\\begin{bmatrix}1&amp;{\\rho}&amp;{\\rho}\\\\{\\rho}&amp;1&amp;{\\rho}\\\\{\\rho}&amp;{\\rho}&amp;1\\end{bmatrix}\\] \\(\\theta_{11}=10,\\theta_{21}=1,\\theta_{22}=10,\\theta_{31}=1,\\theta_{32}=1,\\theta_{33}=10,\\rho=0.5\\). \\(\\boldsymbol{V}\\)  1 \\(\\boldsymbol{V}\\)  AR(1)  \\[\\boldsymbol{V}=\\begin{bmatrix}1&amp;{\\rho}&amp;{\\rho}^2\\\\{\\rho}&amp;1&amp;{\\rho}\\\\{\\rho}^2&amp;{\\rho}&amp;1\\end{bmatrix}\\] \\(\\boldsymbol{V}\\)  1.  28.20:  SAS  x  28.21:  SAS  x  28.22  AIC, AICC  BIC  \\(\\boldsymbol{\\Theta}\\) \\(\\boldsymbol{V}\\)  \\(\\boldsymbol{\\Theta}\\otimes\\boldsymbol{V}\\)   28.22:  x  28.23  SAS-Mixed  SAS-Mixed  Classes  28.24  \\[\\hat{{\\boldsymbol\\Theta}}=\\begin{bmatrix}\\hat{{\\theta}}_{_{FF}}&amp;\\hat{{\\theta}}_{_{FM}}&amp;\\hat{{\\theta}}_{_{FS}}\\\\\\hat{{\\theta}}_{_{MF}}&amp;\\hat{{\\theta}}_{_{MM}}&amp;\\hat{{\\theta}}_{_{MS}}\\\\\\hat{{\\theta}}_{_{SF}}&amp;\\hat{{\\theta}}_{_{SM}}&amp;\\hat{{\\theta}}_{_{SS}}\\end{bmatrix}=\\begin{bmatrix}8.1570&amp;2.7308&amp;1.2415\\\\2.7508&amp;9.7410&amp;2.6035\\\\1.2415&amp;2.6035&amp;14.7547\\end{bmatrix}\\quad\\mathrm{and}\\quad\\hat{{\\rho}}=0.9637\\] \\(\\hat{{\\boldsymbol\\Theta}}\\)  (F) (M)  (S) 28.25  9 × 9  \\(\\boldsymbol{\\Theta}\\otimes\\boldsymbol{V}\\)  28.26   28.23:  SAS  x  28.24:  x  28.25:  x  28.26 A, M, T  A × T  (M)  (A × T).  28.26:  x  28.27  SAS-Mixed  28.23  M  A × T  28.28  28.29  28.30 - 28.32  28.28  28.30   28.27:  SAS  x  28.28:  x  28.29  28.31  0  6  12  28.32  0  12  6  0.05   28.29:  x  28.30:  x  28.31:  x  28.32:  x 28.3   28.33   28.33:  x  (center)  28.33  \\[\\begin{equation} y_{ijk\\ell}=\\mu+\\eta_i+D_j+\\delta_{ij\\ell}+T_k+(DT)_{jk}+\\varepsilon_{ijk\\ell} \\tag{28.5} \\end{equation}\\]  \\(D_j\\)  j \\(T_k\\)  k \\((DT)_{ij}\\) \\(\\eta_i\\)  \\(\\eta_i\\thicksim i.i.d.N(0,\\sigma_\\eta^2)\\)\\(\\delta_{ij\\ell}\\)  i  j  \\(\\ell\\)  \\({\\delta}_{ij\\ell}\\thicksim N(0,{\\sigma}_\\delta^2)\\). \\(\\varepsilon_{ijk\\ell}\\)  i  j  \\(\\ell\\)  i  j  \\(\\ell\\)  \\(\\ell\\)  \\(\\varepsilon_{ijk\\ell}\\sim i.i.d.N(0,\\sigma_{\\varepsilon}^2)\\).   \\[\\begin{equation} y_{ijk\\ell}=\\mu+\\eta_i+D_j+T_k+(DT)_{jk}+\\varepsilon_{ijk\\ell} \\tag{28.6} \\end{equation}\\]  \\(\\eta_i\\thicksim i.i.d.N(0,\\sigma_\\eta^2)\\)  \\[\\left.{\\boldsymbol\\varepsilon}_{ij\\ell}=\\begin{bmatrix}{\\varepsilon}_{ij1\\ell}\\\\{\\varepsilon}_{ij2\\ell}\\\\{\\varepsilon}_{ij3\\ell}\\end{bmatrix}\\thicksim N_3\\left(\\begin{bmatrix}0\\\\0\\\\0\\end{bmatrix}\\right.,\\begin{bmatrix}{\\sigma}_{11}&amp;{\\sigma}_{12}&amp;{\\sigma}_{13}\\\\{\\sigma}_{21}&amp;{\\sigma}_{22}&amp;{\\sigma}_{23}\\\\{\\sigma}_{31}&amp;{\\sigma}_{32}&amp;{\\sigma}_{33}\\end{bmatrix}\\right)\\thicksim N_3(\\boldsymbol{0},{\\boldsymbol\\Sigma})\\text{ (say)}\\]  \\(\\boldsymbol\\Sigma}\\)  (28.6)  (28.5)  \\(\\delta_{ij\\ell}\\)  \\(\\boldsymbol\\Sigma}\\)  \\(\\boldsymbol\\Sigma}\\)  AR(1)  AR(1)  AR(1) BIC  AR(1) AIC  AICC \\(\\rho\\)  0.3141  28.34  SAS-Mixed  28.35  28.36  28.36  28.37  28.38  1  2  3  2  3  28.39  28.40   28.34:  28.33  SAS  x  28.35:  x  28.36:  x  28.37:  x  28.38:  x  28.39:  x  28.40:  x 28.4  "],["chap29.html", " 29   29.1  29.2 / 29.3  29.4  29.5 ", "  29   The most important questions of life are, for the most part, really only problems of probability. - Pierre Simon, Marquis de Laplace  (crossover design)   (carryover)  (residual)  \\(A\\)  \\(B\\)  \\(A\\)  (lingering effect)  \\(B\\)  \\(A\\)  \\(B\\)    \\(t\\)  \\(t\\)  \\(s\\)  \\(i\\)  29.1   29.1: AB  C x 29.1   \\(i\\)  \\(j\\)  \\(\\ell\\)  \\[\\begin{align} y_{ijk\\ell}&amp;=\\mu+S_i+\\delta_{i\\ell}+P_j+T_k+\\varepsilon_{ijk\\ell}\\\\i&amp;=1,2,\\ldots,s,j=1,2,\\ldots,p,k=1,2,\\ldots,t,\\mathrm{~and~}\\ell=1,2,\\ldots,n_j \\tag{29.1} \\end{align}\\] \\(S_i\\)  \\(i\\) \\(P_j\\)  \\(j\\) \\(T_k\\)  \\(k\\)  \\(k\\)  \\(i\\)  \\(j\\)  \\(i,j\\)  \\(\\delta_{i\\ell}\\sim i.i.d.N(0,\\sigma_{\\delta}^{2}),\\varepsilon_{ijk\\ell}\\sim i.i.d.N(0,\\sigma_{\\varepsilon}^{2})\\) \\(\\delta_{i\\ell}\\)  \\(\\varepsilon_{ijk\\ell}\\)   \\(\\delta_{i\\ell}\\)  \\(\\varepsilon_{ijk\\ell}\\)  \\(\\delta_{i\\ell}\\sim i.i.d.N(0,\\sigma_{\\delta}^{2})\\).  \\(\\varepsilon_{ijk\\ell}\\)  27.1  \\(\\delta_{i\\ell}\\)  \\(\\varepsilon_{ijk\\ell}\\)  27  / (two-period/two-treatment crossover design)  29.2  29.3  29.4  29.2 / \\(AB\\)  \\(BA\\)/ \\(AB\\)  \\(A\\)  \\(1\\)  \\(B\\)  \\(2\\) \\(BA\\)  \\(B\\)  \\(1\\)  \\(A\\)  \\(2\\)  \\(n_1\\)  \\(AB\\)  \\(n_2\\)  \\(BA\\)  \\[\\begin{align} y_{ijk\\ell}&amp;=\\mu+S_i+\\delta_{i\\ell}+P_j+T_k+\\varepsilon_{ijk\\ell}\\\\i&amp;=AB,BA,~j=1,2,~k=A,B,~\\mathrm{and}~\\ell=1,2,\\ldots,n_i \\tag{29.2} \\end{align}\\]  \\(k\\)  \\(i\\)  \\(j\\)  \\[\\mu_{ij}=\\mu+S_i+P_j+T_k\\]  \\(i\\)  \\(j\\)  \\(\\hat \\mu_{ij}\\)  \\((i,j)\\)  \\[\\begin{align} \\hat \\mu_{11}=\\bar y_{11\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{AB}+P_1+T_A\\\\ \\hat \\mu_{12}=\\bar y_{12\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{AB}+P_2+T_B\\\\ \\hat \\mu_{21}=\\bar y_{21\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{BA}+P_1+T_B\\\\ \\hat \\mu_{22}=\\bar y_{22\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{BA}+P_2+T_A \\tag{29.3} \\end{align}\\]  (29.3)  \\[\\begin{align} \\hat {\\bar\\mu}_{1\\cdot}&amp;=\\frac{\\bar y_{11\\cdot\\cdot}+\\bar y_{12\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+S_{AB}+\\bar P_\\cdot+\\frac{T_A+T_B}{2}\\\\ \\hat {\\bar\\mu}_{2\\cdot}&amp;=\\frac{\\bar y_{21\\cdot\\cdot}+\\bar y_{22\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+S_{BA}+\\bar P_\\cdot+\\frac{T_A+T_B}{2}\\\\ \\hat {\\bar\\mu}_{\\cdot 1}&amp;=\\frac{\\bar y_{11\\cdot\\cdot}+\\bar y_{21\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+\\bar S_{\\cdot}+\\bar P_1+\\frac{T_A+T_B}{2}\\\\ \\hat {\\bar\\mu}_{\\cdot 2}&amp;=\\frac{\\bar y_{12\\cdot\\cdot}+\\bar y_{22\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+\\bar S_{\\cdot}+\\bar P_2+\\frac{T_A+T_B}{2} \\tag{29.4} \\end{align}\\]  \\(\\hat {\\bar\\mu}_{1\\cdot}-\\hat {\\bar\\mu}_{2\\cdot}\\)  \\(S_{AB} - S_{BA}\\) \\(1\\)  \\(2\\)  \\(\\hat {\\bar\\mu}_{\\cdot1}-\\hat {\\bar\\mu}_{\\cdot2}\\)  \\(P_1 - P_2\\).  \\(T_A - T_B\\) \\((\\hat {\\bar\\mu}_{11}-\\hat {\\bar\\mu}_{12}-\\hat {\\bar\\mu}_{21}+\\hat {\\bar\\mu}_{22})/2\\)  \\[\\begin{equation} \\begin{bmatrix}\\hat{\\mu}_{11}\\\\\\hat{\\mu}_{12}\\\\\\hat{\\mu}_{21}\\\\\\hat{\\mu}_{22}\\end{bmatrix}\\thicksim N\\left(\\begin{bmatrix}\\mu_{11}\\\\\\mu_{12}\\\\\\mu_{21}\\\\\\mu_{22}\\end{bmatrix},\\,\\begin{bmatrix}\\frac{\\sigma_\\varepsilon^2+\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\delta^2}{n_1}&amp;0&amp;0\\\\\\\\\\frac{\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\epsilon^2+\\sigma_\\delta^2}{n_1}&amp;0&amp;0\\\\\\\\0&amp;0&amp;\\frac{\\sigma_\\epsilon^2+\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\delta^2}{n_2}\\\\\\\\0&amp;0&amp;\\frac{\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\epsilon^2+\\sigma_\\delta^2}{n_2}\\end{bmatrix}\\right) \\tag{29.5} \\end{equation}\\]  (29.5)  \\[\\begin{aligned}&amp;\\hat{\\bar{\\mu}}_{1\\cdot}-\\hat{\\bar{\\mu}}_{2\\cdot}\\thicksim N\\bigg[S_{AB}-S_{BA},\\bigg(\\frac{\\sigma_{\\varepsilon}^{2}+2\\sigma_{\\delta}^{2}}{2}\\bigg)\\bigg(\\frac{1}{n_{1}}+\\frac{1}{n_{2}}\\bigg)\\bigg]\\\\&amp;\\hat{\\bar{\\mu}}_{\\cdot1}-\\hat{\\bar{\\mu}}_{\\cdot2}\\thicksim N\\bigg[P_1-P_2,\\frac{\\sigma_{\\varepsilon}^{2}}{2}\\bigg(\\frac{1}{n_1}+\\frac{1}{n_2}\\bigg)\\bigg]\\\\&amp;\\frac{\\hat\\mu_{11}-\\hat\\mu_{12}-\\hat\\mu_{21}+\\hat\\mu_{22}}{2}\\thicksim N\\bigg[T_A-T_B,\\frac{\\sigma_{\\varepsilon}^{2}}{2}\\bigg(\\frac{1}{n_1}+\\frac{1}{n_2}\\bigg)\\bigg]\\end{aligned}\\] / 29.2  \\(H_0: T_A = T_B\\)  \\(F\\)  \\(F = TMS/WSEMS\\)  \\(TMS\\)  29.2  (treatment mean square)\\(WSEMS\\)  (within subject error mea square).  \\(F&gt;F_{\\alpha,1,n_1+n_2-2}\\)  \\(H_0\\). \\(T_A-T_B\\)  \\((1-\\alpha)100\\%\\)  \\[\\frac{\\hat{\\mu}_{11}-\\hat{\\mu}_{12}-\\hat{\\mu}_{21}+\\hat{\\mu}_{22}}2\\pm t_{\\alpha,v}\\sqrt{\\frac{\\hat\\sigma_{\\varepsilon}^2}2{\\left(\\frac1{n_1}+\\frac1{n_2}\\right)}}\\]  \\(v=n_1+n_2-n\\)  \\(\\hat\\sigma_\\varepsilon^2=WSEMS\\).  Grizzle (1965)  29.3  29.4  SAS®-GLM   29.2: / x  29.3: Grizzle (1965)  Seq Period Trt Person Y AB 1 A 11 0.2 AB 2 B 11 1 AB 1 A 12 0 AB 2 B 12 -0.7 AB 1 A 13 -0.8 AB 2 B 13 0.2 AB 1 A 14 0.6 AB 2 B 14 1.1 AB 1 A 15 0.3 AB 2 B 15 0.4 AB 1 A 16 1.5 AB 2 B 16 1.2 BA 1 B 21 1.3 BA 2 A 21 0.9 BA 1 B 22 -2.3 BA 2 A 22 1 BA 1 B 23 0 BA 2 A 23 0.6 BA 1 B 24 -0.8 BA 2 A 24 -0.3 BA 1 B 25 -0.4 BA 2 A 25 -1 BA 1 B 26 -2.9 BA 2 A 26 1.7 BA 1 B 27 -1.9 BA 2 A 27 -0.3 BA 1 B 28 -2.9 BA 2 A 28 0.9  29.4:  29.3  SAS-GLM  x  29.5  \\(WSEMS\\)  \\(\\hat \\sigma_\\varepsilon^2 = 1.245\\).  29.6  \\(H_0:T_A = T_B\\)   \\(BSEMS = \\hat \\sigma_{\\varepsilon} ^2 + 2\\hat \\sigma_{\\delta}^2 = 1.001\\). \\(H_0\\)  \\(\\hat \\alpha = 0.1165\\).  29.7  \\(A\\)  \\(B\\)  \\(A\\)  \\(B\\)  \\(\\hat \\alpha = 0.1165\\) 29.8 × 29.9  29.10   29.5:  x  29.6:  29.3  III  x  29.7:  x  29.8:  29.3  x  29.9:  29.3  SAS-GLM  x  29.10: × x  29.3  29.11  SAS Mixed  GLM  GLM Mixed  \\(\\hat \\sigma _\\delta ^2 = 0\\) GLM  \\[\\hat\\sigma_\\delta^2=\\frac{BSEMS-WSEMS}2=\\frac{1.005-1.245}2=\\frac{-0.240}2=-0.120\\]  29.11  29.11   29.11:  29.3  SAS-Mixed  x  \\[\\begin{align} \\hat \\mu_{11}=\\bar y_{11\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{AB}+P_1+T_A\\\\ \\hat \\mu_{12}=\\bar y_{12\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{AB}+P_2+T_B+\\lambda_A\\\\ \\hat \\mu_{21}=\\bar y_{21\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{BA}+P_1+T_B\\\\ \\hat \\mu_{22}=\\bar y_{22\\cdot\\cdot}\\,\\mathrm{estimates}\\,\\mu+S_{BA}+P_2+T_A+\\lambda_B \\tag{29.6} \\end{align}\\]  \\(\\lambda_A\\)  \\(AB\\)  \\(1\\)  \\(A\\)  \\(2\\)  \\(\\lambda_B\\)  \\(BA\\)  \\(1\\)  \\(B\\)  \\(2\\)   (29.6)  \\[\\begin{align} \\hat {\\bar\\mu}_{1\\cdot}&amp;=\\frac{\\bar y_{11\\cdot\\cdot}+\\bar y_{12\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+S_{AB}+\\bar P_\\cdot+\\frac{T_A+T_B}{2}+\\frac{\\lambda_A}{2}\\\\ \\hat {\\bar\\mu}_{2\\cdot}&amp;=\\frac{\\bar y_{21\\cdot\\cdot}+\\bar y_{22\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+S_{BA}+\\bar P_\\cdot+\\frac{T_A+T_B}{2}+\\frac{\\lambda_B}{2}\\\\ \\hat {\\bar\\mu}_{\\cdot 1}&amp;=\\frac{\\bar y_{11\\cdot\\cdot}+\\bar y_{21\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+\\bar S_{\\cdot}+\\bar P_1+\\frac{T_A+T_B}{2}\\\\ \\hat {\\bar\\mu}_{\\cdot 2}&amp;=\\frac{\\bar y_{12\\cdot\\cdot}+\\bar y_{22\\cdot\\cdot}}{2}\\,\\mathrm{estimates}\\,\\mu+\\bar S_{\\cdot}+\\bar P_2+\\frac{T_A+T_B}{2}+\\frac{\\lambda_A+\\lambda_B}{2} \\tag{29.7} \\end{align}\\]  \\(\\lambda_A\\ne \\lambda_B\\) \\(\\lambda_A\\)  \\(\\lambda_B\\)  \\(\\lambda_A= \\lambda_B\\) \\(\\lambda_A\\)  \\(\\lambda_B\\)  (confounded) (29.2)  \\(\\hat {\\bar\\mu}_{1\\cdot}-\\hat {\\bar\\mu}_{2\\cdot}\\)  \\(S_{AB}-S_{BA}+[(\\lambda_A-\\lambda_B)/2]\\) \\(1\\)  \\(2\\)  \\(\\hat {\\bar\\mu}_{\\cdot1}-\\hat {\\bar\\mu}_{\\cdot2}\\)  \\(P_1-P_2+[(\\lambda_A+\\lambda_B)/2]\\) \\((\\hat{\\mu}_{11}-\\hat{\\mu}_{12}-\\hat{\\mu}_{21}+\\hat{\\mu}_{22})/2\\)  \\(T_A-T_B+[(\\lambda_A-\\lambda_B)/2]\\)  \\(2\\)  \\(\\hat \\mu_{11}-\\hat \\mu_{21}\\)  \\(T_A-T_B\\) \\(1\\)  \\(1\\)  \\(1\\)  \\[\\begin{equation} y_{k\\ell}=\\mu+T_k+\\varepsilon_{k\\ell}^*,~k=A,B,~\\mathrm{and~}~\\ell=1,2,\\ldots,n_i \\tag{29.8} \\end{equation}\\]  \\(\\varepsilon_{k\\ell}^{*}=\\delta_{k\\ell}+\\varepsilon_{k\\ell}\\).  \\[\\mathrm{Var}(\\hat{\\mu}_{11}-\\hat{\\mu}_{21})=(\\sigma_\\varepsilon^2+\\sigma_\\delta^2){\\left(\\frac1{n_1}+\\frac1{n_2}\\right)}\\]  29.12 / 29.2   29.12: / x \\(S_{AB}-S_{BA}\\) \\(F=SeqMS/BSEM\\)  \\(F\\)  \\(F&gt;F_{\\alpha,1,n1+n2-2}\\)/ (wash-out) /// / 29.3  Grizzle (1965)  SAS-Mixed  29.13   29.13:  29.3  SAS-Mixed  x  Mixed  random × ESTIMATE  \\(1\\)   29.14:  x  29.14  29.13  Mixed  \\(0.0665\\)  \\(0.1002\\)   29.15  29.15:  x  29.16  29.13  Mixed  29.14 × 29.14  29.17 × 29.18  \\(1\\)  29.18  29.7  \\(1\\)   29.16:  x  29.17: × x  29.18:  \\(A\\)  \\(B\\) \\(1\\)  x 29.3  / (29.1)  29.429.9 29.11   \\(ABA\\)  \\(BAB\\).  \\(ABA\\)  \\(1\\)  \\(A\\) \\(2\\)  \\(B\\) \\(3\\) \\(A\\). \\(BAB\\)  \\(ABB\\)  \\(BAA\\). \\(ABA\\)\\(BAB\\)\\(ABB\\)  \\(BAA\\)  \\(ABA\\)  \\(BAB\\)   29.19  \\(ABA\\)  \\(BAB\\)   29.19: / x  \\(n_1\\)  \\(ABA\\) \\(n2\\)  \\(BAB\\)  \\(y_{ij\\ell}\\)  \\(i\\)  \\(j\\)  \\(\\ell\\)  \\(\\hat\\mu _{ij} = \\bar y_{ij\\cdot} , i = 1, 2; j = 1, 2, 3\\).  (29.1)  \\[\\begin{equation} \\begin{bmatrix}\\hat{\\mu}_{11}\\\\\\hat{\\mu}_{12}\\\\\\hat{\\mu}_{13}\\\\\\hat{\\mu}_{21}\\\\\\hat{\\mu}_{22}\\\\\\hat{\\mu}_{23}\\end{bmatrix}\\sim N\\left(\\begin{bmatrix}\\mu_{11}\\\\\\mu_{12}\\\\\\mu_{13}\\\\\\mu_{21}\\\\\\mu_{21}\\\\\\mu_{23}\\end{bmatrix},\\begin{bmatrix}\\frac{\\sigma_\\varepsilon^2+\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\delta^2}{n_1}&amp;0&amp;0&amp;0\\\\\\frac{\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\varepsilon^2+\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\delta^2}{n_1}&amp;0&amp;0&amp;0\\\\\\frac{\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\delta^2}{n_1}&amp;\\frac{\\sigma_\\epsilon^2+\\sigma_\\delta^2}{n_1}&amp;0&amp;0&amp;0\\\\0&amp;0&amp;0&amp;\\frac{\\sigma_\\varepsilon^2+\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\delta^2}{n_2}\\\\0&amp;0&amp;0&amp;\\frac{\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\varepsilon^2+\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\delta^2}{n_2}\\\\0&amp;0&amp;0&amp;\\frac{\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\delta^2}{n_2}&amp;\\frac{\\sigma_\\varepsilon^2+\\sigma_\\delta^2}{n_2}\\end{bmatrix}\\right) \\tag{29.9} \\end{equation}\\]  $$ \\[\\begin{aligned} \\begin{aligned}\\mu_{11}-\\frac12\\mu_{12}-\\frac12\\mu_{13}-\\mu_{21}+\\frac12\\mu_{22}+\\frac12\\mu_{23}\\end{aligned}&amp; =(\\mu+S_{ABA}+P_1-T_A)-\\frac12(\\mu+S_{ABA}+P_2+T_B+\\lambda_A) \\\\ &amp;-\\frac12(\\mu+S_{ABA}+P_3+T_A+\\lambda_B)-(\\mu+S_{BAB}+P_1+T_B) \\\\ &amp;+\\frac12(\\mu+S_{BAB}+P_2+T_A+\\lambda_B)+\\frac12(\\mu+S_{BAB}+P_3+T_B+\\lambda_A) \\\\ &amp;=T_{A}-T_{B} \\end{aligned}\\] $$  \\(ABA\\)\\(BAB\\)  \\[\\begin{equation} \\hat{\\mu}_{11}-\\frac12\\hat{\\mu}_{12}-\\frac12\\hat{\\mu}_{13}-\\hat{\\mu}_{21}+\\frac12\\hat{\\mu}_{22}+\\frac12\\hat{\\mu}_{23} \\tag{29.10} \\end{equation}\\]  \\[\\begin{equation} \\mathrm{Var}\\left(\\hat{\\mu}_{11}-\\frac12\\hat{\\mu}_{12}-\\frac12\\hat{\\mu}_{13}-\\hat{\\mu}_{21}+\\frac12\\hat{\\mu}_{22}+\\frac12\\hat{\\mu}_{23}\\right)=\\frac32\\sigma_{\\varepsilon}^2\\left(\\frac1{n_1}+\\frac1{n_2}\\right) \\tag{29.11} \\end{equation}\\]  (29.11)  \\(\\sigma^2_\\varepsilon\\).  29.19  \\(A\\)  \\(A\\) \\(A\\)  \\((\\mu_{11} + \\mu_{22} + \\mu_{13})/3\\)\\(B\\)  \\((\\mu_{21} + \\mu_{12} + \\mu_{23})/3\\) 29.19  \\[\\begin{aligned}\\mu+\\frac23S_{ABA}+\\frac13S_{BAB}+\\bar{P}_\\cdot+T_A+\\frac13(\\lambda_B+\\lambda_A)\\\\\\mu+\\frac13S_{ABA}+\\frac23S_{BAB}+\\bar{P}_\\cdot+T_B+\\frac13(\\lambda_A+\\lambda_B)\\end{aligned}\\]  \\(A\\)  \\(B\\)  \\(\\frac{1}{3}S_{ABA}-\\frac{1}{3}S_{BAB}+T_A-T_B\\) \\(T_A-T_B\\).  \\(A\\)  \\(B\\)  (aliased). \\(A\\)  \\[\\mu+\\bar{S}_\\cdot+\\bar{P}_\\cdot+T_A+\\frac13(\\lambda_B+\\lambda_A)\\] \\(B\\)  \\[\\mu+\\bar{S}_\\cdot+\\bar{P}_\\cdot+T_B+\\frac13(\\lambda_B+\\lambda_A)\\]  29.19  \\[\\frac23\\mu_{11}-\\frac1{12}\\mu_{12}-\\frac1{12}\\mu_{13}-\\frac13\\mu_{21}+\\frac5{12}\\mu_{22}+\\frac5{12}\\mu_{23}\\]  \\[-\\frac13\\mu_{11}+\\frac5{12}\\mu_{12}+\\frac5{12}\\mu_{13}+\\frac23\\mu_{21}-\\frac1{12}\\mu_{22}-\\frac1{12}\\mu_{23}\\]  \\[\\mu_{11}-\\frac12\\mu_{12}-\\frac12\\mu_{13}-\\mu_{21}+\\frac12\\mu_{22}+\\frac12\\mu_{23}=T_A-T_B\\]  (29.10)  \\[\\begin{equation} \\mu_{11}-\\mu_{13}-\\mu_{21}+\\mu_{23}=\\lambda_A-\\lambda_B \\tag{29.12} \\end{equation}\\]  \\[\\begin{equation} \\mathrm{Var}(\\hat{\\mu}_{11}-\\hat{\\mu}_{13}-\\hat{\\mu}_{21}+\\hat{\\mu}_{23})=2\\sigma_{\\varepsilon}^2\\left(\\frac1{n_1}+\\frac1{n_2}\\right) \\tag{29.13} \\end{equation}\\]   29.20  \\(ABA\\)  \\(BAB\\)  \\(n_1 = n_2 = 3\\). × SAS  29.21  29.22  \\(A\\)  \\[\\begin{aligned} \\frac23\\hat{\\mu}_{11}&amp; -\\frac1{12}\\hat{\\mu}_{12}-\\frac1{12}\\hat{\\mu}_{13}-\\frac13\\hat{\\mu}_{21}+\\frac5{12}\\hat{\\mu}_{22}+\\frac5{12}\\hat{\\mu}_{23} \\\\ &amp;=\\frac23(24.133)-\\frac1{12}(26.533)-\\frac1{12}(23.933)-\\frac13(26.367)+\\frac5{12}(26.233)+\\frac5{12}(24.833)=24.372 \\end{aligned}\\] \\(B\\)  \\[\\begin{aligned}-\\frac13\\hat{\\mu}_{11}&amp;+\\frac5{12}\\hat{\\mu}_{12}+\\frac5{12}\\hat{\\mu}_{15}+\\frac23\\hat{\\mu}_{21}-\\frac1{12}\\hat{\\mu}_{22}-\\frac1{12}\\hat{\\mu}_{23}\\\\&amp;=-\\frac13(24.133)+\\frac5{12}(26.533)+\\frac5{12}(23.933)+\\frac23(26.367)-\\frac1{12}(26.233)-\\frac1{12}(24.833)=26.306\\end{aligned}\\]  29.20: \\(ABA/BAB\\)  Seq Per Trt Person Y ABA 1 A 1 25.1 ABA 2 B 1 27.6 ABA 3 A 1 24.5 ABA 1 A 2 22 ABA 2 B 2 24.3 ABA 3 A 2 21.6 ABA 1 A 3 25.3 ABA 2 B 3 27.7 ABA 3 A 3 25.7 BAB 1 B 4 25.5 BAB 2 A 4 23.7 BAB 3 B 4 24.9 BAB 1 B 5 27.4 BAB 2 A 5 27.9 BAB 3 B 5 24.6 BAB 1 B 6 26.2 BAB 2 A 6 27.1 BAB 3 B 6 25  29.21:  29.20 × SAS  x  29.22: × x \\(A\\)  \\(B\\)  \\[\\hat{\\tau}_A-\\hat{\\tau}_B=24.372-26.306=-1.934\\]  SAS-Mixed / 29.20  \\(ABA\\)  \\(1\\)\\(2\\)  \\(3\\)  \\(O\\)\\(A\\)  \\(B\\).  \\(BAB\\)  \\(O\\)\\(B\\)  \\(A\\).  29.23  SAS  PRIORTRT  29.24  29.20  SAS-Mixed  29.25  29.20  29.29  29.26 \\(\\sigma^2_\\delta=2.1378\\)  \\(\\sigma^2_\\varepsilon=0.7872\\).  29.27  \\(A\\)  \\(B\\)  29.27  Trt  \\(H_{01}:\\tau_A=\\tau_B\\) PRIORTRT  \\(H_{02}:\\lambda_A=\\lambda_B\\).  29.27  PER  \\(1\\)  \\(\\lambda_0\\)  (completely confounding) PER  \\(2\\)  \\(3\\).  PER  \\(H_{03}:P_2=P_3\\).  29.25  CONTRAST  CONTRAST  \\(H_{03}:P_1+\\lambda_0=P_2=P_3\\)  29.27   29.23:  29.20  PRIORTRT  SAS  x  29.24:  PRIORTRT  x  29.25:  29.24  SAS  x  29.26:  x  29.27:  x  29.28 SAS-Mixed  29.22  29.25  ESTIMATE  29.29  \\(\\tau_A-\\tau_B\\)  \\(H_{01}:\\tau_A=\\tau_B\\)  \\(t\\)  ESTIMATE  \\(\\lambda_A-\\lambda_B\\)  \\(H_{02}:\\lambda_A=\\lambda_B\\)  \\(t\\)  29.29  29.27  (29.11)  \\(\\sigma_\\varepsilon^2\\)  \\(\\hat\\sigma_\\varepsilon^2\\)  \\[\\begin{aligned} \\widehat{\\mathrm{Var}}\\left(\\hat{\\mu}_{11}-\\frac12\\hat{\\mu}_{12}-\\frac12\\hat{\\mu}_{13}-\\hat{\\mu}_{21}+\\frac12\\hat{\\mu}_{22}+\\frac12\\hat{\\mu}_{23}\\right)&amp; =\\frac32\\hat\\sigma_\\varepsilon^2\\left(\\frac1{n_1}+\\frac1{n_2}\\right) \\\\ &amp;=\\left(\\frac32\\right)(0.7872)\\left(\\frac13+\\frac13\\right)=0.7872 \\end{aligned}\\]  \\(\\hat \\tau_A-\\hat \\tau_B\\)  \\(0.7872=0.8872\\).  (29.13)  \\(\\sigma_\\varepsilon^2\\)  \\(\\hat\\sigma_\\varepsilon^2\\)  \\(\\hat \\lambda_A-\\hat \\lambda_B\\)  \\(2(n_1+n_2-2)=8\\).  29.28:  x  29.29:  Estimate  x 29.4  / \\(ABC,ACB,BAC,BCA,CAB,CBA\\). Williams (1949) Williams   Williams  \\(ABC,BCA,CAB\\)  Williams \\(A\\)  \\(B\\)  \\(A\\)  \\(C\\). \\(B\\)  \\(C\\)  \\(B\\)  \\(A\\)\\(C\\)  \\(A\\)  \\(C\\)  \\(B\\) Williams  \\(ABC,ACB,BAC,BCA,CAB,CBA\\)  24  \\(A,B,C,D\\)  \\(24\\)  Williams  Williams  \\(ABCD,BDAC,CADB,DCBA\\).  \\(t\\)  \\(t\\)  Williams  \\(t×t\\)  \\(t\\) Williams   29.30 / Williams  29.30  \\[\\begin{align} &amp;(5\\mu_{11}-2\\mu_{12}-3\\mu_{13}+4\\mu_{21}+2\\mu_{22}-6\\mu_{23}-5\\mu_{31}+2\\mu_{32}+3\\mu_{33}-4\\mu_{41}-2\\mu_{41}\\\\&amp;+6\\mu_{43}-\\mu_{51}+4\\mu_{52}-3\\mu_{53}+\\mu_{61}-4\\mu_{62}+3\\mu_{63})/24=\\tau_A-\\tau_B \\tag{29.14} \\end{align}\\]  \\[\\begin{align} &amp;(\\mu_{11}+2\\mu_{12}-3\\mu_{13}+0\\mu_{21}+2\\mu_{22}-2\\mu_{23}-\\mu_{31}-2\\mu_{32}+3\\mu_{33}+0\\mu_{41}-2\\mu_{41}\\\\&amp;+2\\mu_{43}-\\mu_{51}+0\\mu_{52}+\\mu_{53}+\\mu_{61}+0\\mu_{62}-\\mu_{63})/8=\\lambda_A-\\lambda_B \\tag{29.15} \\end{align}\\]  \\(\\tau_A-\\tau_C\\)  \\(\\tau_B-\\tau_C\\)  \\(\\lambda_A-\\lambda_C\\)  \\(\\lambda_B-\\lambda_C\\)   29.30: / x  29.31 / 29.31  SAS O SAS-Mixed  29.33  29.34 \\(\\hat\\sigma^2_\\delta = 3.2278\\)  \\(\\hat\\sigma^2_\\varepsilon = 0.8934\\).  29.31: / x  29.32:  29.31  SAS  x  29.33:  29.31  SAS  x  29.34:  x  29.35  29.35 \\(p &lt; 0.0001\\)\\(p = 0.0306\\) 29.36  29.37  LSMEANS  (not estimable) SAS-Mixed  SAS-Mixed  \\(A\\)  \\[\\mu+\\frac{S_{ABC}+S_{ACB}+S_{BAC}+S_{BCA}+S_{CAB}+S_{CBA}}6+\\frac{P_1+P_2+P_3}3+\\tau_A+\\frac{\\lambda_A+\\lambda_B+\\lambda_C+\\lambda_O}4\\]  \\(P_1\\)  \\(\\lambda_O\\)  \\(P_1\\)  \\(1/3\\) \\(\\lambda_O\\)  \\(1/4\\).  \\(A\\)  \\[\\begin{align} \\mu&amp;+\\frac{S_{ABC}+S_{ACB}+S_{BAC}+S_{BCA}+S_{CAB}+S_{CBA}}6+\\frac{P_1+P_2+P_3}3\\\\&amp;+\\tau_A+\\frac{2\\lambda_A+2\\lambda_B+2\\lambda_C+3\\lambda_O}9 \\tag{29.16} \\end{align}\\] \\(P_1\\)  \\(\\lambda_O\\)  \\(1/3\\).  \\(1\\) \\(\\lambda_A,\\lambda_B,\\lambda_C\\)  \\(2/9\\).  (29.16)  \\(B\\)  \\(C\\)   29.35:  x  29.36:  x  29.37:  x  29.36  29.37  29.37  \\[\\hat{\\tau}_{A}-\\hat{\\tau}_{B}=0.8195,\\hat{\\tau}_{A}-\\hat{\\tau}_{C}=-3.0861,\\mathrm{and}\\,\\hat{\\tau}_{B}-\\hat{\\tau}_{C}=-3.9056\\]  \\(p = 0.0041\\)\\(p &lt; 0.0001\\)  \\(p &lt; 0.0001\\).   29.37  \\[\\hat{\\lambda}_A-\\hat{\\lambda}_B=-0.7706,\\hat{\\lambda}_A-\\hat{\\lambda}_C=0.1842,\\mathrm{~and~}\\hat{\\lambda}_B-\\hat{\\lambda}_C=0.9548\\]  \\(p = 0.0557\\)\\(p = 0.6380\\)  \\(p = 0.0118\\).  \\(A\\)  \\(C\\)  \\(B\\)   29.38  SAS  (29.16)  \\(A\\)  29.38  SAS  29.39.  29.39  \\(C\\)  \\(A\\)  \\(B\\).  29.39  29.37   29.38:  SAS  x  29.39:  29.38  x 29.5  // "],["chap30.html", " 30   30.1  30.2  30.3  30.4  JMP  30.5 ", "  30   All models are wrong, but some are useful. - George E. P. Box  (nesting effects)  5  (hierarchical designs). 30.1   B  A  B  A  30.1.1  30.1  (insecticides). A B  C D  30.1   30.1:  x : X   (live bluegrass plants)  400  33 4   \\[\\begin{equation} y_{ijk}=\\mu+\\gamma_i+\\rho_{j(i)}+\\varepsilon_{ijk},\\quad i=1,2,3,4,\\quad j=2,3,\\mathrm{~or~}4,\\quad k=1,2,3 \\tag{30.1} \\end{equation}\\]  \\(y_{ijk}\\)  i  j  k \\(\\mu\\) \\(\\gamma_i\\)  i \\(\\rho_{j(i)}\\)  i  j \\({\\varepsilon}_{ijk}\\sim i.i.d.N(0,{\\sigma}_\\varepsilon^2)\\)  \\(y_{ijk}\\)  \\(\\sigma^2_\\varepsilon\\)  \\(\\mu,\\gamma_i,\\rho_{j(i)}\\)   30.2 30.2  30.3   30.2:  30.1  x 30.1.2  30.2  5.7  \\[\\begin{equation} y_{ijkm}=\\mu_{ik}+c_{j(i)}+p_{m(ijk)}\\quad i=65,70,75,~j=1,2,\\ldots,9,~k=M,F,~m=1,2 \\tag{30.2} \\end{equation}\\]  \\(\\mu_{ik}\\)  i  k \\(c_{j(i)}\\)  i  j  \\(c_{j(i)}\\thicksim N(0,\\sigma_{\\text{hamber}} ^ 2 )\\)\\(p_{m(ijk)}\\)  i  j  k  m  \\(p_{m(ijk)}\\thicksim N(0,\\sigma_{\\text{Person}} ^ 2 )\\).  \\(c_{j(i)}\\)  \\(p_{m(ijk)}\\)  j  i  j  k  m i  \\(\\mu_{ik},i=65,70,75,k=M,F,\\sigma_{\\text{Chamber&#39;}} ^ 2,\\sigma_{\\text{Person}} ^ 2\\).  30.2  30.3  30.1.3  30.3  18  18  \\[y_{ijk}=\\mu+s_i+c_{j(i)}+a_{k(ij)},\\quad i=1,2,\\ldots,r,j=1,2,\\ldots,t_i,\\quad k=1,2,\\ldots,n_{ij}\\]  \\(\\mu\\) \\(s_i\\thicksim i.i.d.~N(0\\text{,}\\sigma_{\\mathrm{State}}^2),c_{j(i)}\\thicksim i.i.d.~N(0\\text{,}\\sigma_{\\mathrm{City}}^2),a_{k(ij)}\\thicksim i.i.d.~N(0\\text{,}\\sigma_{\\mathrm{Store}}^2)\\)  \\(\\sigma_{\\text{State}}^2,\\sigma_{\\text{City}}^2,\\sigma_{\\text{Store}}^2\\)  \\(\\mu\\).  30.3   30.3:  30.3 / x / 30.2   30.2.1  30.1  (30.1)  \\(\\mu + \\gamma_i + \\rho_{j(i)}\\)  i  \\(\\rho_{j(i)}\\)  \\(\\rho_{1(i)}-\\rho_{2(i)}\\)  i  1  2 \\(\\mu + \\gamma_i + \\bar \\rho_{\\cdot(i)}\\)  \\(\\gamma_1 + \\bar\\rho_{\\cdot(1)} - \\gamma_2 + \\bar\\rho_{\\cdot(2)}\\)  1  2 \\(\\gamma_1 + \\rho_{1(1)} - \\gamma_2 + \\rho_{1(2)}\\)  1  1  2  1  \\[\\begin{aligned} \\widehat{\\rho_{1(i)}-\\rho_{2(i)}}&amp;=\\bar y_{i1\\cdot}-\\bar y_{i2\\cdot}\\\\ \\widehat{\\gamma_1 + \\bar\\rho_{\\cdot(1)} - \\gamma_2 + \\bar\\rho_{\\cdot(2)}}-\\bar y_{i2\\cdot}&amp;=\\bar y_{1\\cdot\\cdot}-\\bar y_{2\\cdot\\cdot}\\\\ \\widehat{\\gamma_1 + \\rho_{1(1)} - \\gamma_2 + \\rho_{1(2)}}&amp;=\\bar y_{11\\cdot}-\\bar y_{21\\cdot} \\end{aligned}\\]  (30.1)  \\[y_{ijk}=\\mu_{j(i)}+\\varepsilon_{ijk},\\quad i=1,2,3,4,\\quad j=2,3,\\mathrm{~or~}4,\\quad k=1,2,3\\]  \\(\\mu_{j(i)}\\)  i  j. \\(\\mu_{j(i)}\\)  \\(\\bar y_{ij\\cdot}\\) \\(\\mu_{j(i)}\\) \\(\\sigma^2_\\varepsilon\\)  j(i)  \\[\\hat{\\sigma}_\\varepsilon^2=\\frac1{N-q}\\sum_{i=1}^m\\sum_{j=1}^{p_i}\\sum_{k=1}^{n_{j(i)}}(y_{ijk}-\\bar{y}_{ij\\cdot})^2\\]  \\(n_{j(i)}\\)  j(i) q  \\(n_{j(i)}&gt;0\\) m \\(p_i\\)  i \\(n_{j(i)}\\)  i  j \\(N=\\sum_{j(i)}n_{j(i)}\\)   \\[\\begin{aligned}{\\hat{\\sigma}}_\\varepsilon^2=\\frac{1}{33-11}\\sum_{i=1}^4\\sum_{j=1}^{p_i}\\sum_{k=1}^3(y_{ijk}-\\bar{y}_{ij\\cdot})^2=60.818\\end{aligned}\\]  30.4.  30.4:  30.1  x \\(\\mu_{j(i)}\\)  \\(\\mu_{j(i)}\\)  B  D \\[\\bar{\\mu}_{\\cdot(2)}=\\bar{\\mu}_{\\cdot(4)}\\quad\\mathrm{~where~}\\bar{\\mu}_{\\cdot(2)}=\\frac{\\mu_{1(2)}+\\mu_{2(2)}}2\\quad\\mathrm{and~}\\quad\\bar{\\mu}_{\\cdot(4)}=\\frac{\\mu_{1(4)}+\\mu_{2(4)}+\\mu_{3(4)}+\\mu_{4(4)}}4\\]  B  D  30.3   j(i)  \\(\\mu_{j(i)}\\)  \\(\\hat\\mu_{j(i)}\\)  \\(\\hat\\sigma^2_\\varepsilon\\)  30.2.2  30.2  30.5  30.6  REML  MINQUE0  \\(\\hat{{\\sigma}}_{\\mathrm{Person}}^2=1.65,\\hat{{\\sigma}}_{\\mathrm{Chamber}}^2=2.36\\)ML  \\(\\hat{{\\sigma}}_{\\mathrm{Person}}^2=1.47,\\hat{{\\sigma}}_{\\mathrm{Chamber}}^2=1.48\\) 24  \\(mu_{ij}\\) REML   30.5:  30.2  1 = 8 = 15 =  x  30.6:  30.2  x 30.2.3  30.3  \\(\\mu,\\sigma_{\\text{State}}^2,\\sigma_{\\text{City}}^2,\\sigma_{\\text{Store}}^2\\). ML  MINQUE0  I  REML  30.7  I  30.8  30.3  I  30.9  I , REML, MIVQUE0  ML  95% Wald  \\(2(Z\\text{-value})^2\\)  30.10   30.7:  30.2 I  x  30.8:  I  x  30.9:  x  30.10:  x 30.3   REML  Satterthwaite  \\(2(Z\\text{-value})^2\\).  1 REML ML  MINQUE0  30.9  30.8  \\(H_0\\colon{\\sigma}_\\mathrm{State}^2=0\\mathrm{vs~}H_a\\colon{\\sigma}_\\mathrm{State}^2&gt;0\\)  \\(H_0{:{\\sigma_{\\mathrm{City}}^2}}=0\\operatorname{vs}H_a{:{\\sigma_{\\mathrm{City}}^2}}&gt;0\\) 2.40  11.58  F   30.1  30.3.1  30.1  \\[\\begin{equation} y_{ijk}=\\mu_{j(i)}+\\varepsilon_{ijk}\\quad i=1,2,3,4,\\quad j=2,3,\\mathrm{~or~}4,\\quad k=1,2,3 \\tag{30.3} \\end{equation}\\]  \\[\\begin{equation} y_{ijk}=\\mu+\\gamma_i+\\rho_{j(i)}+\\varepsilon_{ijk}\\quad i=1,2,3,4,\\quad j=2,3,\\mathrm{~or~}4,\\quad k=1,2,3 \\tag{30.4} \\end{equation}\\]  30.11  (30.3)  \\[\\mu_{1(1)}=\\mu_{2(1)}=\\mu_{3(1)}=\\mu_{1(2)}=\\mu_{2(2)}=\\mu_{1(3)}=\\mu_{2(3)}=\\mu_{1(4)}=\\mu_{2(4)}=\\mu_{3(4)}=\\mu_{4(4)}\\]  30.11:  30.1  (30.3)  x  30.12  (30.4)  30.11  \\(\\bar{\\mu}_{\\cdot(1)}=\\bar{\\mu}_{\\cdot(2)}=\\bar{\\mu}_{\\cdot(3)}=\\bar{\\mu}_{\\cdot(4)}\\) \\[\\bar{{\\mu}}_{{\\cdot}(i)}=(1/m_i)\\sum_{j=1}^{m_i}{\\mu}_{j(i)}={\\mu}+\\gamma_i+{\\bar{\\rho}}_{{\\cdot}(i)}\\]  30.12:  30.1  (30.4)  x  \\[\\mu_{1(1)}=\\mu_{2(1)}=\\mu_{3(1)},\\quad\\mu_{1(2)}=\\mu_{2(2)}=\\mu_{1(3)}=\\mu_{2(3)},\\quad\\mathrm{and}\\quad\\mu_{1(4)}=\\mu_{2(4)}=\\mu_{3(4)}=\\mu_{4(4)}\\]  \\[\\rho_{1(1)}=\\rho_{2(1)}=\\rho_{3(1)},\\quad\\rho_{1(2)}=\\rho_{2(2)}=\\rho_{1(3)}=\\rho_{2(3)},\\quad\\mathrm{and}\\quad\\rho_{1(4)}=\\rho_{2(4)}=\\rho_{3(4)}=\\rho_{4(4)}\\]  3 1 \\(\\bar{{\\mu}}_{\\cdot (i)}\\)2 \\(\\bar{{\\mu}}_{j (i)}\\)3 i  \\(\\bar{{\\mu}}_{j (i)}\\) 4III  IV  \\(\\bar{{\\mu}}_{\\cdot (i)}\\)  \\(\\bar{{\\mu}}_{j (i)}\\)   \\(F\\)   III   22  23  30.4  JMP  JMP®  30.2  30.3  30.1  chamber, temperature, gender  person  30.2  fit model  temperature, gender, temperature × gender chamber(temperature) person  30.3  REML  Wald  III Tukey  30.4  30.5  30.3  30.6  fit model  state  city(state) store  30.7  state  city(state)  Wald  store  3.359 REML  SAS®-Mixed  3.2935 30.10  30.1:  30.2  JMP   30.2:  30.2  JMP fit model   30.3:  30.2  JMP AOV   30.4:  30.2  Tukey   30.5:  30.3  JMP   30.6:  30.3 JMP fit model   30.7:  30.3 JMP  REML  30.5   "],["References.html", "References", " References Akaike, H. (1974). A new look at the statistical model identifi cation. IEEE Trans. Autom. Control, AC-19, 716723. Anderson, V. L. and McLean, R. A. (1974). Design of Experiments: A Realistic Approach. Marcel Dekker, New York, NY. Bancroft, T. A. (1968). Topics in Intermediate Statistical Methods, Vol. I. The Iowa State University Press, Ames, IA. Bartlett, M. S. (1937). Properties of suffi ciency and statistical tests. Proc. R. Soc., Ser. A, 160, 268282. Benjamini, Y. and Hochberg, Y. (1995). Controlling the false discovery rate: A practical and powerful approach to multiple testing. J. Roy. Stat. Soc. B., Methodological, 57, 289300. Beyer, W. H., ed. (1966). Handbook of Tables of Probability and Statistics. The Chemical Rubber Co., Cleveland, OH. Beyer, W. H. (1968). CRC Handbook of Tables for Probability and Statistics. The Chemical Rubber Co., Cleveland, OH. Boardman, T. J. (1974). Confi dence intervals for variance componentsA comparative Monte Carlo study. Biometrics, 30, 251262. Box, G. E. P. (1954). Some theorems on quadratic forms applied in the study of analysis of variance problems. Ann. Math. Stat., 25, 290302. Box, G. E. P., Hunter, W. G., and Hunter, J. S. (1978). Statistics for Experimenters. John Wiley and Sons, New York, NY. Brown, K. G. (1976). Asymptotic behavior of MINQUE-type estimators of variance components. Ann. Stat., 4, 746754. Brown, W. A. and Forsythe, A. B. (1974). Robust tests for equality of variances. J. Am. Stat. Assoc., 69, 364367. Burdick, R. K. and Graybill, F. A. (1992). Confi dence Intervals on Variance Components. Marcel Dekker, New York, NY. Cobb, G. W. (1997). Introduction to Design and Analysis of Experiments. Springer, New York, NY. Cochran, W. G., and Cox, G. M. 1957. Experimental Design. 2nd ed. John Wiley and Sons, New York, NY. Conover, W. J., Jounson, M. E., and Johnson, M. M. (1981). A comparative study of tests for homogeneity of variances, with applications to the outer continental shelf bidding data. Technometrics, 23, 351361. Corbeil, R. R. and Searle, S. R. (1976). A comparison of variance component estimators. Biometrics, 32, 779791. Cornell, J. A. (1990). Experiments with Mixtures: Designs, Models and Analysis of Mixture Data. John Wiley and Sons, New York, NY. Davies, O. L. 1954. Design and Analysis of Industrial Experiments. Oliver and Boyd, London, UK. Edwards, D. and Berry, J. J. (1987). The effi ciency of simulation-based multiple comparisons. Biometrics, 43, 913928. Eisenhert, C. (1947). Assumptions underlying analysis of variance. Biometrics, 3, 122. Fai, A. H. T. and Cornelius, P. L. (1996). Approximate F-tests of multiple degree of freedom hypotheses in generalized least squares analyses of unbalanced split-plot experiments. J. Stat. Comput. Simul., 54, 363378. Federer, W. T. (1995). Experimental Design. Macmillan, New York, NY. Fisher, R. A. (1949). The Design and Analysis of Experiments. Oliver and Boyd, Edinburgh, UK. Giesbrecht, F. G. and Burns, J. C. (1985). Two-stage analysis based on a mixed model: Large-sample asymptotic theory and small-samples simulation results. Biometrics, 41, 477486. Graybill, F. A. (1976). Theory and Application of the Linear Model. North Scituate, MA. Graybill, F. A. and Wang, C. M. (1980). Confi dence intervals on nonnegative linear combinations of variances. J. Am. Stat. Assoc., 75, 869873. Greenhouse, S. W., and Geisser, S. (1959). On methods in the analysis of profi le data. Psychometrika, 24, 95112. Grizzle, J. E. (1965). The two-period change-over design and its use in clinical trials. Biometrics, 21, 46780 Hartley, H. O. (1950). The maximum F-ratio as a short-cut test for heterogenity of variances. Biometrika, 37, 308312. Hartley, H. O. (1967). Expectations, variances and covariances of ANOVA mean squares by synthesis. Biometrics, 23, 105114. Hartley, H. O. and Rao, J. N. K. (1967). Maximum likelihood estimation for the mixed analysis of variance model. Biometrika, 54, 93108. Hayter, A. J. (1984). A proof of the conjecture that the TukeyKramer method is conservative. Ann. Stat., 12, 6175. Hemmerle, W. J. and Hartley, H. O. (1973). Computing maximum likelihood estimates for the mixed A.O.V. model using the W transformation. Technometrics, 15, 819831. Henderson, C. R. (1984). ANOVA, MIVQUE, REML, and ML algorithms for estimation of variances and covariances. Statistics: An Appraisal, pp. 257280. David, H. A. and David, H. T. (eds.), Iowa State University, Ames, IA. Henderson, C. R. (1984). Applications of Linear Models in Animal Breeding. University of Guelph, Ontario, Canada. Hicks, Charles R. (1993). Fundamental Concepts in the Design of Experiments, 4th ed. W.B. Saunders Co., Philadelphia, PA. Holland, B. S. and Copenhaver, M. D. (1987). An improved sequentially rejective Bonferroni test procedure. Biometrics, 43, 417424. Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scand. J. Stat., 6, 6570. Hurvich, Clifford M. and Tsai, C.-L. (1989). Regression and time series model selection in small samples. Biometrika, 76, 297307. Huynh, H., and Feldt, L. S. (1970). Conditions under which mean square rations in repeated measures designs have exace F-distributions. J. Am. Stat. Assoc., 65, 15821589. John, P. W. M. (1971). Statistical Design and Analysis of Experiments. John Wiley and Sons, New York, NY. Johnson, D. E. (1976). Some new multiple comparison procedures for the two-way AOV model with interaction. Biometrics, 32, 929934. Johnson, D. E. and Graybill, F. A. (1972). An analysis of a two-way model with interaction and no replication. J. Am. Stat. Assoc., 67, 862868. Kackar, A. N. and Harville, D. A. (1984). Approximations for standard errors of estimators of fi xed and random effects in mixed linear models. J. Am. Stat. Assoc., 86, 557568. Kempthorne, O. (1952). Design and Analysis of Experiments. John Wiley and Sons, New York, NY. Kendall, M. G. and Stuart, A. (1952). The Advanced Theory of Statistics, Vol. 1. Hafner, New York, NY. Kendall, M. G. and Stuart, A. (1973). The Advanced Theory of Statistics, Vol. 2, 3rd ed. Griffi n, London, UK. Kenward, M. G. and Roger, J. H. (1997). Small sample inference for fi xed effects from restricted maximum likelihood. Biometrics, 53, 983997. Kirk, R. E. (1968). Experimental Design: Procedures for the Behavioral Sciences. Brooks/Cole, Belmont, CA. Kramer, C. Y. (1956). Extension of multiple range tests to group means with unequal numbers of replications. Biometrics, 12, 307310. Laundsby, R. G. and Weese, D. L. (1993). Straight Talk on Designing Experiments: An Introductory Design of Experiments Reference Handbook. Launsby Consulting, Colorado Springs, CO. Lehmann, E. L. (1986). Testing Statistical Hypotheses. John Wiley and Sons, New York, NY. Lentner, M. and Bishop, T. (1986). Experimental Design and Analysis. Valley Book Company, Blacksburg, VA. Levene, H. (1960). Robust tests for the equality of variances. In Contributions to Probability and Statistics, pp. 278292. I. Olkin, S. G. Ghurye, W. Hoeffding, W. G. Madow, and H. B. Mann (eds.). Stanford University Press, Palo Alto, CA. Littell, R., Milliken, G. A., Stroup, W., Wolfi nger, R., and Schabenberger, O. (2006). SAS for Mixed Models, 2nd edn. SAS Institute, Inc., Cary, NC. Lu, T.-F. C., Graybill, F. A., and Burdick, R. K. (1989). Confi dence intervals on the ratio of expected (q1 - dq2)/q3. J. Stat. Plan. Infer., 21, 179190. McGaughey, K. B. (2003). Tests of scale parameters using data depth. Ph.D. dissertation. Department of Statistics, Kansas State University, Manhattan, KS. McLean, R. A. and Sanders, W. L. (1988). Approximating degress of freedom for standard errors in mixed linear models. ASA Proceedings of the Statistical Computing Section, 5059. American Statistical Association, Alexandria, VA. Meed, R. (1988). The Design of Experiments: Statistical Principles for Practical Application. Cambridge University Press, Cambridge, UK. Miller, R. G. (1967). Simultaneous Statistical Inference. McGraw-Hill Inc., New York, NY. Miller, R. G., Jr. (1981). Simultaneous Statistical Inference. Springer, New York, NY. Milliken, G. A. (2003). Mixed models and repeated measures: Some illustrative industrial examples. Handbook of Statistics 22: Statistics in Industry, pp. 171207. Elsevier Science Publishing, New York, NY; North-Holland Publishing Co., Amsterdam. Milliken, G. A. (2003a). Mixed models and repeated measures: some illustrative industrial examples. In Handbook of Statistics Vol. 22: Statistics in Industry, Khattree, R. and Rao, C. R., eds. Elsevier Science Publishing, Amsterdam/NY. Milliken, G. A. (2003b). Multi-Level Models and Their Analyses. Proceeding of the 28th SUGI Conference, Seattle, WA. SAS Institute Inc., Cary, NC. Milliken, G. A, and Graybill, F. A. (1970). Extensions of the general linear hypothesis model. J. Am. Stat. Assoc., 65, 797807. Milliken, G. A. and Johnson, D. E. (1989). Analysis of Messy Data, Vol. 2: Nonreplicated Experiments. Chapman &amp; Hall/CRC Press, Boca Raton, FL. Milliken, G. A. and Johnson, D. E. (1992). Analysis of Messy Data, Volume 1: Designed Experiments. Chapman &amp; Hall/CRC Press, Boca Raton, FL. Milliken, G. A. and Johnson, D. E. (2002). Analysis of Messy Data, Vol 3: Analysis of Covariance. Chapman and Hall/CRC, Boca Raton, FL. Milliken, G. A., Shi, X., Mendicino, M., and Vasudev, P. K. (1998). Strip-plot design for two-step processes. Qual. Reliab. Enging. Int., 14, 115. Montgomery, D. C. (1991). Design and Analysis of Experiments, 3rd edn. John Wiley and Sons, New York, NY. Montgomery, D. C. and Runger, G. C. (19931994). Gauge capability and designed experiments. Part II: Experimental design models and variance component estimation. Quality Engineering, 6, 289305. Morrison, D. F. (1976). Multivariate Statistical Methods. McGraw-Hill, New York, NY. Njuho, P. M. and Milliken, G. A. (2005). Analysis of linear models with one factor having both fixed and random levels. Commun. Stat. Theory Meth., 34, 19791999. Olejnik, S. F. and Algina, J. (1987). Type I error rates and poser estimates of selected parametric and nonparametric tests of scale. J. Educ. Stat., 12, 4561. OBrien, R. G. (1979). A general ANOVA method for robust tests of additive models for variances. J. Am. Stat. Assoc, 74, 877880. Ott, L. (1988). An Introduction to Statistical Methods and Data Analysis, 3rd ed. PWS-Kent Publishng Co., Boston, MA. Rao, C. R. (1971). Minimum variance quadratic unbiased estimation of variance components. J. Multivariate Anal., 1, 445456. SAS Institute, Inc. (1999). SAS/STAT Users Guide, Version 8. SAS Institute, Inc., Cary, NC. SAS Institute, Inc. (2005) JMP Introductory Guide, Release 6. SAS Institute, Inc., Cary, NC. Satterthwaite, F. E. (1946). An approximate distribution of estimates of variance components. Biometrics Bulletin 2, 110114. Schwarz, Gideon. (1978). Estimating the dimension of a model. Ann. Stat., 6, 461464. Searle, S. R. (1971). Linear Models. John Wiley and Sons, New York, NY. Searle, S. R. (1987). Linear Models for Unbalanced Data. John Wiley and Sons, New York, NY. Searle, S. R., Cassella, G. and McCulloch, C. E. (1992). Variance Components. John Wiley and Sons, New York, NY. Searle, S. R., Speed, F. M. and Milliken, G. A. (1980). Population marginal means in the linear model: An alternative to least squares means. Am. Stat., 34, 216221. idák, Z. (1967). Rectangular confi dence regions for the means of multivariate normal distributions. J. Am. Stat. Assoc., 62, 626633. St John, R. C. and Draper, N. R. (1975). D-Optimality for regression designs: A review. Technometrics, 17, 15. Swallow, W. H. and Monahan, J. F. (1984). Monte Carlo Comparison of ANOVA, MIVQUE, REML, and ML estimators of variance components. Technometrics, 26, 4757. Swallow, W. H. and Searles, S. R. (1978). Minimum variance quadratic unbiased estimation (MIVQUE) of variance components. Technometrics, 20, 265272. Ting, N., Burdick, R. K., Graybill, F. A., Jeyaratnam, S. and Lu, T.-F. C. (1990). Confi dence intervals on linear combinations of variance components that are unrestricted in sign. J. Stat. Comput. Simul., 35, 135143. Tukey, J. W. (1952). Allowances for various types of error rates. Unpublished IMS address, Chicago, IL. Tukey, J. W. (1953). The problem of multiple comparisons. Unpublished manuscript. Westfall, P. H. (2002). From Farms to Pharmaceuticals: Multiple Comparisons Enter the 21st Century. Proceedings of the 13th Annual Kansas State University Conference on Applied Statistics in Agriculture, G. A. Milliken, ed. Department of Statistics, Kansas State University, Manhattan, KS. Westfall, P. H., Tobias, R. D., Rom, D., Wolfi nger, R. D., and Hochberg, Y. (1999). Multiple Comparisons and Multiple Tests Using the SAS System. SAS Institute, Inc., Cary, NC. Williams, E. J. (1949). Experimental designs balanced for the estimation of residual effects of treatments. Aust. J. Sci. Res., Ser. A 2, 149168. Williams, J. S. (1962). A confi dence interval for variance components. Biometrika, 49, 278281. Winer, B. J. (1971). Statistical Principles in Experimental Design, 2nd ed. McGraw-Hill, New York, NY. Welch, B. L. (1951). On the comparison of several mean values: An alternative approach. Biometrika, 38, 330336. "]]
